<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Soapdenovo2</title>
    <url>/blog/2022/02/24/2022-02-25-soapdenovo2/</url>
    <content><![CDATA[<h1 id="soapdenovo2"><a href="#soapdenovo2" class="headerlink" title="soapdenovo2:"></a>soapdenovo2:</h1><span id="more"></span>

<p>SOAPdenovo使用说明，内容包括程序<font color="green"><strong>使用</strong></font>、<font color="green"><strong>参数说明</strong></font>、<font color="green"><strong>参数调整</strong></font>、主要<font color="green"><strong>输出文件</strong></font>的格式说明等。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/1.png" alt="img"></p>
<h1 id="contiging"><a href="#contiging" class="headerlink" title="contiging"></a>contiging</h1><p><em><strong>a.</strong></em>  基因组DNA随机打断，使用paired-end测序。长度在150-500bp的short clones扩增直接测序。在2-10kb的长paired-end libraries 通过DNA环化、fragmentation破碎，然后净化400-600bp的碎片为了cluster 结构。</p>
<p><em><strong>b.</strong></em>  raw reads 或预修正reads被存储，de Bruijn graph data structure 被用于表示reads间overlap。</p>
<p>Kmer-graph构建：所有reads被切割成某一固定Kmer长度的序列（21bp=&lt;kmer&lt;=127bp），形成等长的Kmers。将Kmers连成图。<font color="green"><strong>相邻的kmers是通过K-1 overlaping连接</strong></font>，所以它不需要成对序列比对（The neighboring kmers are K-1 overlaping which generated from read sequences, so it doesn’t need pair-wise reads alignment.）。重复序列在图中被压缩。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/2.png" alt="img"></p>
<p><em><strong>c.</strong></em>  产生<font color="red"><strong>tips翼尖、bubbles气泡、low coverage links低覆盖率链接、tiny repeat微小重复</strong></font>等问题。</p>
<p><font color="blue"><strong>tips翼尖（a）</strong></font>和<font color="blue"><strong>bubbles气泡（c）</strong></font>：由于<strong>测序错误</strong>或<strong>杂合</strong>或<strong>高重复序列</strong>相似性，将会导致翼尖和气泡出现。</p>
<p><font color="blue"><strong>low coverage links低覆盖率链接：（b）（d）</strong></font>。</p>
<p><font color="blue"><strong>tiny repeat微小重复(e)</strong></font>：重复在graph中被压缩，并作为不同路径的共享边缘，但是能够通过reads 穿过来解决。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/3.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/4.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/5.png" alt="img"></p>
<p>移除错误链接和graph simplification图形简化，得到contigs or contig  graphs：tips翼尖移除；删除低覆盖链接；bubbles合并气泡；解决微小重复；</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/6.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/7.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/8.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/9.png" alt="img"></p>
<p> <em><strong>d.</strong></em>  contig  graphs,在重复的节点处剪断?，输出contigs</p>
<h1 id="scaffolding"><a href="#scaffolding" class="headerlink" title="scaffolding"></a>scaffolding</h1><p><em><strong>e.</strong></em>  重新用reads和contigs进行比对，使用<font color="red"><strong>paired-end信息</strong></font>把单一的contigs连接成scaffolds。reads 比对到contigs上，临近的contig建立连接；repeat将会引来冲突矛盾信息；<font color="red"><strong>在组装成scaffold时，repeat contigs将会被屏蔽</strong></font>；paired-end信息的不同插入片段被用来一步步从短到长的建立scaffold graph(Scaffolding iteratively from short to long insert PEs./Various insert size of paired-end information is used to build contig graph step by step from short to long)。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/10.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/11.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/12.png" alt="img"></p>
<h1 id="Gap-Filling"><a href="#Gap-Filling" class="headerlink" title="Gap Filling:"></a>Gap Filling:</h1><p><em><strong>f.</strong></em>  使用paired-end reads来填补scaffolds内部可能是由重复序列所造成的Gap。contig N50 通常比较小（&lt;3KB）,但是，gap filling之后能够显著提高N50值（i.e.,&gt;20KB）;Most of the gaps are repeat relative sequences.;Reads locate at gaps can collected by their paired-end which uniquely map to the contig.</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/13.png" alt="img"></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>SOAPdenovo（目前最新版是SOAPdenovo2）是利用一种新的组装短read的方法，它以kerm为节点单位，利用<font color="green"><strong>de Bruijn图</strong></font>的方法实现全基因组的组装，和其他短序列组装软件相比，它可以进行大型基因组比如人类基因组的组装，组装结果更加准确可靠，可以通过组装的结果非常准确地鉴别出基因组上的序列结构性变异，为构建全基因组参考序列和以低测序成本对未知基因组实施精确分析创造了可能。</p>
<p>SOAPdenovo aims for large plant and animal genomes, although it also works well on bacteria and fungi genomes. It runs on 64-bit Linux system with a minimum of 5G physical memory. For <strong>big genomes</strong> like human, about <strong>150 GB memory</strong> would be required.</p>
<p>程序的下载及安装：<br>下载地址：<a href="http://soap.genomics.org.cn/soapdenovo.html">http://soap.genomics.org.cn/soapdenovo.html</a><br>安装：<br>(a) 下载SOAPdenovo的压缩包   </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/aquaskyline/SOAPdenovo2.git</span><br><span class="line"><span class="built_in">cd</span> SOAPdenovo2</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>(b) 解压缩<br>(c)将得到可执行文件SOAPdenovo和一个配置文件的模板example.contig</p>
<p><strong>3个可执行文件</strong></p>
<ol>
<li><font color="green"><strong>SOAPdenovo-63mer</strong></font></li>
<li><font color="green"><strong>SOAPdenovo-127mer</strong></font></li>
<li><font color="green"><strong>SOAPdenovo-fusion</strong></font></li>
</ol>
<p>第一个支持最大k-mer为63，第二个最大kmer为127，第三个文件用于单细胞测序和宏基因组测序数据。</p>
<h1 id="使用程序及参数"><a href="#使用程序及参数" class="headerlink" title="使用程序及参数"></a>使用程序及参数</h1><p>SOAPdenovo可以一步跑完，也可以分成四步单独跑<br><font color="green"><strong>一步跑完脚本:</strong></font><br>./ SOAPdenovo <font color="red"><strong>all</strong></font> <strong>-s</strong> lib.cfg <strong>-K</strong> 29 <strong>-D</strong> 1 <strong>-o</strong> ant &gt;&gt;ass.log<br><font color="green"><strong>四步单独跑的脚本</strong></font><br>./ SOAPdenovo <font color="red"><strong>pregraph</strong></font> <strong>-s</strong> lib.cfg <strong>-d</strong> 1  <strong>-K</strong> 29 <strong>-o</strong> ant &gt;pregraph.log<br>./ SOAPdenovo <font color="red"><strong>contig</strong></font> <strong>-g</strong> ant <strong>-D</strong> 1 <strong>-M</strong> 3 &gt;contig.log<br>./ SOAPdenovo <font color="red"><strong>map</strong></font> <strong>-s</strong> lib23.cfg <strong>-g</strong> ant &gt;map.log<br>./ SOAPdenovo <font color="red"><strong>scaff</strong></font> <strong>-g</strong> ant <strong>-F</strong> &gt;scaff.log</p>
<h1 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h1><p>用法：/PathToProgram/SOAPdenovo all -s configFile [-K kmer -d KmerFreqCutOff -D EdgeCovCutoff -M mergeLevel -R -u -G gapLenDiff -L minContigLen -p n_cpu] -o Output</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-s    STR     配置文件√</span><br><span class="line">-o    STR     图形输出的文件名前缀 √</span><br><span class="line">-g    STR     输入文件的文件名前缀</span><br><span class="line">-K    INT     输入的K-mer值大小，默认值23，取值范围 13-63 √</span><br><span class="line">-p    INT     程序运行时设定的cpu线程数，默认值8</span><br><span class="line">-R            <span class="string">&quot;利用read鉴别短的重复序列，默认值不进行此操作&quot;</span> √</span><br><span class="line">-d    INT     去除频数不大于该值的k-mer，默认值为0;<span class="string">&quot;最小化错误测序带来的影响&quot;</span> √</span><br><span class="line">-D    INT     去除频数不大于该值的由k-mer连接的边，默认值为1，即该边上每个点的频数都小于等于1时才去除,最小化错误测序带来的影响 ?</span><br><span class="line">-M    INT     连接contig时合并相似序列的等级(强度)，默认值为1，最大值3。</span><br><span class="line">-F            利用<span class="built_in">read</span>对scaffold中的gap进行填补，默认不执行</span><br><span class="line">-u            构建scaffold前不屏蔽高覆盖度的contig，这里高频率覆盖度指平均contig覆盖深度的2倍。默认屏蔽</span><br><span class="line">-G    INT     估计gap的大小和实际补gap的大小的差异，默认值为50bp。</span><br><span class="line">-L            用于构建scaffold的contig的最短长度，默认为：Kmer参数值 ×2</span><br></pre></td></tr></table></figure>

<p><font color="blue"><strong>全局配置</strong></font></p>
<p><code>max_rd_len</code></p>
<p><font color="blue"><strong>文库配置</strong></font></p>
<p>每个文库的配置以<code>[LIB]</code>开头，主要指定输入文件的路径，支持多种格式的输入文件，用不同的前缀表示， <code>q</code>代表输入序列为fastq格式；<code>f</code>代笔输入序列为fasta格式，<code>b</code>代表输入文件为bam格式，对于双端数据，分别用后缀<code>1</code>和<code>2</code>表示R1端和R2端的reads。</p>
<p><font color="blue"><strong>主要参数</strong></font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-avg_ins    This value indicates the average insert size of this library or the peak value position <span class="keyword">in</span> the <span class="string">&quot;insert size distribution figure?&quot;</span>. <span class="comment">#文库平均插入长度(或取插入大小分布图中的峰值位置)，根据建库情况设置。 </span></span><br><span class="line"></span><br><span class="line">-reverse_seq    This option takes value 0 or 1. It tells the assembler <span class="keyword">if</span> the <span class="built_in">read</span> sequences need to be complementarily reversed. Illumima GA produces two types of paired-end libraries: a) <span class="string">&quot;forward-reverse&quot;</span>, generated from fragmented DNA ends with typical <span class="string">&quot;insert size less than 500 bp&quot;</span>; b) <span class="string">&quot;reverse-forward&quot;</span>, generated from <span class="string">&quot;circularizing libraries&quot;</span> with typical <span class="string">&quot;insert size greater than 2 Kb&quot;</span>. The parameter <span class="string">&quot;reverse_seq&quot;</span> should be <span class="built_in">set</span> to indicate this: 0, forward-reverse; 1, reverse-forward. </span><br><span class="line"></span><br><span class="line">-asm_flags    This indicator decides <span class="keyword">in</span> <span class="built_in">which</span> part(s) the reads are used. It takes value 1(only contig assembly), 2 (only scaffold assembly), <span class="string">&quot;3(both contig and scaffold assembly)&quot;</span><span class="string">&quot;, or 4 (only gap closure). </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-rd_len_cutof    The assembler will &quot;</span>cut the reads from the current library to this length<span class="string">&quot;.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-rank    It takes integer values and decides in which &quot;</span>order the reads are used <span class="keyword">for</span> scaffold assembly<span class="string">&quot;. Libraries with the same &quot;</span>rank<span class="string">&quot; are used at the same time during scaffold assembly.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-pair_num_cutoff    This parameter is the cutoff value of pair number for a &quot;</span>reliable connection<span class="string">&quot; between two contigs or pre-scaffolds. The minimum number for &quot;</span>paired-end reads and mate-pair reads is 3 and 5 respectively<span class="string">&quot;. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-map_len    This takes effect in the &quot;</span>map<span class="string">&quot; step and is the minimun alignment length between a read and a contig required for a reliable read location. The minimum length for &quot;</span>paired-end reads and mate-pair reads is 32 and 35 respectively<span class="string">&quot;.</span></span><br></pre></td></tr></table></figure>

<p><font color="blue"><strong>实例</strong></font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">max_rd_len=100</span><br><span class="line">[LIB]</span><br><span class="line"><span class="comment">#avg_ins 文库插入片段的平均长度，在实际设置时，可以参考文库size分布图，取峰值即可???</span></span><br><span class="line">avg_ins=200</span><br><span class="line"><span class="comment">#reverse_seq 是否需要将序列反向互补，pair-end数据，不需反向互补，设置为0；mate-pair需要设置为1</span></span><br><span class="line">reverse_seq=0</span><br><span class="line"><span class="comment">#asm_flags 1只组装contig. 2只组装scaffold,3同时组装contig和scaffold,4只补gap</span></span><br><span class="line">asm_flags=3</span><br><span class="line"><span class="comment">#序列长度阈值，作用和max_rd_len相同，大于该长度的序列会被切除到该长度</span></span><br><span class="line">rd_len_cutoff=100</span><br><span class="line"><span class="comment">#设置不同文库数据的优先级顺序，取值范围为整数，rank值相同的多个文库，在组装scaffold时，会同时使用。</span></span><br><span class="line">rank=1</span><br><span class="line">q1=fastq1_read_1.fq</span><br><span class="line">q2=fastq1_read_2.fq</span><br><span class="line">-pair_num_cutoff</span><br><span class="line"><span class="comment">#contig或者scaffold之前的最小overlap个数，pair-end数据默认为3；mate-paird数据默认为5</span></span><br><span class="line">-map_len</span><br><span class="line"><span class="comment">#比对长度的最小阈值，pair-end数据默认为32；mate-pair数据默认为35</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">SOAPdenovo-63mer all -s config_file -K 63 -R -o graph_prefix</span><br></pre></td></tr></table></figure>



<h1 id="使用方法及示例"><a href="#使用方法及示例" class="headerlink" title="使用方法及示例"></a>使用方法及示例</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#（1）示例</span></span><br><span class="line">SOAPdenovo all -s HCB.lib -K 25 -d -o <span class="built_in">test</span></span><br><span class="line"><span class="comment">#（2）配置文件 configFile</span></span><br><span class="line"><span class="comment">#maximal read length （read的最大长度），该值【一般设置的比实际read读长稍微短一些？】，截去测序最后的部分，具体长度看测序质量</span></span><br><span class="line">max_rd_len=50    </span><br><span class="line"></span><br><span class="line"><span class="comment">#[LIB]文库信息以此开头</span></span><br><span class="line"></span><br><span class="line">avg_ins=200<span class="comment">#?</span></span><br><span class="line"></span><br><span class="line">reverse_seq=0</span><br><span class="line"><span class="comment">#序列是否需反转，目前测序技术，插入片段大于等于2k的采用了环化，对于插入长度大于等于2k文库，序列需要反转，reverse_seq＝1，小片段设为0</span></span><br><span class="line"></span><br><span class="line">asm_flags=3</span><br><span class="line"><span class="comment">#该文库中的read序列在组装的哪些过程（contig/scaff/fill）中用到</span></span><br><span class="line"><span class="comment">#短插入片段(&lt;2K)的设为3，同时构建contig和scaffold，长插入片段(&gt;=2k)设为2，不构建contig，只构建scaffold，454single 长reads只用于补洞。</span></span><br><span class="line"></span><br><span class="line">rank=1</span><br><span class="line"><span class="comment">#该值取整数，决定了reads用于构建scaffold的次序，值越低数据越优先用于构建scaffold。【相同rank的文库数据会同时用于组装scaffold】。一般将短插入片段设为1；2k设为2；5k设为3；10k设为4；当【某个档的数据量较大】时可以将其分为多个档，同样当【某档数据量不足够】时，可以将多个档的数据合在一起构建scaffold?。这里说的数据量够与不够是从该档的测序覆盖度和物理覆盖度两个方面考虑。</span></span><br><span class="line"></span><br><span class="line">pair_num_cutoff=3</span><br><span class="line"><span class="comment">#【可选参数】，该参数规定连接两个contig 或者是pre-scaffold 的可信连接的阈值，当连接数大于该值，连接才算有效。短插入片段(&lt;2k)默认值为3，长插入长度序列默认值为5</span></span><br><span class="line"></span><br><span class="line">map_len=32</span><br><span class="line"><span class="comment">#map_len该参数规定在map过程中 reads和contig的比对长度必须达到该值（比对不容mismacth和gap），该比对才能作为一个可信的比对。可选参数，短插入片段(&lt;2k)一般设置为32，长插入片段设置为35，默认值是K＋2。</span></span><br><span class="line"></span><br><span class="line">q1=/path/LIBNAMEA/fastq_read_1.fq<span class="comment">#read 1的fastq</span></span><br><span class="line">q2=/path/LIBNAMEA/fastq_read_2.fq<span class="comment">#read 2的fastq【注意顺序】</span></span><br><span class="line">f1=/path/LIBNAMEA/fasta_read_1.fa<span class="comment">#read 1的fa</span></span><br><span class="line">f2=/path/LIBNAMEA/fasta_read_2.fa</span><br><span class="line">q=/path/LIBNAMEA/fastq_read_single.fq<span class="comment">#单向测序fastq</span></span><br><span class="line">f=/path/LIBNAMEA/fasta_read_single.fa<span class="comment">#单向测序fa</span></span><br><span class="line">p=/path/LIBNAMEA/pairs_in_one_file.fa<span class="comment">#双向测序一个fasta</span></span><br></pre></td></tr></table></figure>





<h1 id="输出文件及说明"><a href="#输出文件及说明" class="headerlink" title="输出文件及说明"></a>输出文件及说明</h1><p>SOAPdenovo 分四部分别对应的输出文件：<br>  ● pregraph  生成7个文件 *.kmerFreq  *.edge  *.preArc  *.markOnEdge  *.path  *.vertex  *.preGraphBasic<br>  ● contig       生成4个文件 <font color="red"> ***.contig**</font>  *.ContigIndex  *.updated.edge  *.Arc<br>  ● map          生成3个文件 *.readOnContig  *.peGrads  *.readInGap<br>  ● scaff          生成6个文件 *.newContigIndex  *.links  *.scaf  *.scaf_gap  <font color="red"> ***.scafSeq**</font>  *.gapSeq</p>
<p>*.kmerFreq             #每行显示一个数，这个数是kmer值出现的频率等于行号的kmer个数。</p>
<p><font color="red"><em><strong>.contig</strong></em></font>：没有使用mate pair 信息的contig sequences<br><font color="red"><strong>.scafSeq</strong></font>：fasta格式scaffold序列文件，contig之间的gap用N填充；<br><strong>对于得到的.scafSeq文件还需要用<font color="red">GapCloser</font>去合并其中的gap，最后的contig文件则是对补洞之后的scaffold文件通过打断N区的方法得到?</strong><br>以上两个文件是组装结果中最主要的输出。</p>
<p><font color="red"><em><strong>.scaf</strong></em></font>：包括scaffold中contig的详细信息；<br>在*scaffold行<strong>中包括scaffold名字、contig长度和该scaffold长度。<br>在</strong>contig行**包括contig名字、contig在scaffold上的起始位置、正反链、长度和contig间的链接信息<br><font color="red"> *.links</font>：contig间的pair-end连接信息<br><font color="red"> *.readOnContig</font>：reads在contig上的位置<br><font color="red"> *.peGrads</font>： 通过调整本文件中参数来显示构建scaffold所用到的插入片段库的个数，总共用到的read数，最长read，每个库对应的哪些reads，rank设置，pair_num_cutoff设置。例如：</p>
<blockquote>
<p>grads&amp;num: 10   522083934       70<br>323     104577616       1       3<br>334     180770522       1       3<br>345     226070520       1       3<br>486     361955834       2       3<br>2200    392088076       3       5<br>2290    422272580       3       5<br>2400    445522690       3       5<br>4870    475666064       4       5<br>9000    511030930       5       8<br>9110    522083934       5       5</p>
<p>该文件中共分成4列。<strong>组装的配置文件中有n个文库，该文件则有n+1行，且按照文库大小顺序排列。</strong><br><strong>第1行</strong>，二三四列分别是所用文库数目，reads总数和<font color="red">组装中用到的最长的reads长度？</font>。<br><strong>第2行</strong>，四列分别是文库大小，文库reads数目，文库reads的rank等级和pair_num_cutoff。<br><strong>第3～n+1行</strong>，四列分别是文库大小，文库reads数目加上前面文库中的reads总数，文库reads的rank等级pair_num_cutoff。#contig或者scaffold之前的最小overlap个数，pair-end数据默认为3；mate-paird数据默认为5,若配置文件没设置pair_num_cutoff，即使用默认参数0。</p>
</blockquote>
<p><strong>对于SOAPdenovo的每个步骤都有日志文件输出，要保存好日志文件，日志文件中包含有很多有用的信息。</strong></p>
<p>SOAPdenovo日志输出说明：</p>
<p>1）<font color="red">pregraph.log</font>:  其中有很多的统计信息，包括构建debruijn-graph所用reads数目，构图产生多少uniq的kmer以及设置-d参数后去除了多少kmer。</p>
<blockquote>
<p>-R            利用read鉴别短的重复序列，默认值不进行此操作</p>
<p>-d    INT     去除频数不大于该值的k-mer，默认值为0</p>
</blockquote>
<p>在pregraph中，可选参数有 –R –K –d  结果如：<br>5467781332 <strong>nodes</strong> allocated, 70662750348 <strong>kmer</strong> <strong>in reads</strong>, 70662750348 <strong>kmer processed</strong><br>3283081670 <strong>kmer removed</strong><br>其中Kmer 数取决于k值和数据量，nodes数即特异性kmer数，当nodes数目过高<strong>（一般和基因组大小差不多大小），可能是数据的错误率比较高，也可能是存在杂合</strong>。若nodes数目偏小，且kmer数目多，则基因组重复度较高。</p>
<p>k值的选取，当数据量充足（&gt;=40X），<strong>植物基因组一般采用大kmer效果较好</strong>，而<strong>动物基因组k值一般取27和29足够</strong>。kmer removed表示的 <strong>–d 参数所去除的低频的kmer</strong>。</p>
<p>2）<font color="red">contig.log</font>: contig 中，可选参数 –R –D –M，注，-R 参数的选定，必须pregraph和contig中同时选择才有效。</p>
<blockquote>
<p>-R            利用read鉴别短的重复序列，默认值不进行此操作</p>
</blockquote>
<p>结果例子：<br>16430183 pairs found, 2334584 pairs of paths compared, 1674493 pairs merged<br><strong>merged的数量可作为估计杂合以及测序错误的程度</strong>。<br>sum up 1932549703bp, with average length 1170<br>the longest is 36165bp, contig N50 is 2871 bp,contig N90 is 553 bp<br>相关统计信息，通常<strong>植物基因组的contig N90在200bp左右</strong>，若<strong>N90高于200bp则该基因组scaffold构建不会有太大问题</strong>。动物基因组scaffold构建很少有出问题的。</p>
<p>3）<font color="red">map.log</font>:<br>Output 415219610 out of 1956217742 (21.2)% reads in gaps<br><strong>1661094582 out of 1956217742 (84.9)% reads mapped to contigs</strong><br>一般情况下，reads in gap比例和map to contig 比例<strong>总和大于1（21.2%+84.9%）</strong>。因为reads map到多个地方都被统计。当map to contig的比例很高（80%左右时），但组装效果不好可能是重复序列较多。reads in gap比例较高（大于40%）是因为基因组组装的较碎gap区域较多。<br>map_len 默认值=K+5，短插入片段(&lt;2k)一般设置为32，长插入片段为35。取值为max{K+5,map_len}</p>
<p>4）<font color="red">scaff.log</font>:<br>average contig coverage is 23, 5832270 contig masked<br>构建scaffold是对高频覆盖的contig进行屏蔽（即<strong>频率高于average contig coverage的两倍的contig不用于构建scaffold(average-dep 2倍以上repeat sequences)?<strong>），从这里可以看出组装的基因组一定的重复情况。<br><strong>estimated PE size 162</strong>, by 40034765 pairs<br>on contigs longer than 173, 38257479 pairs found,SD=8, insert_size estimated: 163<br><font color="green"><strong>173 是配置文件文库insertsize</strong></font>，<font color="green"><strong>163 是reads  map到contig上的距离的估计值</strong></font>，8是分布标准偏差。一般考虑比对上去的pair数目和SD值。若pair对数很多且SD值很小？（小片段文库数据不超过三位数，大片段文库数据不超过500），<font color="green">一般可将配置文件中</font></strong>文库插入片段值修改</strong>为对短插入片段文库（&lt;1k）的大小<strong>估计值<strong>，下次</strong>组装<strong>以及</strong>补洞<strong>时应根据估计值对原配置文件中的</strong>insertsize修正**。对于大片段文库（&gt;=2K），因为是把reads map到contig上，若最长contig较短，可能找不到成pair比对上去的reads，无法估计文库大小，需要自己将大片段一级一级的map到前一级的组装结果上，然后再分析大片段文库的插入片段大小。注，</strong>需要调整insertsize时，只需修改* .peGrads文件中第一列，后删除*.links文件，重跑scaff即可*<em>。即构建scaffold时，主要是根据</em>.links文件的信息进行连接。<br>Cutoff for number of pairs to make a reliable connection: 3<br>1124104 weak connects removed (there were 4773564 active cnnects))<br>Cutoff for number是在配置文件中设的pair_num_cutoff值，weak connects是低于这个值被认定为无效的连接数，active connects是满足cutoff的连接数，根据这个数值可对pair_num_cutoff做调整<br>Picked  25241 subgraphs,4 have conflicting connections<br>conflicting connections 是表示构建scaffold时的矛盾数，矛盾数比较高（&gt;100）时，可根据前面的有效连接数，适当提高pair_num_cutoff值，即提高scaffold连接要求的最少关系数<br>182483 scaffolds&amp;singleton sum up 1990259817bp, with average length 10906<br>the longest is 6561520bp,scaffold N50 is 836795 bp, scaffold N90 is 157667 bp<br>scaffold 统计信息，将是根据rank分梯度的统计<br>Done with 13301 scaffolds, 2161915 gaps finished, 2527441 gaps overall<br><strong>-F 参数补洞的统计信息。</strong></p>
<h1 id="参数调整"><a href="#参数调整" class="headerlink" title="参数调整"></a>参数调整</h1><p>组装时需调整的参数，主要分两种：</p>
<p>一种是脚本中参数改动：如调整  -K  -R  -d  -D  -M<br>-K 值一般与基因组的特性和数据量相关，目前用到的SOAPdenovo软件主要有两个版本，SOAPdenovo-63mer是可使用大kmer组装，K值范围13-63。<br>【<strong>经验</strong>】：植物基因组组装采用大kmer效果会比较好（要求短片段reads长度75bp），动物基因组很少有用到大kmer后有明显改进效果的，且<strong>动物基因组组装K值一般设置为27和29较多</strong>。</p>
<p><font color="red"><strong>组装杂合子基因组的K-mer值应该小一点；组装含有高repeats基因组且要求其有高的测序深度和长的reads,的K-mer应该大一点。</strong></font></p>
<p>-R参数，对于<font color="green">动物基因组R参数一般不设置</font>，<font color="red"><strong>植物基因组</strong>由于<strong>较多的repeat区</strong>则<strong>设置R参数</strong>后效果更好</font>。注意<strong>设置-R时，一般使用-M 的默认值</strong>。（熊猫基因组组装时得出的结论）</p>
<p>-M 参数，0-3,<strong>默认值1</strong>。一般杂合率为千分之几就设为几。熊猫基因组组装时-M 2 。</p>
<p>-d 参数，对于没有纠错，没有处理的质量又较差的原始数据，kmer频数为1数据较多的组装，<font color="red"><strong>设置为-d 1 足够</strong></font>。对于处理过或是测序质量较好数据可不设置。数据量较多时，也可设置-d 去除部分质量稍差数据。</p>
<p>-D 参数，默认为1，一般不用另行设置。</p>
<p>第二种，从<strong>map</strong>过程去调节参数。可以<font color="red"> 调整配置文件map_len的值和调整文件 * .peGrads  </font>。<br>当<strong>文库插入片段分布图</strong>中文库大小与<strong>实验给出的文库大小</strong><font color="red">差异很大</font>，<font color="red"><em><em>调整</em>.peGrad</em>*s</font>文件中的插入片段大小。</p>
<p>根据每一档数据的数据量去调整文库的<strong>rank等级</strong>。</p>
<p>当该文库的数据量很多或者是在构建scaffold的过程中的冲突数很多时，可是适当的调大第四列的<strong>pair_num_cutoff</strong>，把条件设置的更严。</p>
<h1 id="内存估计"><a href="#内存估计" class="headerlink" title="内存估计"></a>内存估计</h1><p>SOAPdenovo四个步骤消耗的内存不一样</p>
<p>第一步消耗内存最多，使用没有纠错的的reads，(<font color="blue"> <strong>K&lt;=31**</strong></font>)第一步消耗的内存在<font color="blue"><strong>基因组大小80－100倍</strong>左右</font>，<font color="blue">纠过错在40－50倍**左右</font></p>
<p>第二步相对消耗内存会少很多</p>
<p>第三步消耗内存仅次于第一步，在第一步的一半左右</p>
<p>第四步消耗的内存也会比较少</p>
<p>对于CPU的使用，默认是8个，如果申请内存时申请一个计算节点的所有内存, CPU就设置为该计算节点的CPU个数充分利用计算资源，如果仅申请一个节点的部分内存则根据实际情况考虑。</p>
<p>对于<font color="blue"><strong>大kemr(K&gt;31)</strong></font>其内存使用是<font color="blue">**(k&lt;=31)**</font>的<font color="blue"><strong>1.5倍</strong></font>左右，有时甚至更多，要充分估计内存使用，在第一次运行时考虑不能太保守。</p>
<h1 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h1><p>1）配置文件reads存储路径错误<br>只输出日志文件。<br>pregraph.log中的错误信息：“Cannot open /path/LIBNAMEA/fastq_read_1.fq. Now exit to system…”<br>2）-g 后所跟参数与pregraph（第一步） -o  后所跟参数名不一致【**-o对应后面的-g**】<br>contig  map  scaff 这三个步骤都只是输出日志文件。<br><font color="green">contig.log</font>错误信息：“Cannot open *.preGraphBasic. Now exit to system…”<br><font color="green">map.log</font>错误信息：“Cannot open *.contig. Now exit to system…”<br><font color="green">scaff.log</font>错误信息：“Cannot open *.preGraphBasic. Now exit to system…”<br>3）<font color="blue">从map开始重新跑时，需要删除 *.links文件</font>，否则会生成core文件，程序退出。</p>
<hr>
<h1 id="Github-Readme-md"><a href="#Github-Readme-md" class="headerlink" title="Github-Readme.md"></a>Github-Readme.md</h1><h2 id="Configuration-file"><a href="#Configuration-file" class="headerlink" title="Configuration file"></a>Configuration file</h2><p>For big genome projects with deep sequencing, <font color="red">the data is usually organized as <strong>multiple read sequence files</strong> generated from <strong>multiple libraries</strong></font>. The configuration file: where? information? example.config</p>
<p>The configuration file has a section for <font color="red"><strong>global information</strong></font>, and then <font color="red"><strong>multiple library sections</strong></font>. Right now only “max_rd_len” is included in the global information section. Any read longer than max_rd_len will be cut to this length.</p>
<p>The library information and the information of sequencing data generated from the library should be organized in the corresponding library section. <font color="red"><strong>Each library section starts with tag [LIB]</strong></font> and includes the following items:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-avg_ins</span><br><span class="line">-reverse_seq</span><br><span class="line">-asm_flags</span><br><span class="line">-rd_len_cutof</span><br><span class="line">-rank</span><br><span class="line">-pair_num_cutoff</span><br><span class="line">-map_len</span><br></pre></td></tr></table></figure>



<p>The assembler accepts read file in three kinds of formats: <font color="green">FASTA, FASTQ and BAM</font>. Mate-pair relationship could be indicated in two ways: two sequence files with reads in the same order belonging to a pair, or two adjacent reads in a single file (FASTA only) belonging to a pair. If a read in <strong>bam</strong> file <strong>fails</strong> platform/vendor <strong>quality checks</strong>(the flag field 0x0200 is set), itself and it’s <strong>paired read</strong> would be <strong>ignored</strong>.</p>
<p>All the above items in each library section are optional. The assembler assigns default values for most of them. <strong>If you are not sure how to set a parameter, you can remove it from your configuration file</strong>.</p>
<h2 id="Get-started"><a href="#Get-started" class="headerlink" title="Get started"></a>Get started</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;one step&quot;</span></span><br><span class="line">SOAPdenvo all -s config_file -K 63 -R -o graph_prefix 1&gt;ass.log 2&gt;ass.err</span><br><span class="line"><span class="comment">#-R            利用read鉴别短的重复序列，默认值不进行此操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#step by step </span></span><br><span class="line"><span class="string">&quot;step1:&quot;</span></span><br><span class="line">SOAPdenvo pregraph -s config_file -K 63 -R -o graph_prefix 1&gt;pregraph.log 2&gt;pregraph.err</span><br><span class="line"><span class="string">&quot;OR&quot;</span></span><br><span class="line">SOAPdenvo sparse_pregraph -s config_file -K 63 -z 5000000000 -R -o graph_prefix 1&gt;pregraph.log 2&gt;pregraph.err</span><br><span class="line"><span class="comment">#-z genomize(required):estimated genome size</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;step2:&quot;</span></span><br><span class="line">SOAPdenvo contig -g graph_prefix -R 1&gt;contig.log 2&gt;contig.err</span><br><span class="line"><span class="comment">#-g    STR     输入文件的文件名前缀</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;step3:&quot;</span></span><br><span class="line">SOAPdenvo map -s config_file -g graph_prefix 1&gt;map.log 2&gt;map.err</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;step4:&quot;</span></span><br><span class="line">SOAPdenvo scaff -g graph_prefix -F 1&gt;scaff.log 2&gt;scaff.err</span><br><span class="line"><span class="comment">#-F            利用read对scaffold中的gap进行填补，默认不执行       </span></span><br></pre></td></tr></table></figure>



<h2 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h2><h3 id="Options-for-all-pregraph-contig-map-scaff"><a href="#Options-for-all-pregraph-contig-map-scaff" class="headerlink" title="Options for all (pregraph-contig-map-scaff)"></a>Options for all (<font color="red">pregraph-contig-map-scaff</font>)</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;-s&quot;</span>    configFile: the config file of solexa reads</span><br><span class="line"><span class="string">&quot;-o&quot;</span>     outputGraph: prefix of <span class="string">&quot;output graph file name&quot;</span></span><br><span class="line"><span class="string">&quot;-K&quot;</span>        kmer(min 13, max 63/127): kmer size, [23]</span><br><span class="line"><span class="string">&quot;-p&quot;</span>        n_cpu: number of cpu <span class="keyword">for</span> use, [8]</span><br><span class="line"><span class="string">&quot;-a?&quot;</span>        initMemoryAssumption: memory assumption initialized to avoid further reallocation, unit G, [0]</span><br><span class="line"><span class="string">&quot;-d&quot;</span>        KmerFreqCutoff: kmers with frequency no larger than KmerFreqCutoff will be deleted, [0]	INT     去除频数不大于该值的k-mer，默认值为0</span><br><span class="line"><span class="string">&quot;-R&quot;</span> (optional)  resolve repeats by reads, [NO]</span><br><span class="line"><span class="string">&quot;-D&quot;</span>        EdgeCovCutoff: edges with coverage no larger than EdgeCovCutoff will be deleted, [1]	INT     去除频数不大于该值的由k-mer连接的边，默认值为1，即该边上每个点的频数都小于等于1时才去除</span><br><span class="line"><span class="string">&quot;-M&quot;</span>        mergeLevel(min 0, max 3): the strength of merging similar sequences during contiging, [1]	INT     连接contig时合并相似序列的等级，默认值为1，最大值3。</span><br><span class="line">-m        max k when using multi kmer</span><br><span class="line">-e        weight to filter arc when linearize two edges(default 0)</span><br><span class="line">-r (optional)  keep available <span class="built_in">read</span>(*.<span class="built_in">read</span>)</span><br><span class="line">-E (optional)  merge clean bubble before iterate</span><br><span class="line">-f (optional)  output gap related reads <span class="keyword">in</span> map step <span class="keyword">for</span> using SRkgf to fill gap, [NO]</span><br><span class="line">-k        kmer_R2C(min 13, max 63): kmer size used <span class="keyword">for</span> mapping <span class="built_in">read</span> to contig, [K]</span><br><span class="line">-F (optional)  fill gaps <span class="keyword">in</span> scaffold, [NO]利用<span class="built_in">read</span>对scaffold中的gap进行填补，默认不执行</span><br><span class="line">-u (optional)  un-mask contigs with high/low coverage before scaffolding, [mask]构建scaffold前不屏蔽高覆盖度的contig，这里高频率覆盖度指平均contig覆盖深度的2倍。默认屏蔽</span><br><span class="line">-w (optional)  keep contigs weakly connected to other contigs <span class="keyword">in</span> scaffold, [NO]</span><br><span class="line">-G        gapLenDiff: allowed length difference between estimated and filled gap, [50]INT     估计gap的大小和实际补gap的大小的差异，默认值为50bp。</span><br><span class="line">-L        minContigLen: shortest contig <span class="keyword">for</span> scaffolding, [K+2]用于构建scaffold的contig的最短长度，默认为：Kmer参数值 ×2</span><br><span class="line">-c      minContigCvg: <span class="string">&quot;minimum contig coverage&quot;</span> (c*avgCvg), contigs shorter than 100bp with coverage smaller than c*avgCvg will be masked before scaffolding unless -u is <span class="built_in">set</span>, [0.1]</span><br><span class="line">-C      maxContigCvg: <span class="string">&quot;maximum contig coverage&quot;</span> (C*avgCvg), contigs with coverage larger than C*avgCvg or contigs shorter than 100bp with coverage larger than 0.8*C*avgCvg will be masked before scaffolding unless -u is <span class="built_in">set</span>, [2]</span><br><span class="line">-b      insertSizeUpperBound: (b*avg_ins) will be used as upper bound of insert size <span class="keyword">for</span> large insert size ( &gt; 1000) when handling pair-end connections between contigs <span class="keyword">if</span> b is <span class="built_in">set</span> to larger than 1, [1.5]</span><br><span class="line">-B      bubbleCoverage: remove contig with lower cvoerage <span class="keyword">in</span> bubble structure <span class="keyword">if</span> both contigs<span class="string">&#x27; coverage are smaller than bubbleCoverage*avgCvg, [0.6]</span></span><br><span class="line"><span class="string">-N        genomeSize: genome size for statistics, [0]</span></span><br><span class="line"><span class="string">-V (optional)  output visualization information of assembly, [NO]</span></span><br></pre></td></tr></table></figure>

<h3 id="Options-for-sparse-pregraph"><a href="#Options-for-sparse-pregraph" class="headerlink" title="Options for sparse_pregraph"></a>Options for sparse_pregraph</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Usage: ./SOAPdenovo2 sparse_pregraph -s configFile -K kmer -z genomeSize -o outputGraph [-g maxKmerEdgeLength -d kmerFreqCutoff -e kmerEdgeFreqCutoff -R -r runMode -p n_cpu]</span><br><span class="line">  -s      configFile: the config file of solexa reads</span><br><span class="line">  -K         kmer(min 13, max 63/127): kmer size, [23]</span><br><span class="line">  -g         maxKmerEdgeLength(min 1, max 25): number of skipped intermediate kmers, [15]</span><br><span class="line">  <span class="string">&quot;-z&quot;</span>         genomeSize(mandatory): estimated genome size</span><br><span class="line">  <span class="string">&quot;-d&quot;</span>         kmerFreqCutoff: delete kmers with frequency no larger than,[1]</span><br><span class="line">  -e         kmerEdgeFreqCutoff: delete kmers<span class="string">&#x27; related edge with frequency no larger than [1]</span></span><br><span class="line"><span class="string">  -R (optional)   output extra information for resolving repeats in contig step, [NO]</span></span><br><span class="line"><span class="string">  -r         runMode: 0 build graph &amp; build edge and preArc, 1 load graph by prefix &amp; build edge and preArc, 2 build graph only, 3 build edges only, 4 build preArcs only [0]</span></span><br><span class="line"><span class="string">  &quot;-p&quot;         n_cpu: number of cpu for use,[8]</span></span><br><span class="line"><span class="string">  -o         outputGraph: prefix of output graph file name</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">contigs：</span><br><span class="line">      -g  &lt;string&gt;      输入graph file文件名前缀 </span><br><span class="line">    -R  (optional)    移除repeats，使用pregraph步骤中产生的结果，如果参数-R在pregraph步骤中被设置的话，默认[NO]</span><br><span class="line">    -D  &lt;int&gt;         去除频数不大于该值（edgeCovCutoff）的由k-mer连接的边，默认值[1]，即该边上每个点的频数都小于等于1时才去除。edges with coverage no larger than EdgeCovCutoff will be deleted, [1] <span class="comment">#最小化错误测序带来的影响</span></span><br><span class="line">    -M  &lt;int&gt;         在contiging操作时，合并相似序列的强度，默认值为[1]，最小值0，最大值3。<span class="comment">#deal with heterozygosis</span></span><br><span class="line">    -e  &lt;int&gt;         两边缘之间的弧的权重大于该值（arcWeight），将被线性化，默认值[0]</span><br><span class="line">    -m  &lt;int&gt;         最大的kmer size（max 127）用于multi-kmer，默认[NO]</span><br><span class="line">    -E  (optional)    在iterate迭代之前，合并clean bubble功能，仅在当使用multi-kmer时且设置-M参数，默认[NO]</span><br><span class="line"> </span><br><span class="line">map：</span><br><span class="line">    -g  &lt;string&gt;      输入graph file文件名前缀 </span><br><span class="line">    -k  &lt;int&gt;         该值（kmer_R2C）是kmer size用于mapping reads到contigs上时的值，默认值[K]</span><br><span class="line">    -f  (optional)    在map那一步中，对于使用SRkgf去填充gap，输出与gap相关的reads,默认[NO]</span><br><span class="line"> </span><br><span class="line">scaffold：</span><br><span class="line">      -F  (optional)    利用<span class="built_in">read</span>对scaffold中的gap进行填补，默认[NO]</span><br><span class="line">    -u  (optional)    构建scaffolding前不屏蔽高/低覆盖度的contigs，这里高频率覆盖度指平均contig覆盖深度的2倍。默认[mask]屏蔽</span><br><span class="line">    -w  (optional)    在scaffold中，保持contigs弱连接于其他contigs，默认[NO]</span><br><span class="line">    -G  &lt;int&gt;         估计gap的大小和实际补gap的大小的差异值，默认值[50]bp。</span><br><span class="line">    -L  &lt;int&gt;         用于构建scaffold的contig的最短长度(minContigLen)，默认为：[Kmer参数值+2]</span><br><span class="line">    -c  &lt;<span class="built_in">float</span>&gt;       在scaffolding之前，contigs小于100bp，且覆盖率小于该最小contig覆盖率（c*avgCvg），将被屏蔽，除非参数-u已设定，默认值[0.1]</span><br><span class="line">    -C  &lt;<span class="built_in">float</span>&gt;       在scaffolding之前，contigs覆盖率大于该最大contigs覆盖率（C*avgCvg），或者contigs小于100bp且覆盖率大于0.8*（C*avgCvg），将被屏蔽，除非参数-u已设定，默认值[2]</span><br><span class="line">    -b  &lt;<span class="built_in">float</span>&gt;       当处理contigs间的pair-end连接时，如果参数-b&gt;1，该插入片段的上限值（b*avg_ins）将被用来作为大的插入片段（&gt;1000）的上限，默认值[1.5]</span><br><span class="line">    -B  &lt;<span class="built_in">float</span>&gt;       如果两个contigs的覆盖率都小于bubble覆盖率（bubbleCoverage）乘以contigs平均覆盖率（bubbleCoverage*avgCvg），则去除在bubble结构中的低覆盖率contig，默认值[0.6]</span><br><span class="line">    -N  &lt;int&gt;         统计基因组大小，默认值[0]</span><br><span class="line">    -V  (optional)    输出相关信息为了可视化组装，默认[NO]</span><br></pre></td></tr></table></figure>



<h2 id="Output-files"><a href="#Output-files" class="headerlink" title="Output files"></a>Output files</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. <span class="string">&quot;*.contig&quot;</span></span><br><span class="line">  contig sequences without using mate pair information.</span><br><span class="line">b. <span class="string">&quot;*.scafSeq&quot;</span></span><br><span class="line">  scaffold sequences (final contig sequences can be extracted by breaking down scaffold sequences at gap regions).</span><br></pre></td></tr></table></figure>



<h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><h3 id="How-to-set-K-mer-size"><a href="#How-to-set-K-mer-size" class="headerlink" title="How to set K-mer size?"></a>How to set K-mer size?</h3><p>The program accepts odd numbers between 13 and 31? <strong>Larger K-mers would have higher rate of uniqueness in the genome and would make the graph simpler, but it requires deep sequencing depth and longer read length to guarantee the overlap at any genomic location.</strong> <font color="red"><strong>Balance?</strong></font></p>
<p>The <strong>sparse_pregraph</strong> module usually needs <strong>2-10bp smaller kmer</strong> length to achieve the same performance as the original <strong>pregraph</strong> module. <font color="red"><strong>Difference?</strong></font></p>
<h3 id="How-to-set-genome-size-z-for-sparse-pregraph-module"><a href="#How-to-set-genome-size-z-for-sparse-pregraph-module" class="headerlink" title="How to set genome size(-z) for sparse_pregraph module?"></a>How to set genome size(-z) for sparse_pregraph module?</h3><p>The -z parameter for sparse pregraph should be set <font color="red"><strong>a litter larger than the real genome size</strong></font>, it is used to allocate memory.</p>
<h3 id="How-to-set-library-rank"><a href="#How-to-set-library-rank" class="headerlink" title="How to set library rank?"></a>How to set library rank?</h3><p>SOAPdenovo will <font color="red">use the <strong>pair-end libraries</strong> with <strong>insert size</strong> from <strong>smaller to larger</strong> to <strong>construct</strong> scaffolds</font>. Libraries with the same rank would be used at the same time. For example, in a dataset of a human genome, we set <strong><font color="red">five ranks</font> for five libraries with insert size 200-bp, 500-bp, 2-Kb, 5-Kb and 10-Kb</strong>, separately. It is desired that the pairs in each rank provide adequate physical coverage of the genome.</p>
<h2 id="APPENDIX-A-an-example-config"><a href="#APPENDIX-A-an-example-config" class="headerlink" title="APPENDIX A: an example.config"></a>APPENDIX A: an example.config</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#maximal read length</span></span><br><span class="line">max_rd_len=100</span><br><span class="line"><span class="string">&quot;[LIB]&quot;</span></span><br><span class="line"><span class="comment">#average insert size</span></span><br><span class="line">avg_ins=200</span><br><span class="line"><span class="comment">#if sequence needs to be reversed</span></span><br><span class="line">reverse_seq=0</span><br><span class="line"><span class="comment">#in which part(s) the reads are used</span></span><br><span class="line">asm_flags=3</span><br><span class="line"><span class="comment">#use only first 100 bps of each read</span></span><br><span class="line">rd_len_cutoff=100</span><br><span class="line"><span class="comment">#in which order the reads are used while scaffolding</span></span><br><span class="line">rank=1</span><br><span class="line"><span class="comment"># cutoff of pair number for a reliable connection (at least 3 for short insert size)</span></span><br><span class="line">pair_num_cutoff=3</span><br><span class="line"><span class="comment">#minimum aligned length to contigs for a reliable read location (at least 32 for short insert size)</span></span><br><span class="line">map_len=32</span><br><span class="line"><span class="comment">#a pair of fastq file, read 1 file should always be followed by read 2 file</span></span><br><span class="line">q1=/path/**LIBNAMEA**/fastq1_read_1.fq</span><br><span class="line">q2=/path/**LIBNAMEA**/fastq1_read_2.fq</span><br><span class="line"><span class="comment">#another pair of fastq file, read 1 file should always be followed by read 2 file</span></span><br><span class="line">q1=/path/**LIBNAMEA**/fastq2_read_1.fq</span><br><span class="line">q2=/path/**LIBNAMEA**/fastq2_read_2.fq</span><br><span class="line"><span class="comment">#a pair of fasta file, read 1 file should always be followed by read 2 file</span></span><br><span class="line">f1=/path/**LIBNAMEA**/fasta1_read_1.fa</span><br><span class="line">f2=/path/**LIBNAMEA**/fasta1_read_2.fa</span><br><span class="line"><span class="comment">#another pair of fasta file, read 1 file should always be followed by read 2 file</span></span><br><span class="line">f1=/path/**LIBNAMEA**/fasta2_read_1.fa</span><br><span class="line">f2=/path/**LIBNAMEA**/fasta2_read_2.fa</span><br><span class="line"><span class="comment">#fastq file for single reads</span></span><br><span class="line">q=/path/**LIBNAMEA**/fastq1_read_single.fq</span><br><span class="line"><span class="comment">#another fastq file for single reads</span></span><br><span class="line">q=/path/**LIBNAMEA**/fastq2_read_single.fq</span><br><span class="line"><span class="comment">#fasta file for single reads</span></span><br><span class="line">f=/path/**LIBNAMEA**/fasta1_read_single.fa</span><br><span class="line"><span class="comment">#another fasta file for single reads</span></span><br><span class="line">f=/path/**LIBNAMEA**/fasta2_read_single.fa</span><br><span class="line"><span class="comment">#a single fasta file for paired reads</span></span><br><span class="line">p=/path/**LIBNAMEA**/pairs1_in_one_file.fa</span><br><span class="line"><span class="comment">#another single fasta file for paired reads</span></span><br><span class="line">p=/path/**LIBNAMEA**/pairs2_in_one_file.fa</span><br><span class="line"><span class="comment">#bam file for single or paired reads, reads 1 in paired reads file should always be followed by reads 2</span></span><br><span class="line"><span class="comment">#	<span class="doctag">NOTE:</span> If a read in bam file fails platform/vendor quality checks(the flag field 0x0200 is set), itself and it&#x27;s paired read would be ignored.</span></span><br><span class="line">b=/path/**LIBNAMEA**/reads1_in_file.bam</span><br><span class="line"><span class="comment">#another bam file for single or paired reads</span></span><br><span class="line">b=/path/**LIBNAMEA**/reads2_in_file.bam</span><br><span class="line"><span class="string">&quot;[LIB]&quot;</span></span><br><span class="line">avg_ins=2000</span><br><span class="line">reverse_seq=1</span><br><span class="line">asm_flags=2</span><br><span class="line">rank=2</span><br><span class="line"><span class="comment"># cutoff of pair number for a reliable connection (at least 5 for large insert size)</span></span><br><span class="line">pair_num_cutoff=5</span><br><span class="line"><span class="comment">#minimum aligned length to contigs for a reliable read location (at least 35 for large insert size)</span></span><br><span class="line">map_len=35</span><br><span class="line">q1=/path/**LIBNAMEB**/fastq_read_1.fq</span><br><span class="line">q2=/path/**LIBNAMEB**/fastq_read_2.fq</span><br><span class="line">f1=/path/**LIBNAMEA**/fasta_read_1.fa</span><br><span class="line">f2=/path/**LIBNAMEA**/fasta_read_2.fa</span><br><span class="line">p=/path/**LIBNAMEA**/pairs_in_one_file.fa</span><br><span class="line">b=/path/**LIBNAMEA**/reads_in_file.bam</span><br></pre></td></tr></table></figure>

<h2 id="Appendix-B-output-files"><a href="#Appendix-B-output-files" class="headerlink" title="Appendix B: output files"></a>Appendix B: output files</h2><h3 id="1-Output-files-from-the-command-“pregraph”"><a href="#1-Output-files-from-the-command-“pregraph”" class="headerlink" title="1. Output files from the command “pregraph”"></a>1. Output files from the command “pregraph”</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. *.kmerFreq</span><br><span class="line">   Each row shows the number of Kmers with a frequency equals the row number. Note that those peaks of frequencies <span class="built_in">which</span> are the integral multiple of 63 are due to the data structure.</span><br><span class="line">b. *.edge</span><br><span class="line">   Each record gives the information of an edge <span class="keyword">in</span> the pre-graph: length, Kmers on both ends, average kmer coverage, whether it<span class="string">&#x27;s reverse-complementarily identical and the sequence.</span></span><br><span class="line"><span class="string">c. *.markOnEdge &amp; *.path</span></span><br><span class="line"><span class="string">   These two files are for using reads to solve small repeats.</span></span><br><span class="line"><span class="string">e. *.preArc</span></span><br><span class="line"><span class="string">   Connections between edges which are established by the read paths.</span></span><br><span class="line"><span class="string">f. *.vertex</span></span><br><span class="line"><span class="string">   Kmers at the ends of edges.</span></span><br><span class="line"><span class="string">g. *.preGraphBasic</span></span><br><span class="line"><span class="string">   Some basic information about the pre-graph: number of vertex, K value, number of edges, maximum read length etc.</span></span><br></pre></td></tr></table></figure>

<h3 id="2-Output-files-from-the-command-“contig”"><a href="#2-Output-files-from-the-command-“contig”" class="headerlink" title="2. Output files from the command “contig”"></a>2. Output files from the command “contig”</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. *.contig</span><br><span class="line">      Contig information: corresponding edge index, length, kmer coverage, whether it<span class="string">&#x27;s tip and the sequence. Either a contig or its reverse complementry counterpart is included. Each reverse complementary contig index is indicated in the *.ContigIndex file.</span></span><br><span class="line"><span class="string">   b. *.Arc</span></span><br><span class="line"><span class="string">      Arcs coming out of each edge and their corresponding coverage by reads</span></span><br><span class="line"><span class="string">   c. *.updated.edge</span></span><br><span class="line"><span class="string">      Some information for each edge in graph: length, Kmers at both ends, index difference between the reverse-complementary edge and this one.</span></span><br><span class="line"><span class="string">   d. *.ContigIndex</span></span><br><span class="line"><span class="string">      Each record gives information about each contig in the *.contig: it&#x27;</span>s edge index, length, the index difference between its reverse-complementary counterpart and itself.</span><br></pre></td></tr></table></figure>

<h3 id="3-Output-files-from-the-command-“map”"><a href="#3-Output-files-from-the-command-“map”" class="headerlink" title="3. Output files from the command “map”"></a>3. Output files from the command “map”</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. *.peGrads</span><br><span class="line">      Information <span class="keyword">for</span> each <span class="built_in">clone</span> library: insert-size, <span class="built_in">read</span> index upper bound, rank and pair number cutoff <span class="keyword">for</span> a reliable link. This file can be revised manually <span class="keyword">for</span> scaffolding tuning.</span><br><span class="line">   b. *.readOnContig</span><br><span class="line">      Reads<span class="string">&#x27; locations on contigs. Here contigs are referred by their edge index. Howerver about half of them are not listed in the *.contig file for their reverse-complementary counterparts are included already.</span></span><br><span class="line"><span class="string">   c. *.readInGap</span></span><br><span class="line"><span class="string">      This file includes reads that could be located in gaps between contigs. This information will be used to close gaps in scaffolds if &quot;-F&quot; is set.</span></span><br></pre></td></tr></table></figure>

<h3 id="4-Output-files-from-the-command-“scaff”"><a href="#4-Output-files-from-the-command-“scaff”" class="headerlink" title="4. Output files from the command “scaff”"></a>4. Output files from the command “scaff”</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. *.newContigIndex</span><br><span class="line">      Contigs are sorted according their length before scaffolding. Their new index are listed <span class="keyword">in</span> this file.  This is useful <span class="keyword">if</span> one wants to corresponds contigs <span class="keyword">in</span> *.contig with those <span class="keyword">in</span> *.links.</span><br><span class="line">   b. *.links</span><br><span class="line">      Links between contigs <span class="built_in">which</span> are established by <span class="built_in">read</span> pairs. New index are used.</span><br><span class="line">   c. *.scaf_gap</span><br><span class="line">      Contigs <span class="keyword">in</span> gaps found by contig graph outputted by the contiging procedure. Here new index are used.</span><br><span class="line">   d. *.scaf</span><br><span class="line">      Contigs <span class="keyword">for</span> each scaffold: contig index (concordant to index <span class="keyword">in</span> *.contig),  approximate start position on scaffold, orientation, contig length, and its links to others contigs.</span><br><span class="line">   e. *.gapSeq</span><br><span class="line">      Gap sequences between contigs.</span><br><span class="line">   f. *.scafSeq</span><br><span class="line">      Sequences of each scaffolds.</span><br><span class="line">   g. *.contigPosInscaff</span><br><span class="line">      Contigs<span class="string">&#x27; positions in each scaffold.</span></span><br><span class="line"><span class="string">   h. *.bubbleInScaff</span></span><br><span class="line"><span class="string">      Contigs that form bubble structures in scaffolds. Every two contigs form a bubble and the contig with higher coverage will be kept in scaffold.</span></span><br><span class="line"><span class="string">   i. *.scafStatistics</span></span><br><span class="line"><span class="string">      Statistic information of final scaffold and contig.</span></span><br></pre></td></tr></table></figure>

<hr>
<h1 id="小记1"><a href="#小记1" class="headerlink" title="小记1"></a>小记1</h1><p> ref：<a href="https://www.cnblogs.com/Formulate0303/p/6879841.html">https://www.cnblogs.com/Formulate0303/p/6879841.html</a></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>确定基因组缺失什么；确定难以生化研究的基因和pathways；研究感兴趣pathway通路中每一个基因；研究基因组非编码区（introns、promoters、telomeres端粒等）的调控机理和结构特征；基因组提供可进行各种统计的大型数据库（provide large databases that are amenable to statistical methods）;识别不同可能有细微表型的序列；研究物种和基因组的进化过程。一般都是用不同梯度的插入片段来测序，小片段（200,500,800）和大片段（1k, 2kb 5kb 10kb 20kb 40kb）。</p>
<h2 id="测序前准备"><a href="#测序前准备" class="headerlink" title="测序前准备"></a>测序前准备</h2><p>搜集物种相关信息（染色体的倍型、基因组大小、杂合度、重复序列比例、是否有可用的遗传图谱、GC含量 和 GC分布）。提供已经发表的近源物种。根据近源物种分析以上信息，尤其是GC含量以及对应的GC分布，重复程度。</p>
<h3 id="1-获取基因组大小"><a href="#1-获取基因组大小" class="headerlink" title="1 获取基因组大小"></a>1 获取基因组大小</h3><ul>
<li><p>基因组太大（&gt;10Gb）超出了目前denovo组装基因组软件对机器内存的要求，则无法实现组装；对组装结果的大小的进行正确性与否判断。</p>
</li>
<li><p>动物基因组大小数据库（ANIMAL GENOME SIZE DATABASE）: <a href="http://www.genomesize.com/%EF%BC%9B%E5%AF%B9%E4%BA%8E%E6%9F%A5%E4%B8%8D%E5%88%B0%E7%9A%84%E7%89%A9%E7%A7%8D%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%A4%A7%E5%B0%8F%E7%9A%84%EF%BC%8C%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E4%B8%80%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8E%BB%E4%BC%B0%E8%AE%A1%E3%80%82">http://www.genomesize.com/；对于查不到的物种基因组大小的，可以通过一些方法去估计。</a></p>
</li>
<li><p>实验（流式细胞仪）估计基因组大小的例子： “A full-length enriched cDNA library and expressed sequence tag analysis of the parasitic weed, Striga hermonthica.” BMC Plant Biol (2010)</p>
</li>
<li><p>基于福尔摩根染色估计基因组大小：书The evolution of the genome《基因组进化》, Gregory, T. (2005).</p>
</li>
<li><p>定量PCR估计基因组大小: “Real-time PCR-based method for the estimation of genome sizes.” Nucleic Acids Res (2003); “The nuclear genome of the phytoseiid Metaseiulus occidentalis (Acari: Phytoseiidae) is among the smallest known in arthropods.” Exp Appl Acarol (2009)</p>
</li>
<li><p>通过Kmer估计基因组大小：Kim, E. B., X. Fang, et al. (2011). “<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3319411/"><strong>Genome sequencing reveals insights into physiology and longevity of the naked mole rat</strong></a>.” Nature 479(7372): 223-227. [Obtained 2.5 G contig sequences with N50 19.3 kbp and N90 4.7 kbp, and 2.7 G scaffold sequences with N50 1.6 Mbp and N90 0.3 Mbp.]</p>
</li>
</ul>
<h3 id="2-杂合度评估"><a href="#2-杂合度评估" class="headerlink" title="2 杂合度评估"></a>2 杂合度评估</h3><ul>
<li><p>主要体现在<font color="green">不能合并姊妹染色体</font>，杂合度高的区域，会把两条姊妹染色单体都组装出来，造成组装的基因组<font color="green">偏大</font>。</p>
</li>
<li><p><font color="red"><strong>杂合度&gt;0.5%则组装有一定难度</strong></font>。杂合度&gt;1%则很难组装出来。</p>
</li>
<li><p>杂合度高则组装的序列不适合用于后续生物学分析（eg:拷贝数、基因完整结构等）。</p>
</li>
</ul>
<h3 id="3-是否有遗传图谱可用"><a href="#3-是否有遗传图谱可用" class="headerlink" title="3 是否有遗传图谱可用"></a>3 是否有遗传图谱可用</h3><p>随着测序对质量提高和相关技术成熟，<font color="red"><strong>遗传图谱？</strong></font>也快成了denovo基因组的必须组成。</p>
<p><a href="https://cdmd.cnki.com.cn/Article/CDMD-10504-1019065822.htm">矮牵牛遗传图谱构建及重瓣分子标记筛选</a></p>
<p>遗传图谱是某一物种的染色体图，显示所知的基因和/或遗传标记的相对位置，而不是在每条染色体上特殊的物理位置。由<a href="https://baike.baidu.com/item/%E9%81%97%E4%BC%A0%E9%87%8D%E7%BB%84/6391485">遗传重组</a>测验结果推算出来的、在一条染色体上可以发生的突变座位的直线排列（<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E4%BD%8D%E7%82%B9/3613206">基因位点</a>的排列）图。</p>
<p>Genetic map，<a href="https://baike.baidu.com/item/%E9%81%97%E4%BC%A0%E5%9B%BE/2951032">遗传图</a>或遗传<a href="https://baike.baidu.com/item/%E8%BF%9E%E9%94%81%E5%9B%BE/1586423">连锁图</a>是以<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E8%BF%9E%E9%94%81/7740242">基因连锁</a>、重组<a href="https://baike.baidu.com/item/%E4%BA%A4%E6%8D%A2%E5%80%BC/5106108">交换值</a>构建的图谱，图距为cM（<a href="https://baike.baidu.com/item/%E5%8E%98%E6%91%A9/1586351">厘摩</a>），1%交换值为1cM，约相当于1000kb。人基因组全长约3300cM，如两个标记之间相距1cM，则需3300个标记，如相距2～5cM，则需660～l650个标记。标记可以是体质性状，也可以是可检出的DNA序列，例如基因、<a href="https://baike.baidu.com/item/%E9%99%90%E5%88%B6%E7%89%87%E6%AE%B5%E9%95%BF%E5%BA%A6%E5%A4%9A%E6%80%81%E6%80%A7/3841692">限制片段长度多态性</a>（<a href="https://baike.baidu.com/item/RFLP/5060944">RFLP</a>）和特定的<a href="https://baike.baidu.com/item/%E5%8D%95%E4%B8%80%E5%BA%8F%E5%88%97/1851974">单一序列</a>等。每一个标记都要用专一序列位点（STS）作鉴定。STS是指其位置及核苷酸序列均已知的、人基因组中只有一份拷贝的DNA短片段（一般长200～500碱基对），它很容易用多聚酶链反应（PCR）加以验证。当各个实验室报道定位和测序的数据时，可用STS来确定这些DNA片段的定位与取向。人类基因组计划的研究目标是，完成一个完全连接的人类遗传图，标记之间平均相距2～5cM。</p>
<p>遗传图谱构建相关概念推荐参考书：<strong>The handbook of plant genome mapping: genetic and physical mapping</strong> </p>
<h3 id="4-生物学问题的调研"><a href="#4-生物学问题的调研" class="headerlink" title="4 生物学问题的调研"></a>4 生物学问题的调研</h3><h2 id="组装"><a href="#组装" class="headerlink" title="组装"></a>组装</h2><ul>
<li><p>BAC-by-BAC:测序和组装每一个BAC, 合并BAC和移除BAC冗余部分，获得参考基因组序列。</p>
</li>
<li><p>whole genome shotgun：全基因组鸟枪法，染色体DNA被随机打断成片段，依次测序和组装。</p>
</li>
</ul>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>二代测序数据从头组装的解决overlap的三种算法</p>
<ul>
<li><p>overlap-layout-consensus：重叠布局一致OLC法，【软件：PHRAP.NEWBLER.CABOG.CELERA.SHORTY.EDENA,popular for long reads】，1. Overlap discovery involves all-against-all, pair-wise read comparison. 2. Construction an approximate read layout according to the pair-wise alignment 3. Multiple sequence alignment determines the precise layout and the consensus.</p>
</li>
<li><p>De bruijn graph:DBG法，【软件：SOAPdenovo2.Velvet.EULER,popular for illumina ，for short reads】,1.所有的测序reads都被切割成某一固定Kmer长度的序列（21bp=&lt;kmer&lt;=127bp）.2.相邻kmers链接是来自read序列，所以它不需要成对序列比对(The links between neighboring Kmers are derived from read sequences,so it doesn’t need pair-wise reads alignment.）3.冗余的数据自动被压缩。</p>
</li>
<li><p>greedy method：贪婪法(use OLC or DBG)，【软件：SSAKE.SHARCGS.VCAKE】，从给定的reads和contigs开始，使用下一个得分最高的overlap去做下一个连接，这样一直做下去，直到不能进行下去为止。 </p>
</li>
</ul>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>组装short reads的挑战</p>
<p>1.基因组的复杂性，<strong>重复序列</strong>、<strong>杂合</strong>的<strong>二倍体</strong>基因组heterozygous diploid genome、<strong>多倍性</strong>polyploidy.</p>
<p>2.illumina reads 的数据特征，<strong>测序错误</strong>率<del>1%、short read 长度</del>100bp、<del>100X的高测序深度、不同级别的文库插入片段（200bp</del>40Kbp）。</p>
<p>3.Complexity of computation</p>
<h2 id><a href="#" class="headerlink" title></a></h2><hr>
<h1 id="小记2"><a href="#小记2" class="headerlink" title="小记2"></a>小记2</h1><p>ref <a href="https://www.jianshu.com/p/e02ecd537c83">https://www.jianshu.com/p/e02ecd537c83</a></p>
<h2 id="reads质量控制"><a href="#reads质量控制" class="headerlink" title="reads质量控制"></a>reads质量控制</h2><ul>
<li>认识数据。(read类型，read数量，其GC含量，可能的污染和其他问题)</li>
<li>数据清理。(组装前清理原始数据可以使组装结果更好,因为移除了低质量和污染的reads)</li>
<li>为组装软件提供一些组装的参数</li>
</ul>
<h2 id="检查原始read数据的质量"><a href="#检查原始read数据的质量" class="headerlink" title="检查原始read数据的质量"></a>检查原始read数据的质量</h2><p>(1)read长度:在设置组装的最大k-mer值时将很重要。</p>
<p>(2)质量编码类型:对于quality trimming软件很重要。(Phred33、64)</p>
<p>(3)GC含量:<strong>高GC的生物体往往组装得不好，并且read覆盖率分布可能不均匀</strong></p>
<p>(4)总的reads数:<strong>了解coverage范围</strong></p>
<p>(4)在read的开始、中间或结尾附近质量下降:确定可能的修整/清除方法和参数。</p>
<p>(5)出现<strong>高度重复的k-mers</strong>:说明序列可能存在污染。</p>
<p>(6)reads中存在<strong>大量N</strong>:可能表明测序质量较差。你需要修剪这些read，以删除N.</p>
<h2 id="genome-survey"><a href="#genome-survey" class="headerlink" title="genome survey"></a>genome survey</h2><p>正式组装前进行kmer分析，以了解以下信息。</p>
<p>(1)基因组杂合度。</p>
<p>(2)重复序列比例。</p>
<p>(3)预估基因组大小。</p>
<p>(4)测序深度。</p>
<p>所用软件为kmergenie，<a href="https://links.jianshu.com/go?to=http://kmergenie.bx.psu.edu/">http://kmergenie.bx.psu.edu/</a> </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装(使用时，确保服务器装有Pthon与R)</span></span><br><span class="line">tar -xzvf kmergenie-1.7051.tar.gz &amp;&amp; <span class="built_in">cd</span> kmergenie-1.7051</span><br><span class="line">python setup.py install</span><br><span class="line"> </span><br><span class="line"><span class="comment">#添加可执行权限</span></span><br><span class="line">chmod -R 755 *</span><br></pre></td></tr></table></figure>

<p>接下来介绍怎么用，参考：<a href="https://links.jianshu.com/go?to=http://wap.sciencenet.cn/blog-3406804-1159967.html">http://wap.sciencenet.cn/blog-3406804-1159967.html</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">touch fq_501.txt                                 <span class="comment">#存储fastq文件的路径。</span></span><br><span class="line">vim fq_501.txt                                   <span class="comment">#编辑fq.txt，输入fastq文件路径。</span></span><br><span class="line">mkdir kmergenie_result     </span><br><span class="line">./tools/kmergenie-1.7051/kmergenie fq_501.list -o ./kmergenie_result/PB_501 -k 105 -</span><br><span class="line">l 15 -s 10 -t 12                               </span><br><span class="line"><span class="comment">#-o:输出文件存放的地址。</span></span><br><span class="line"><span class="comment">#-k:最大的k值</span></span><br><span class="line"><span class="comment">#-l:最小的k值</span></span><br><span class="line"><span class="comment">#-s:从最小的k----最大的k，每次增加的k。</span></span><br><span class="line"><span class="comment">#-t:线程数。</span></span><br><span class="line"><span class="comment">#注:刚开始s可以设大点，可以根据判断出的最佳k值，缩小s再进行判断((第一次:I:15,k:105,s:10 第二次I:85,k:140,s:6)。</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">usage:</span><br><span class="line"></span><br><span class="line">    ./kmergenie reads_file</span><br><span class="line"></span><br><span class="line">reads_file is either a single FASTA, FASTQ, FASTA.gz, FASTQ.gz file or a list of file names, one per line. For example:</span><br><span class="line">    </span><br><span class="line">    ls -1 *.fastq.gz &gt; list_files</span><br><span class="line">    ./kmergenie list_files</span><br><span class="line"></span><br><span class="line">    type ./kmergenie to see extra options</span><br><span class="line"></span><br><span class="line">input:</span><br><span class="line"></span><br><span class="line">    Input reads should be exactly those the de novo assembler will use to create contigs, i.e. the list of all single and paired-end reads.</span><br><span class="line"></span><br><span class="line">    The order does not matter, KmerGenie treats the reads as an unordered set of k-mers. Orientation of the reads also does not matter.</span><br><span class="line">    With Velvet, if you have mate-pairs, Velvet uses them to create contigs, so do include them in KmerGenie.</span><br><span class="line">    Otherwise, if the mate-pairs are used only for scaffolding (i.e. asm_flag=2 in SOAPdenovo), do not include them.</span><br><span class="line"></span><br><span class="line">tips:</span><br><span class="line"></span><br><span class="line">    * Take a look at the generated HTML report. It provides a summary of the results, and contains an Advanced Help section to help analysis.</span><br><span class="line"></span><br><span class="line">    * There is no need to use Kmergenie for a multi-k assembler, like SPAdes. Default parameters of multi-k assemblers are generally better than a single best k.</span><br><span class="line"></span><br><span class="line">    * By default, KmerGenie will perform another pass to estimate k more precisely. You may skip it by using the &quot;--one-pass&quot; option (roughly 2x faster).</span><br><span class="line"></span><br><span class="line">    * To run multiple instances of KmerGenie on the same folder, specify the &quot;-o&quot; and &quot;-t&quot; parameters (output prefix, number of threads per instance).</span><br><span class="line"></span><br><span class="line">    * The sampling value e (&quot;-e&quot; parameter) makes sure that roughly n/e k-mers are sampled out of the n distinct kmers in the dataset. The datasets are fully analyzed, though. Kmergenie samples from the set of distinct kmers, not from the set of reads.</span><br><span class="line"></span><br><span class="line">    * The diploid model should only be used for moderate-high heterozygosity rates. The haploid model works better when only one peak is visible in the histograms (indicating low heterozygosity).</span><br><span class="line"></span><br><span class="line">outputs:</span><br><span class="line"></span><br><span class="line">    histograms_report.html</span><br><span class="line">        html report of all the results</span><br><span class="line">    histograms.dat</span><br><span class="line">        file containing the raw data for the number of genomic kmers for each k value</span><br><span class="line">    histograms-k*.histo</span><br><span class="line">        files containing raw sampled histograms for each k value</span><br><span class="line">    histograms-k*.histo.pdf</span><br><span class="line">        plots of the histograms and the fits. Colors: red is the fit of the complete statistical model of the histogram (erroneous k-mers + genomic k-mers). With the diploid model, green are only the heterozygous k-mers, blue are only the homozygous k-mers.</span><br><span class="line">    &lt;stdout&gt;</span><br><span class="line">        last line is the best k value</span><br><span class="line">    &lt;return code / error code&gt;</span><br><span class="line">        0 if and only if a best k was found (note: no longer returns the best k as error code)</span><br></pre></td></tr></table></figure>



<p>结果文件生成report。报告以折线图形式给出每种长度的kmer下，估计的基因组大小，同时给出了最佳的kmer(评估基因组总大小最高)</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/14.png" alt="img"></p>
<p>理想条件该图应该为一条平滑的曲线，有明确最大值。然而在一些情况下有多个局部最大值。</p>
<p>这些情况表明，对于某些k值，Kmergenie中的统计模型并不总是正确地拟合输入数据。因此由Kmergenie预测的最佳k值可能不是最佳的。在随后的分析中，还尝试使用比Kmergenie预测的k大的k(其他峰值)</p>
<p>若基因组k-mers的数量不会随着k值的升高而下降，则是一个高覆盖率(high coverage)数据集的迹象？<br>什么是覆盖率呢？<br>覆盖率(coverage)：指的是测序过程中读取单个碱基的平均次数。如果覆盖度为100×，说明平均每个碱基测序了100次。对碱基测序的频率越高，数据的质量越高。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/15.png" alt="img"></p>
<h2 id="soapdevovo2"><a href="#soapdevovo2" class="headerlink" title="soapdevovo2"></a>soapdevovo2</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#正式组装(kmer选103,113,123,127分别跑)</span></span><br><span class="line"><span class="comment">#SOAPdenovo2既可以一步组装也可以分四步，如果基因组大且复杂建议分四步。</span></span><br><span class="line"> nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer all -s config_file -d 1 -R -F -K 113 -p 60 -o PB_501_113 &gt; PB_501_113.log &amp;  <span class="comment">#注:加nohup和&amp;是为了让它在后台运行(防止远程连接断开程序停止)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#分四步(在k=103、113、123、及127(支持的最大kmer)跑了后发现127在同样参数下contig N50最大)，下面是为了优化结果跑的。</span></span><br><span class="line"><span class="comment">#pregraph(d=1,2,3,4)</span></span><br><span class="line">nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer pregraph -s config_file -o PB_501_127_d_3 -R -K 127 -p 60 -d 2 &gt;PB_501_127_d_3_pre.log &amp;</span><br><span class="line">nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer contig -g PB_501_127_d_3 -R -p 60 &gt;PB_501_127_d_3_con.log &amp;</span><br><span class="line">nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer map -s config_file -g PB_501_127_d_3 -p 60 -k 127 &gt;PB_501_127_d_3_map.log &amp;  </span><br><span class="line">nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer scaff -g PB_501_127_d_3 -F -p 60 &gt;PB_501_127_d_3_scaf.log &amp;</span><br></pre></td></tr></table></figure>

<h2 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h2><p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/16.png" alt="img"></p>
<h2 id="组装评估"><a href="#组装评估" class="headerlink" title="组装评估"></a>组装评估</h2><p>QUAST软件下载:<a href="https://links.jianshu.com/go?to=https://sourceforge.net/projects/quast/files/quast-5.0.2.tar.gz/download">https://sourceforge.net/projects/quast/files/quast-5.0.2.tar.gz/download</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#解压安装</span></span><br><span class="line">tar -zxvf quast-5.0.2.tar.gz &amp;&amp; <span class="built_in">cd</span> quast-5.0.2</span><br><span class="line">python  setup.py install_full</span><br></pre></td></tr></table></figure>

<h3 id="参考基因组下载"><a href="#参考基因组下载" class="headerlink" title="参考基因组下载"></a>参考基因组下载</h3><h3 id="QUAST使用"><a href="#QUAST使用" class="headerlink" title="QUAST使用"></a>QUAST使用</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./tools/quast-5.0.2/quast.py -o ./quast_results -R ./reference/IRGSP-1.0_genome.fasta.gz -t 70 ./PB_501_results/PB_501_127_d_1/PB_501_127_d_1.scafSeq ./PB_501_results/PB_501_127_d_2/PB_501_127_d_2.scafSeq ./PB_501_results/PB_501_127_d_3/PB_501_127_d_3.scafSeq ./PB_501_results/PB_501_127_d_6/PB_501_127_d_6.scafSeq</span><br><span class="line"><span class="comment">#-o输出目录</span></span><br><span class="line"><span class="comment">#-R参考基因组序列</span></span><br><span class="line"><span class="comment">#-t线程数</span></span><br><span class="line"><span class="comment">#后面为要比较的contig/scaffold所在目录。</span></span><br></pre></td></tr></table></figure>

<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><h3 id="统计结果"><a href="#统计结果" class="headerlink" title="统计结果"></a>统计结果</h3><p>将contig/scaffold比对到参考基因组上，下面是比对得到的结果。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/17.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/18.png" alt="img"></p>
<p>累计长度:若与灰色线重合越好，组装结果越好。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/19.png" alt="img"></p>
<p>错误组装情况：</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/20.png" alt="img"></p>
<p>GC含量:</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/21.png" alt="img"></p>
<h3 id="contig-scaffold大小可视化"><a href="#contig-scaffold大小可视化" class="headerlink" title="contig/scaffold大小可视化"></a>contig/scaffold大小可视化</h3><p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/22.png" alt="img"></p>
<h3 id="比对到每条染色体情况"><a href="#比对到每条染色体情况" class="headerlink" title="比对到每条染色体情况"></a>比对到每条染色体情况</h3><p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/23.png" alt="img"></p>
<p>比对到每条染色体可视化情况:</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/24.png" alt="img"></p>
]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>sequence-tool</tag>
      </tags>
  </entry>
  <entry>
    <title>seqkit</title>
    <url>/blog/2022/02/24/2022-02-24-Seqkit/</url>
    <content><![CDATA[<h1 id="SeqKit-a-cross-platform-and-ultrafast-toolkit-for-FASTA-Q-file-manipulation"><a href="#SeqKit-a-cross-platform-and-ultrafast-toolkit-for-FASTA-Q-file-manipulation" class="headerlink" title="SeqKit - a cross-platform and ultrafast toolkit for FASTA/Q file manipulation"></a>SeqKit - a cross-platform and ultrafast toolkit for FASTA/Q file manipulation</h1><span id="more"></span>

<p><a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">Official doc</a></p>
<h1 id="Quick-Guide"><a href="#Quick-Guide" class="headerlink" title="Quick Guide"></a>Quick Guide</h1><ul>
<li>Basic: <a href="https://bioinf.shenwei.me/seqkit/usage/#seq">seq</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#stats">stats</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#subseq">subseq</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#sliding">sliding</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#faidx">faidx</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#watch">watch</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#sana">sana</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#scat">scat</a></li>
<li>Format conversion: <a href="https://bioinf.shenwei.me/seqkit/usage/#fq2fa">fq2fa</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">fx2tab</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">tab2fx</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#convert">convert</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#translate">translate</a></li>
<li>Searching: <a href="https://bioinf.shenwei.me/seqkit/usage/#grep">grep</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#locate">locate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#amplicon">amplicon</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fish">fish</a></li>
<li>Set operation: <a href="https://bioinf.shenwei.me/seqkit/usage/#sample">sample</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#rmdup">rmdup</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#common">common</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#duplicate">duplicate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#split">split</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#split2">split2</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#head">head</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#head-genome">head-genome</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#range">range</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#pair">pair</a></li>
<li>Edit: <a href="https://bioinf.shenwei.me/seqkit/usage/#concat">concat</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#replace">replace</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#restart">restart</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#mutate">mutate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#rename">rename</a></li>
<li>Ordering: <a href="https://bioinf.shenwei.me/seqkit/usage/#sort">sort</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#shuffle">shuffle</a></li>
<li>BAM processing: <a href="https://bioinf.shenwei.me/seqkit/usage/#bam">bam</a></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">conda install -c bioconda seqkit</span><br></pre></td></tr></table></figure>

<h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">amplicon        通过引物检索扩增子(或其周围的特定区域)</span><br><span class="line">bam             检查和在线绘制BAM记录文件的直方图</span><br><span class="line">common          通过id/名称/序列查找多个文件的公共序列</span><br><span class="line">concat          连接多个文件中具有相同ID的序列</span><br><span class="line">convert         转换FASTQ质量编码格式：支持格式包括：桑格，Solexa和Illumina</span><br><span class="line">duplicate       重复序列N次</span><br><span class="line">faidx           创建FASTA索引文件并提取子序列</span><br><span class="line">fish            使用局部比对在较大的序列中寻找短序列</span><br><span class="line">fq2fa           转换FASTQ到FASTA</span><br><span class="line">fx2tab          将FASTA/Q转换为表格格式(包含长度/GC含量/GC偏好)</span><br><span class="line">genautocomplete 生成shell自动完成脚本</span><br><span class="line">grep            通过ID/name/sequence/sequence motif搜索序列，允许错配</span><br><span class="line">head            打印第一条序列</span><br><span class="line"><span class="built_in">help</span>            打印帮助信息</span><br><span class="line">locate          定位序列，或者motifs，允许错配</span><br><span class="line">mutate          编辑序列(点突变、插入、删除)</span><br><span class="line">pair            匹配双端序列文件</span><br><span class="line">range           打印一个范围内的序列</span><br><span class="line">rename          重命名重复序列ID</span><br><span class="line">replace         使用正则表达式修改名称或者序列</span><br><span class="line">restart         重置环状基因组的起始位置</span><br><span class="line">rmdup           通过id/名称/序列删除重复的序列</span><br><span class="line">sample          按数量或比例对序列进行抽样</span><br><span class="line">sana            清理损坏的单行fastq文件</span><br><span class="line">scat            real time recursive concatenation and streaming of fastx files</span><br><span class="line">seq             转换序列(反向，补充，提取ID…)</span><br><span class="line">shuffle         随机序列</span><br><span class="line">sliding         序列滑窗提取，支持环形基因组</span><br><span class="line">sort            按id/名称/序列/长度排序序列</span><br><span class="line">split           按id/seq区域/大小/部件将序列拆分为文件(主要用于FASTA)</span><br><span class="line">split2          按序列数量/文件数将序列拆分为多个文件(FASTA, PE/SE FASTQ)</span><br><span class="line">stats           FASTA/Q文件的简单统计</span><br><span class="line">subseq          通过region/gtf/bed得到子序列，包括侧翼序列</span><br><span class="line">tab2fx          转换表格格式为FASTA/Q格式</span><br><span class="line">translate       翻译DNA/RNA到蛋白质序列(支持歧义碱基)</span><br><span class="line">version         打印版本信息并检查是否更新</span><br><span class="line">watch           序列特征的监测和在线直方图</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Parameter"><a href="#Parameter" class="headerlink" title="Parameter:"></a>Parameter:</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Flags:</span><br><span class="line">      --alphabet-guess-seq-length int   seqkit根据第一个FASTA记录猜测序列类型的序列前缀的长度(0表示整个序列)(默认10000)</span><br><span class="line">  -h, --<span class="built_in">help</span>                            显示帮助</span><br><span class="line">      --id-ncbi                         FASTA头是ncbi风格的，例如&gt;gi|110645304|ref|NC_002516.2 </span><br><span class="line">      --id-regexp string                用于解析ID的正则表达式(default <span class="string">&quot;^(\\S+)\\s?&quot;</span>)，匹配空格前的部分为序列名</span><br><span class="line">      --infile-list string              输入文件列表中的文件 (one file per line), <span class="keyword">if</span> given, they are appended to files from cli arguments</span><br><span class="line">  -w, --line-width int                  输出FASTA格式时的行宽 (0 <span class="keyword">for</span> no wrap) (default 60)</span><br><span class="line">  -o, --out-file string                 输出 (<span class="string">&quot;-&quot;</span> <span class="keyword">for</span> stdout, suffix .gz <span class="keyword">for</span> gzipped out) (default <span class="string">&quot;-&quot;</span>) -代表标准输出，加.gz可输出压缩文件</span><br><span class="line">      --quiet                           保持安静，不要显示额外的信息</span><br><span class="line">  -t, --seq-type string                 序列类型 (dna|rna|protein|<span class="built_in">unlimit</span>|auto) (auto, 按第一个序列自动检测) (default <span class="string">&quot;auto&quot;</span>)</span><br><span class="line">  -j, --threads int                     CPU数量 (默认单核为1，多核为2) (default 2)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="stats-FASTA-Q文件的简单统计"><a href="#stats-FASTA-Q文件的简单统计" class="headerlink" title="stats FASTA/Q文件的简单统计"></a>stats FASTA/Q文件的简单统计</h1><p>统计序列格式fa/fq、内容类型DNA/RNA/Protein，<font color="red">序列数量、总长度，最小、平均和最大长度</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># FASTA DNA</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nacgtryswkmbdhvACGTRYSWKMBDHV&quot;</span> | seqkit stats</span><br><span class="line">file  format  <span class="built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len</span><br><span class="line">-     FASTA   DNA          1       28       28       28       28</span><br><span class="line"></span><br><span class="line"><span class="comment"># RNA </span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nACGUN\nACGUN&quot;</span> | seqkit stats</span><br><span class="line">file  format  <span class="built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len</span><br><span class="line">-     FASTA   RNA          1       10       10       10       10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Protein</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nabcdefghijklmnpqrstvwyz&quot;</span> | seqkit stats</span><br><span class="line">file  format  <span class="built_in">type</span>     num_seqs  sum_len  min_len  avg_len  max_len</span><br><span class="line">-     FASTA   Protein         1       23       23       23       23</span><br><span class="line"></span><br><span class="line"><span class="comment"># FASTQ DNA</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;@read\nACTGCN\n+\n@IICCG&quot;</span> | seqkit stats</span><br><span class="line">file  format  <span class="built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len</span><br><span class="line">-     FASTQ   DNA          1        6        6        6        6</span><br><span class="line"></span><br><span class="line">file                             format  <span class="built_in">type</span>     num_seqs         sum_len  min_len  avg_len  max_len</span><br><span class="line">R1.fastq.gz  FASTQ   DNA   254,677,261  34,439,769,981       50    135.2      138</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 一般模式</span><br><span class="line">seqkit stats C1_1.fq.gz</span><br><span class="line">#--输出结果tab分隔</span><br><span class="line">seqkit stats C1_1.fq.gz -T</span><br><span class="line">#--输出文件转化其他格式</span><br><span class="line">seqkit stats C1_1.fq.gz -T| csvtk pretty -t</span><br><span class="line">seqkit stats C1_1.fq.gz -T| csvtk csv2md -t</span><br><span class="line"># 统计更多信息 -a</span><br><span class="line">seqkit stats C1_1.fq.gz -a</span><br><span class="line"># j多线程加速，尤其是对于具有多个序列文件会加速</span><br><span class="line"># seqkit stats -j 2 *.fq.gz</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="seq-转换序列-（反向、互补-提取ID）"><a href="#seq-转换序列-（反向、互补-提取ID）" class="headerlink" title="seq 转换序列 （反向、互补/提取ID）"></a>seq 转换序列 （反向、互补/提取ID）</h1><p>“-n”: 提取序列ID，包括“&gt;”后面的全部内容</p>
<p>“-n -i”: 仅提取第一个空格前的ID</p>
<h1 id="按长度过滤-常用"><a href="#按长度过滤-常用" class="headerlink" title="按长度过滤(常用)"></a>按长度过滤(常用)</h1><p>扩增子分析时要筛选扩增长度相近的片段，过长或过短一般都要删除。宏基因组中比如组装的结果，经常要过滤&lt;200/300bp的短片段，分箱时要筛选&gt;1000/2000的长片段使用。本条命令非常多的应用场景。筛选后结果可用 &gt; 写入文件</p>
<p>-m 按照序列长度过滤，表示保留的最小长度，-M 此为保留的最大长度</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#--提取序列长度大于60的并统计长度信息</span></span><br><span class="line">zcat hairpin.fa.gz | seqkit seq -m 60 | seqkit stats</span><br><span class="line"><span class="comment"># 设置最小序列长度和最大序列长度，用于过滤序列，并统计</span></span><br><span class="line">zcat hairpin.fa.gz | seqkit seq -m 100 -M 1000 | seqkit stats</span><br><span class="line"><span class="comment"># 保存&gt;100且&lt;1000长度的序列</span></span><br><span class="line">seqkit seq -m 100 -M 1000 hairpin.fa.gz &gt; hairpin100-1000.fa</span><br><span class="line">seqkit <span class="built_in">stat</span> hairpin100-1000.fa</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="提取ID"><a href="#提取ID" class="headerlink" title="提取ID"></a>提取ID</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">head gene.fa</span><br><span class="line"><span class="comment">## 名称全行</span></span><br><span class="line">seqkit seq gene.fa -n | head</span><br><span class="line"><span class="comment"># 仅仅打印ID</span></span><br><span class="line">seqkit seq gene.fa -n -i | head</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用正则表达式提取名字中的信息</span></span><br><span class="line">zcat hairpin.fa.gz | head</span><br><span class="line"><span class="comment"># 提取ID中第二个字段作为ID</span></span><br><span class="line">seqkit seq hairpin.fa.gz -n -i --id-regexp <span class="string">&quot;^[^\s]+\s([^\s]+)\s&quot;</span> | head</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="单行-多行转换"><a href="#单行-多行转换" class="headerlink" title="单行/多行转换"></a>单行/多行转换</h1><ul>
<li>-s提取并展示序列</li>
<li>-w 代表每行的碱基数量，0代表不换行</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#仅仅提取序列 -s</span></span><br><span class="line">seqkit seq gene.fa -s -w 0|head</span><br><span class="line"><span class="comment">#--将多行序列转化为标准4行FASTQ</span></span><br><span class="line">seqkit seq C1_1.fq.gz -w 0|head</span><br></pre></td></tr></table></figure>

<h1 id="反向-互补"><a href="#反向-互补" class="headerlink" title="反向/互补"></a>反向/互补</h1><ul>
<li>-r 序列反向</li>
<li>-p序列互补</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 序列反向互补,-r反向，-p互补</span></span><br><span class="line">seqkit seq hairpin.fa.gz -r -p|head</span><br></pre></td></tr></table></figure>

<h1 id="删除gap-大小写转换"><a href="#删除gap-大小写转换" class="headerlink" title="删除gap/大小写转换"></a>删除gap/大小写转换</h1><ul>
<li>-g 去除序列中的间隔,将中间的横杠去掉</li>
<li>-u转化序列为大写字母展示</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nACGT-ACTGC-acc&quot;</span> | seqkit seq -g -u</span><br></pre></td></tr></table></figure>

<h1 id="RNA转为DNA"><a href="#RNA转为DNA" class="headerlink" title="RNA转为DNA"></a>RNA转为DNA</h1><ul>
<li>—rna2dna 将RNA序列转化为DNA序列</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nUCAUAUGCUUGUCUCAAAGAUUA&quot;</span> | seqkit seq --rna2dna</span><br></pre></td></tr></table></figure>

<h1 id="subseq通过指定区域"><a href="#subseq通过指定区域" class="headerlink" title="subseq通过指定区域"></a>subseq通过指定区域</h1><ul>
<li>-r 通过区域来截取序列</li>
</ul>
<p>如1:12提取前12个碱基，-12:-1提取序列结尾12个碱基；<br>for last 12 bases, 13:-1 for cutting first 12 bases. type “seqkit subseq -h” for more examples</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#-提取序列前1：12个碱基</span><br><span class="line">zcat C1_1.fq.gz | seqkit subseq -r 1:12 |head</span><br><span class="line">#-提取序列最后1：12个碱基</span><br><span class="line">zcat C1_1.fq.gz | seqkit subseq -r -12:-1 |head</span><br><span class="line"> </span><br><span class="line">#取第12至倒数第12个碱基，即前11和后11个碱基去掉</span><br><span class="line">zcat C1_1.fq.gz | seqkit subseq -r 12:-12| head</span><br></pre></td></tr></table></figure>

<p>基于gtf/bed信息挑选子序列。</p>
<p>—gtf  根据gtf文件挑选基因，这部分功能用于根据基因注释快速提取基因序列，在宏基因组、转录组、重测序中常用。—chr 选择染色体，—feature cds选择序列类型</p>
<p>以拟南芥基因组的序列和注释数据演示：提取第一条染色体上的CDS基因信息，并统计基本信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit subseq --gtf Arabidopsis_thaliana.TAIR10.49.gtf.gz --chr 1 --feature cds  Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz  &gt; chr1.gtf.cds.fa</span><br><span class="line">seqkit stats chr1.gtf.cds.fa</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>-u 可以提取目标基因上游的序列</li>
<li>-f 目标区域不展示</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#--挑选序列并多加上上游的3个碱基</span><br><span class="line">seqkit subseq --gtf Arabidopsis_thaliana.TAIR10.49.gtf.gz Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz -u 3 |head</span><br><span class="line"> </span><br><span class="line"># 仅提取上游序列，如提取启动子区2k：-f仅定位不输出位置序列，-u输出上游序列，此处示例3bp</span><br><span class="line">seqkit subseq --gtf Arabidopsis_thaliana.TAIR10.49.gtf.gz Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz -u 3 -f |head</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="sliding-滑窗提取序列，支持环状基因组"><a href="#sliding-滑窗提取序列，支持环状基因组" class="headerlink" title="sliding 滑窗提取序列，支持环状基因组"></a>sliding 滑窗提取序列，支持环状基因组</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#-s 步长为3，-W 序列长度为6个碱基</span><br><span class="line">echo -e &quot;&gt;seq\nACGTacgtNN&quot; | seqkit sliding -s 3 -W 6</span><br><span class="line"># -g 贪婪模式，后面不足6个那也取</span><br><span class="line">echo -e &quot;&gt;seq\nACGTacgtNN&quot; | seqkit sliding -s 3 -W 6 -g</span><br><span class="line"># 环状DNA模式-C，首尾不算中断，环状</span><br><span class="line">echo -e &quot;&gt;seq\nACGTacgtNN&quot; | seqkit sliding -s 3 -W 6 -C</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>步长为5，取30个碱基序列，然后统计GC含量</li>
</ul>
<ul>
<li>fx2tab：统计fasta/fastq序列的信息为表格</li>
<li>-n仅输出ID，不输出序列</li>
<li>-g为GC含量</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zcat hairpin.fa.gz | seqkit sliding -s 5 -W 30 | seqkit fx2tab -n -g |head</span><br></pre></td></tr></table></figure>

<h1 id="faidx-创建FASTA索引文件并提取子序列"><a href="#faidx-创建FASTA索引文件并提取子序列" class="headerlink" title="faidx 创建FASTA索引文件并提取子序列"></a>faidx 创建FASTA索引文件并提取子序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 解压</span><br><span class="line">zcat hairpin.fa.gz &gt; hairpin.fa</span><br><span class="line"> </span><br><span class="line"># 建索引*.fai文件</span><br><span class="line">seqkit faidx hairpin.fa</span><br><span class="line"> </span><br><span class="line"># ID信息：hsa-let-7a-1 hsa-let-7a-2</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1 hsa-let-7a-2</span><br><span class="line"># -f 标题行全部显示</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1 hsa-let-7a-2 -f</span><br><span class="line"># 提取序列并选择区域显示</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1:1-10</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1:-10--1</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1:1</span><br><span class="line"># 检查hsa开头的序列并统计</span><br><span class="line">seqkit faidx hairpin.fa hsa -r | seqkit stats</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="watch-序列质量的监测和在线直方图"><a href="#watch-序列质量的监测和在线直方图" class="headerlink" title="watch 序列质量的监测和在线直方图"></a>watch 序列质量的监测和在线直方图</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#-取对数展示直方图</span><br><span class="line">seqkit watch -L -f ReadLen hairpin.fa</span><br><span class="line"> </span><br><span class="line"># 每五千个做一个图保存在pdf文件中</span><br><span class="line">seqkit watch -p 500000 -O qhist.pdf -f MeanQual C1_1.fq.gz</span><br></pre></td></tr></table></figure>

<p>从有错误记录的fastq文件中挽救可用的读取</p>
<h1 id="sana：清理损坏fastq文件"><a href="#sana：清理损坏fastq文件" class="headerlink" title="sana：清理损坏fastq文件"></a>sana：清理损坏fastq文件</h1><p>这里我专门将C1_1.fq的第一个序列进行了错位，进行测试。这个操作往往在进行数据整合的时候可以有很大作用。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zcat C1_1.fq.gz|sed &#x27;2 s/^/A/&#x27; &gt; C1_1_bad.fq</span><br><span class="line">seqkit sana C1_1_bad.fq -o rescued.fq.gz</span><br></pre></td></tr></table></figure>

<h1 id="fq2fa-将fq转为fa格式"><a href="#fq2fa-将fq转为fa格式" class="headerlink" title="fq2fa 将fq转为fa格式"></a>fq2fa 将fq转为fa格式</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit fq2fa C1_1.fq.gz -o C1_1.fa</span><br></pre></td></tr></table></figure>

<h1 id="fx2tab-amp-tab2fx-序列转化表格格式"><a href="#fx2tab-amp-tab2fx-序列转化表格格式" class="headerlink" title="fx2tab &amp; tab2fx 序列转化表格格式"></a>fx2tab &amp; tab2fx 序列转化表格格式</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">这一转化很有用，往往用于表格/矩阵处理的时候。</span><br><span class="line">seqkit fx2tab hairpin.fa.gz | head -n 2</span><br><span class="line">通过矩阵格式的序列文件统计序列长度和质量值</span><br><span class="line"></span><br><span class="line">-l 统计序列长度</span><br><span class="line"></span><br><span class="line">-g 统计平均GC含量</span><br><span class="line"></span><br><span class="line">-i 只打印名称(不打印序列)</span><br><span class="line"></span><br><span class="line">-H 打印标题行</span><br><span class="line"># 打印序列长度、GC含量</span><br><span class="line">seqkit fx2tab hairpin.fa.gz -l -g -n -i -H | head</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>tab2fx 和表格格式转化为序列格式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># seqkit tab2fx 表格形式转化为序列形式</span><br><span class="line">zcat hairpin.fa.gz | seqkit fx2tab | seqkit tab2fx | head</span><br><span class="line"> </span><br><span class="line"># 转化为表格，然后排序，然后转化回去</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit fx2tab -l \</span><br><span class="line">    | sort -t &quot;`echo -e &#x27;\t&#x27;`&quot; -n -k4,4 \</span><br><span class="line">    | seqkit tab2fx | head</span><br><span class="line"># 等同于下面的命令</span><br><span class="line">seqkit sort -l hairpin.fa.gz | head</span><br><span class="line"> </span><br><span class="line"># 通过这个转化可以将很多在表格中实现的数据处理方法用于序列</span><br><span class="line">例如下面的提取1000个序列：seqkit fx2tab hairpin.fa.gz | head -n 1000 | seqkit tab2fx | head</span><br></pre></td></tr></table></figure>

<h1 id="translate-翻译DNA-RNA为蛋白质序列"><a href="#translate-翻译DNA-RNA为蛋白质序列" class="headerlink" title="translate 翻译DNA/RNA为蛋白质序列"></a>translate 翻译DNA/RNA为蛋白质序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#--转化为蛋白序列</span><br><span class="line">seqkit translate gene.fa|head</span><br><span class="line"> </span><br><span class="line"># 去除&#x27;X&#x27; 和 &#x27;*&#x27;</span><br><span class="line">seqkit translate hairpin.fa </span><br><span class="line">seqkit translate hairpin.fa --trim | head</span><br></pre></td></tr></table></figure>

<h1 id="grep-序列匹配"><a href="#grep-序列匹配" class="headerlink" title="grep  序列匹配"></a>grep  序列匹配</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 生成一个ID列表</span><br><span class="line">grep &#x27;&gt;&#x27; C1_1.fa|cut -c2-|head -n 10 &gt; id.txt</span><br><span class="line"> </span><br><span class="line"># 使用序列id列表进行搜索(不包含空格)</span><br><span class="line">seqkit grep -f id.txt C1_1.fq.gz -o result.fq.gz</span><br><span class="line"># 使用序列名称列表进行搜索(它们可能包含空格)</span><br><span class="line">seqkit grep -n -f id.txt C1_1.fq.gz -o result.fa.gz</span><br><span class="line">zcat  result.fa.gz</span><br><span class="line"># 提取hsa开头的序列</span><br><span class="line">zcat hairpin.fa.gz | seqkit grep -r -p ^hsa |head</span><br><span class="line"> </span><br><span class="line"># -v参数v用于移除序列</span><br><span class="line">zcat hairpin.fa.gz | seqkit grep -r -p ^hsa -p ^mmu -v | head</span><br><span class="line"> </span><br><span class="line"># 提取ID</span><br><span class="line">zcat miRNA.diff.gz | grep ^# -v | grep NEW | cut -f 2 &gt; list</span><br><span class="line">head list</span><br><span class="line"># 根据ID提取文件</span><br><span class="line">zcat hairpin.fa.gz | seqkit grep -f list &gt; new.fa</span><br><span class="line">head new.fa</span><br><span class="line"> </span><br><span class="line"># 提取包含特定碱基组合的序列</span><br><span class="line">cat hairpin.fa.gz | seqkit grep -s -i -p aggcg |head</span><br><span class="line"># 统计</span><br><span class="line">cat hairpin.fa.gz | seqkit grep -s -i -p aggcg | seqkit stats</span><br><span class="line"> </span><br><span class="line">#  去除 包含特定组合碱基的序列</span><br><span class="line">zcat hairpin.fa.gz | seqkit grep -s -r -i -p ^aggcg |head</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="locate-输出匹配位置"><a href="#locate-输出匹配位置" class="headerlink" title="locate 输出匹配位置"></a>locate 输出匹配位置</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">＃　其他两种输出格式</span><br><span class="line">zcat hairpin.fa.gz | seqkit locate -i -d -p AUGGACUN --bed</span><br><span class="line">zcat hairpin.fa.gz | seqkit locate -i -d -p AUGGACUN --gtf</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="fish-使用局部比对在较大的序列中寻找短序列"><a href="#fish-使用局部比对在较大的序列中寻找短序列" class="headerlink" title="fish 使用局部比对在较大的序列中寻找短序列"></a>fish 使用局部比对在较大的序列中寻找短序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -e &#x27;&gt;seq\nACGACGACGA&#x27; \</span><br><span class="line">    | seqkit locate -p ACGA -G | csvtk -t pretty</span><br><span class="line"> </span><br><span class="line">echo -e &#x27;&gt;seq\nACGACGACGA&#x27; \</span><br><span class="line">    | seqkit fish -F ACGA -a 2&gt;&amp;1 | csvtk -t pretty</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="amplicon-通过引物检索扩增子-或其周围的特定区域"><a href="#amplicon-通过引物检索扩增子-或其周围的特定区域" class="headerlink" title="amplicon 通过引物检索扩增子(或其周围的特定区域)"></a>amplicon 通过引物检索扩增子(或其周围的特定区域)</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -ne &quot;&gt;seq\nacgcccactgaaatga\n&quot; \</span><br><span class="line">    | seqkit amplicon -F ccc -R ttt</span><br><span class="line"> </span><br><span class="line"># 设置输出格式为bed，匹配的位点等信息</span><br><span class="line">echo -ne &quot;&gt;seq\nacgcccactgaaatga\n&quot; \</span><br><span class="line">    | seqkit amplicon -F ccc -R ttt --bed</span><br><span class="line"> </span><br><span class="line">#- 使用引物文件，这用于刘老师组的高通量分菌的序列拆分速度应该很客观</span><br><span class="line"># cat seqs4amplicon.fa | seqkit amplicon -p primers.tsv --bed</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 输出除去引物之外的部分，-r输出几个碱基</span><br><span class="line">echo -ne &quot;&gt;seq\nacgcccactgaaatga\n&quot; \</span><br><span class="line">    | seqkit amplicon -F ccc -R ttt -r 4:7</span><br><span class="line"># 输出格式为bed</span><br><span class="line">echo -ne &quot;&gt;seq\nacgcccactgaaatga\n&quot; \</span><br><span class="line">    | seqkit amplicon -F ccc -R ttt -r 4:7 --bed</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="duplicate-对序列重复N次"><a href="#duplicate-对序列重复N次" class="headerlink" title="duplicate 对序列重复N次"></a>duplicate 对序列重复N次</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 重复序列1次，但是名字没有修改</span><br><span class="line">cat hairpin.fa | seqkit head -n 1 \</span><br><span class="line">    | seqkit duplicate -n 2</span><br><span class="line"># 对重复序列改名，使其独一无二</span><br><span class="line">cat hairpin.fa | seqkit head -n 1 \</span><br><span class="line">    | seqkit duplicate -n 2 | seqkit rename</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="rmdup-通过id-名称-序列删除重复的序列"><a href="#rmdup-通过id-名称-序列删除重复的序列" class="headerlink" title="rmdup 通过id/名称/序列删除重复的序列"></a>rmdup 通过id/名称/序列删除重复的序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 去除重复的序列</span><br><span class="line">zcat hairpin.fa.gz | seqkit rmdup -s -o clean.fa.gz</span><br><span class="line"> </span><br><span class="line"># 保存重复序列得到文件 -D duplicated.detail.txt</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit rmdup -s -i -o clean.fa.gz -d duplicated.fa.gz -D duplicated.detail.txt</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="common-：通过id-名称-序列查找多个文件的公共序列"><a href="#common-：通过id-名称-序列查找多个文件的公共序列" class="headerlink" title="common ：通过id/名称/序列查找多个文件的公共序列"></a>common ：通过id/名称/序列查找多个文件的公共序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 通过ID匹配，文件夹下全部的fa序列公共部分输出来</span><br><span class="line">seqkit common *.fq.gz</span><br><span class="line"> </span><br><span class="line"># 通过-n实现全部名字匹配，-o输出结果</span><br><span class="line">seqkit common *.fq.gz -n -o common.fq </span><br><span class="line"># 通过-s序列匹配</span><br><span class="line">seqkit common *.fq.gz -s -i -o common.fq</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="split-拆分序列为子文件"><a href="#split-拆分序列为子文件" class="headerlink" title="split 拆分序列为子文件"></a>split 拆分序列为子文件</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">按名称ID、给定区域的子序列、文件大小或序列数量将序列拆分为文件</span><br><span class="line"></span><br><span class="line">可用于将大文件拆分后，并行处理，加速分析。如从contig中预测基因。</span><br><span class="line">#按照10000个序列为一个文件拆分，结果为hairpin.fa.gz.split/目录 ，文件名为hairpin.part_00x.fasta，-s</span><br><span class="line">seqkit split hairpin.fa.gz -s 10000 -2</span><br><span class="line"> </span><br><span class="line"># 将序列拆分为四个部分(常用，等分然后并行)</span><br><span class="line">seqkit split hairpin.fa.gz -p 5 -2</span><br><span class="line"> </span><br><span class="line"># 复杂一点的就是按照ID区分</span><br><span class="line">seqkit split hairpin.fa.gz -i --id-regexp &quot;^([\w]+)\-&quot; -2</span><br><span class="line"> </span><br><span class="line"># 按照前三个序列碱基来区分</span><br><span class="line">seqkit split hairpin.fa.gz -r 1:3 -2</span><br></pre></td></tr></table></figure>

<h1 id="split2-拆分文件-升级版本"><a href="#split2-拆分文件-升级版本" class="headerlink" title="split2 拆分文件 升级版本"></a>split2 拆分文件 升级版本</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Flags:</span><br><span class="line">  -l, --by-length string   split sequences into chunks of &gt;=N bases, supports K/M/G suffix</span><br><span class="line">  -p, --by-part int        按照拆分出来的数量，比如：拆分成两个子文件2。-s, --by-size int        按照序列数量拆分</span><br><span class="line">  -f, --force              强制覆盖文件</span><br><span class="line">  -h, --help               查看帮助文件</span><br><span class="line">  -O, --out-dir string     输出文件夹 (default value is $infile.split)</span><br><span class="line">  -1, --read1 string       (gzipped) 双端序列第一个</span><br><span class="line">  -2, --read2 string       (gzipped) 双端序列第二个</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>同时支持fa和fq文件。单端和双端序列拆分实例</p>
<p>-f强制覆盖结果，适合重复计算时使用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit split2 hairpin.fa.gz -s 10000 -f</span><br><span class="line"> </span><br><span class="line"># 双端序列拆分(重点)，p指定拆分数量，-O指定输出目录，-f覆盖结果，默认为压缩</span><br><span class="line">seqkit split2 -1 C1_1.fq.gz -2 C1_2.fq.gz -p 2 -O out -f</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="pair-拼接两个fastq文件"><a href="#pair-拼接两个fastq文件" class="headerlink" title="pair 拼接两个fastq文件"></a>pair 拼接两个fastq文件</h1><p>留下匹配的，去除不匹配的，这里我们使用扩增子的双端序列做一个演示：</p>
<p>注意：双端序列在两个文件中的顺序最好是一样的，否则会消耗大量内存去匹配。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit pair -1 C1_1.fq.gz -2 C1_2.fq.gz -O result</span><br><span class="line"># -u 输出未匹配上的文件</span><br><span class="line">seqkit pair -1 C1_1.fq.gz -2 C1_2.fq.gz -O result -u -f</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="sample-按数量或比例对序列进行抽样。"><a href="#sample-按数量或比例对序列进行抽样。" class="headerlink" title="sample 按数量或比例对序列进行抽样。"></a>sample 按数量或比例对序列进行抽样。</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">按照百分比例和序列数量进行抽样</span><br><span class="line"># 抽样百分之十</span><br><span class="line">zcat C1_1.fq.gz | seqkit sample -p 0.1 -o sample.fq.gz</span><br><span class="line"># 抽样1000条</span><br><span class="line">zcat C1_1.fq.gz | seqkit sample -n 1000 -o sample.fq.gz</span><br><span class="line"></span><br><span class="line">注意：1000条并不是很准确，可能是900多条，为什么呢？看这里了解问题。https://bioinf.shenwei.me/seqkit/note/#effect-of-random-seed-on-results-of-seqkit-sample</span><br></pre></td></tr></table></figure>



<p>这里为大家展示一下减少内存的序列抽样方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 抽样 seqkit sample </span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit sample -p 0.1 \</span><br><span class="line">    | seqkit head -n 1000 -o sample.fa.gz</span><br><span class="line"> </span><br><span class="line"># 设置随机种子，方便重复结果: -s 11</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit sample -p 0.1 -s 11 |head</span><br><span class="line"> </span><br><span class="line"># 抽样后打乱序列 :seqkit shuffle</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit sample -p 0.1 \</span><br><span class="line">    | seqkit shuffle -o sample.fa.gz</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="range-打印序列-按照一个范围"><a href="#range-打印序列-按照一个范围" class="headerlink" title="range 打印序列 按照一个范围"></a>range 打印序列 按照一个范围</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 打印一个范围内的序列</span><br><span class="line">cat hairpin.fa | seqkit range -r 1:10</span><br><span class="line"># 打印最后几行的序列</span><br><span class="line">cat hairpin.fa | seqkit range -r -100:-1 | seqkit stats</span><br><span class="line"># 打印中间范围的序列</span><br><span class="line">cat hairpin.fa | seqkit range -r 101:150 | seqkit stats</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="repeat-使用正则表达式替换名称-序列。"><a href="#repeat-使用正则表达式替换名称-序列。" class="headerlink" title="repeat 使用正则表达式替换名称/序列。"></a>repeat 使用正则表达式替换名称/序列。</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改序列名称：删除空格后内存</span><br><span class="line">echo -e &quot;&gt;seq1 abc-123\nACGT-ACGT&quot; \</span><br><span class="line">    | seqkit replace -p &quot;\s.+&quot;</span><br><span class="line"> </span><br><span class="line"># 修改序列名：替换</span><br><span class="line">echo -e &quot;&gt;seq1 abc-123\nACGT-ACGT&quot; \</span><br><span class="line">    | seqkit replace -p &quot;\-&quot; -r &#x27;=&#x27;</span><br><span class="line"> </span><br><span class="line"># 修改序列：去除序列间隔</span><br><span class="line">echo -e &quot;&gt;seq1 abc-123\nACGT-ACGT&quot; \</span><br><span class="line">    | seqkit replace -p &quot; |-&quot; -s</span><br><span class="line"> </span><br><span class="line"># 修改序列：给每一个碱基加上空格</span><br><span class="line">echo -e &quot;&gt;seq1 abc-123\nACGT-ACGT&quot; \</span><br><span class="line">    | seqkit replace -p &quot;(.)&quot; -r &#x27;$1 &#x27; -s</span><br><span class="line"> </span><br><span class="line"># 使用字符加数据重命名序列-用于扩增子代表序列改名非常优秀</span><br><span class="line">echo -e &quot;&gt;abc\nACTG\n&gt;123\nATTT&quot; \</span><br><span class="line">    |  seqkit replace -p .+ -r &quot;ASV_&#123;nr&#125;&quot;</span><br><span class="line"> </span><br><span class="line">echo -e &quot;&gt;abc\nACTG\n&gt;123\nATTT&quot; \</span><br><span class="line">    |  seqkit replace -p .+ -r &quot;SAV_&#123;nr&#125;&quot; --nr-width 5</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="rename-重命名重复的ID"><a href="#rename-重命名重复的ID" class="headerlink" title="rename 重命名重复的ID"></a>rename 重命名重复的ID</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 重命名：相同序列会在后面加上_2 来处理</span><br><span class="line">echo -e &quot;&gt;a comment\nacgt\n&gt;b comment of b\nACTG\n&gt;a comment\naaaa&quot; \</span><br><span class="line">    | seqkit rename</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="concat-连接多个文件中具有相同ID的序列"><a href="#concat-连接多个文件中具有相同ID的序列" class="headerlink" title="concat 连接多个文件中具有相同ID的序列"></a>concat 连接多个文件中具有相同ID的序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#这里演示组合前面两个碱基和最后两个碱基的用法</span><br><span class="line">seqkit concat &lt;(seqkit subseq -r 1:2 C1_1.fq.gz) &lt;(seqkit subseq -r -2:-1 C1_2.fq.gz)|head</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="shuffle-随机打乱序列-默认全部读入内存"><a href="#shuffle-随机打乱序列-默认全部读入内存" class="headerlink" title="shuffle 随机打乱序列 默认全部读入内存"></a>shuffle 随机打乱序列 默认全部读入内存</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit shuffle hairpin.fa.gz -2  &gt; shuffled.fa</span><br></pre></td></tr></table></figure>



<h1 id="sort-按id-名称-序列-长度排序序列"><a href="#sort-按id-名称-序列-长度排序序列" class="headerlink" title="sort 按id/名称/序列/长度排序序列"></a>sort 按id/名称/序列/长度排序序列</h1><p>—quiet 屏幕不输出过程</p>
<p>-i 排序忽略大小写</p>
<p>-l 按照序列长度排序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ID排序</span><br><span class="line">echo -e &quot;&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAA&quot; \</span><br><span class="line">    | seqkit sort --quiet</span><br><span class="line"> </span><br><span class="line"># 按照ID排序，忽略大小写</span><br><span class="line">echo -e &quot;&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAA&quot; \</span><br><span class="line">    | seqkit sort --quiet -i</span><br><span class="line"> </span><br><span class="line"># 按照序列长度排序，由小到大</span><br><span class="line">echo -e &quot;&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAAnnn\n&gt;seq3\nacgt&quot; \</span><br><span class="line">    | seqkit sort --quiet -l</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="mutate-编辑序列-点突变、插入、删除"><a href="#mutate-编辑序列-点突变、插入、删除" class="headerlink" title="mutate 编辑序列(点突变、插入、删除)"></a>mutate 编辑序列(点突变、插入、删除)</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot;</span><br><span class="line"> </span><br><span class="line"># 修改第一个碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -p 1:x</span><br><span class="line"> </span><br><span class="line"># 修改第五个位置的碱基，输出信息隐藏    </span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -p 5:x --quiet</span><br><span class="line"> </span><br><span class="line"># 可以同时修改多个碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -p 1:x -p -1:x --quiet</span><br><span class="line"> </span><br><span class="line"># 删除碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -d 1:1 --quiet</span><br><span class="line"> </span><br><span class="line"># 删除倒数三个碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -d -3:-1 --quiet</span><br><span class="line"> </span><br><span class="line"># 插入碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -i 0:xx --quiet</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="head-展示开头N行的序列"><a href="#head-展示开头N行的序列" class="headerlink" title="head 展示开头N行的序列"></a>head 展示开头N行的序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit head -n 1 hairpin.fa.gz</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="locate-定位子序列或者保守序列位置"><a href="#locate-定位子序列或者保守序列位置" class="headerlink" title="locate 定位子序列或者保守序列位置"></a>locate 定位子序列或者保守序列位置</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat gene.fa | seqkit locate -p ACT | csvtk pretty -t</span><br><span class="line"># 调整错配 最大错配为1</span><br><span class="line">cat gene.fa \</span><br><span class="line">  | seqkit locate -p ACTG -m 1 \</span><br><span class="line">  | csvtk pretty -t</span><br><span class="line"> </span><br><span class="line"># 简并碱基</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit locate -i -d -p AUGGACUN \</span><br><span class="line">    | head -n 4</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="restart-重置循环基因组的起始位置"><a href="#restart-重置循环基因组的起始位置" class="headerlink" title="restart 重置循环基因组的起始位置"></a>restart 重置循环基因组的起始位置</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -e &quot;&gt;seq\nacgtnACGTN&quot;</span><br><span class="line"> </span><br><span class="line">echo -e &quot;&gt;seq\nacgtnACGTN&quot; | seqkit restart -i 2</span><br><span class="line">echo -e &quot;&gt;seq\nacgtnACGTN&quot; | seqkit restart -i -2</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="convet-二代测序质量值的转化为-Sanger"><a href="#convet-二代测序质量值的转化为-Sanger" class="headerlink" title="convet 二代测序质量值的转化为 Sanger"></a>convet 二代测序质量值的转化为 Sanger</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Illumina-1.8+ -&gt; Sanger</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz  | seqkit head -n 1</span><br><span class="line"># 40分以上的都认为40 Illumina-1.8+ -&gt; Sanger</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz -f | seqkit head -n 1</span><br><span class="line"> </span><br><span class="line">#Illumina-1.8+ -&gt; Illumina-1.5+</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz --to Illumina-1.5+ | seqkit head -n 1</span><br><span class="line"> </span><br><span class="line"># Illumina-1.8+ -&gt; Illumina-1.5+ -&gt;  Sanger.</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz --to Illumina-1.5+ | seqkit convert | seqkit head -n 1</span><br><span class="line"> </span><br><span class="line"># Solexa -&gt; Sanger</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz --from Solexa</span><br><span class="line"> </span><br><span class="line"># Illumina-1.5+ -&gt; Sanger</span><br><span class="line"># seqkit convert tests/Illimina1.5.fq | seqkit head -n 1</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="技术细节和使用"><a href="#技术细节和使用" class="headerlink" title="技术细节和使用"></a>技术细节和使用</h1><p>seqkit处理压缩文件</p>
<p>pigz 或者 gzip 在部分操作中不能加速，所以在v.0.8.1版本以便关注了，然而还是可以使用命令：</p>
<p>pigz -d -c seqs.fq.gz | seqkit xxx<br>因为seqkit使用了pgzip去写gzip。这比gzip和pigz更快。（10X of gzip, 4X of pigz），而且gzip压缩文件比较大。</p>
<p>从数据处理格式来讲</p>
<p>seqkit无缝支持fa和fq格式数据，并且可以自动识别。除了 faidx之外，全部命令都可以处理这两种格式的数据。</p>
<p>只有fa格式支持命令(subseq, split, sort和shuffle)利用FASTA索引(by flag -two-pass)下提高大文件的性能。</p>
<p>序列类型的检测DNA/RNA/Protein，会使用子序列进行，默认检测第一条子序列，通过—alphabet-guess-seq-length参数默认为10000，如果长度小于10000，则检查整条序列。</p>
<p>序列名字</p>
<p>所有的软件，包括seqkit，使用第一个空格之前的字符作为序列的名字：<br>需要注意的NCBI等一些序列的格式并不是如此，例如：</p>
<blockquote>
<p>gi|110645304|ref|NC_002516.2| Pseudomona<br>想要在seqkit中识别出来的序列ID为：NC_002516.2。</p>
</blockquote>
<p>此时使用参数–id-regexp “|([^|]+)| “，或者添加参数–id-ncbi，但如果是只要前面的gi数字作为ID的话，添加参数：–id-regexp “^gi|([^|]+)|“。</p>
<p>注意：.seqkit.fai不同于samtools产生的.fai格式文件，seqkit使用整个序列开头而不是ID作为索引。</p>
<p>并行运算</p>
<p>单核CPU默认线程：—threads 1，多个CPU，线程默认2.</p>
<p>内存占用</p>
<p>seqkit许多的命令都不需要将整个序列读入到内存中。包括：stat, fq2fa, fx2tab, tab2fx, grep, locate, replace, seq, sliding, subseq。</p>
<p>注意：如果使用subseq —gtf | —bed时，如果GTF或者BED文件太大，内存使用量会暴增，可以通过指定染色体：—chr，或者—feature去限制特征。</p>
<p>有一些命令需要将文件读入内存，但是可以用过rmdup 和 common减少内存使用。</p>
<p>随机—抽样</p>
<p>抽样命令sample和shuffle使用了随机功能，为了保证重现性，可以使用-s设置随机种子。这可以保证在不同的环境中可以有相同的抽样结果。</p>
<h1 id="序列长度分布"><a href="#序列长度分布" class="headerlink" title="序列长度分布"></a>序列长度分布</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -j 是线程数</span></span><br><span class="line">seqkit fx2tab -j 30 -l  -n -i -H file.fastq.gz | cut -f 4 &gt; Length.txt</span><br><span class="line"><span class="comment"># 查看Length.txt</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library(tidyverse)</span><br><span class="line"></span><br><span class="line">length &lt;- read_tsv(<span class="string">&quot;Length.txt&quot;</span>) %&gt;% group_by(<span class="built_in">length</span>) %&gt;%</span><br><span class="line">  summarise(Count = n())</span><br><span class="line"><span class="built_in">length</span>$length &lt;- <span class="built_in">as.character</span>(<span class="built_in">length</span>$<span class="built_in">length</span>)</span><br><span class="line">sum &lt;- <span class="built_in">sum</span>(<span class="built_in">length</span>$Count)</span><br><span class="line">ggplot(<span class="built_in">length</span>) + geom_col(aes(<span class="built_in">length</span>, Count), width = <span class="number">0.8</span>) + </span><br><span class="line">  geom_line(aes(<span class="built_in">length</span>, Count), group = <span class="number">1</span>) + geom_point(aes(<span class="built_in">length</span>, Count)) + </span><br><span class="line">  scale_y_continuous(sec.axis = sec_axis(~.*<span class="number">100</span>/<span class="built_in">sum</span>, name = <span class="string">&quot;% Relative Abundance&quot;</span>)) + xlab(<span class="string">&quot;Length&quot;</span>) +</span><br><span class="line">  theme_bw() + theme(panel.grid = element_blank(), </span><br><span class="line">                     axis.title = element_text(size = <span class="number">15</span>))</span><br><span class="line"></span><br><span class="line">ggsave(<span class="string">&quot;Length.png&quot;</span>, height = <span class="number">5</span>, width = <span class="number">8</span>)</span><br><span class="line">ggsave(<span class="string">&quot;Length.pdf&quot;</span>, height = <span class="number">5</span>, width = <span class="number">8</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>sequence-tool</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 内存 存储</title>
    <url>/blog/2022/02/24/2022-02-24-memory/</url>
    <content><![CDATA[<h1 id><a href="#" class="headerlink" title></a></h1><span id="more"></span>

<h1 id="内存是什么"><a href="#内存是什么" class="headerlink" title="内存是什么"></a>内存是什么</h1><ul>
<li><p>内存又称主存，是 CPU 能直接寻址的存储空间，由半导体器件制成</p>
</li>
<li><p>内存的特点是存取速率快</p>
</li>
<li><p>CPU、IO、磁盘、内存可以说是影响计算机性能关键因素</p>
</li>
<li><p>内存为进程的运行提供物理空间，同时作为快速CPU和慢速磁盘之间的适配器，</p>
</li>
</ul>
<h1 id="内存的作用"><a href="#内存的作用" class="headerlink" title="内存的作用"></a>内存的作用</h1><ul>
<li><p>暂时存放 cpu 的运算数据</p>
</li>
<li><p>硬盘等外部存储器交换的数据</p>
</li>
<li><p>保障 cpu 计算的稳定性和高性能</p>
</li>
</ul>
<h1 id="查看内存情况"><a href="#查看内存情况" class="headerlink" title="查看内存情况"></a>查看内存情况</h1><p>free命令是一个快速查看内存使用情况的方法，它是对 /proc/meminfo 收集到的信息的一个概述。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">free -h</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zds@ubuntu ~ $ free -m   <span class="comment"># 以 Mb 为单位显示</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line"><span class="comment"># 物理内存</span></span><br><span class="line">Mem:           2990        1528         383          49        1078        1217</span><br><span class="line"><span class="comment"># 虚拟内存</span></span><br><span class="line">Swap:          2044           0        2044</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zds@ubuntu ~ $ top</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">top - 23:43:07 up 32 min,  1 user,  load average: 0.17, 0.36, 0.34</span><br><span class="line">Tasks: 230 total,   1 running, 229 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s): 12.9 us,  5.6 sy,  0.0 ni, 81.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem :  2029876 total,   148224 free,   998788 used,   882864 buff/cache</span><br><span class="line">KiB Swap:  2094076 total,  2087304 free,     6772 used.   819128 avail Mem </span><br><span class="line"></span><br><span class="line">   PID 进程号    PR 优先级  VIRT 进程占用的虚拟内存值</span><br><span class="line">       USER 进程所有者              RES 进程占用的物理内存值</span><br><span class="line">                     NI 优先级相对值       SHR 进程使用的共享内存值</span><br><span class="line"></span><br><span class="line">   PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND</span><br><span class="line">   978 root      20   0  356740  84104  37752 S  8.9  4.1   0:19.39 Xorg    </span><br><span class="line">  1909 zds       20   0 1023828 118576  80360 S  4.6  5.8   0:18.36 compiz       </span><br><span class="line">  2439 zds       20   0  630364  52556  42052 S  4.3  2.6   0:08.29 gnome-terminal-   </span><br><span class="line">  1945 zds       20   0  633568  35384  28860 S  0.7  1.7   0:10.46 sogou-qimpanel- </span><br><span class="line">     7 root      20   0       0      0      0 S  0.3  0.0   0:01.94 rcu_sched   </span><br><span class="line">   845 root      20   0  187344   9684   8508 S  0.3  0.5   0:03.35 vmtoolsd  </span><br><span class="line">  1631 zds       20   0   43736   4216   2924 S  0.3  0.2   0:01.82 dbus-daemon </span><br><span class="line">  1795 zds       20   0  564648  29760  24496 S  0.3  1.5   0:01.08 unity-panel-ser</span><br><span class="line">  1958 zds       20   0 1026996  95708  27980 S  0.3  4.7   0:07.03 gnome-software</span><br><span class="line">  1966 zds       20   0  496776  28904  25224 S  0.3  1.4   0:03.52 vmtoolsd   </span><br><span class="line">  7336 zds       20   0   43652   3948   3340 R  0.3  0.2   0:01.25 top  </span><br><span class="line">     1 root      20   0  119836   5652   4024 S  0.0  0.3   0:03.27 systemd </span><br><span class="line">     2 root      20   0       0      0      0 S  0.0  0.0   0:00.00 kthreadd </span><br><span class="line">     3 root      20   0       0      0      0 S  0.0  0.0   0:00.52 ksoftirqd/0</span><br><span class="line">     5 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 kworker/0:0H </span><br><span class="line">     8 root      20   0       0      0      0 S  0.0  0.0   0:00.00 rcu_bh</span><br><span class="line">     9 root      rt   0       0      0      0 S  0.0  0.0   0:00.00 migration/0</span><br><span class="line">    10 root      rt   0       0      0      0 S  0.0  0.0   0:00.01 watchdog/0</span><br><span class="line">    11 root      20   0       0      0      0 S  0.0  0.0   0:00.00 kdevtmpfs </span><br><span class="line">    12 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 netns </span><br><span class="line">    13 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 perf </span><br><span class="line">    14 root      20   0       0      0      0 S  0.0  0.0   0:00.00 khungtaskd  </span><br></pre></td></tr></table></figure>



<p><strong>htop</strong>命令显示了每个进程的内存实时使用率。它提供了所有进程的常驻内存大小、程序总内存大小、共享库大小等的报告。列表可以水平及垂直滚动。</p>
<p><strong>top</strong>命令提供了实时的运行中的程序的资源使用统计。你可以根据内存的使用和大小来进行排序。</p>
<h1 id="Core-Dump"><a href="#Core-Dump" class="headerlink" title="Core Dump"></a>Core Dump</h1><ul>
<li>Core意思是内存, Dump的意思是扔出来, 堆出来。在开发（或使用）一个程序时，有时程序莫名其妙的down了, 却没有任何提示(有时提示core dumped)。虽然系统没事，但下次仍可能遇到相同问题。这时可查看有无形如core.PID的core文件生成，这个文件便是操作系统把程序down掉时的内存内容扔出来生成的，让debugger 做参考。这个动作叫 core dump。<ul>
<li>core dump又叫<strong>核心转储</strong>, 当程序运行过程中发生异常, 程序异常退出时, 由操作系统把程序当前的内存状况存储在一个core文件中, 叫core dump。简而言之，<font color="red">进程异常终止，进程用户空间的数据就会被写到磁盘core文件</font>。</li>
</ul>
</li>
</ul>
<h2 id="为何有时程序Down了，却没生成-Core文件"><a href="#为何有时程序Down了，却没生成-Core文件" class="headerlink" title="为何有时程序Down了，却没生成 Core文件"></a>为何有时程序Down了，却没生成 Core文件</h2><ul>
<li><font color="red">有时候程序down了, 不像编译错误会提示到文件某一行，而是没有任何信息</font>。一种办法是用gdb的step（linux下调试工具gdb是很强大的调试器）, 一步一步寻找，但要step一个上万行的代码让人难以想象。 更好的办法就是core file。</li>
<li><font color="red">如果core文件没有生成</font>，是因为core.PID的core文件的生成跟当前系统的环境设置有关系，<font color="red">系统默认core文件的大小为0</font>（注意core file size (blocks, -c) 0 这行，表示分配给core文件的长度（单位为字节，一个块的大小要分系统而定了），为0肯定无core文件，可修改之）</li>
<li>用ulimit命令查看和修改core文件的大小，使用<code>ulimit -a</code>查看大小，使用 <code>ulimit -c unlimited</code>表示对core文件不做限制 或 使用<code>ulimit -c 1024</code> 对core文件分配1024个字节</li>
<li><font color="red">程序运行过程出现aborted(core dumped)，ulimit -a，结果确实 core file size (blocks, -c) 0，无法生成中断文件</font></li>
<li>若修改后再运行程序便生成<code>core.PID</code>的core文件（<strong>core文件生成的位置一般和运行程序的路径相同, 文件名一般为core.进程号</strong>）。</li>
</ul>
<h2 id="如何使用core文件"><a href="#如何使用core文件" class="headerlink" title="如何使用core文件?"></a>如何使用core文件?</h2><ul>
<li>发生core dump后，使用gdb查看core文件内容, 以定位文件中引发core dump的行，在Linux下，查看core文件中的出错堆栈信息有二种方式，使用：<font color="red">gdb -c core.pid program_name</font>或gdb [program_name] [core.pid]可以进入gdb模式</li>
<li>在进入gdb后输入<font color="red">where并回车</font>，就可以指出是在哪一行被Down掉，在哪个函数内，由谁调用等等。</li>
<li>在进入gdb后输入<font color="red"> bt</font>，用bt命令查看backtrace以检查发生程序运行到哪里，来定位core dump的文件-&gt;行。</li>
</ul>
<h2 id="core-dump-原因"><a href="#core-dump-原因" class="headerlink" title="core dump 原因"></a>core dump 原因</h2><ul>
<li><p><font color="red">batch_size过大导致的。Aborted(core dumped)</font></p>
</li>
<li><p>线程被谋杀， 被谋杀者所在线程会抛出一个异常。Cancellation &amp; C++ Exception</p>
</li>
<li><p>pure virtual method called terminate called without an active exception 解决方案</p>
</li>
</ul>
<p>对于多线程的程序，这个错误的主要原因是当前对象已经被销毁或者正在被销毁，但是其又在被调用，导致了冲突。</p>
<ul>
<li>pure virtual method called</li>
</ul>
<hr>
<h1 id="查看存储空间："><a href="#查看存储空间：" class="headerlink" title="查看存储空间："></a>查看存储空间：</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zds@ubuntu ~ $ df -hl</span><br><span class="line">文件系统         容量   已用  可用 已用% 挂载点</span><br><span class="line">udev            972M     0  972M    0% /dev</span><br><span class="line">tmpfs           199M  6.3M  192M    4% /run</span><br><span class="line">/dev/sda1        23G  5.3G   17G   25% /</span><br><span class="line">tmpfs           992M  212K  991M    1% /dev/shm</span><br><span class="line">tmpfs           5.0M  4.0K  5.0M    1% /run/lock</span><br><span class="line">tmpfs           992M     0  992M    0% /sys/fs/cgroup</span><br><span class="line">tmpfs           199M   60K  199M    1% /run/user/1000 </span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>jellyfish &amp; Genomescope</title>
    <url>/blog/2022/02/23/2022-02-23-jellyfish-genomescope/</url>
    <content><![CDATA[<h1 id="A-fast-lock-free-approach-for-efficient-parallel-counting-of-occurrences-of-k-mers"><a href="#A-fast-lock-free-approach-for-efficient-parallel-counting-of-occurrences-of-k-mers" class="headerlink" title="A fast, lock-free approach for efficient parallel counting of occurrences of k-mers"></a>A fast, lock-free approach for efficient parallel counting of occurrences of k-mers</h1><span id="more"></span>

<h1 id="1-Paper-2011"><a href="#1-Paper-2011" class="headerlink" title="1. Paper-2011 :"></a><a href="https://pubmed.ncbi.nlm.nih.gov/21217122/">1. Paper-2011</a> :</h1><ul>
<li><p><font color="red">Counting the number of occurrences of every k-mer</font> </p>
</li>
<li><p> <font color="green">genome assembly</font></p>
</li>
<li><p><font color="purple">error correction</font> of sequencing reads</p>
</li>
<li><p><font color="daekred">fast multiple sequence alignment</font> </p>
</li>
<li><p><font color="blue">repeat detection</font></p>
</li>
<li><p><strong>current</strong> k-mer counting tools <strong>too slow</strong> , <strong>memory intensive</strong></p>
</li>
<li><p>multicore computers facilities <strong>parallel computational paradigm</strong></p>
</li>
<li><p>multithreaded, <font color="red">lock-free hash table</font> </p>
</li>
<li><p><strong>k-mers up to 31</strong> </p>
</li>
<li><p><strong>suffix arrays</strong> </p>
</li>
</ul>
<hr>
<h1 id="2-github-doc"><a href="#2-github-doc" class="headerlink" title="2. github-doc :"></a><font color="red"><a href="https://github.com/gmarcais/Jellyfish/tree/master/doc">2. github-doc</a></font> :</h1><h2 id="2-1-Counting-k-mers-in-sequencing-reads"><a href="#2-1-Counting-k-mers-in-sequencing-reads" class="headerlink" title="2.1 Counting k-mers in sequencing reads"></a>2.1 Counting k-mers in sequencing reads</h2><ul>
<li><p>The <code>-C</code> switch instructs to save in the hash only canonical规范 k-mers, while the count is the number of occurrences of both a k-mer and it reverse complement.</p>
</li>
<li><p><font color="green"><strong>-s</strong></font> 预估值设置：The size parameter (given with <font color="red">-s</font>) is an indication of <font color="red">the number k-mers [N*(L-K+1)]</font> that will be <font color="red"><strong>stored in the hash</strong></font>. For sequencing reads, this size should be the size of <font color="red">the genome plus the k-mers generated by sequencing errors</font>. For example, if the error rate is <font color="red">e</font> (e.g.Illumina reads, usually e~<font color="red">1%</font>), with an estimated genome size of G and a coverage of <font color="red">c</font>, the number of expected k-mers is <font color="red"><strong>G+Gcek</strong></font>.</p>
</li>
</ul>
<blockquote>
<p>NOTE: unlike in Jellyfish 1, this <code>-s</code> parameter is <font color="red">only an estimation</font>. <font color="red">If the size given is too small to fit all the k-mers, the hash size will be increased automatically or partial results will be written to disk and finally merged automatically</font>. Running <code>jellyfish merge</code> should never be necessary, as now jellyfish now takes care of this task on its own. </p>
</blockquote>
<ul>
<li><font color="green"><strong>-s 预估kmer以hash表存储所需内存大小，设置小了会自动扩大，并自动merge</strong></font>。</li>
<li>If the low frequency k-mers (k-mers occurring only once), which are mostly due to sequencing errors, are not of interest, one might consider counting only high-frequency k-mers (see section <a href="https://github.com/gmarcais/Jellyfish/tree/master/doc#Counting-high-frequency-k-mers">Counting high frequency k-mers</a>), which uses less memory and is potentially faster. <font color="green"><strong>低频k-mers由测序错误导致，只考虑高频减少内存使用提高速度</strong></font>。</li>
</ul>
<h2 id="2-2-Counting-k-mers-in-a-genome"><a href="#2-2-Counting-k-mers-in-a-genome" class="headerlink" title="2.2 Counting k-mers in a genome"></a>2.2 Counting k-mers in a genome</h2><ul>
<li>In an 【actual genome or finished sequence？】, a k-mer and its reverse complement are not equivalent, hence using the <code>-C</code> switch does not make sense. In addition, the size for the hash can be set directly to the size of the genome.</li>
<li>-C没有意义？哈希表的size直接设置为基因组大小？不够自动调整？</li>
</ul>
<h2 id="2-3-Counting-high-frequency-k-mers"><a href="#2-3-Counting-high-frequency-k-mers" class="headerlink" title="2.3 Counting high-frequency k-mers"></a>2.3 Counting high-frequency k-mers</h2><p>Jellyfish offers <font color="red">two way</font> to count only high-frequency k-mers (<font color="red"><strong>count &gt;1</strong></font>), which reduces significantly the memory usage. Both methods are based on using <font color="red">Bloom filters</font>. The first method is a one pass method, which <font color="red">provides approximate count for some percentage of the k-mers</font>. The second method is a two pass method which <font color="red">provides exact count</font>. In both methods, most of the low-frequency k-mers are not reported.</p>
<h3 id="2-3-1-One-pass-method"><a href="#2-3-1-One-pass-method" class="headerlink" title="2.3.1 One pass method"></a>2.3.1 One pass method</h3><h3 id="2-3-2-Two-passes-method"><a href="#2-3-2-Two-passes-method" class="headerlink" title="2.3.2 Two passes method"></a>2.3.2 Two passes method</h3><h2 id="2-4-Counting-a-subset-of-k-mers"><a href="#2-4-Counting-a-subset-of-k-mers" class="headerlink" title="2.4 Counting a subset of k-mers"></a>2.4 Counting a subset of k-mers</h2><ul>
<li>It is possible to count the number of occurrences of <font color="red">only a subset of</font> predefined k-mers, using the <font color="red"><strong>–if</strong></font> switch. Only count the 20-mers of chromosome 20 in chromosome 1 of human </li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish count -m 20 -s 100M -C -t 10 -o 20and1.jf --<span class="keyword">if</span> chr20.fa chr1.fa</span><br></pre></td></tr></table></figure>

<ul>
<li><p>This <strong>reads all the canonical 20-mers from the file chr20.fa</strong> (<font color="green"><strong>but don’t count them</strong></font>) and <font color="green"><strong>loads them in memory</strong></font>. Then it <strong>reads chr1.fa and counts the number of occurrences of the 20-mers</strong> <font color="green"><strong>only of the k-mers already loaded in memory</strong></font>.</p>
</li>
<li><p>把chr20的kmer，存储。统计chr1的20-mer在上一步存储中已存在的部分的数目。？chr1和20的关联？</p>
</li>
<li><p>Now, the histogram will also report k-mers with a <font color="green"><strong>0 count</strong></font> (<font color="green"><strong>the 20-mers of chr20</strong></font> which <font color="green"><strong>do not exists in chr1</strong></font>):</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ jellyfish histo 20and1.jf | head </span><br><span class="line">0 49401674</span><br><span class="line">1 1116213</span><br><span class="line">2 425471</span><br></pre></td></tr></table></figure>

<p>Note that the file given to <code>--if</code> is a fasta file. If a list of k-mers is available instead (say one per line in a text file), it can be transformed into a fasta file with one k-mer per line using the following one liner Perl command:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">perl -ne <span class="string">&#x27;print(&quot;&gt;\n$_&quot;)&#x27;</span></span><br><span class="line"><span class="comment">#kmer line转fa，一行&gt;号，一行kmer</span></span><br></pre></td></tr></table></figure>

<h2 id="2-5-如何读取压缩文件"><a href="#2-5-如何读取压缩文件" class="headerlink" title="2.5 如何读取压缩文件"></a>2.5 如何读取压缩文件</h2><p> jellyfish只读入fq或fa</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zcat *.fastq.gz | jellyfish count /dev/fd/0 ...</span><br><span class="line"><span class="comment">#using the &lt;() redirection provided by the shell (e.g. bash, zsh):</span></span><br><span class="line"><span class="comment">#!/usr/bin/bash</span></span><br><span class="line">jellyfish count &lt;(zcat file1.fastq.gz) &lt;(zcat file2.fasta.gz) ...</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="3-Jellyfish介绍"><a href="#3-Jellyfish介绍" class="headerlink" title="3. Jellyfish介绍"></a>3. Jellyfish介绍</h1><p><a href="http://www.cbcb.umd.edu/software/jellyfish/">JELLYFISH</a>是<a href="http://www.cbcb.umd.edu/">CBCB(Center for Bioinformatics and Computational Biology)</a>的Guillaume Marçais 和 <a href="http://www.cs.cmu.edu/~ckingsf/">Carl Kingsford</a> 研发的一款计数 DNA 的 k-mers 的软件。该软件运用 Hash 表来存储数据，同时能多线程运行，速度快，内存消耗小。该软件只能运行在64位的Linux系统下。其<a href="http://bioinformatics.oxfordjournals.org/content/27/6/764">文章</a>于2011年发表在杂志 <a href="http://bioinformatics.oxfordjournals.org/">Bioinformatics</a> 上。</p>
<h1 id="4-Jellyfish安装"><a href="#4-Jellyfish安装" class="headerlink" title="4. Jellyfish安装"></a>4. Jellyfish安装</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ wget 最新targz</span><br><span class="line">$ tar zxvf .tar.gz</span><br><span class="line">$ mkdir jellyfish</span><br><span class="line">$ <span class="built_in">cd</span> jellyfish-2.3.0</span><br><span class="line">$ ./configure --prefix=Your/Path/to/jellyfish</span><br><span class="line">如果安装在当前目录中，会报错。</span><br><span class="line">$ make -j 8</span><br><span class="line">$ make install</span><br></pre></td></tr></table></figure>

<h1 id="5-Jellyfish使用"><a href="#5-Jellyfish使用" class="headerlink" title="5. Jellyfish使用"></a>5. Jellyfish使用</h1><h2 id="jellyfish-count-【count-kmers-to-estimate-genome-size】"><a href="#jellyfish-count-【count-kmers-to-estimate-genome-size】" class="headerlink" title="jellyfish count 【count kmers to estimate genome size】"></a>jellyfish count 【count kmers to estimate genome size】</h2><p>Theory:</p>
<ul>
<li>If k is large enough so that each kmer found is unique in the genome,</li>
<li>and if the genome length (e.g. 1,000,000) is much larger than the kmer length (e.g. 21),</li>
<li>and if no PCR or sequencing errors,</li>
<li>then the number of kmers will be approximately equal to the length of the genome.</li>
</ul>
<p>！<font color="red">Kmer counting tutorial</font>: <a href="https://bioinformatics.uconn.edu/genome-size-estimation-tutorial/#">https://bioinformatics.uconn.edu/genome-size-estimation-tutorial/#</a></p>
<ul>
<li>Jellyfish: <a href="https://github.com/gmarcais/Jellyfish">https://github.com/gmarcais/Jellyfish</a></li>
<li>Further jellyfish steps : <a href="https://github.com/gmarcais/Jellyfish/tree/master/doc">https://github.com/gmarcais/Jellyfish/tree/master/doc</a></li>
</ul>
<p>Note: Aug 2019: conda install seems to work only with: conda install jellyfish=2.2.3</p>
<p>Steps:</p>
<ul>
<li><font color="green">“&gt;Go through</font> the sequencing reads</li>
<li>For each <font color="green">new kmer seen</font>, <font color="green">add to table with count</font>.</li>
<li>If kmer <font color="green">seen before</font>, <font color="green">increment count</font>.</li>
<li>Find the <font color="green">average kmer frequency</font> (sequencing depth), e.g. 50</li>
<li><font color="green">Exclude kmers with a count of ~ 1</font>, as these are likely from <font color="green">errors</font></li>
<li>Add all the other kmers, and <font color="green"><strong>divide by average kmer frequency</strong></font> =&gt; This is the approx genome length</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish count -m 21 -s 100M -t 10 -C reads.fasta</span><br></pre></td></tr></table></figure>

<p>To use gzipped files: and <font color="green">paired-end reads</font>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish count -m 21 -s 100M -t 10 -C &lt;zcat R1.fq.gz) &lt;(zcat R2.fq.gz)</span><br></pre></td></tr></table></figure>

<ul>
<li>-m: kmer length, 21 is commonly used, <strong>17</strong></li>
<li>-s: size of hash table: should be genome size + extra kmers from seq errors. <font color="green">However, it does say that hash size <strong>will be increased automatically if needed</strong>.</font></li>
<li>-C: canonical. <font color="green">Reverse complement kmers are considered to be identical and are counted as the same thing</font>. <font color="green"><strong>This is recommended</strong></font>.</li>
<li>-t: number of threads</li>
<li>output: mer_counts.jf</li>
</ul>
<p>Plot the histogram:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish histo -t 10 mer_counts.jf &gt; reads.histo</span><br></pre></td></tr></table></figure>

<p><strong>???Plot the histogram with an x axis of one million instead of default 10,000</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish histo -t 10 --high=1000000 mer_counts.jf &gt; reads.histo</span><br></pre></td></tr></table></figure>

<ul>
<li>Discussion on setting to 1 million: <a href="https://github.com/schatzlab/genomescope/issues/22">https://github.com/schatzlab/genomescope/issues/22</a></li>
<li>There may be very high counts of some kmers due to chloroplast sequences, spike-in sequences, etc.</li>
</ul>
<blockquote>
<p>使用fastq文件在默认参数上和fasta文件没有区别。生成的hash结果为二进制文件。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-m | --mer-len=&lt;num&gt;</span><br><span class="line"> 使用的k-mer的长度。如果基因组大小为G，则k-mer长度选择为: k ~= <span class="built_in">log</span>(200G)</span><br><span class="line">/<span class="built_in">log</span>(4)。</span><br><span class="line">-s | --size=&lt;num&gt;</span><br><span class="line"> Hash 的大小。最好设置的值大于总的独特的(distinct)k-mer数,这样生成的文件只</span><br><span class="line">有一个。若该值不够大，则会生成多个<span class="built_in">hash</span>文件，以数字区分文件名。该值识别 </span><br><span class="line">M 和 G。</span><br><span class="line">-t | --threads=&lt;num&gt;  default: 1</span><br><span class="line"> 使用的CPU线程数</span><br><span class="line">-o | --output=&lt;string&gt;  default: mer_counts.jf</span><br><span class="line"> 输出的结果文件前缀</span><br><span class="line">-c | --counter-len=&lt;num&gt;  default:7</span><br><span class="line"> k-mer的计数结果所占的比特数,默认支持的最大数字是2^7=128。对于基因组测序覆盖</span><br><span class="line">度为N，则要使设置的该值要大于N。该值越大，消耗内存越大。</span><br><span class="line">-out-counter-len=&lt;num&gt;  default:4</span><br><span class="line"> 输出的二进制<span class="built_in">hash</span>文件中的计数结果所占的字节数,一个字节是8比特。则默认支持的最大</span><br><span class="line">数字是2^32=4.3G</span><br><span class="line"><span class="comment">#The count of k-mers which cannot be represented with the given number of bytes will have a value equal to the maximum value that can be represented. Meaning, if the counter field uses 1 byte, any k-mers with count greater or equal to 255 will be reported of having a count of 255.</span></span><br><span class="line">-C | --both-strand  default: <span class="literal">false</span></span><br><span class="line"> 【对正义链和反义链都进行计数】</span><br><span class="line">-q | --quake  default: <span class="literal">false</span></span><br><span class="line"> quake兼容模式</span><br><span class="line">--quality-start=&lt;num&gt;  default: 64</span><br><span class="line"> 起始碱基质量的ASCII值，默认为PHRED64</span><br><span class="line">--min-quality=&lt;num&gt;  default: 0</span><br><span class="line"> 支持的最小的碱基质量值，低于此值的碱基将由N代替</span><br><span class="line">-L | --lower-count=&lt;num&gt;</span><br><span class="line"> 【不输出数目低于此值的k-mer】</span><br><span class="line">-U | --upper-count=&lt;num&gt;</span><br><span class="line"> 【不输出数目高于此值的k-mer】</span><br><span class="line"><span class="comment">#low frequency and high frequency k-mers can be skipped using the --L and --U` switches respectively. Although it might be more appropriate to filter out the low frequency $k$-mers using Bloom filters, as shown in section Counting-high-frequency-k-mers.</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="jellyfish-merge-合并"><a href="#jellyfish-merge-合并" class="headerlink" title="jellyfish merge 合并"></a>jellyfish merge 合并</h2><p>Count的输出结果为二进制文件，可能输出多个hash文件，需要hash文件合并一个文件, merge 命令。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#The merge subcommand is of little direct use with version version 2 of Jellyfish</span></span><br><span class="line"><span class="comment">#The count subcommand will merge intermediary files automatically as needed.</span></span><br><span class="line">jellyfish merge -o mer_counts_merged.jf hash1 hash2 ...</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-o | –output=<string>  default: mer_counts_merged.jf<br>    输出的结果文件<br>–out-counter-len=<num>  default: 4<br>输出的二进制hash文件中的计数结果所占的字节数,一个字节是8比特。则默认支持的最大数字是2^32=4.3G</num></string></p>
</blockquote>
<h2 id="jellyfish-stats-统计"><a href="#jellyfish-stats-统计" class="headerlink" title="jellyfish stats 统计"></a>jellyfish stats 统计</h2><p>k-mer的结果以hash的二进制文件结果给出，需要统计出k-mer总数，特异的k-mer数目，只出现过一次的kmer数，出现了最多的k-mer的数目等信息。以stats命令来运行。使用方法：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Although these statistics could be computed from the histogram, it provides quick summary information</span></span><br><span class="line">$ jellyfish stats <span class="built_in">hash</span></span><br><span class="line">示例结果为：</span><br><span class="line">Unique:    32355544    <span class="comment">#只出现过一次的k-mer的数目</span></span><br><span class="line">Distinct:  88414020    <span class="comment">#特异性的k-mer数目，包含上一个的数据</span></span><br><span class="line">Total:     432232807   <span class="comment">#总的k-mer数目</span></span><br><span class="line">Max_count: 85348       <span class="comment">#同一个k-mer出现的最多的数目</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>-L | –lower-count=<num><br>    不统计数目低于此值的k-mer<br>-U | –upper-count=<num><br>    不统计数目高于此值的k-mer</num></num></p>
</blockquote>
<h2 id="jellyfish-histo-绘图"><a href="#jellyfish-histo-绘图" class="headerlink" title="jellyfish histo 绘图"></a>jellyfish histo 绘图</h2><p>对k-mer的计数结果有个直观的认识，则需要统计出现了x(x=1,2,3…)次的kmer的数目y,以x，y为横纵坐标画出直方图。使用 histo 命令能给出 x 和 y 对应的值，将结果默认输出到标准输出。其使用方法为</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish histo -l 1 -h 1000 <span class="built_in">hash</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>-l | –low=<num>  default: 1<br>    最低的 x 轴的值。同时结果会将低于此值的所有的k-mer的数目作为 (x-1) 的值。因<br>此该值为 2 和 1 的结果是一致的。<br>-h | –high=<num>  【default: 10000？？】<br>    最高的 x 轴的值。同时结果会将高于此值的所有的k-mer的数目的和作为 (x+1) 的值。<br>-i | –increment=<num>  default: 1<br>    x 轴取值是每隔该数值取值<br>-t | –threads=<num>  default: 1<br>    使用的CPU线程数<br>-f | –full  default: false<br>    全部的直方图</num></num></num></num></p>
</blockquote>
<h2 id="jellyfish-dump-结果文件格式转换"><a href="#jellyfish-dump-结果文件格式转换" class="headerlink" title="jellyfish dump 结果文件格式转换"></a>jellyfish dump 结果文件格式转换</h2><p>由于count命令生成的结果为二进制的，如有需要，则可以转换成可读文本文件。使用 dump 命令，使用方法：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish dump -c -t -U 1000 <span class="built_in">hash</span></span><br><span class="line"><span class="comment">#To output all the counts for all the k-mers in the file</span></span><br><span class="line"><span class="comment">#By default, the output is in FASTA format</span></span><br><span class="line">jellyfish dump mer_counts.jf &gt; mer_counts_dumps.fa</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-c | --colum  default: <span class="literal">false</span></span><br><span class="line"> 生成结果为2列，第一列为k-mer序列，第二列为对应的数目。默认情况下是是fasta格</span><br><span class="line">式，fasta的头为k-mer的数目，fasta的序列为k-mer的序列。</span><br><span class="line">-t | --tab  default: <span class="literal">false</span></span><br><span class="line"> 当 -c 参数存在时，以tab来进行分隔两行。默认是以空格来分开的。</span><br><span class="line"><span class="comment"># Low frequency and high frequency k-mers can be skipped with the `-L` and `-U` switches respectively.</span></span><br><span class="line">-L | --lower-count=&lt;num&gt;</span><br><span class="line"> 不输出小于该值的k-mer</span><br><span class="line">-U | --upper-count=&lt;num&gt;</span><br><span class="line"> 不输出高于该值的k-mer</span><br><span class="line">-o | --output=&lt;file&gt;</span><br><span class="line"> 输出文件的路径和名称</span><br></pre></td></tr></table></figure>



<h2 id="jellyfish-query-查询"><a href="#jellyfish-query-查询" class="headerlink" title="jellyfish query 查询"></a>jellyfish query 查询</h2><p>如果需要从Hash结果中查询指定的k-mer出现的次数，则要是用 query 命令。从标准输入读取k-mer的序列，从标准输出得到k-mer对应的数目。使用方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish query hash</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-C | –both-strands  default: false<br>   同时查询k-mer序列的正负链<br>-i | –input=<file><br>   输入的文件<br>-o | –output=<file><br>   输出的文件</file></file></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish query mer_counts.jf AACGTTG</span><br></pre></td></tr></table></figure>



<h2 id="jellyfish-info"><a href="#jellyfish-info" class="headerlink" title="jellyfish info"></a>jellyfish info</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#To get some information on 【how, when and where】 this jellyfish file was 【generated】, use the info subcommand</span></span><br><span class="line"><span class="comment">#outputs some information about the jellyfish file and the command used to generated it, in which directory and at what time the command was run</span></span><br><span class="line">jellyfish info mer_counts.jf</span><br></pre></td></tr></table></figure>

<h2 id="jellyfish-mem"><a href="#jellyfish-mem" class="headerlink" title="jellyfish mem"></a>jellyfish mem</h2><p>The <code>mem</code> subcommand shows how much memory a count subcommand will need or conversely how large of a hash size will fit in a given amount of memory.</p>
<hr>
<p>ref：</p>
<p><a href="https://www.annasyme.com/docs/jellyfish.html">https://www.annasyme.com/docs/jellyfish.html</a></p>
<hr>
<h1 id="Genomescope"><a href="#Genomescope" class="headerlink" title="Genomescope"></a>Genomescope</h1><p>安装github最新</p>
<p><font color="red">githubdoc</font>  : <a href="https://github.com/schatzlab/genomescope">https://github.com/schatzlab/genomescope</a></p>
<p><font color="red">paperlink</font> : <a href="https://doi.org/10.1093/bioinformatics/btx153">https://doi.org/10.1093/bioinformatics/btx153</a></p>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>将paired-end数据整合？将read2数据的序列反向重复后与read1文件合并？使用Trinity附带的fastool程序完成转换。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ zcat read_1.clean.fq.gz | <span class="variable">$Trinity_Home</span>/trinity-plugins/fastool/fastool --illumina-trinity --to-fasta &gt; reads_1.fasta</span><br><span class="line">$ zcat read_2.clean.fq.gz | <span class="variable">$Trinity_Home</span>/trinity-plugins/fastool/fastool --rev --illumina-trinity --to-fasta &gt; reads_2.fasta</span><br><span class="line">$ cat reads_1.fasta reads_2.fasta &gt; both.fasta</span><br></pre></td></tr></table></figure>

<h2 id="统计kmer"><a href="#统计kmer" class="headerlink" title="统计kmer"></a>统计kmer</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish count -C -m [] -s [] -t [] s.fasta -o s.jf</span><br></pre></td></tr></table></figure>

<h2 id="绘直方图"><a href="#绘直方图" class="headerlink" title="绘直方图"></a>绘直方图</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish histo -t 10 s.jf &gt; s.histo</span><br></pre></td></tr></table></figure>

<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-s 预估哈希表的大小，即G+Gce*k。G是Genome Size；c是coverage（genome survey测序通常低于100x）；e是测序错误率（illumina为1%）；k是kmer大小。</span><br><span class="line">-C 表示考虑DNA正义与反义链，遇到反义kmer时，计入正义kmer频数中。</span><br></pre></td></tr></table></figure>

<h2 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Rscript genomescope.R histogram_file k-mer_length read_length output_dir [kmer_max] [verbose]</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>survey-kmer</tag>
      </tags>
  </entry>
  <entry>
    <title>SMRT Sequencing 7 HiFi Reads [High fidelity reads]</title>
    <url>/blog/2022/02/20/2022-02-20-SMRT-sequencing/</url>
    <content><![CDATA[<h1 id="主流三代测序平台Oxford-的-Nanopore，Pacific-Biosciences（-PacBio）的-Single-Molecule-Real-Time（SMRT）Sequencing"><a href="#主流三代测序平台Oxford-的-Nanopore，Pacific-Biosciences（-PacBio）的-Single-Molecule-Real-Time（SMRT）Sequencing" class="headerlink" title="主流三代测序平台Oxford 的 Nanopore，Pacific Biosciences（ PacBio）的 Single Molecule Real-Time（SMRT）Sequencing"></a>主流三代测序平台Oxford 的 Nanopore，Pacific Biosciences（ PacBio）的 Single Molecule Real-Time（SMRT）Sequencing</h1><span id="more"></span>

<p>Ref:<a href="https://zhuanlan.zhihu.com/p/339875837">https://zhuanlan.zhihu.com/p/339875837</a></p>
<p><a href="http://pacbiofileformats.readthedocs.io/en/5.0/">http://pacbiofileformats.readthedocs.io/en/5.0/</a></p>
<p>PacBio优势：</p>
<ul>
<li>在不影响吞吐量和准确性前提下，提供目前<font color="green">最长的读取长度</font></li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/1.png" alt="img"></p>
<ul>
<li>如果不含系统误差，准确度可达<font color="green"> 99.999％</font></li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/2.png" alt="img"></p>
<ul>
<li>可测取富<font color="green">含AT或GC区域</font>，<font color="green">高度重复序列</font>，<font color="green">回文序列</font>等，不会产生GC的较大偏差</li>
<li>可以直接<font color="green">测取化学修饰</font>，在<font color="green">表观遗传学</font>中有重要应用</li>
</ul>
<h1 id="文库构建"><a href="#文库构建" class="headerlink" title="文库构建"></a>文库构建</h1><p>将样本中的DNA或RNA分子提取后，构建<font color="green">哑铃状分子结构<strong>SMRTbell</strong></font>：</p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/3.png" alt="img"></p>
<p>黄色，紫色：双链DNA分子; 蓝色：接头（Adapter）</p>
<p>文库分子展开，一个完整的<font color="green">圆环</font>：</p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/4.png" alt="img"></p>
<p>圆环结构有利于周而复始的滚环复制，利于纠错。</p>
<p>将样本中所有的DNA片段都构建哑铃状分子结构，组成的集合叫<font color="green">文库</font>（SMRTbell Library），随后被放到测序芯片中。</p>
<p>以基因组HiFi文库为例（15-20K文库）。当得到gDNA后，先利用G-tube管或Megaruptor System将基因组<strong>片段化</strong>至合适大小，而后通过<strong>去除单链悬突</strong>、<strong>损伤修复</strong>和<strong>末端修复</strong>等步骤，得到完整的双链插入片段。接下来，通过将<strong>接头连接</strong>至双链DNA来创建SMRTbell文库，从而得到环状模板。完成接头连接后，需要对连接产物进行纯化，利用<strong>酶处理</strong>来消化线性或内部损伤环形DNA分子（游离的Hairpin Adapter、两端未连接Adapter的DNA模板、已成环但内部有损伤的DNA模板），酶处理完毕后，一般会利用<strong>Bulepippin</strong>或Sage ELF System切胶<strong>回收目标大小范围</strong>内的文库。文库质检</p>
<h1 id="测序芯片"><a href="#测序芯片" class="headerlink" title="测序芯片"></a>测序芯片</h1><p>以 RSII 测序平台为例，测序仪芯片（SMRT Cell）：</p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/5.png" alt="img"></p>
<p>放大：上面整齐排列着<font color="green">15万个</font>直径为<font color="green">70纳米的测序微孔</font>（<font color="red">Zero-Model Waveguides，ZMWs</font>）。</p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/6.png" alt="img"></p>
<h1 id="上机测序"><a href="#上机测序" class="headerlink" title="上机测序"></a>上机测序</h1><h2 id="1-构建测序复合物"><a href="#1-构建测序复合物" class="headerlink" title="1. 构建测序复合物"></a>1. <strong>构建测序复合物</strong></h2><p>测序复合物：聚合酶，测序模板，测序引物</p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/7.png" alt="img"></p>
<h2 id="2-复合物撒入测序小孔"><a href="#2-复合物撒入测序小孔" class="headerlink" title="2. 复合物撒入测序小孔"></a>2. <strong>复合物撒入测序小孔</strong></h2><p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/8.png" alt="img"></p>
<h2 id="3-固定测序复合物"><a href="#3-固定测序复合物" class="headerlink" title="3. 固定测序复合物"></a>3. <strong>固定测序复合物</strong></h2><p>由于<font color="green">聚合酶加了<strong>生物素</strong></font>，在<font color="green">芯片玻璃底板有<strong>链酶亲和素</strong></font>。利用生物素和链酶亲和素的亲和力，包含聚合酶的<strong>测序复合物会被<font color="green">固定</font>在玻璃底板。</strong></p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/9.png" alt="img"></p>
<h2 id="4-构建带有荧光基团的dNTP"><a href="#4-构建带有荧光基团的dNTP" class="headerlink" title="4. 构建带有荧光基团的dNTP"></a>4. <strong>构建带有荧光基团的dNTP</strong></h2><p>在芯片溶液中含有许多游离dNTP，所谓游离dNTP就是随机飘在溶液中的dNTP。</p>
<p>ATGC四种碱基的dNTP，在磷酸基团上分别带有<font color="green">四种颜色的荧光基团</font>。</p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/10.png" alt="img"></p>
<h2 id="5-边合成边测序"><a href="#5-边合成边测序" class="headerlink" title="5. 边合成边测序"></a>5. <strong>边合成边测序</strong></h2><p>在合成时，游离的dNTP被固定在底板上的酶捕获，<font color="green">激发光会从玻璃板底部发出</font>。</p>
<p><video src="2022-02-20-SMRT-sequencing/11.mp4"></video></p>
<p><strong>怎么保证每次测取一个碱基？</strong></p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/12.png" alt="img"></p>
<p>由于测序小孔直径很小，激发光的穿透能力会逐渐衰减，只能在小孔中传输很短的距离，所以<font color="green">只有当dNTP足够靠近底部，荧光基团才会被激发光照到，发出荧光</font>。其他游离dNTP虽然也有可能飘到小孔底部被激发光照到，但这种情况极少。<br>在一个碱基合成结束后，带有荧光基团的磷酸基团会从dNTP上掉落，发生猝灭，不影响其他碱基的信号检测。 在发生测序的小孔有各自的DNA片段和测序复合物，同一时间发出不同颜色的激发光，机器会检测到如下的光信号，实际同时会得到多达几万个光点。</p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/13.png" alt="img"></p>
<p>重复上述步骤，经过计算机分析光谱，最终我们拿到样本的测序文件。SMRT Sequencing 测序过程中，<font color="green">每秒读取三个碱基</font>，一个小时可检测大约一万多碱基。</p>
<h2 id="6-检测碱基甲基化"><a href="#6-检测碱基甲基化" class="headerlink" title="6. 检测碱基甲基化"></a>6. <strong>检测碱基甲基化</strong></h2><p>在SMRT Sequencing测序过程中，可以<font color="green">直接测到碱基被修饰状态</font>，聚合酶遇到碱基上带有甲基化的碱基，<font color="green">合成速度明显变慢</font>，而且<font color="green">光谱也会发生改变</font>。SMRT Sequencing 可以检测到碱基的甲基化修饰。</p>
<h1 id="测序模型"><a href="#测序模型" class="headerlink" title="测序模型"></a>测序模型</h1><h2 id="1-Circular-Consensus-Sequencing-CCS-–-HiFi"><a href="#1-Circular-Consensus-Sequencing-CCS-–-HiFi" class="headerlink" title="1. Circular Consensus Sequencing (CCS) – HiFi"></a>1. Circular Consensus Sequencing (CCS) – HiFi</h2><p>说这种测序模型前，就不得不提三代测序最大的缺点：<font color="green">碱基读取不准，错误率在12.5%</font>。每八个碱基读错一个。</p>
<p>碱基读取<font color="green">错误随机</font>，重读一遍同样位置的碱基，不一定发生相同错误。</p>
<p>对同一个序列，多测几遍，<font color="red">矫正</font>读错碱基。</p>
<p>滚环复制的优势: 利用测序复合物在<font color="red">环状文库分子循环测序</font><strong>同一个片段</strong>来<font color="green">消除错误率</font>。</p>
<p>HiFi reads（High Fidelity reads）是2019年由PacBio推出的基于<font color="red">环化共有序列（Circular Consensus Sequencing，CCS）</font>模式产生的既兼顾长读长（<font color="red">10-20kb</font>长度）又具有高精度（&gt;99%准确率）的测序结果。</p>
<p>超长酶读长中，去掉接头序列，即可获得多条subreads。多条subreads合并生成高度一致性的hifi reads。</p>
<p><video src="2022-02-20-SMRT-sequencing/14.mp4"></video></p>
<p>这种测序模型，复制出的 Reads叫 <font color="red">HiFi Reads [High fidelity reads]</font>，测序准确率 &gt; 99%。</p>
<p>HiFi reads are a <strong>type of data produced using the circular consensus sequencing (CCS) mode on one of the PacBio Sequel Systems</strong>.</p>
<p>HiFi reads（High fidelity reads）是 <font color="red">Sequel II</font>三代测序平台推出的兼顾长读长和高准确度的测序序列，一般采用CCS（Circular Consensus Sequencing）模式测序。</p>
<p>在单次测序中得到更多的HiFi reads往往需要<strong>平衡</strong>测序的 <font color="red">酶读长</font>和 <font color="red">插入片段的长度</font>，插入片段太长会导致酶无法进行滚环测序，插入片段太短又牺牲了三代长读长测序的优势。</p>
<p>根据前期的官方经验推荐，目前HiFi文库构建的<font color="red">插入片段一般为8-13 kb</font>左右。安诺优达构建约10 kb的HiFi文库在<font color="red">Sequel II</font>平台进行测序。原始下机数据单cell产出268 Gb数据，其中<font color="red">酶平均读长51 kb</font>，<font color="red">酶读长N50 124 kb</font>，<font color="red">subreads平均读长11 kb</font>，<font color="red">subreads N50 13 kb</font>。</p>
<ul>
<li>下机数据产出统计表</li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/15.png" alt="1562200674629303.png"></p>
<p>进一步利用官方软件调取CCS，设置最小pass数为3，经过调取获得CCS总数据量为<strong>22.43 Gb</strong>，CCS 序列数目为<strong>172.5万</strong>条<strong>，平均长度</strong>13 kb<strong>。与下机总数据量相比，</strong>目前CCS reads的得率约为8%，并且能够兼顾reads的读长，达到平均13 kb左右，数据质量相当不错??</p>
<ul>
<li>CCS数据产出统计表</li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/16.png" alt="1562200759526715.png"></p>
<p>对拿到的HiFi reads进行进一步的<font color="red">质量评估</font>，我们发现大部分HiFi reads的<font color="red">准确度?</font>都在0.95以上，其中约35%的reads（pass≥10）质量值达到QV30（99.9%），这样高质量的reads非常有助于研究者开展下游深入的研究。</p>
<ul>
<li>CCS质量分布图</li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/17.png" alt="1562200823347872.png"></p>
<p>同时兼顾长读长和高准确度的HiFi reads究竟有何用处呢？2019年<em>BioRxiv</em>题为“<strong>Highly-accurate long-read sequencing improves variant detection and assembly of a human genome</strong>”的文章。在这篇文章里研究者利用约30X的CCS reads组装人基因组，通过<font color="green">FALCON、Canu3和 wtdbg2</font>等不同软件进行组装，<font color="red">contig N50达到15.43-28.95 Mb</font>。从组装连续性来看，<strong>CCS reads能够做到与<font color="red">传统的CLR reads</font>组装相当的结果，重要的是基因组碱基准确度得到了明显提升，基因组组装消耗的计算资源和时间大幅下降</strong>。进一步利用CCS reads进行<font color="red">SNP、InDel等变异检测</font>，发现CCS reads在小的变异检出率和准确度上都有显著提升，数据结果与30X的Illumina数据分析结果基本接近。</p>
<ul>
<li>文章中CCS reads进行SNV和InDel calling统计表</li>
</ul>
<p><img src="/blog/./18.png" alt="1562200919110586.png"></p>
<p>综上，HiFi reads无论在<font color="red">基因组全变异检测（SNV、InDel、SV）</font>还是<font color="red">基因组<em>de novo</em></font>领域都适用。目前<font color="red">唯一的限制因素</font>是要获得足够的HiFi reads，测序成本投入比较<font color="red">昂贵</font>，从组装<strong>计算资源节省</strong>和<strong>项目时间缩短</strong>的角度看，HiFi reads未尝不是更好的选择。<strong>对于基因组<font color="red">重复序列较多的复杂基因组</font>，目前市场上<font color="red">传统长读长测序准确度不高</font>的特点给组装造成了一定的困难，高准确度的HiFi reads未来可能是一个更好的解决方案。</strong>而对于昆虫、中草药、藻类等重复序列较高、基因组较小的物种（＜700 Mb），目前利用一个8 M SMRT Cell 产出的数据量基本足以支持CCS组装，性价比更高。需要完善的HiFi文库建库流程和基于CCS reads组装的生信流程！</p>
<h2 id="2-Continuous-Long-Read-CLR-Sequencing"><a href="#2-Continuous-Long-Read-CLR-Sequencing" class="headerlink" title="2. Continuous Long Read (CLR) Sequencing"></a>2. Continuous Long Read (CLR) Sequencing</h2><p>这种测序的优势在于可以读取更长的 Reads。<font color="red">？为什么更长</font></p>
<p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/19.gif" alt="img"></p>
<h1 id="其他影响因素"><a href="#其他影响因素" class="headerlink" title="其他影响因素"></a>其他影响因素</h1><h2 id="1-GC-bias-影响"><a href="#1-GC-bias-影响" class="headerlink" title="1. GC bias 影响"></a>1. <font color="red">GC bias 影响</font></h2><blockquote>
<p>什么是 GC bias？<br>PCR 时，如果模板里的<font color="red">G、C碱基含量高，PCR效率低</font>，A、T碱基含量高，PCR效率高。一般测序过程，如二代测序，都会有大量的PCR过程。这样就会有一个问题，<font color="red">G、C含量高的片段，读到的 Reads 数少</font>。</p>
</blockquote>
<p>SMRT 没有 PCR ，因此GC含量高低的 Reads 片段都会有相似的概率被测序， GC Bias 影响小。</p>
<h2 id="2-读长的限制因素"><a href="#2-读长的限制因素" class="headerlink" title="2. 读长的限制因素"></a>2. 读长的限制因素</h2><ul>
<li><strong>DNA模板断裂</strong>，用激发光长时间照射DNA链时，会发生断裂，DNA链会从酶上掉下来，测序终止。</li>
<li><strong>酶变性</strong>，酶被长时间照射时，酶会变性，失去聚合酶活性，测序终止。</li>
<li><strong>文库序列短</strong>，如果做文库序列片段大于 20~30 K ，且保证质量的文库是有技术难度的</li>
</ul>
<h2 id="3-测序通量"><a href="#3-测序通量" class="headerlink" title="3. 测序通量"></a>3. 测序通量</h2><p><img src="/blog/2022/02/20/2022-02-20-SMRT-sequencing/20.png" alt="img"></p>
<p>目前，主流的测序平台有三种，各有利弊，可以根据自己的课题来选择。</p>
<p>以RSII为例，将测序复合物，随机撒到15万个小孔中，正好有一个<font color="red">复合物进入到单个小孔的概率符合泊松分布</font>。理论情况是</p>
<ul>
<li>1/3 的小孔中有<font color="red">一个</font>测序复合物，正常信号</li>
<li>1/3 的小孔什么都<font color="red">没有</font>，无信号</li>
<li>1/3 的小孔中有<font color="red">两个以上的测序复合物</font>，杂乱信号</li>
</ul>
<p>五万个小孔 * 10kb，所以一张芯片大约会产出500M的数据。</p>
<hr>
<h1 id="三代下机数据（以sequel-平台为主）"><a href="#三代下机数据（以sequel-平台为主）" class="headerlink" title="三代下机数据（以sequel 平台为主）"></a>三代下机数据（以sequel 平台为主）</h1><h2 id="测序过程"><a href="#测序过程" class="headerlink" title="测序过程"></a>测序过程</h2><ul>
<li><font color="green">A adapter</font>通用接头，两端的接头可以一样也可以不一样</li>
<li><font color="green">B barcode</font>(客户自己设计)</li>
<li><font color="green">I insert </font>插入片段，即我们测序的目的片段</li>
<li>由于SMRTbell是环状的，测序过程是边合成边测序，因此可以沿着新链合成的方向不停地读取序列，读取一圈又一圈</li>
</ul>
<h2 id="测序结果"><a href="#测序结果" class="headerlink" title="测序结果"></a>测序结果</h2><ul>
<li>根据SMRTbell的形状以及测序的过程，我们容易知道，测序出来的reads如上图所示，由接头序列, 条码序列, 插入序列间隔线性分布，即ABIB-ABIB—ABIB-ABIB—…（A: adapter, B: barcode, I: insert）</li>
<li> <font color="green">ZMW read</font> 是测序出来的完整结果，也即是<font color="green">polymerase read</font>，聚合酶合成过的所有的序列。</li>
<li> PostPrimary 分析后输出<font color="green">HQ region</font>，由ZMW read <font color="green">去除两端低质量</font>区域得到。</li>
</ul>
<h2 id="测序文件"><a href="#测序文件" class="headerlink" title="测序文件"></a>测序文件</h2><ul>
<li><p>RS II：<a href="https://www.itdaan.com/blog/2017/05/26/6e59c682169d236cb41a2b6ba146125e.html">https://www.itdaan.com/blog/2017/05/26/6e59c682169d236cb41a2b6ba146125e.html</a></p>
</li>
<li><p>Sequel</p>
<ul>
<li>在下机文件中，主要有三类文件，<font color="red">bam 文件</font>，<font color="red">bam.pbi 文件</font>，以及<font color="red">xml文件</font>。</li>
<li>无fastq文件，sequel平台中bam 文件成为了fq的替代者，更节约储存空间。这是文件格式的一个重大更新。</li>
<li> 用于后续分析的文件一般是<font color="red">.subreads.bam</font>，这等同于<font color="red">RS II </font>中的<font color="red">.subreads.fastq</font></li>
<li>下面介绍三类主要文件的具体格式</li>
</ul>
</li>
</ul>
<h3 id="BAM"><a href="#BAM" class="headerlink" title="BAM"></a>BAM</h3><ul>
<li><p><font color="green">普通bam</font>文件大多是<font color="green">比对结果文件</font>，例如用重测序分析中BWA生成的bam文件就是reads与基因组的比对文件。但<font color="red">pacbio的下机文件是没有与基因组进行过比对过</font>的，其主要作用是<font color="red">储存序列</font>。</p>
</li>
<li><p>Bam文件主要分为两个部分，头一部分是<font color="red">Header</font>，储存测序的相关信息，另一部分也即是文件的主要部分是records，保存<font color="red">序列信息</font>。就以subreads.bam文件为例，分析下bam文件的具体格式。</p>
</li>
<li><p>可以用samtools view 命令查看bam文件</p>
<blockquote>
<p>第一列：reads信息</p>
<p>{movieName}/{holeNumber}/{qStart}_{qEnd}<br>[对于CCS：{movieName}/{holeNumber}/ccs]<br>MovieName 是cell的名字，holeNumer是ZMW孔的编号，qStart和qEnd是subreads相对于ZMW reads的位置。<br>第二列 (sum of flags)：比对信息 均为4 代表没有比对上，也表明了bam文件只储存了序列信息，而没有比对信息。<br>第三列 (RNAM)：参考序列 值为 ，代表无参考序列<br>第四列 (position) : 比对上的第一个碱基位置 0<br>第五列 (Mapping quality) : 比对质量分数 255<br>第六列 (CIGAR值) : 比对的具体情况<br>第七列 (MRNM, ) : mate 对应的染色体<br>第八列 (mate position) : mate对应的位置 0<br>第九列 (ISIZE, Inferred fragment size) : 推断的插入片段大小 0</p>
<p>第十列 (Sequence) : 序列信息 具体的ATCG<br>第十一列 (ASCII码) : 碱基质量分数 ASCII+33<br>第十二列: 可选区域 记录Reads 的总体属性包括信号长度，信号强度等信息。</p>
</blockquote>
</li>
</ul>
<ol>
<li>zmws.bam 以及ccs.bam似乎公司并不一定会提供</li>
<li>经过检查，一条zmw reads 可以产生多条 subreads，也就是说subreads.bam 中，序列只是被剪下来了。</li>
<li>scraps.bam 格式保存的是获取subreads时废弃的序列，包括adapter，以及一些低质量的序列</li>
<li><strong>CCS.bam保存的是矫正后的一致性序列</strong>。</li>
</ol>
<h3 id="BAM-pbi"><a href="#BAM-pbi" class="headerlink" title="BAM.pbi"></a>BAM.pbi</h3><ul>
<li><p>是bam文件的<font color="red">索引文件</font>(PacBio BAM index)，与上一个版本（<font color="red">RS II</font>）的<font color="red">*cmp.h5</font>文件<font color="red">兼容</font>，其格式类似于<font color="red">HDF5</font>， 通过<font color="red"><strong>BGZF格式压缩</strong></font>。</p>
</li>
<li><p> 其存在主要有两个作用</p>
</li>
<li><h5 id="随机访问"><a href="#随机访问" class="headerlink" title="随机访问"></a><font color="red">随机</font>访问</h5><p>通过参考序列，基因组区域；通过read 组别；通过qurey name；通过ZMW；通过barcode；其他</p>
</li>
<li><h5 id="在无需完全访问BAM文件的情况下，获取信息"><a href="#在无需完全访问BAM文件的情况下，获取信息" class="headerlink" title="在无需完全访问BAM文件的情况下，获取信息"></a>在无需完全访问BAM文件的情况下，获取信息</h5></li>
</ul>
<p>   获取<font color="red">统计信息</font>；通过提供index访问记录信息</p>
<h3 id="xml"><a href="#xml" class="headerlink" title="xml"></a>xml</h3><ul>
<li>MetaData, 储存数据描述。可用于<strong>filter</strong> 或者<strong>subset</strong>等功能。</li>
<li> sts.xml 储存数据的统计信息。</li>
<li> SMRT Link CL tools in 5.0.0 dataset命令可以进行方便的操作。</li>
</ul>
<hr>
<h1 id="Pacbio-Sequel-下机数据实例"><a href="#Pacbio-Sequel-下机数据实例" class="headerlink" title="Pacbio Sequel 下机数据实例"></a>Pacbio Sequel 下机数据实例</h1><blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;m54134_180724_220656.scraps.bam</span><br><span class="line">&gt;m54134_180724_220656.subreads.bam</span><br><span class="line">&gt;m54134_180724_220656.scraps.bam.pbi</span><br><span class="line">&gt;m54134_180724_220656.subreads.bam.pbi</span><br><span class="line">&gt;m54134_180724_220656.baz2bam_1.log</span><br><span class="line">&gt;m54134_180724_220656.sts.xml</span><br><span class="line">&gt;m54134_180724_220656.subreadset.xml</span><br><span class="line">&gt;m54134_180724_220656.transferdone</span><br><span class="line">&gt;m54134_180724_220656.adapters.fasta</span><br></pre></td></tr></table></figure>
</blockquote>
<p>m54134_180724_220656.subreads.bam</p>
<p><font color="red">m: 是movie 的缩写</font></p>
<p><font color="red">54134： 是设备的编号</font></p>
<p><font color="red">180724_220656： 是测序运行的开始时间，为2018年07月24日22时06分56秒</font></p>
<p><font color="red">subreads: 这部分是不同的数据类型，一般有scraps， subreads等</font></p>
<p><font color="red">bam: 这是数据的格式，一般有bam格式，xml，fasta格式等</font></p>
<p>BAM文件官网：<a href="https://pacbiofileformats.readthedocs.io/en/3.0/BAM.html">https://pacbiofileformats.readthedocs.io/en/3.0/BAM.html</a></p>
<p><a href="https://github.com/PacificBiosciences/PacBioFileFormats/blob/3.0/BAM.rst">https://github.com/PacificBiosciences/PacBioFileFormats/blob/3.0/BAM.rst</a></p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>三代测序</title>
    <url>/blog/2022/02/20/2022-02-20-Pacbio/</url>
    <content><![CDATA[<h1 id="第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。"><a href="#第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。" class="headerlink" title="第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。"></a>第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。</h1><span id="more"></span>

<h1 id="技术原理"><a href="#技术原理" class="headerlink" title="技术原理"></a>技术原理</h1><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p><font color="green">单分子荧光测序</font>，代表性技术为<font color="green">美国螺旋生物(Helicos)</font>的<font color="green">SMS技术</font>和<font color="green">美国太平洋生物(Pacific Bioscience)</font>的<font color="green">SMRT技术</font>。脱氧核苷酸荧光标记，显微镜实时记录荧光强度变化。当荧光标记脱氧核苷酸被掺入DNA链时，荧光同时在DNA链上测到。当它与DNA链形成化学键时，荧光基团被DNA聚合酶切除，荧光消失。荧光标记脱氧核苷酸不影响DNA聚合酶活性，荧光基团切除后，合成的DNA链和天然DNA链完全一样。</p>
<p>PacBio采用<font color="green">边合成边测序</font>方式，以其中一条DNA链为模板，通过DNA聚合酶合成另外一条链，进一步将荧光信号转变为碱基信号。同时PacBio已升级<font color="green">CCS测序模式</font>以获得<font color="green">长读长高保真（HiFi）15 kb reads</font>，由此提升基因组组装准确性。</p>
<h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><p><font color="green">纳米孔测序</font>，<font color="green">英国牛津纳米孔公司</font>。新型纳米孔测序法（nanopore sequencing）是采用电泳技术，借助<font color="green">电泳驱动单个分子逐一通过纳米孔</font>实现测序。纳米孔直径非常细小，仅允许单个核酸聚合物通过，而ATCG<font color="green">单个碱基带电性质</font>不一样，通过<font color="green">电信号差异</font>检测出通过碱基类别，实现测序。</p>
<p>Nanopore当单链DNA分子穿过纳米孔，相对于每个核苷酸，获得不同电流信号。记录每个孔的离子电流变化，并基于<font color="red">马尔可夫模型</font>或<font color="red">递归神经网络</font>的方法将其转换为碱基序列。此外，<font color="green">Ultra-long reads (ULRs) </font>是ONT平台的另一重要特征，并具有促进<font color="green">大型基因组组装</font>潜力。</p>
<table>
<thead>
<tr>
<th>De novo研究</th>
<th>研究内容</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>基因组组装</td>
<td>多软件组装、组装结果评估</td>
<td></td>
</tr>
<tr>
<td>基因预测与注释</td>
<td>编码基因预测；重复序列注释和转座元件分类；非编码RNA注释；假基因注释等</td>
<td></td>
</tr>
<tr>
<td>Hi-C辅助基因组组装</td>
<td>有效数据评估；Contig聚类、排序及定向分析；挂载结果评估</td>
<td></td>
</tr>
<tr>
<td>生物学问题解析</td>
<td>比较基因组学研究</td>
<td>基因家族聚类；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>系统发育树的构建；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>基因家族扩张与收缩分析；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>物种分化时间推算；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LTR形成时间估算；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>全基因组复制事件；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>选择压力分析</td>
</tr>
<tr>
<td></td>
<td>特定生物学问题剖析</td>
<td>结合组学研究方法，深入对某物种生物学问题进行解析</td>
</tr>
</tbody></table>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/13.png" alt="33"></p>
<p>草莓基因家族聚类分析</p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/14.png" alt="44"></p>
<p>薏苡全基因组复制事件分析</p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/15.png" alt="img"></p>
<p>开心果系统进化树与基因家族收缩扩张分析</p>
<p><img src="/blog/./16.png" alt="img"></p>
<p>陆地棉亚基因组共线性分析</p>
<h1 id="关键点"><a href="#关键点" class="headerlink" title="关键点"></a>关键点</h1><p>第一：<font color="green">显微镜</font>实时记录DNA链荧光时，<font color="green">DNA链周围众多荧光标记脱氧核苷酸</font>形成非常强大的<font color="green">荧光背景</font>。强大荧光背景阻碍单分子荧光探测。Pacific Biosciences公司发明了一种<font color="green">直径只有几十纳米的纳米孔</font>[zero-mode waveguides (ZMWs)]，单分子的<font color="green">DNA聚合酶</font>被固定在孔内。在小孔内，DNA链<font color="green">周围荧光标记</font>的脱氧核苷酸<font color="green">有限</font>，而且由于A，T，C，G这四种荧光标记的脱氧核苷酸非常快速地从外面进入到孔内又出去，形成了非常<font color="green">稳定的背景荧光信号</font>。当某一种荧光标记的脱氧核苷酸被掺入到DNA链时，特定颜色的<font color="green">荧光会持续一小段时间</font>，直到新的化学键形成，荧光基团被DNA聚合酶切除为止。</p>
<p>第二：<font color="green">共聚焦显微镜</font>实时快速地对集成在<font color="green">板上的无数纳米小孔同时记录</font>。</p>
<h1 id="技术特点"><a href="#技术特点" class="headerlink" title="技术特点"></a>技术特点</h1><p>1、实现DNA聚合酶内在自身的<font color="green">反应速度</font>，一秒测10个碱基，测序速度是<font color="green">化学法测序2万倍</font>。</p>
<p>2、实现了DNA聚合酶内在自身的<font color="green">延续性</font>，一个反应可测非常长的序列。二代测序可以测到上百个碱基，但是三代测序可测几千个碱基。</p>
<p>3、<font color="green">精度</font>非常高，达到<font color="green">99.9999%</font>。</p>
<p>4、直接测<font color="green">RNA序列</font> (<strong>ISO</strong>)。既然<font color="green">DNA聚合酶</font>能够实时观测，那么以RNA为模板复制<font color="green">DNA的逆转录酶</font>也同样可以。RNA直接测序，将大大降低体外逆转录产生的系统误差。</p>
<p>5、第二个是直接测<font color="green">甲基化DNA序列</font>。实际上DNA聚合酶<font color="red"><strong>复制A、T、C、G的速度不一样</strong></font>。<font color="red"><strong>正常的C或者甲基化的C为模板，DNA聚合酶停顿的时间不同</strong></font>。根据时间不同，可以<font color="red"><strong>判断模板的C是否甲基化</strong></font>。</p>
<h1 id="平台比较"><a href="#平台比较" class="headerlink" title="平台比较"></a>平台比较</h1><table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>测序方法/平台</td>
<td>公司</td>
<td>方法/酶</td>
<td>测序长度</td>
<td>每个循环的数据产出量</td>
<td>每个循环耗时</td>
<td>主要错误来源</td>
<td></td>
</tr>
<tr>
<td>第三代测序技术</td>
<td>Heliscope/HelicosGenetic AnalysisSystem</td>
<td>Helicos</td>
<td>边合成边测序/DNA聚合酶</td>
<td>30-35 bp</td>
<td>21-28 Gb</td>
<td>8 d</td>
<td>替换</td>
</tr>
<tr>
<td>SMRT</td>
<td>Pacific Biosciences</td>
<td>边合成边测序/DNA聚合酶</td>
<td>100000 bp</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>纳米孔单分子</td>
<td>Oxford Nanopore</td>
<td>电信号测序/核酸外切酶</td>
<td>无限长</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="基因组测序"><a href="#基因组测序" class="headerlink" title="基因组测序"></a>基因组测序</h2><p>由于具有读长长的特点，SMRT测序平台在基因组测序中能<font color="green"><strong>降低测序后的Contig数量</strong></font>，明显<font color="green"><strong>减少</strong></font>后续基因组<font color="green"><strong>拼接和注释工作量</strong></font>，节省大量时间。Christophern等仅仅用0.5的Pacbio RS系统长度的数据与二代测序(NGS)的测序数据，对<strong>马达加斯加指猴</strong>基因组进行拼装，大幅度<font color="green">提高</font>数据的<font color="green">质量和完整度</font>，同时借助Pacbio RS将原有<font color="green">Contig数量减少10倍</font>。DavidA．等利用Pachio RS平台C2试剂通过全球合作几天内就完成了从<font color="green"><strong>德国大肠杆菌疫情</strong></font>中获得的<font color="green">大肠杆菌样品</font>以及<font color="green">近似菌株</font>的测序和数据分析，最终获得<font color="green">2900bp平均读长</font>以及<font color="green">99.998%一致性准确度</font>。在对<font color="green"><strong>霍乱病菌</strong></font>的研究中第三代测序技术已初现锋芒。研究人员对<font color="green">5株霍乱菌株</font>的基因组进行了测序研究，并与其他<font color="green">23株霍乱弧菌</font>的<font color="green">基因组进行对比</font>。结果发现海地霍乱菌株与2002年和2008年孟加拉国变异霍乱弧菌ElTorO1菌株之间关系密切，而与1991年拉丁美洲霍乱分离株的关系较远。相对NGS的优势就是能<font color="red">更快获得结果</font>，因此该系统在<font color="red">鉴定新的病原体和细菌</font>的基因组测序方面得到广泛应用。</p>
<h2 id="甲基化研究"><a href="#甲基化研究" class="headerlink" title="甲基化研究"></a>甲基化研究</h2><p><strong>SMRT技术</strong>对DNA<strong>聚合酶</strong>的工作状态<strong>实时监测</strong>，聚合酶<strong>合成每一个碱基</strong>，都有<strong>一个时间段</strong>，而当模板碱基<strong>带有修饰时</strong>，聚合酶会<strong>慢下来</strong>，使<strong>带有修饰的碱基两个相邻的脉冲峰</strong>之间的<strong>距离</strong>和<strong>参考序列的距离之间的比值</strong>结果<strong>大于1</strong>，由此就可以推断这个位置有修饰。甲基化研究中关于<strong>5mC和5hmC</strong>（5mC的羟基化形式）是甲基化研究中的热点。但<strong>现有测序方法无法区分</strong>5mC和5hmC。<strong>美国芝加哥大学</strong>利用<strong>SMRT</strong>测序技术和<strong>5hmC的选择性化学标记方法</strong>来高通量检测5hmC。通过聚合酶动力学提供的信息，可直接检测到<font color="green">DNA甲基化</font>，包括<font color="red">N6甲基腺嘌呤、5mC和5hmC</font>，为表观遗传学研究打开了一条通路。</p>
<h2 id="突变鉴定（SNP检测）"><a href="#突变鉴定（SNP检测）" class="headerlink" title="突变鉴定（SNP检测）"></a>突变鉴定（SNP检测）</h2><p>单分子测序的分辨率具有不可比拟的优势，而且没有PCR扩增，就<font color="green">没有扩增引入的碱基错误</font>，该优势使其在<font color="green">特定序列的SNP检测</font>，<font color="green">稀有突变及其频率测定</font>中大显身手。例如在医学研究中，对于FLT3基因是否是急性髓细胞白血病（AML）的有效治疗靶标一直存在质疑。研究人员用单分子测序分析耐药性患者基因，意外发现耐药性与FLT3基因下游出现的稀有新突变有关，重新证明了FLT3基因是这种最常见白血病—急性髓细胞白血病（AML）的有效治疗靶标，打破了一直以来对于这一基因靶标的疑惑。凭借PacBio平均3000bp的读长，获得了更多基因下游的宝贵信息，而基于单核酸分子的测序能够<font color="red"><strong>检测到低频率（低至1%）罕见突变</strong></font>，正是这项成果的关键所在。</p>
<hr>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/1.png" alt="img"></p>
<h1 id="第一代测序"><a href="#第一代测序" class="headerlink" title="第一代测序"></a>第一代测序</h1><p>第一代DNA测序技术用的是1975年由桑格（Sanger）和考尔森（Coulson）开创的链终止法或者是1976-1977年由马克西姆（Maxam）和吉尔伯特（Gilbert）发明的化学法（链降解）. 并在1977年，桑格测定了第一个基因组序列，是噬菌体X174的，全长5375个碱基1。自此，人类获得了窥探生命遗传差异本质的能力，并以此为开端步入基因组学时代。研究人员在Sanger法的多年实践之中不断对其进行改进。在2001年，完成的首个人类基因组图谱就是以改进了的Sanger法为其测序基础，Sanger法核心原理是：由于ddNTP的2’和3’都不含羟基，其在DNA的合成过程中不能形成磷酸二酯键，因此可以用来中断DNA合成反应，在4个DNA合成反应体系中分别加入一定比例带有放射性同位素标记的ddNTP（分为：ddATP,ddCTP,ddGTP和ddTTP），通过凝胶电泳和放射自显影后可以根据电泳带的位置确定待测分子的DNA序列（图2）。这个<a href="http://smcg.cifn.unam.mx/enp-unam/03-EstructuraDelGenoma/animaciones/secuencia.swf">网址</a>为sanger测序法制作了一个小短片，形象而生动。</p>
<p>　　值得注意的是，就在测序技术起步发展的这一时期中，除了Sanger法之外还出现了一些其他的测序技术，如焦磷酸测序法、链接酶法等。其中，焦磷酸测序法是后来Roche公司454技术所使用的测序方法2–4，而连接酶测序法是后来ABI公司SOLID技术使用的测序方法2,4，但他们的共同核心手段都是利用了Sanger1中的可中断DNA合成反应的dNTP。</p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/2.png" alt="img"></p>
<h1 id="第二代测序"><a href="#第二代测序" class="headerlink" title="第二代测序"></a>第二代测序</h1><p>总的说来，第一代测序技术的主要特点是测序读长可达1000bp，准确性高达99.999%，但其测序成本高，通量低等方面的缺点，严重影响了其真正大规模的应用。因而第一代测序技术并不是最理想的测序方法。经过不断的技术开发和改进，以Roche公司的454技术、illumina公司的Solexa，Hiseq技术和ABI公司的Solid技术为标记的第二代测序技术诞生了。第二代测序技术大大降低了测序成本的同时，还大幅提高了测序速度，并且保持了高准确性，以前完成一个人类基因组的测序需要3年时间，而使用二代测序技术则仅仅需要1周，但在序列读长方面比起第一代测序技术则要短很多。表1和图3对第一代和第二代测序技术各自的特点以及测序成本作了一个简单的比较5，以下我将对这三种主要的第二代测序技术的主要原理和特点作一个简单的介绍。 </p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/3.png" alt="img"></p>
<h2 id="Illumina"><a href="#Illumina" class="headerlink" title="Illumina"></a>Illumina</h2><p>　　Illumina公司的Solexa和Hiseq应该说是目前全球使用量最大的第二代测序机器，这两个系列的技术核心原理是相同的2,4。这两个系列的机器采用的都是边合成边测序的方法，它的测序过程主要分为以下4步，如图4.</p>
<p>​     （1）DNA待测文库构建</p>
<p>　　利用超声波把待测的DNA样本打断成小片段，目前除了组装之外和一些其他的特殊要求之外，主要是打断成200-500bp长的序列片段，并在这些小片段的两端添加上不同的接头，构建出单链DNA文库。</p>
<p>​     （2）Flowcell</p>
<p>　　Flowcell是用于吸附流动DNA片段的槽道，当文库建好后，这些文库中的DNA在通过flowcell的时候会随机附着在flowcell表面的channel上。每个Flowcell有8个channel，每个channel的表面都附有很多接头，这些接头能和建库过程中加在DNA片段两端的接头相互配对（这就是为什么flowcell能吸附建库后的DNA的原因），并能支持DNA在其表面进行桥式PCR的扩增。</p>
<p>​     （3）桥式PCR扩增与变性</p>
<p>　　桥式PCR以Flowcell表面所固定的接头为模板，进行桥形扩增，如图4.a所示。经过不断的扩增和变性循环，最终每个DNA片段都将在各自的位置上集中成束，每一个束都含有单个DNA模板的很多分拷贝，进行这一过程的目的在于实现将碱基的信号强度放大，以达到测序所需的信号要求。 </p>
<p>（4）测序</p>
<p>　　测序方法采用边合成边测序的方法。向反应体系中同时添加DNA聚合酶、接头引物和带有碱基特异荧光标记的4中dNTP（如同Sanger测序法）。这些dNTP的3’-OH被化学方法所保护，因而每次只能添加一个dNTP。在dNTP被添加到合成链上后，所有未使用的游离dNTP和DNA聚合酶会被洗脱掉。接着，再加入激发荧光所需的缓冲液，用激光激发荧光信号，并有光学设备完成荧光信号的记录，最后利用计算机分析将光学信号转化为测序碱基。这样荧光信号记录完成后，再加入化学试剂淬灭荧光信号并去除dNTP 3’-OH保护基团，以便能进行下一轮的测序反应。Illumina的这种测序技术每次只添加一个dNTP的特点能够很好的地解决同聚物长度的准确测量问题，它的主要测序错误来源是碱基的替换，目前它的测序错误率在1%-1.5%之间，测序周期以人类基因组重测序为例，30x测序深度大约为1周。</p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/4.png" alt="img"></p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/5.png" alt="img"></p>
<h2 id="Roche-454"><a href="#Roche-454" class="headerlink" title="Roche 454"></a>Roche 454</h2><p>Roche 454测序系统是第一个商业化运营二代测序技术的平台。它的主要测序原理是（图5 abc）2：</p>
<p>（1）DNA文库制备</p>
<p>　　454测序系统的文件构建方式和illumina的不同，它是利用喷雾法将待测DNA打断成300-800bp长的小片段，并在片段两端加上不同的接头，或将待测DNA变性后用杂交引物进行PCR扩增，连接载体，构建单链DNA文库（图5a）。</p>
<p>（2）Emulsion PCR （乳液PCR，其实是一个注水到油的独特过程）</p>
<p>454当然DNA扩增过程也和illumina的截然不同，它将这些单链DNA结合在水油包被的直径约28um的磁珠上，并在其上面孵育、退火。</p>
<p>　　乳液PCR最大的特点是可以形成数目庞大的独立反应空间以进行DNA扩增。其关键技术是“注水到油”（水包油），基本过程是在PCR反应前，将包含PCR所有反应成分的水溶液注入到高速旋转的矿物油表面，水溶液瞬间形成无数个被矿物油包裹的小水滴。这些小水滴就构成了独立的PCR反应空间。理想状态下，每个小水滴只含一个DNA模板和一个磁珠。</p>
<p>　　这些被小水滴包被的磁珠表面含有与接头互补的DNA序列，因此这些单链DNA序列能够特异地结合在磁珠上。同时孵育体系中含有PCR反应试剂，所以保证了每个与磁珠结合的小片段都能独立进行PCR扩增，并且扩增产物仍可以结合到磁珠上。当反应完成后，可以破坏孵育体系并将带有DNA的磁珠富集下来。进过扩增，每个小片段都将被扩增约100万倍，从而达到下一步测序所要求的DNA量。</p>
<p>（3）焦磷酸测序</p>
<p>　　测序前需要先用一种聚合酶和单链结合蛋白处理带有DNA的磁珠，接着将磁珠放在一种PTP平板上。这种平板上特制有许多直径约为44um的小孔，每个小孔仅能容纳一个磁珠，通过这种方法来固定每个磁珠的位置，以便检测接下来的测序反应过程。　　</p>
<p>　　测序方法采用焦磷酸测序法，将一种比PTP板上小孔直径更小的磁珠放入小孔中，启动测序反应。测序反应以磁珠上大量扩增出的单链DNA为模板，每次反应加入一种dNTP进行合成反应。如果dNTP能与待测序列配对，则会在合成后释放焦磷酸基团。释放的焦磷酸基团会与反应体系中的ATP硫酸化学酶反应生成ATP。生成的ATP和荧光素酶共同氧化使测序反应中的荧光素分子并发出荧光，同时由PTP板另一侧的CCD照相机记录，最后通过计算机进行光信号处理而获得最终的测序结果。由于每一种dNTP在反应中产生的荧光颜色不同，因此可以根据荧光的颜色来判断被测分子的序列。反应结束后，游离的dNTP会在双磷酸酶的作用下降解ATP，从而导致荧光淬灭，以便使测序反应进入下一个循环。由于454测序技术中，每个测序反应都在PTP板上独立的小孔中进行，因而能大大降低相互间的干扰和测序偏差。454技术最大的优势在于其能获得较长的测序读长，当前454技术的平均读长可达400bp，并且454技术和illumina的Solexa和Hiseq技术不同，它最主要的一个缺点是无法准确测量同聚物的长度，如当序列中存在类似于PolyA的情况时，测序反应会一次加入多个T，而所加入的T的个数只能通过荧光强度推测获得，这就有可能导致结果不准确。也正是由于这一原因，454技术会在测序过程中引入插入和缺失的测序错误。 </p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/6.png" alt="img"></p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/7.png" alt="img"></p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/8.png" alt="img"></p>
<h2 id="Solid技术"><a href="#Solid技术" class="headerlink" title="Solid技术"></a>Solid技术</h2><p>Solid测序技术是ABI公司于2007年开始投入用于商业测序应用的仪器。它基于连接酶法，即利用DNA连接酶在连接过程之中测序（图6）2,4。它的原理是：</p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/9.png" alt="img"></p>
<p>　（1）DNA文库构建</p>
<p>​              　　片段打断并在片段两端加上测序接头，连接载体，构建单链DNA文库。</p>
<p>​           （2）Emulsion PCR</p>
<p>　　Solid的PCR过程也和454的方法类似，同样采用小水滴emulsion PCR，但这些微珠比起454系统来说则要小得多，只有1um。在扩增的同时对扩增产物的3’端进行修饰，这是为下一步的测序过程作的准备。3’修饰的微珠会被沉积在一块玻片上。在微珠上样的过程中，沉积小室将每张玻片分成1个、4个或8个测序区域（图6-a）。Solid系统最大的优点就是每张玻片能容纳比454更高密度的微珠，在同一系统中轻松实现更高的通量。</p>
<p>​           （3）连接酶测序</p>
<p>　　这一步是Solid测序的独特之处。它并没有采用以前测序时所常用的DNA聚合酶，而是采用了连接酶。Solid连接反应的底物是8碱基单链荧光探针混合物，这里将其简单表示为：3’-XXnnnzzz-5’。连接反应中，这些探针按照碱基互补规则与单链DNA模板链配对。探针的5’末端分别标记了CY5、Texas Red、CY3、6-FAM这4种颜色的荧光染料（图6-a）。这个8碱基单链荧光探针中，第1和第2位碱基（XX）上的碱基是确定的，并根据种类的不同在6-8位（zzz）上加上了不同的荧光标记。这是Solid的独特测序法，两个碱基确定一个荧光信号，相当于一次能决定两个碱基。这种测序方法也称之为两碱基测序法。当荧光探针能够与DNA模板链配对而连接上时，就会发出代表第1，2位碱基的荧光信号，图6-a和图6-b中的比色版所表示的是第1，2位碱基的不同组合与荧光颜色的关系。在记录下荧光信号后，通过化学方法在第5和第6位碱基之间进行切割，这样就能移除荧光信号，以便进行下一个位置的测序。不过值得注意的是，通过这种测序方法，每次测序的位置都相差5位。即第一次是第1、2位，第二次是第6、7位……在测到末尾后，要将新合成的链变性，洗脱。接着用引物n-1进行第二轮测序。引物n-1与引物n的区别是，二者在与接头配对的位置上相差一个碱基（图6-a. 8）。也即是，通过引物n-1在引物n的基础上将测序位置往3’端移动一个碱基位置，因而就能测定第0、1位和第5、6位……第二轮测序完成，依此类推，直至第五轮测序，最终可以完成所有位置的碱基测序，并且每个位置的碱基均被检测了两次。该技术的读长在2×50bp，后续序列拼接同样比较复杂。由于双次检测，这一技术的原始测序准确性高达99.94%，而15x覆盖率时的准确性更是达到了99.999%，应该说是目前第二代测序技术中准确性最高的了。但在荧光解码阶段，鉴于其是双碱基确定一个荧光信号，因而一旦发生错误就容易产生连锁的解码错误。</p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/10.png" alt="img"></p>
<h1 id="第三代测序技术"><a href="#第三代测序技术" class="headerlink" title="第三代测序技术"></a>第三代测序技术</h1><p>以PacBio公司的<font color="red">SMRT</font>和<font color="red">Oxford Nanopore Technologies纳米孔单分子测序技术</font>，被称之为第三代测序技术。与前两代相比，最大的特点是单分子测序，测序过程<font color="red">无需PCR</font>扩增。</p>
<p>　　PacBio SMRT技术也应用了边合成边测序思想，并以SMRT芯片为测序载体。基本原理： DNA聚合酶和模板结合,4色荧光标记 4 种碱基（即是dNTP）,在碱基配对阶段,不同碱基加入,发不同光,根据<font color="green">光的波长与峰值</font>判断进入碱基类型。 DNA 聚合酶是实现超长读长的关键之一,读长主要跟<font color="red">酶的活性保持</font>有关,它主要受激光对其造成的损伤所影响。</p>
<p>​        PacBio SMRT技术的一个关键是怎样将反应信号与周围游离碱基的<font color="red">强大荧光背景</font>区别。<font color="red"><strong>ZMW（零模波导孔）原理</strong></font>：如同微波炉壁上可看到的很多密集小孔。小孔直径有考究,如果直径大于微波波长,能量就会在衍射效应的作用下穿透面板而泄露出来，从而与周围小孔相互干扰。如果孔径小于波长,能量不会辐射到周围，而是保持直线状态（光衍射的原理）,从而可起保护作用。同理,在一个反应管(SMRTCell:单分子实时反应孔)中有许多这样的圆形纳米小孔, 即 ZMW(零模波导孔),外径 100多纳米,比检测激光波长小(数百纳米),激光从底部打上去后不能穿透小孔进入上方溶液区,能量被限制在一个小范围(体积20X 10-21 L)里,正好足够覆盖需要检测的部分,使得信号仅来自这个小反应区域,孔外过多游离核苷酸单体依然留在黑暗中,从而实现将背景降到最低。另外，可以通过检测相邻两个碱基之间的测序时间，来检测一些碱基修饰情况，既如果碱基存在修饰，则通过聚合酶时的速度会减慢，相邻两峰之间的距离增大，可以通过这个来之间检测甲基化等信息（图7）。SMRT技术的测序速度很快，每秒约10个dNTP。但是，同时其测序<font color="red">错误率比较高</font>（这几乎是目前单分子测序技术的通病），达到<font color="red">15%</font>,但好在它的出错是随机的，并不会像第二代测序技术那样存在测序错误的偏向，因而可以通过<font color="red">多次测序来进行有效的纠错</font>。</p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/11.png" alt="img"></p>
<p>Oxford Nanopore Technologies公司所开发的纳米单分子测序技术与以往的测序技术皆不同，它是基于电信号而不是光信号的测序技术。该技术的关键之一是，他们设计了一种特殊的纳米孔，孔内共价结合有分子接头。当DNA碱基通过纳米孔时，它们使电荷发生变化，从而短暂地影响流过纳米孔的电流强度（每种碱基所影响的电流变化幅度是不同的），灵敏的电子设备检测到这些变化从而鉴定所通过的碱基。</p>
<p>　　该公司在去年基因组生物学技术进展年会(AGBT)上推出第一款商业化的纳米孔测序仪，引起了科学界的极大关注。纳米孔测序（和其他第三代测序技术）有望解决目前测序平台的不足，纳米孔测序的主要特点是：读长很长，大约在几十kb，甚至100 kb;错误率目前介于1%至4%，且是随机错误，而不是聚集在读取的两端;数据可实时读取;通量很高(30x人类基因组有望在一天内完成);起始DNA在测序过程中不被破坏;以及样品制备简单又便宜。理论上，它也能直接测序RNA。</p>
<p>　　纳米孔单分子测序计算还有另一大特点，它能够直接读取出甲基化的胞嘧啶，而不必像传统方法那样对基因组进行bisulfite处理。这对于在基因组水平直接研究表观遗传相关现象有极大的帮助。并且改方法的测序准确性可达99.8%，而且一旦发现测序错误也能较容易地进行纠正。但目前似乎还没有应用该技术的相关报道。</p>
<p><img src="/blog/2022/02/20/2022-02-20-Pacbio/12.png" alt="img"></p>
<h1 id="其他测序技术"><a href="#其他测序技术" class="headerlink" title="其他测序技术"></a>其他测序技术</h1><p>目前还有一种基于半导体芯片的新一代革命性测序技术——Ion Torrent6。该技术使用了一种布满小孔的高密度半导体芯片， 一个小孔就是一个测序反应池。当DNA聚合酶把核苷酸聚合到延伸中的DNA链上时，会释放出一个氢离子，反应池中的PH发生改变，位于池下的离子感受器感受到H+离子信号，H+离子信号再直接转化为数字信号，从而读出DNA序列（图9）。这一技术的发明人同时也是454测序技术的发明人之一——Jonathan Rothberg，它的文库和样本制备跟454技术很像，甚至可以说就是454的翻版，只是测序过程中不是通过检测焦磷酸荧光显色，而是通过检测H+信号的变化来获得序列碱基信息。Ion Torrent相比于其他测序技术来说，不需要昂贵的物理成像等设备，因此，成本相对来说会低，体积也会比较小，同时操作也要更为简单，速度也相当快速，除了2天文库制作时间，整个上机测序可在2-3.5小时内完成，不过整个芯片的通量并不高，目前是10G左右，但非常适合小基因组和外显子验证的测序。    </p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上，对各代测序技术的原理做了简要的阐述，这三代测序技术的特点比较汇总在以下表1和表2中。其中测序成本，读长和通量是评估该测序技术先进与否的三个重要指标。第一代和第二代测序技术除了通量和成本上的差异之外，其测序核心原理（除Solid是边连接边测序之外）都是基于边合成边测序的思想。第二代测序技术的优点是成本较之一代大大下降，通量大大提升，但缺点是所引入PCR过程会在一定程度上增加测序的错误率，并且具有系统偏向性，同时读长也比较短。第三代测序技术是为了解决第二代所存在的缺点而开发的，它的根本特点是单分子测序，不需要任何PCR的过程，这是为了能有效避免因PCR偏向性而导致的系统错误，同时提高读长，并要保持二代技术的高通量，低成本的优点。</p>
<table>
<thead>
<tr>
<th><strong>第<strong><strong>X</strong></strong>代</strong></th>
<th><strong>公司</strong></th>
<th><strong>平台名称</strong></th>
<th><strong>测序方法</strong></th>
<th><strong>检测方法</strong></th>
<th><strong>大约读长</strong><strong>(<strong><strong>碱基数</strong></strong>)</strong></th>
<th><strong>优点</strong></th>
<th><strong>相对局限性</strong></th>
</tr>
</thead>
<tbody><tr>
<td>第一代</td>
<td>ABI/生命技术公司</td>
<td>3130xL-3730xL</td>
<td>桑格-毛细管电泳测序法</td>
<td>荧光/光学</td>
<td>600-1000</td>
<td>高读长，准确度一次性达标率高，能很好处理重复序列和多聚序列</td>
<td>通量低；样品制备成本高，使之难以做大量的平行测序</td>
</tr>
<tr>
<td>第一代</td>
<td>贝克曼</td>
<td>GeXP遗传分析系统</td>
<td>桑格-毛细管电泳测序法</td>
<td>荧光/光学</td>
<td>600-1000</td>
<td>高读长，准确度一次性达标率高，能很好处理重复序列和多聚序列；易小型化</td>
<td>通量低；单个样品的制备成本相对较高</td>
</tr>
<tr>
<td>第二代</td>
<td>Roche/454</td>
<td>基因组测序仪FLX系统</td>
<td>焦磷酸测序法</td>
<td>光学</td>
<td>230-400</td>
<td>在第二代中最高读长；比第一代的测序通量大</td>
<td>样品制备较难；难于处理重复和同种碱基多聚区域；试剂冲洗带来错误累积；仪器昂贵</td>
</tr>
<tr>
<td>第二代</td>
<td>Illumina</td>
<td>HiSeq2000,HiSeq2500/MiSeq</td>
<td>可逆链终止物和合成测序法</td>
<td>荧光/光学</td>
<td><strong>2x150</strong></td>
<td>很高测序通量</td>
<td>仪器昂贵；用于数据删节和分析的费用很高</td>
</tr>
<tr>
<td>第二代</td>
<td>ABI/Solid</td>
<td>5500xlSolid系统</td>
<td>连接测序法</td>
<td>荧光/光学</td>
<td>25-35</td>
<td>很高测序通量；在广为接受的几种第二代平台中，所要拼接出人类基因组的试剂成本最低</td>
<td>测序运行时间长；读长短，造成成本高，数据分析困难和基因组拼接困难；仪器昂贵</td>
</tr>
<tr>
<td>第二代</td>
<td>赫利克斯</td>
<td>Heliscope</td>
<td>单分子合成测序法</td>
<td>荧光/光学</td>
<td>25-30</td>
<td>高通量；在第二代中属于单分子性质的测序技术</td>
<td>读长短，推高了测序成本，降低了基因组拼接的质量；仪器非常昂贵</td>
</tr>
<tr>
<td>第三代</td>
<td>太平洋生物科学公司</td>
<td>PacBio RS</td>
<td>实时单分子DNA测序</td>
<td>荧光/光学</td>
<td>~1000</td>
<td>高平均读长，比第一代的测序时间降低；不需要扩增；最长单个读长接近3000碱基</td>
<td>并不能高效地将DNA聚合酶加到测序阵列中；准确性一次性达标的机会低（81-83%）；DNA聚合酶在阵列中降解；总体上每个碱基测序成本高（仪器昂贵）；</td>
</tr>
<tr>
<td>第三代</td>
<td>全基因组学公司</td>
<td>GeXP遗传分析系统</td>
<td>复合探针锚杂交和连接技术</td>
<td>荧光/光学</td>
<td>10</td>
<td>在第三代中通量最高；在所有测序技术中，用于拼接一个人基因组的试剂成本最低；每个测序步骤独立，使错误的累积变得最低</td>
<td>低读长； 模板制备妨碍长重复序列区域测序；样品制备费事；尚无商业化供应的仪器</td>
</tr>
<tr>
<td>第三代</td>
<td>Ion Torrent/生命技术公司</td>
<td>个人基因组测序仪（PGM）</td>
<td>合成测序法</td>
<td>以离子敏感场效应晶体管检测pH值变化</td>
<td>100-200</td>
<td>对核酸碱基的掺入可直接测定；在自然条件下进行DNA合成（不需要使用修饰过的碱基）</td>
<td>一步步的洗脱过程可导致错误累积；阅读高重复和同种多聚序列时有潜在困难；</td>
</tr>
<tr>
<td>第三代</td>
<td>牛津纳米孔公司</td>
<td>gridION</td>
<td>纳米孔外切酶测序</td>
<td>电流</td>
<td>尚未定量</td>
<td>有潜力达到高读长；可以成本生产纳米孔；无需荧光标记或光学手段</td>
<td>切断的核苷酸可能被读错方向；难于生产出带多重平行孔的装置</td>
</tr>
</tbody></table>
<hr>
<p>ref</p>
<p><a href="https://www.cnblogs.com/huangshujia/p/3233693.html">https://www.cnblogs.com/huangshujia/p/3233693.html</a></p>
<p><a href="http://www.biomarker.com.cn/technology-services/denovo3">http://www.biomarker.com.cn/technology-services/denovo3</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/339875837">https://zhuanlan.zhihu.com/p/339875837</a></p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>assemble</title>
    <url>/blog/2022/02/19/20220219_assembly/</url>
    <content><![CDATA[<p>Pacbio</p>
<span id="more"></span>

<p><a href="https://www.bilibili.com/video/BV1pD4y1R7nK">https://www.bilibili.com/video/BV1pD4y1R7nK</a></p>
<h1 id="1目标，现状和影响因素"><a href="#1目标，现状和影响因素" class="headerlink" title="1目标，现状和影响因素"></a>1目标，现状和影响因素</h1><h2 id="追求"><a href="#追求" class="headerlink" title="追求"></a>追求</h2><p>基因组组装：连续度contigN50，准确度，速度。</p>
<p>仪器：Pacbio</p>
<p>实验：CLR，CCS文库</p>
<p>软件：Canu，Falcon，Smartdenovo，WTDBG</p>
<h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>复杂度：基因组重复度，杂合度。<strong>Survey</strong></p>
<p>数据量：CLR：100X左右；HIFI：25X（纠错后）</p>
<p>算法是否合适：OLC，DBG</p>
<p>数据质量：Pacbio：碱基质量（纠错CDS？Q40？）；ONT：序列长度</p>
<h1 id="2基因组组装的软件使用方法"><a href="#2基因组组装的软件使用方法" class="headerlink" title="2基因组组装的软件使用方法"></a>2基因组组装的软件使用方法</h1><h2 id="组装软件"><a href="#组装软件" class="headerlink" title="组装软件"></a>组装软件</h2><ul>
<li>Canu：三代数据主流软件，具有纠错，修正和组装功能</li>
</ul>
<p>比较慢，准确度高，连续度表现优秀的概率高</p>
<ul>
<li>Falcon：PB公司推荐，可用于杂合度较高或亲缘关系较远物种组装</li>
</ul>
<p>适合一定的杂合基因组，可以装出haplotype区域，一定杂合的基因可以利用hic数据进行Mb级别的phasing</p>
<ul>
<li>Smart Denovo适用PB和ONT，无纠错</li>
<li>WTDBG：内存及存储占用少，速度快</li>
</ul>
<p>速度快，对重复序列敏感，简单基因组组装效果比较好</p>
<ul>
<li>Hifiasm：适用HiFi。速度快，连续度高，完整性高</li>
<li>HiCanu：适用HiFi</li>
<li>根据基因组特征，选择合适软件进行组装或者多软件配合使用组装获得高质量物种基因组</li>
</ul>
<h2 id="评估软件"><a href="#评估软件" class="headerlink" title="评估软件"></a>评估软件</h2><ul>
<li>BUSCO</li>
<li></li>
</ul>
<h1 id="3超大基因组的组装经验"><a href="#3超大基因组的组装经验" class="headerlink" title="3超大基因组的组装经验"></a>3超大基因组的组装经验</h1><p>数据量大：运算量大，软件适应性，组装结果，存储需求</p>
<h1 id="4基因组组装展望"><a href="#4基因组组装展望" class="headerlink" title="4基因组组装展望"></a>4基因组组装展望</h1><p>CSS组装，未来趋势。</p>
<hr>
<h1 id="三代数据预处理"><a href="#三代数据预处理" class="headerlink" title="三代数据预处理"></a>三代数据预处理</h1><h2 id="了解三代数据预处理中的输入和输出数据"><a href="#了解三代数据预处理中的输入和输出数据" class="headerlink" title="了解三代数据预处理中的输入和输出数据"></a>了解三代数据预处理中的输入和输出数据</h2><h2 id="三代上机文库简介"><a href="#三代上机文库简介" class="headerlink" title="三代上机文库简介"></a>三代上机文库简介</h2><h2 id="了解数据质量矫正的方法"><a href="#了解数据质量矫正的方法" class="headerlink" title="了解数据质量矫正的方法"></a>了解数据质量矫正的方法</h2><h2 id="如何评价数据质量和有效产出比"><a href="#如何评价数据质量和有效产出比" class="headerlink" title="如何评价数据质量和有效产出比"></a>如何评价数据质量和有效产出比</h2>]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/blog/2022/02/18/20220218-ggplot2/</url>
    <content><![CDATA[<h1 id><a href="#" class="headerlink" title></a></h1><p>reorder降序实现(加**<font color="red">-</font>**号)：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">ggplot(data,aes(x=reorder(v1,v2),y=v2))+genom_bar(stat = <span class="string">&quot;identity&quot;</span>)</span><br><span class="line"></span><br><span class="line">ggplot(data,aes(x=reorder(v1,-v2),y=v2))+genom_bar(stat = <span class="string">&quot;identity&quot;</span>)</span><br></pre></td></tr></table></figure>



]]></content>
  </entry>
  <entry>
    <title>染色质三维结构图谱 Hi-C</title>
    <url>/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/</url>
    <content><![CDATA[<h1 id="Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。"><a href="#Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。" class="headerlink" title="Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。"></a>Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。</h1><span id="more"></span>

<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/0.png" alt="img"></p>
<h1 id="1-C技术"><a href="#1-C技术" class="headerlink" title="1. C技术"></a>1. C技术</h1><h2 id="1-1-3C（一对一）"><a href="#1-1-3C（一对一）" class="headerlink" title="1.1 3C（一对一）"></a>1.1 3C（一对一）</h2><ul>
<li><p>基因组捕获技术（Chromosome conformation capture，3C）是最早研究三维基因组的技术，需要<font color="green">提前知道互作区域</font>，才能<font color="green">量化一对基因组基因座之间的互作</font>。</p>
</li>
<li><p>3C技术2002年Deker提出，目的捕获染色体的interaction，假设染色体中的interaction以蛋白为介导。通过限制酶酶切，补平，连接，打断，PCR后，若染色体A，B两点相互作用，根据这两点特异序列的引物能PCR出产物，验证interaction。每<font color="green">一对位点的验证</font>需要<font color="green">设计一对特异性引物</font>。</p>
</li>
</ul>
<h2 id="1-2-4C（一对多）"><a href="#1-2-4C（一对多）" class="headerlink" title="1.2 4C（一对多）"></a>1.2 4C（一对多）</h2><ul>
<li><p>染色体构象捕获芯片（Chromosome conformation capture-on-chip，4C ），可以捕获<font color="green">一个基因区域</font>和其他区域间的互相作用。该技术不需要知道作用区域的先验知识就可以使用。</p>
</li>
<li><p>3C较麻烦，后设计双酶切位点，然后<font color="green">成环</font>，保证只需要设计一对引物就可以检测一个位点对多个位点的相互作用，4C有circle的意思。</p>
</li>
</ul>
<h2 id="1-3-5C（多对多）"><a href="#1-3-5C（多对多）" class="headerlink" title="1.3 5C（多对多）"></a>1.3 5C（多对多）</h2><p>染色体构象捕获碳拷贝（Chromosome conformation capture carbon copy，5C） ，可以检测<font color="green">某段区域内所有的互作</font>，但是该<font color="red">区域一般&lt;1 Mb</font>。覆盖度问题造成该技术<font color="green">不适用于全基因组测序</font>。</p>
<h2 id="1-4-Hi-C（全部互作）"><a href="#1-4-Hi-C（全部互作）" class="headerlink" title="1.4 Hi-C（全部互作）"></a>1.4 <font color="red">Hi-C（全部互作）</font></h2><ul>
<li><p>高通量基因组捕获技术（High-throughput/resolution chromosome conformation capture），基本解决了上述技术的缺点，可以实现<font color="green">全基因组覆盖</font>检测<font color="green">全部未知互作区域</font>。</p>
</li>
<li><p>Hi-C基本步骤，甲醛交联，限制酶切，末端补平加biotin，平末端连接，超声破碎，biotin富集，建库测序。整个过程没有特异引物存在。</p>
</li>
<li><p>将线性距离远，空间结构近的DNA片段进行交联，并将交联的DNA片段富集，高通量测序，对测序数据分析可以揭示染色质的远程互作，推导出基因组的三维空间结构的可能的记忆之间的调控关系。</p>
</li>
<li><p>\1. 通过Scaffold间的交互频率大小，可以对已组装的基因组序列进行纠错（基因组更准确）。</p>
<p>\2. 基因信息不再仅仅是contig片段，而是被划分至染色体上，成为染色体水平。</p>
<p>\3. 无需辛苦的构建群体，单一一个体就能实现染色体定位。</p>
<p>\4. 相比遗传图谱，标记密度更大，序列定位更完整（能把更多的contig挂至染色体上!信息更全面！）</p>
<p>\5. 染色体重排等结构变异研究可以开展啦~(研究可以更深入！）</p>
<p>\6. QTL、GWAS可以定位区间到某个染色体啦~（追踪变异！）</p>
<p>\7. 该物种的三维基因结构、染色体互作及动态变化可以解析啦~（从基因到表观！全方位解析）</p>
</li>
</ul>
<h2 id="1-5-ChIP-loop-基于免疫沉淀"><a href="#1-5-ChIP-loop-基于免疫沉淀" class="headerlink" title="1.5 ChIP-loop (基于免疫沉淀)"></a>1.5 ChIP-loop (基于免疫沉淀)</h2><p>该技术将 3C 与 ChIP-seq 结合，可以检测<font color="red">目的蛋白质介导</font>的<font color="red">两个目的基因区域互作</font>。</p>
<h2 id="1-6-ChIA-PET-基于免疫沉淀"><a href="#1-6-ChIA-PET-基于免疫沉淀" class="headerlink" title="1.6 ChIA-PET (基于免疫沉淀)"></a>1.6 ChIA-PET (基于免疫沉淀)</h2><p>该技术将 HiC 与 ChIP-seq 结合，可以检测<font color="red">目的蛋白质的所有互相作用</font>。 用特异性抗体富集interaction信息，比如CTCF，pol II抗体，类似步骤建库测序。<font color="red">ChIA-PET数据是Hi-C数据的子集</font>。</p>
<hr>
<table>
<thead>
<tr>
<th></th>
<th>互作</th>
<th>覆盖</th>
<th>作用</th>
<th>研究应用</th>
</tr>
</thead>
<tbody><tr>
<td>3C</td>
<td>单对单</td>
<td>&lt;1Mb</td>
<td>检测已知<font color="red">基因组基因区域之间</font>的互作</td>
<td>确定已知启动子和增强子之间的互作</td>
</tr>
<tr>
<td>4C</td>
<td>一对多</td>
<td>全基因组</td>
<td>确定<font color="red">基因某组区域</font>与<font color="red">其他区域的互作</font></td>
<td>与已知LCR(locus control regions)区互作的全部基因和元件</td>
</tr>
<tr>
<td>5C</td>
<td>多对多</td>
<td>&lt;1Mb</td>
<td>确定<font color="red">染色体特定区域</font>的全部高级结构</td>
<td>确定染色体特定区域的全部高级结构</td>
</tr>
<tr>
<td>Hi-C</td>
<td>全部互作</td>
<td>全基因组</td>
<td>检测<font color="red">全基因组</font>范围的<font color="red">全部高级结构</font></td>
<td>全基因组范围所有染色体互作</td>
</tr>
<tr>
<td>ChIP-loop</td>
<td>一对一</td>
<td>&lt;1Mb</td>
<td>检测目的蛋白介导的<font color="red">两个目的基因区域互作</font></td>
<td></td>
</tr>
<tr>
<td>ChIA-PET</td>
<td>全部互作</td>
<td>全基因组</td>
<td>检测<font color="red">目的蛋白质的所有互作</font></td>
<td>构建已知转录因子介导的染色质互作</td>
</tr>
</tbody></table>
<hr>
<h1 id="2-技术原理"><a href="#2-技术原理" class="headerlink" title="2. 技术原理"></a>2. 技术原理</h1><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/1.png" alt="img"></p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/8.png" alt="img"></p>
<h2 id="2-1-甲醛固定"><a href="#2-1-甲醛固定" class="headerlink" title="2.1 甲醛固定"></a>2.1 甲醛固定</h2><p>先加入甲醛将基因组中参与<font color="red">染色质互作的蛋白质凝固</font>。一般将活体样本在室温用 1-3%的甲醛处理 10-30min，但是此步骤会<font color="green">减少限制内切酶</font>对DNA序列的消化<font color="green">效率</font>，需要严格控制。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/2.png" alt="img"></p>
<h2 id="2-2-酶切序列"><a href="#2-2-酶切序列" class="headerlink" title="2.2 酶切序列"></a>2.2 酶切序列</h2><p>用限制性内切酶切割基因组，打断后的片段大小会影响测序分辨率，一般有两种酶可供选择：6bp 的限制性内切酶，4bp 的限制性内切酶。后者具有更高的分辨率。EcoR1 或 HindIII 用于每4000bp切割一次基因组，在人类基因组中产生约100万个片段。<br><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/3.png" alt="img"></p>
<h2 id="2-3-末端修复"><a href="#2-3-末端修复" class="headerlink" title="2.3 末端修复"></a>2.3 末端修复</h2><p>得到的片段具有平末端或粘性末端，然后将<font color="red">末端补平修复，加入生物素</font>。【生物素pull-down保证只有连接的部分用于分析。读长reads被定位到基因组上，当这一对读长发现在不同片段上的时候，对<font color="red">互作片段进行相应评分</font>。一个包含基因组所有片段的<font color="red">连接频率矩阵被构建</font>。】</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/4.png" alt="img"></p>
<h2 id="2-4-连接及解交联"><a href="#2-4-连接及解交联" class="headerlink" title="2.4 连接及解交联"></a>2.4 连接及解交联</h2><p>使用 <font color="red">T4 DNA连接酶连接互作片段形成环状</font>。将连接DNA片段的<font color="red">蛋白质消化掉</font>，得到交联片段。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/5.png" alt="img"></p>
<h2 id="2-5-序列打断"><a href="#2-5-序列打断" class="headerlink" title="2.5 序列打断"></a>2.5 序列打断</h2><p>使用超声波或其他方式，再次打断片段。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/6.png" alt="img"></p>
<h2 id="2-6-上机测序"><a href="#2-6-上机测序" class="headerlink" title="2.6 上机测序"></a>2.6 上机测序</h2><p>用<font color="red">磁珠将带生物素的捕获</font>，制作文库，上机测序。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/7.png" alt="img"></p>
<h1 id="3-Hi-C应用"><a href="#3-Hi-C应用" class="headerlink" title="3. Hi-C应用"></a>3. Hi-C应用</h1><ul>
<li><font color="red">量化</font>在三维空间中基因组的<font color="red">染色质间交联</font>（cross-linked chromatin ）</li>
<li>解析<font color="red">全基因组互作<strong>模式</strong></font>，如<font color="red">启动子和增强子互作</font></li>
<li>构建<font color="red">三维空间结构<strong>模型</strong></font>，如研究基因组三维结构特征：<strong>compartment，TAD，loop</strong>等</li>
<li>构建<font color="red">全基因组互作<strong>图谱</strong></font></li>
<li><font color="red">辅助提升<strong>基因组组装</strong></font></li>
<li>构建<font color="red">基因组<strong>单体型图谱</strong></font></li>
</ul>
<h1 id="4-分析流程"><a href="#4-分析流程" class="headerlink" title="4. 分析流程"></a>4. 分析流程</h1><h2 id="4-1-基本分析"><a href="#4-1-基本分析" class="headerlink" title="4.1 基本分析"></a>4.1 基本分析</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/9.png" alt="img"></p>
<p>Ferhat Ay et al;2015</p>
<ul>
<li>(a)首先是<font color="green">质控</font>，过滤后高质量的FASTQ数据（PE，150bp），如果比对软件<font color="red">不支持split mapping</font>，一般选用<font color="red">迭代比对</font>，因为连接处由于是基因组外的碱基，可能比对不上。<strong>从序列左端25bp开始比对，如果有唯一比对，则停止，如果多个比对位置，则再继续延伸5bp，直到出现唯一比对</strong>。或选择<strong>支持split mapping的软件进行比对</strong>，可以通过<strong>分段比对处理</strong>。</li>
<li>(b)选择高质量的比对数据</li>
<li>(c)HiC特异的<font color="green">比对标准</font></li>
<li>(d)对Vaild pairs进行<font color="green">矫正</font>。矫正完可以得到<font color="green">互作矩阵</font>。</li>
</ul>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/10.png" alt="img"></p>
<p>Bryan R. Lajoie et al;2014</p>
<h2 id="4-2-Hi-C可视化"><a href="#4-2-Hi-C可视化" class="headerlink" title="4.2 Hi-C可视化"></a>4.2 Hi-C可视化</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/11.png" alt="img"></p>
<h2 id="4-3-序列过滤"><a href="#4-3-序列过滤" class="headerlink" title="4.3 序列过滤"></a>4.3 序列过滤</h2><p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/12.png" alt="img"></p>
<h2 id="4-4-数据矫正"><a href="#4-4-数据矫正" class="headerlink" title="4.4 数据矫正"></a>4.4 数据矫正</h2><p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/13.png" alt="img"></p>
<p>Eitan Yaffe &amp; Amos Tanay；2011</p>
<p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/14.png" alt="img"></p>
<h1 id="5-分析"><a href="#5-分析" class="headerlink" title="5. 分析"></a>5. 分析</h1><h2 id="5-1-cis-trans互作比例"><a href="#5-1-cis-trans互作比例" class="headerlink" title="5.1 cis/trans互作比例"></a>5.1 cis/trans互作比例</h2><p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/15.png" alt="img"></p>
<h2 id="5-2-互作频率与距离有关"><a href="#5-2-互作频率与距离有关" class="headerlink" title="5.2 互作频率与距离有关"></a>5.2 互作频率与距离有关</h2><p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/16.png" alt="img"></p>
<h2 id="5-3-compartment分析"><a href="#5-3-compartment分析" class="headerlink" title="5.3 compartment分析"></a>5.3 compartment分析</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/17.png" alt="img"></p>
<h2 id="5-4-TAD分析"><a href="#5-4-TAD分析" class="headerlink" title="5.4 TAD分析"></a>5.4 TAD分析</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/18.png" alt="img"></p>
<p>Hi-C辅助TAD结构研究（<em>Wang et al</em>., Nature Commuications 2018）</p>
<h2 id="5-5-显著互作分析"><a href="#5-5-显著互作分析" class="headerlink" title="5.5 显著互作分析"></a>5.5 显著互作分析</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/19.png" alt="img"></p>
<h1 id="6-应用"><a href="#6-应用" class="headerlink" title="6. 应用"></a>6. 应用</h1><h2 id="6-1-解析全基因组互作模式"><a href="#6-1-解析全基因组互作模式" class="headerlink" title="6.1 解析全基因组互作模式"></a>6.1 解析全基因组互作模式</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/20.png" alt="img"></p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/21.png" alt="img"></p>
<h2 id="6-2-辅助提升基因组组装"><a href="#6-2-辅助提升基因组组装" class="headerlink" title="6.2 辅助提升基因组组装"></a>6.2 辅助提升基因组组装</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/22.png" alt="img"></p>
<ul>
<li><p>Hi-C辅助陆地棉与海岛棉基因组染色体水平组装（<em>Wang et al</em>.,Nature Genetics 2018）</p>
</li>
<li><p>Hi-C无需群体，单一个体就能实现染色体定位。很多物种都无法构建遗传群体，包括大部分高等动物、野生动植物、林木、果树等等。Hi-C是通过染色体上空间距离、线性距离的不同而导致的交互频率的不同来完成染色体的定位，所以不需要构建群体。</p>
</li>
<li><p>标记密度更大，序列定位更完整。相比遗传图谱，染色质之间的交互频率具有更高的标记密度，如此高密度的图谱不仅可以挂载上长的Scaffold，较短的Scaffold也可以被定位，所以通过Hi-C技术，一般可以将90%以上基因组序列定位到染色体。</p>
</li>
<li><p>可以对已组装的基因组进行纠错。通过Scaffold间的交互频率大小，可以对已组装的基因组序列进行纠错。</p>
</li>
</ul>
<h3 id="6-2-1-数据统计和过滤；"><a href="#6-2-1-数据统计和过滤；" class="headerlink" title="6.2.1 数据统计和过滤；"></a>6.2.1 数据统计和过滤；</h3><h3 id="6-2-2-Hi-C文库评估；"><a href="#6-2-2-Hi-C文库评估；" class="headerlink" title="6.2.2 Hi-C文库评估；"></a>6.2.2 Hi-C文库评估；</h3><h3 id="6-2-3Hi-C染色体定位；"><a href="#6-2-3Hi-C染色体定位；" class="headerlink" title="6.2.3Hi-C染色体定位；"></a>6.2.3Hi-C染色体定位；</h3><p>​    ✓ 组装序列染色体群组划分；</p>
<p>   ✓  组装序列各群组内排序；</p>
<p>   ✓  组装序列各群组内定向；</p>
<h3 id="6-2-4-Hi-C定位后统计评估；"><a href="#6-2-4-Hi-C定位后统计评估；" class="headerlink" title="6.2.4 Hi-C定位后统计评估；"></a>6.2.4 Hi-C定位后统计评估；</h3><p>​    ✓  近缘物种参考基因组评估；</p>
<p>​    ✓  遗传标记评估；</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/24.png" alt="img"></p>
<h2 id="6-3-构建基因组单体型图谱"><a href="#6-3-构建基因组单体型图谱" class="headerlink" title="6.3 构建基因组单体型图谱"></a>6.3 构建基因组单体型图谱</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/23.png" alt="img"></p>
<h1 id="7-文献案例"><a href="#7-文献案例" class="headerlink" title="7. 文献案例"></a>7. 文献案例</h1><h2 id="7-1"><a href="#7-1" class="headerlink" title="7.1"></a>7.1</h2><p><strong>物种：棉花</strong></p>
<p><strong>题目：</strong>Genome sequence of<em>Gossypium herbaceum</em>and genome updates of<em>Gossypium arboreum</em>and<em>Gossypium hirsutum</em>provide insights into cotton A-genome evolution</p>
<p><strong>期刊：</strong>Nature genetics</p>
<p><strong>影响因子：</strong>25.455</p>
<p><strong>研究单位：</strong>武汉大学</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年4月13日，武汉大学朱玉贤院士团队关于草棉、亚洲棉和陆地棉基因组研究成果发表在国际著名期刊Nature genetics。该研究利用了PacBio三代分子测序和北京百迈客生物技术有限公司的Hi-C技术绘制了三个高质量棉花基因图谱，发现了三种棉花中多个染色体易位与倒位事件，解决了围绕A基因组起源的现有争议性概念，确定了与棉花纤维长度这一重要农艺性状相关的丰富的候选基因，并为棉花遗传改良提供了宝贵的基因组资源。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/25.png" alt="草棉与亚洲棉基因组Hi-C热图"></p>
<h2 id="7-2"><a href="#7-2" class="headerlink" title="7.2"></a>7.2</h2><p><strong>物种：珙桐</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/31970919">Genomic analyses of a “living fossil”: The endangered dove-tree</a></p>
<p><strong>期刊：</strong>Molecular Ecology Resources</p>
<p><strong>影响因子：</strong>7.049</p>
<p><strong>研究单位：</strong>四川大学</p>
<p><strong>主要研究内容：</strong>2020年1月四川大学刘建全团队破译了中国特有的濒危物种珙桐（<em>Davidia involucrata</em>）基因组，相关成果发表在著名期刊Molecular Ecology Resources上。四川大学刘建全教授和杨勇志博士为该论文的通讯作者，陈阳和马涛教授为并列一作。该研究利用单分子实时测序SMRT和北京百迈客生物技术有限公司的Hi-C技术组装了一个高质量、染色体体水平的珙桐基因组，研究发现苞片中光合作用相关基因几乎缺失或表达减少，而抗菌、抗冷、抗水等抗逆相关基因在苞片中高度表达，突出了苞片在保护花和吸引授粉者中的重要作用。有效群体大小等研究分析了珙桐的生存机制和濒危原因。在未来气候持续变暖的背景下，研究结果为保护这独特的濒危物种提供了依据。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/26.png" alt="珙桐基因组Hi-C热图"></p>
<h2 id="7-3"><a href="#7-3" class="headerlink" title="7.3"></a>7.3</h2><p><strong>物种：二倍体草莓</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32003918">The high-quality genome of diploid strawberry (Fragaria nilgerrensis) provides new insights into anthocyanin accumulation</a></p>
<p><strong>期刊：</strong>Plant Biotechnology Journal</p>
<p><strong>影响因子：</strong>6.84</p>
<p><strong>研究单位：</strong>沈阳农业大学</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年1月31日沈阳农业大学张志宏研究团队与北京百迈客生物科技有限公司合作，基于单分子实时测序PacBio和染色体构象捕获Hi-C技术，成功构建亚洲东部和东南部地区特有的野生二倍体草莓——黄毛草莓（<em>Fragaria nilgerrensis</em>）高质量基因图谱，相关研究成果发表在知名期刊Plant Biotechnology Journal上。文中通过比较基因组学等系列分析找寻到可能与黄毛草莓特异表型以及环境适应性相关的扩张基因，以及可能与其白色果实相关的变异。该研究为草莓属物种的生物学以及比较基因组学研究提供了宝贵的遗传资源。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/27.png" alt="黄毛草莓基因组Hi-C热图"></p>
<h2 id="7-4"><a href="#7-4" class="headerlink" title="7.4"></a>7.4</h2><p><strong>物种：油桐</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32224189">Tung Tree (Vernicia fordii) Genome Provides A Resource for Understanding Genome Evolution and Improved Oil Production</a></p>
<p><strong>期刊：</strong>Genomics Proteomics &amp; Bioinformatics</p>
<p><strong>影响因子：</strong>6.597</p>
<p><strong>研究单位：</strong>中南林业科技大学</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年4月7日，Genomics Proteomics &amp; Bioinformatics 在线发表了由中南林业科技大学谭晓风团队牵头完成的油桐基因组研究论文。该研究利用Illumina+PacBio组装了1.12Gb油桐基因组，并通过北京百迈客生物技术有限公司的Hi-C技术将95.15%的序列挂载到11条染色体上。基于比较基因组等系列相关研究解析了油桐基因组进化和桐油生物合成的分子机制。该研究为理解基因组演化、以及油脂产量的分子育种与遗传改良都提供了宝贵的遗传资源，为油桐种质资源保护、分子遗传学研究、良种选育及加工利用，奠定了重要的科学基础。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/28.png" alt="油桐基因组circos图"></p>
<h2 id="7-5"><a href="#7-5" class="headerlink" title="7.5"></a>7.5</h2><p><strong>物种：亚麻</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32240956">Genomic Comparison and Population Diversity Analysis Provide Insights into the Domestication and Improvement of Flax</a></p>
<p><strong>期刊：</strong>iScience</p>
<p><strong>影响因子：</strong>——</p>
<p><strong>研究单位：</strong>甘肃省农业科学院</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年4月24日，由甘肃省农科院和北京百迈客等单位合作的亚麻基因组研究成果荣登iScience, 其中张建平研究员，党占海研究员，刘头明研究员，百迈客CEO郑洪坤为本文通讯作者。该研究使用Illumina技术对油用亚麻品种Longya-10、纤维亚麻品种Heiya-14和pale flax分别进行测序与组装，后期利用HiC技术与遗传图谱辅助Longya-10基因组组装，将434 scaffolds组装至染色体水平。通过比较基因组及群体进化等研究探索油用及纤维用亚麻在驯化中受到的选择作用，以及可能在重塑亚麻形态结构中起着至关重要作用的相关基因。该研究揭示了对亚麻驯化和改良有重要影响的基因，这将有助于今后的分子育种。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/29.png" alt="亚麻基因组Hi-C热图"></p>
<h2 id="7-6"><a href="#7-6" class="headerlink" title="7.6"></a>7.6</h2><p><strong>物种：枇杷</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32141509">Chromosome-level genome assembly and annotation of the loquat (Eriobotrya japonica) genome</a></p>
<p><strong>期刊</strong>：Gigascience</p>
<p><strong>影响因子：</strong>4.688</p>
<p><strong>研究单位：</strong>上海市农业科学院</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年2月6日，上海市农业科学院张学英研究员团队于知名期刊Gigascience上首次发表枇杷基因组相关研究论文，该研究中基于北京百迈客生物科技有限公司的Nanopore测序和Hi-C染色体构象捕获技术，构建了高质量的枇杷基因组。文中通过与苹果、水蜜桃、梨、覆盆莓、月季和野草莓的蛋白质序列比较，探索了枇杷的全基因组复制与进化事件，并进行了染色体重排分析。该研究提供了宝贵的染色体水平基因组数据，为研究枇杷性状提供了重要的基因组数据。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/30.png" alt="枇杷基因组circos图"></p>
<h2 id="7-7"><a href="#7-7" class="headerlink" title="7.7"></a>7.7</h2><p><strong>物种：板蓝根（菘蓝）</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32025321">A chromosome-scale genome assembly of Isatis indigotica, an important medicinal plant used in traditional Chinese medicine</a></p>
<p><strong>期刊：</strong> Horticulture Research</p>
<p><strong>影响因子：</strong>3.640</p>
<p><strong>研究单位：</strong>四川大学</p>
<p><strong>主要研究内：</strong></p>
<p>2020年2 月1日，四川大学生命科学学院刘建全课题组与华中农业大学作物遗传改良国家重点实验室李再云课题组首次完成了菘蓝（<em>Isatis indigotica</em>，2n=14）染色体级别基因组图谱绘制。该研究利用Pacbio测序(140X)结合北京百迈客生物技术有限公司的Hi-C技术（284X）组装得到294Mb高质量基因组（contigN50=1.2Mb）。基于同源搜索和功能注释，确定了该物种主要化合物（如吲哚类、萜类、黄酮、木脂素等物质）的可能生物合成通路和相关的候选基因。该研究强调了基因组测序在鉴定药用植物代谢产物合成候选基因中的重要性，为今后十字花科植物比较基因组等研究提供了重要遗传信息。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/31.png" alt="菘蓝基因组Hi-C热图"></p>
<h2 id="7-8"><a href="#7-8" class="headerlink" title="7.8"></a>7.8</h2><h6 id="以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究"><a href="#以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究" class="headerlink" title="以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究"></a>以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究</h6><h6 id="RESEQUENCING-OF-243-DIPLOID-COTTON-ACCESSIONS-BASED-ON-AN-UPDATED-A-GENOME-IDENTIFIES-THE-GENETIC-BASIS-OF-KEY-AGRONOMIC-TRAITS"><a href="#RESEQUENCING-OF-243-DIPLOID-COTTON-ACCESSIONS-BASED-ON-AN-UPDATED-A-GENOME-IDENTIFIES-THE-GENETIC-BASIS-OF-KEY-AGRONOMIC-TRAITS" class="headerlink" title="RESEQUENCING OF 243 DIPLOID COTTON ACCESSIONS BASED ON AN UPDATED A GENOME IDENTIFIES THE GENETIC BASIS OF KEY AGRONOMIC TRAITS"></a>RESEQUENCING OF 243 DIPLOID COTTON ACCESSIONS BASED ON AN UPDATED A GENOME IDENTIFIES THE GENETIC BASIS OF KEY AGRONOMIC TRAITS</h6><p>期刊：Nature Genetics</p>
<p>影响因子：27.125</p>
<p>发表单位：中国农业科学院棉花研究所、北京百迈客生物科技有限公司等</p>
<p>发表年份：2018年5月</p>
<p>研究背景：</p>
<p>棉花是研究植物多倍化的有价值的资源。亚洲棉(<em>Gossypium arboreum</em>)和草棉(<em>Gossypium herbaceum</em>)的祖先是现代栽培异源四倍体棉花A亚基因组的供体。 本研究中，利用了三代PacBio和Hi-C技术，重新组装了高质量的亚洲棉基因组，分析了243份二倍体棉花种质的群体结构和基因组分化趋势，同时确定了一些有助于棉花皮棉产量遗传改良的候选基因位点。</p>
<p>研究结果：</p>
<p>1、亚洲棉三代基因组组装：</p>
<p>利用三代测序和Hi-C相结合的方法进行亚洲棉基因组组装。共计获得了142.54 Gb ，组装1.71 Gb亚洲棉基因组，Contig N50=1.1 Mb，最长的Contig为12.37 Mb。利用Hi-C技术将组装的1573 Mb的数据定位到13条染色体上，与已经发表的基因组相比，当Hi-C数据比对到更新的基因组后，对角线外的不一致性明显减少（图1 a-b）</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/33.png" alt="img"></p>
<p>图1 HI-C数据在两版亚洲棉基因组上的比对</p>
<p>2、二倍体棉花群体遗传进化分析：</p>
<p>对230份亚洲棉和13份草棉重测序，进行基因组比对、系统发育树、群体结构分析、PCA、LD和选择性清除分析得出亚洲棉和草棉（A）与雷蒙德氏棉同时进行了分化；亚洲棉起源于中国南部，随后被引入长江和黄河地区，大多数具有驯化相关特性的种质都经历了地理隔离（图2）。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/34.png" alt="img"></p>
<p>图2 二倍体棉群体进化和群体结构分析</p>
<p>3、亚洲棉的全基因组关联分析（GWAS）：</p>
<p>对来自不同环境下的11个重要性状进行全基因组关联分析，鉴定了亚洲棉11个重要农艺性状的98个显著关联位点，GaKASIII的非同义替换（半胱氨酸/精氨酸替换）使得棉籽中的脂肪酸组成（C16:0和C16:1）发生了变化；发现棉花枯萎病抗性与GaGSTF9基因的表达激活相关。选择了亚洲棉种质中的158份有绒毛和57份无绒毛材料进行GWAS关联分析，发现与毛状体和纤维发育有关信息（图3）。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/35.png" alt="img"></p>
<p>图3 二倍体棉群体进化和群体结构分析</p>
<p>研究结论：</p>
<p>利用三代测序+Hi-C技术完成了亚洲棉基因组的重新组装，将基因组组装指标从72 Kb提升到1.1 Mb，为亚洲棉后续的群体遗传学等相关研究奠定了基础；通过群体遗传进化等相关分析，发现亚洲棉和草棉(A型)与雷蒙德氏棉(D型)同时进行了分化，并证明了亚洲棉起源于中国南部，随后被引入长江和黄河地区；整合GWAS与QTL等分析方法，对亚洲棉脂肪酸含量，抗病性及棉绒生长发育相关基因进行定位，并进行相关功能验证，促进了亚洲棉复杂农艺性状的改良。</p>
<h2 id="7-9"><a href="#7-9" class="headerlink" title="7.9"></a>7.9</h2><h6 id="二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良"><a href="#二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良" class="headerlink" title="二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良"></a>二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良</h6><h6 id="COMPARISON-OF-ARACHIS-MONTICOLA-WITH-DIPLOID-AND-CULTIVATED-TETRAPLOID-GENOMES-REVEALS-ASYMMETRIC-SUBGENOME-EVOLUTION-AND-IMPROVEMENT-OF-PEANUT"><a href="#COMPARISON-OF-ARACHIS-MONTICOLA-WITH-DIPLOID-AND-CULTIVATED-TETRAPLOID-GENOMES-REVEALS-ASYMMETRIC-SUBGENOME-EVOLUTION-AND-IMPROVEMENT-OF-PEANUT" class="headerlink" title="COMPARISON OF ARACHIS MONTICOLA WITH DIPLOID AND CULTIVATED TETRAPLOID GENOMES REVEALS ASYMMETRIC SUBGENOME EVOLUTION AND IMPROVEMENT OF PEANUT"></a>COMPARISON OF <em>ARACHIS MONTICOLA</em> WITH DIPLOID AND CULTIVATED TETRAPLOID GENOMES REVEALS ASYMMETRIC SUBGENOME EVOLUTION AND IMPROVEMENT OF PEANUT</h6><p>期刊：Advanced Science</p>
<p>影响因子：15.804</p>
<p>发表单位：河南农业大学、北京百迈客生物科技有限公司等</p>
<p>发表年份：2019年11月</p>
<p>研究背景：</p>
<p>花生作为我国重要的经济作物，是提供重要的蛋白和油料的基础。花生属一共包括30个二倍体品种，1个异源四倍体野生花生(<em>A. monticola</em>)和1个栽培花生(<em>A. hypogaea</em>)。作为栽培花生农艺性状改良的重要野生资源供体，野生四倍体花生一直是国内外学者的研究热点。研究中对花生属唯一的野生异源四倍体花生<em>Arachis monticola</em>基因组进行了研究，同时对17个野生二倍体花生（AA;BB;EE;KK和CC）与30个野生和栽培四倍体花生进行了重测序分析。</p>
<p>研究结果：</p>
<p>1、野生四倍体花生基因组denovo及与栽培四倍体花生的比较分析：</p>
<p>基于 Illumina、PacBio 、Hi-C和光学图谱数据，组装<em>Arachis monticola</em>(2n = 4x = 40)基因组大小为2.62 Gb ，contigs N50=106.66 Kb，scaffolds N50=124.92 Mb；与栽培四倍体花生<em>A. hypogaea</em>基因组结构变异高度保守，且比野生祖先二倍体更加保守；</p>
<p>2、A、B亚基因组的单系起源和多样性：</p>
<p>对17个二倍体野生种（AA、BB、EE、KK和CC）和30个野生和栽培四倍体花生进行了进化树和PCA分析。结果表明，栽培四倍体花生与野生四倍体花生最接近， A和B亚基因组的单系起源（图1）；</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/36.png" alt="img"></p>
<p>3、四倍体花生不对称亚基因组进化及表达差异 <strong>：</strong></p>
<p>栽培花生和野生花生的亚基因组间的同源序列交换率（HSE）分别为2.46%和2.54%。野生花生中A到B的HSE富集的基因为类黄酮生物合成和昼夜节律途径的基因，暗示不对称HSEs在生物学功能中的作用；</p>
<p>4、SV对荚发育和驯化相关基因表达的影响及抗病基因鉴定 <strong>：</strong></p>
<p>对野生四倍体花生和栽培四倍体花生不同发育阶段荚果的SV分析发现SV在荚果发育过程中基因表达的变化上可能起着重要作用；同时在栽培四倍体花生中鉴定到190个SV抗病基因（SV-RGAs），其中32个基因在接种后易感组或抗性组中表现出显著的表达变化（图2）。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/37.png" alt="img"></p>
<p>研究结论：</p>
<p>充分注释了高质量野生四倍体花生基因组，揭示了花生亚基因组单系起源和遗传进化模型，表明了野生和栽培四倍体花生亚基因组发生了不对称进化；此外，野生花生中存在的独特等位基因可以改善栽培花生的抗性和荚果大小等形状，为研究多倍体基因组进化、作物驯化和基因组辅助花生生产改良提供独特的价值。</p>
<hr>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/32.png" alt="其他"></p>
<p>北京百迈客自启动Hi-C技术研究以来，自主开发Hi-C排图软件，具有实验+生物信息分析专利双保护，也是中国市场上能独立完成Hi-C实验——数据分析的测序企业之一！并完成上千个物种，近万个文库构建；文库含酶切位点有效数据比例最高达93%以上，针对物种推出定制化内切酶服务；实现多倍体物种的Hi-C辅助基因组组装，<strong>挂载效率最高达100%。</strong></p>
<p>另外为了让更多科研工作者体验Hi-C建库，百迈客在成功构建多种物种Hi-C建库测序的经验上，正式推出了Biomarker Hi-C Library Prep Kit for Illumina。</p>
<p>Biomarker Hi-C Library Prep Kit for Illumina涵盖了Hi-C实验全部环节，包括甲醛交联、Hi-C提取和Hi-C文库构建，适用于细胞系、动物和植物组织样本。1套Hi-C试剂盒包含5个反应，1个反应构建的文库可用于200Gb数据量的测序，试剂盒构建的文库适用于Illumina测序平台。</p>
<hr>
<p>Ref:<a href="https://www.zhihu.com/question/48308074">https://www.zhihu.com/question/48308074</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1625366">https://cloud.tencent.com/developer/article/1625366</a></p>
<p><a href="http://www.biomarker.com.cn/technology-services/hi-c">http://www.biomarker.com.cn/technology-services/hi-c</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/140795830">https://zhuanlan.zhihu.com/p/140795830</a></p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>选择基因</title>
    <url>/blog/2022/02/16/2022-0216-select-gene/</url>
    <content><![CDATA[<h1 id="选择基因-selector-genes-是一类决定体节发育的基因。"><a href="#选择基因-selector-genes-是一类决定体节发育的基因。" class="headerlink" title="选择基因(selector genes)是一类决定体节发育的基因。"></a>选择基因(selector genes)是一类决定体节发育的基因。</h1><span id="more"></span>

<p>有<font color="green">两簇选择基因</font>在控制<font color="green">果蝇外部结构</font>的正确发育途径中起关键作用：<font color="green">双胸复合物(bithorax complex,BX-C)</font>和<font color="green">触角足复合物(antennapedia complex,ANT-C)</font>。BX-C含有三个结构基因，分别是：<font color="green">Ultrabithorax(Ubx)、Abdominal A(abdA)和Abdominal B(abdB)</font>，它们<font color="green">各编码一种具有同源框的转录因子。这三个基因都含有很多内含子</font>，这些内含子对于调节这些基因在不同<a href="https://baike.baidu.com/item/%E5%89%AF%E8%8A%82">副节</a>进行不同的表达具有重要作用。ANT-C<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E7%B0%87">基因簇</a>含有5个基因：<font color="green">labial(lab)、proboscipedia(pb)、Deformed(Dfd)、Sex combs reduced(Scr)和antennapedia(Antp)</font>。这两簇基因都定位于<font color="green">3号染色体</font>。ANT-C簇编码的蛋白质控制<font color="green">0-5副节</font>的发育，BX-C基因簇编码的蛋白质控制<font color="green">5-14</font>副节的发育。</p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>biology</tag>
      </tags>
  </entry>
  <entry>
    <title>染色质三维结构图谱 Micro-C</title>
    <url>/blog/2022/02/16/2022-0216-chromosome-structure-Micro-C/</url>
    <content><![CDATA[<h1 id="Micro-C"><a href="#Micro-C" class="headerlink" title="Micro-C"></a>Micro-C</h1><span id="more"></span>

<h1 id="Micro-C-1"><a href="#Micro-C-1" class="headerlink" title="Micro-C"></a>Micro-C</h1><p>染色质结构与基因表达的调控密切相关（如<font color="green">常染色质/异染色质</font>）。随着近年<font color="green">染色质构象捕捉技术</font>的发展，了解到细胞核内的DNA存在着<font color="green">多重结构调节机制</font>，例如<font color="green">A/B染色质区室（compartment）</font>和<font color="green">拓扑结构域（TAD）</font>。大小分别在<font color="green">百万碱基</font>和<font color="green">十万碱基</font>左右。由于测序深度和技术条件限制，<font color="green">Hi-C很难达到更高分辨率</font>，<strong>限制</strong>了分析关于单个基因，以及启动子（P）、增强子（E）等<font color="green">调控元件之间相互作用</font>。</p>
<p>Molecular Cell杂志发表背靠背文章Resolving the 3D Landscape of Transcription-Linked Mammalian Chromatin Folding和Ultrastructural Details of Mammalian Chromosome Architecture。<font color="green">一种新的染色质构象捕捉技术名为Micro-C</font>。Micro-C达到<strong>单核小体长度（～200bp）</strong>左右的<strong>分辨率</strong>，可以观察到更为精细的染色质结构。</p>
<p>Micro-C和Hi-C在实验步骤上最大的不同，在于Micro-C先对核小体上缠绕的DNA做交联，而后用MNase切断核小体之间的连接DNA。以Tjian和Darzacq实验室的文章为例，他们对38个小鼠干细胞进行Micro-C测序，总共获得约26亿个reads。<strong>相似测序深度</strong>下<strong>20kb精度</strong>的<strong>Micro-C图谱与Hi-C结果相似</strong>，但在<strong>100至20kb的精度之间</strong>，<strong>Micro-C</strong>展示<strong>Hi-C不具备</strong>的<strong>精细</strong>结构，例如很多有关基因启动子和增强子的结构域、条带和点圈。从Hi-C可以得到约6000个DNA环（loop），即高度相互作用的一对区域。而Micro-C可以得到约30000个。</p>
<p>在证实了Micro-C具备可重复性和高精度之后，进一步分析，<font color="green">相比Hi-C，Micro-C独特</font>的主要在于可探查<font color="green">调控元件之间相互作用</font>，如EP，PP等。其中有些相互作用形成了比传统TAD小的结构域。研究者通过隔离分值的分析得到了大约13万个这样的结构域边界。这些<font color="green">边界通常有着活跃转录的基因和动态的核小体结构</font>，而与之前所了解的，<font color="green">以CTCF和Cohesin为标志的TAD边界</font>有很大<font color="green">不同</font>。</p>
<p>利用<strong>回归模型</strong>分析了这些<strong>结构域边界</strong>和<strong>表关遗传特征</strong>的<strong>关联性</strong>。<font color="green">CTCF</font>和<font color="green">Cohesin</font>在<font color="green">决定边界位置</font>最重要，然而决定<font color="green">边界强度</font>却主要是<font color="green">转录活跃的标志物</font>，如<font color="green">H3K4me3修饰和染色质开放度</font>等。进一步发现边界也存在很大差别，将其分为五类：<font color="red">转录相关</font>；<font color="red">干细胞特异性增强子</font>；<font color="red">一般增强子</font>；<font color="red">抑制型</font>；<font color="red">CTCF-Cohesin相关型</font>。各有不同的化学修饰。</p>
<p>选取了一些代表性的区域发现，不仅<strong>启动子、增强子和CTCF之间相互作用</strong>，在<strong>聚梳抑制区</strong>还可以观察到显著的<strong>“巢状”环</strong>。<strong>CTCF相互作用范围较长</strong>，而<strong>Pol II</strong>介导的相互作用则<strong>较短</strong>。基因附近的相互作用越紧密，其转录活性也常常越高。进一步<strong>证明</strong><font color="green">转录对染色质折叠</font>的影响，利用<font color="green">药物抑制转录</font>。对比观察到，<font color="green">TAD等大尺度结构无变化</font>，然而<font color="green">基因附近的相互作用</font>条纹<font color="green">大大减弱</font>，证明了这些条纹团确实是由转录过程导致的。</p>
<p>两篇文章显示了<strong>哺乳动物</strong>的<font color="green">染色质相互作用</font>还有<font color="green">更多的精细结构等待开发</font>。更高精度的数据能帮助人们理解这些<strong>结构的形成和对基因转录的影响</strong>。</p>
<p>原文链接：<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzQyNjY1MQ==&amp;mid=2652482974&amp;idx=3&amp;sn=acc0381ecc6ab6779e335510b87de062&amp;chksm=84e23e2ab395b73">https://mp.weixin.qq.com/s?__biz=MzA3MzQyNjY1MQ==&amp;mid=2652482974&amp;idx=3&amp;sn=acc0381ecc6ab6779e335510b87de062&amp;chksm=84e23e2ab395b73</a></p>
<hr>
<p><font color="green">染色质高级结构</font>由不同层次的结构单元组成。从<font color="green">区块（compartment）</font>，<font color="green">拓扑结构域（TAD）</font>，到单个的<font color="green">环（loop）</font>，这些大小不同的单元各有特征，也对<strong>染色质功能</strong>和<strong>基因表达</strong>起到多种多样的<strong>调控</strong>。CTCF蛋白扮演了重要的角色。</p>
<p><font color="red">CTCF</font>常常位于<strong>TAD和loop的边界</strong>，起到“<font color="red">隔离子</font>”的作用。近年来提出的loop extrusion模型也认为<font color="green">CTCF和cohesin的协调作用是loop形成的普遍机理</font>。虽然有假设，却一直不清楚CTCF<font color="red">如何作用</font>于染色质，并导致复杂结构形成。CTCF蛋白的各个结构域，除了同DNA结合的11-ZF外，其他结构域功能？</p>
<p>2019年9月12日，Molecular Cell杂志发表背靠背文章“Distinct Classes of ChromatinLoops Revealed by Deletion of anRNA-Binding Region in CTCF”和“RNA Interactions Are Essentialfor CTCF-Mediated Genome Organization”<strong>，</strong>共同揭示<font color="green">CTCF与RNA的相互作用</font>对CTCF功能的重要意义。</p>
<p>之前研究发现<font color="green">CTCF常在细胞中成簇聚集</font>。为研究聚集的<font color="green">机理</font>，在细胞中分别加入<font color="green">DNase和RNase</font>。结果吃惊，被认为是DNA结合蛋白的CTCF的聚合对<font color="green">DNase并不敏感</font>，而<font color="green">RNase却显著减少了CTCF的互相结合</font>。 结合之前研究，CTCF上的ZF10和ZF11结构域有一段具有RNA结合功能（<font color="red">RNA-binding region</font>，<strong>RBR</strong>），其中<strong>38个氨基酸</strong>对其结合是必不可少。研究者于是在<font color="red">小鼠干细胞</font>上将这段被称为<font color="red">RBRi的片段替换</font>，发现<font color="green">缺陷型细胞</font>的<strong>CTCF表达水平</strong>虽然<strong>无明显变化</strong>，<strong>生长却慢了2倍</strong>，显示<strong>RBRi</strong>可能具有重要的<strong>生理作用</strong>。RBRi缺陷的CTCF在细胞中和RNA的<font color="green">结合减少但却没有完全消失</font>。研究者接着对<strong>RBRi缺陷和不缺陷的CTCF</strong>分别做了荧光<strong>标记</strong>。结果<strong>野生型CTCF</strong>呈现了明显<strong>更高程度聚团</strong>。不过这些结果并<strong>不排除RBRi间接作用</strong>于其他因子的可能。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Micro-C/1.png" alt="img"></p>
<p>研究者接着分析了**<font color="red">RBRi片段功能和Compartment，TAD，Loop三大结构单元的关系</font><strong>。对</strong>RBRi缺陷<strong>和</strong>野生型<strong>细胞</strong>Micro-C测序<strong>。Micro-C是一种比Hi-C清晰度更高的研究基因组范围染色质相互作用的方法。RBRi的<font color="green">缺陷并不影响compartment形成</font>，但却</strong><font color="red">大范围改变了TAD和loop的结构</font>**。将RBRi<font color="green">替换后</font>，小鼠细胞内<font color="green">TAD的数目和强度都有所减少</font>，其中<font color="green">大部分同TAD边缘CTCF和Cohesin的ChIP-seq信号变化一致</font>。RBRi的替换也使得<font color="green"><strong>Micro-C</strong></font>热图上的<font color="green"><strong>条带（strip）变长</strong></font>，这符合loop extrusion模型的假设。而loop的改变更为有趣–有些loop完全明显削弱（38%～57%），而有些loop却完好无损甚至增强了。研究者于是<font color="green"><strong>将loop分成RBRi依赖和不依赖两类</strong></font>，并发现它们具有不同的转录因子结合特征。他们还据此假设，这两类loop同CTCF有不同的结合方式，因此稳定性也不同。这也许可以解释为什么不是所有的CTCF位点都会形成loop。最后，发现大约500个基因由于RBRi的替换产生了差异表达。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Micro-C/2.png" alt="img"></p>
<p>Danny Reinberg实验室则将目光集中在<strong>CTCF的ZF1和ZF10结构域</strong>上。他们发现对小鼠细胞的转录抑制在没有降低CTCF表达水平的前提下，减少了CTCF在全基因组范围的结合程度。<font color="red">ZF1或ZF10缺陷的CTCF与RNA的结合能力都大大减少，并且在一定程度导致CTCF结合位点和基因表达改变。而不同的是，ZF1缺陷使得大部分CTCF loop消失，而ZF10缺陷型细胞的loop却仍然保持完好。</font></p>
<p><strong>这两篇背靠背文章共同揭示了CTCF的RNA结合域</strong>（RBR）<strong>在CTCF发挥正常功能中扮演着重要的角色。</strong></p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>CTCF</title>
    <url>/blog/2022/02/15/2022-02-15-CTCF/</url>
    <content><![CDATA[<h1 id="【paper1】CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops"><a href="#【paper1】CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops" class="headerlink" title="【paper1】CTCF: the protein, the binding partners, the binding sites and their chromatin loops"></a>【paper1】CTCF: the protein, the binding partners, the binding sites and their chromatin loops</h1><span id="more"></span>

<p>review: <a href="https://pubmed.ncbi.nlm.nih.gov/23650640/">https://pubmed.ncbi.nlm.nih.gov/23650640/</a></p>
<h1 id="CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops"><a href="#CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops" class="headerlink" title="CTCF: the protein, the binding partners, the binding sites and their chromatin loops"></a>CTCF: the protein, the binding partners, the binding sites and their chromatin loops</h1><p>CTCF:蛋白质，结合伙伴，结合位点和染色质环</p>
<p>CTCF什么都有。转录因子与成千上万个基因组位点结合，有些是组织特异性的，有些是超保守的。它可以作为<strong>转录激活因子</strong>、<strong>抑制子</strong>和<strong>绝缘子</strong>，并可以<strong>暂停转录</strong>。CTCF<strong>结合</strong>在<strong>染色质结构域边界</strong>，<strong>增强子</strong>和<strong>启动子</strong>，以及<strong>基因区</strong>。它可以吸引许多其他转录因子到染色质，包括组织特异性转录激活因子、抑制子、粘连蛋白和RNA聚合酶II，并形成染色质环。因此，CTCF在特定基因组位点的确切功能是不可预测的。它似乎是由相关的转录因子、结合位点相对于基因转录起始位点的位置、以及该位点在染色质环中与其他ctcf位点的结合、与增强子或启动子的结合决定的。该review将讨论CTCF结合事件的全基因组特征，以及这个显著的转录因子的位点特异性功能。</p>
<ol>
<li>introduction</li>
</ol>
<p>CTCF是一种普遍表达的必需蛋白，在许多方面都是一种特殊的转录因子。它最初被描述为转录<strong>抑制</strong>因子，但也被发现作为转录<strong>激活</strong>因子。还具有<strong>绝缘体活性</strong>:当它位于增强子和基因启动子之间时，它阻断它们的通信并阻止转录激活。通过<strong>ChIP-seq</strong>系统研究，在<strong>不同物种的许多组织</strong>中绘制CTCF在基因组尺度的结合事件。结果显示基因组被<strong>无数的CTCF结合位点</strong>所覆盖。与大多数其他转录因子相比，CTCF似乎<strong>更容易</strong>与基因间序列<strong>结合</strong>，通常<strong>距</strong>离转录起始位点(<strong>TSS</strong>)<strong>较远</strong>。CTCF是<strong>最早被证实介导染色质成环</strong>的蛋白之一。进一步观察到，它经常会<strong>结合</strong>到位于细胞核中不同位置的<strong>染色体区域之间的边界</strong>，<strong>结合</strong>具有<strong>不同表观遗传特征</strong>和/或<strong>不同转录活性</strong>的<strong>区域边界</strong>，以及最近确定的<strong>拓扑域之间的边界</strong>，这是空间上确定的<strong>染色体单位</strong>，在其中<strong>序列优先相互作用</strong>。本文讨论CTCF的研究，并评估其在<strong>基因组折叠</strong>和<strong>基因表达</strong>中的功能。</p>
<ol start="2">
<li>CTCF在<strong>Β-globin</strong>和<strong>h19-igf2</strong>位点:一个短暂的历史</li>
</ol>
<p>多功能DNA结合蛋白CTCF的功能最初是在<strong>单个位点</strong>上探索的，特别是在<strong>β-珠蛋白位点</strong>和<strong>印迹H19-Igf2位点</strong>。<strong>chicken β-珠蛋白位点</strong>在其5 ‘侧携带一个DNaseI超敏位点(5 ‘ hs4)，该位点将该位点<strong>与邻近的异染色质分离</strong>，该位点被发现能够<strong>阻断增强子活性</strong>。CTCF随后被证明与5 ‘ hs4的绝缘体活性有关。人和小鼠的β-珠蛋白位点也位于不活跃染色质的大染色体区域内，并类似地被ctcf结合位点包围。这些被怀疑会对进入的异染色质形成屏障，但它们的缺失不会导致β-珠蛋白位点的关闭或失活。<strong>染色体构象捕获(3C)技术</strong>的应用使β-珠蛋白CTCF位点的物理相互作用成为可能。它们形成<strong>大染色质环</strong>，包括β-珠蛋白的主要调节元件，<strong>Locus control region基因位点控制区(LCR)<strong>及其</strong>基因</strong>。这些环是红细胞特异性的，在lcr介导的β-珠蛋白基因高表达之前，在红细胞祖细胞中形成(图1a;)。据推测，CTCF环可以<strong>促进LCR与其靶基因之间的后续空间相互作用</strong>，但这方面的证据仍然缺乏。</p>
<p><img src="/blog/2022/02/15/2022-02-15-CTCF/1.png"></p>
<p>Figure 1. CTCF，染色质环和特定基因位点的转录调控。(a)<strong>位于β-珠蛋白位点的基因</strong>受<strong>基因位点控制区(LCR)*<em><strong>控制。</strong>ctcf结合位点相互作用</em>*，形成</strong>染色质枢纽<strong>，其中包含</strong>LCR和β-珠蛋白基因<strong>。在</strong>红细胞分化<strong>时，</strong>红细胞特异性转录因子和内聚蛋白能够形成一个活跃的染色质枢纽<strong>，其中</strong>LCR与基因接触并增强其表达<strong>。(b) H19和Igf2基因的印迹表达是通过CTCF在印迹控制区(ICR)的甲基化依赖结合介导的。(i)在父系等位基因上，ICR的甲基化</strong>阻止CTCF结合**，并通过远端增强子(E)与Igf2启动子的接触介导Igf2基因的表达。(ii) <strong>CTCF结合在ICR上阻断了Igf2基因和远端增强子之间的通信</strong>，从而导致母源等位基因H19基因的表达。</p>
<p>印迹H19/Igf2位点。该位点包含一个<strong>差异甲基化区域</strong>，称为<strong>印迹控制区(ICR)<strong>，位于H19和Igf2基因之间。ICR决定了H19在</strong>母体等位基因</strong>上<strong>活跃</strong>，而<strong>Igf2</strong>则是从<strong>父系等位基因转录</strong>而来的。当CTCF被发现以<strong>甲基化依赖</strong>的方式与<strong>ICR结合</strong>时，CTCF进入了这个阶段:<strong>CTCF与未甲基化的母源ICR的结合阻</strong>止了H19基因附近的共享增强子<strong>跨越并激活</strong>Igf2。在<strong>父系等位基因CTCF不能发挥其绝缘体活性，因为DNA甲基化阻止了其与ICR的结合</strong>(图1b;)。染色质环再次形成，似乎对ICR的功能很重要。带有增强子和启动子的等位基因特异性染色质环是由母体的、与ctcf结合的ICR形成的，这表明这种接触可能是ctcf介导的绝缘体活性的基础。总的来说，早期关于CTCF在β-珠蛋白和H19-Igf2位点功能的研究表明，该蛋白可以<strong>干扰启动子-增强子通信</strong>。CTCF可以在其结合位点之间形成染色质环，也可能与其他调控序列形成染色质环。</p>
<ol start="3">
<li>CTCF通过基因组与染色质边界、增强子和基因启动子结合</li>
</ol>
<p>通过ChIP对全基因组结合位点的定位发现，CTCF可与数万个基因组位点结合。在不同的细胞类型中，大约<strong>三分之一的位点相对保守</strong>。一项对五种哺乳动物肝脏中CTCF结合谱的物种间比较发现，物种和组织之间大约有5000个超<strong>保守位点</strong>。这些似乎是<strong>高亲和力的结合位点</strong>，提示亲和力的差异可能与的保守强度有关。逆转录因子的激活产生了物种特异性的CTCF结合位点的扩展，这种形式的基因组进化在哺乳动物中仍然高度活跃。基于一致motif评分对CTCF结合位点进行分类得出了类似的结论:<strong>高占用位点似乎在所有细胞类型中都是保守的，而低占用位点则更受组织限制</strong>。</p>
<p>CTCF一致结合序列包含CpG，因此可能受到DNA甲基化的影响。CTCF能够在<strong>体外结合甲基化DNA序列</strong>，但<strong>优先结合未甲基化的序列</strong>，在H19-Igf2位点也可以看到。事实上，DNA甲基化似乎在CTCF的一些组织特异性结合事件中发挥作用。此外，<strong>CTCF</strong>可以通过与两种与DNA甲基化相关的酶:多聚(adp -核糖)聚合酶1 (<strong>PARP1</strong>)和无处不在表达的DNA(胞嘧啶-5)甲基转移酶1 (<strong>DNMT1</strong>)形成<strong>复合物来影响DNA甲基化</strong>。<strong>CTCF激活PARP1, PARP1在DNMT1上添加adp -核糖基团使DNMT1失活，从而维持无甲基CpGs的存在</strong>。</p>
<p><strong>部分CTCF结合位点</strong>在<strong>活性染色质</strong>(<strong>高H2K5Ac</strong>)和<strong>非活性</strong>染色质结构域(<strong>高H3K27me3</strong>)之<strong>间</strong>的过渡<strong>富集</strong>。对于逆转录转座的CTCF结合位点似乎尤其如此。CTCF位点经常位于所谓的<strong>膜相关域</strong>(lad)旁边。lad是与<strong>覆盖核膜内侧的层状蛋白网络相关的染色体区域</strong>;这些染色体区域往往是<strong>转录不活跃</strong>的。它的存在提示<strong>CTCF有助于染色质的三维结构的组织</strong>。在果蝇中，CTCF的抑制导致非活性域内H3K27me3水平的降低，表明CTCF在边界上的结合是<strong>维持抑制</strong>所必需的。CTCF的关联伴随着细胞分化过程中<strong>活性域和非活性域的重置</strong>，进一步表明它的功能是<strong>分离不同的染色质状态</strong>。一些lad在细胞分化过程中也会发生动态变化[35]，但CTCF是否与这些差异lad的边界结合目前尚不清楚。</p>
<p>尽管CTCF结合常出现在TSSs远端，但它确实与<strong>基因密度有很强的相关性</strong>(图2a,b)。事实上，CTCF在转录调控中<strong>直接作用的证据来自于早期对单个基因的研究</strong>。在全基因组范围内，部分CTCF位点与<strong>启动子特异性H3K4me3标记共定位</strong>，另一部分与<strong>增强子标记H3K4me1重合</strong>。启动子上的CTCF结合事件在组织中趋于<strong>保守</strong>，而CTCF与增强子的结合则更受<strong>组织限制</strong>。</p>
<p><img src="/blog/2022/02/15/2022-02-15-CTCF/2.png"></p>
<p>Figure2. CTCF在染色质生物学中的广泛作用。(a) CTCF结合位点的全基因组功能分类，采用Chen et al.[36]。(b) (i) CTCF结合位点位于<strong>分离活性域和非活性域的边界</strong>上。CTCF结合到(ii)<strong>增强子</strong>样序列和(iv)基因<strong>启动子</strong>上可以促进这些序列之间的环环相扣。(iii) CTCF结合在<strong>增强子和基因启动子之间</strong>，可以<strong>阻断</strong>增强子与其目标启动子之间的相互作用。</p>
<ol start="4">
<li>CTCF和内聚蛋白共享DNA结合位点</li>
<li>5.ctcf和其他绑定伙伴</li>
<li>CTCF在单个基因位点的功能</li>
<li>CTCF介导的全基因组染色质环</li>
</ol>
<p>CTCF的基因组结合位点(通过全基因组<strong>ChIP</strong>)与<strong>Hi-C</strong>生成的<strong>genome-wide DNA contact map</strong>的计算交叉表明，CTCF参与染色体之间和基因组内的染色质相互作用。染色质相互作用分析与配对末端标记测序<strong>Chromatin interaction analysis with paired-end tag sequencing (ChIA-PET)</strong> 结合了ChIP和3C方法，用于研究由<strong>感兴趣的蛋白质介导的全基因组DNA相互作用</strong>。当靶向CTCF时，ChIA-PET揭示了蛋白介导的大约<strong>1500个染色体内</strong>和<strong>300个染色体间</strong>的相互作用。随后，根据<strong>组蛋白标记</strong>的分布，对<strong>染色体内环</strong>所包围的<strong>区域(10-200 kb)进行聚类</strong>。这表明CTCF环可以包含从环外非活性染色质分离出来的活性染色质，反之亦然。CTCF还可以同时<strong>捕获染色质环中的增强子和启动子</strong>。在大约<strong>40000个CTCF结合位点</strong>中，只有<strong>一小部分</strong>参与了大约1500个CTCF介导的<strong>环</strong>。这意味着不是所有CTCF介导的相互作用都被识别出来了，或者<strong>大多数CTCF位点没有参与环的形成</strong>。</p>
<p>后者很可能是正确的，因为5C(<strong>chromosome conformation capture carbon copy</strong>染色体构象捕获碳复制)技术表明，在1%的基因组中，大多数CTCF位点不参与染色质环，无论它们是否被内聚蛋白共同占据。<strong>CTCF结合序列常被基因启动子跳过，与增强子或更远的CTCF位点进行接触</strong>。</p>
<p>最近大量的全基因组DNA相互作用数据集有助于<strong>评估CTCF对染色体拓扑的影响</strong>。染色体上靠近<strong>CTCF结合位点的序列</strong>显示在它们的DNA接触中存在偏倚:它们与<strong>CTCF位点同侧</strong>的其他<strong>序列的相互作用</strong>大于与<strong>CTCF位点跨侧</strong>的序列的相互作用(图3a;)。同样的结果也出现在果蝇中另一种不同的绝缘体蛋白上:它与一个位点的结合阻止了侧翼序列在这个位点上相互接触。有趣的是，这可能为绝缘体的功能提供了一种解释:它们可以阻止DNA在绝缘序列上的空间接触。在一个特别详细的全基因组DNA接触研究中，<strong>拓扑域</strong>被定义;它们是<strong>平均大小为1mb的染色体区域</strong>，其中<strong>序列优先相互作用</strong>。在组织之间，甚至在物种之间，拓扑结构域具有很强的<strong>保持性</strong>，这表明这些结构域对<strong>细胞的特异性身份没有贡献</strong>。有趣的是，CTCF结合位点在这些<strong>区域边界周围的20kb窗口中富集</strong>(图3b)，再次强调了其作为<strong>染色质组织者</strong>的作用。其中一项研究表明，边界的破坏会导致拓扑域的混合，并导致相关基因的表达失调[79]。不同于拓扑域本身，域内的接触在分化过程中是变化的。在这里，CTCF似乎发挥了作用，可能适应基因表达的发育变化。</p>
<p><img src="/blog/2022/02/15/2022-02-15-CTCF/3.png"></p>
<p>Fig 3. CTCF通过阻碍DNA在其结合位点上的接触而起到绝缘体的作用。(a) CTCF<strong>阻碍其结合位点在10kb以内的序列跨越</strong>。<strong>线的厚度减小表明交互作用的概率减小</strong>。(b) CTCF结合位点常出现在拓扑域的边界处。(i) ESCs和皮质的Hi-c数据，用小鼠第12号染色体序列之间的颜色编码接触频率。<strong>三角形</strong>显示和突出<strong>拓扑域</strong>，是<strong>染色体序列优先相互作用的区域</strong>。(ii)层关联域(LAD)数据，LAD边界与拓扑域边界重合。(iii) CTCF ChIP-seq profiles，显示在边界的CTCF结合位点簇。请注意，这种CTCF集群在其他地方也存在，特别是在非lad地区。显示区域:chr12: 112.3-119.3 Mb (mm9)。</p>
<ol start="8">
<li>结论</li>
</ol>
<p>尽管CTCF一直是研究的热点，但它仍然是一种<strong>神秘的转录因子</strong>。它与基因组中成千上万个位点结合，与大量其他转录因子相互作用。它常被发现参与染色质<strong>环</strong>，有时有，有时没有<strong>内聚蛋白</strong>的参与。它可以<strong>与其他CTCF结合位点</strong>形<strong>成</strong>染色质<strong>环</strong>，也可以与<strong>增强子</strong>和<strong>启动子</strong>序列形<strong>成</strong>染色质<strong>环</strong>。CTCF不仅与基因内外的序列结合，也与<strong>基因体内</strong>的<strong>序列结合</strong>，在基因体内它似乎能够<strong>暂停滑动聚合酶分子</strong>。最后，CTCF结合位点仍然作为<strong>反转录转座序列</strong>活跃地跳跃，使CTCF结合景观在不同哺乳动物物种之间具有多样性。</p>
<p>可以解释CTCF与染色质关联的许多，<strong>有时是相反的功能</strong>后果的统一主题可能是其<strong>成环能力</strong>。根据环中包含的序列和环外的序列，由CTCF形成的染色质可能会<strong>促进或阻碍增强子和靶基因之间的三维接触</strong>，从而产生不同的转录结果。许多问题仍然存在:为什么一些CTCF位点形成染色质环而另一些则没有?这在多大程度上依赖于相关的蛋白质因子?当蛋白质与染色质结合时，它是如何设法与这么多其他转录因子相互作用的?一种可能是CTCF作为染色质扫描转录因子的路障，当遇到结合蛋白时，这些转录因子以某种方式被困住。ctcf介导的染色体间接触有何相关性?CTCF是否通过阻止3D DNA接触来阻断增强子-启动子通信?或者绝缘是否涉及绝缘体序列与增强剂和启动剂的物理相互作用?这些问题的答案需要能够预测给定的CTCF结合事件是否在功能上不相关，是否会引起转录激活或抑制，是否会干扰转录激活或会产生染色质边界。</p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>【GO】【KEGG】</title>
    <url>/blog/2021/12/20/2021_12_20_GO_KEGG_post/</url>
    <content><![CDATA[<h2 id="Oryza-Sativa-【Gene-ID】【GO】【KEGG】"><a href="#Oryza-Sativa-【Gene-ID】【GO】【KEGG】" class="headerlink" title="Oryza Sativa 【Gene ID】【GO】【KEGG】"></a>Oryza Sativa 【Gene ID】【GO】【KEGG】</h2><span id="more"></span>

<p><strong>GO分析</strong>：基因-&gt;功能类群</p>
<p>**KEGG(Pathway)**：基因-&gt;代谢网络</p>
<p><strong>GO/KEGG选取目标基因</strong></p>
<ul>
<li><p>指标：Enrichment score，p值，FDR</p>
</li>
<li><p>pathway：p和FDR越小越好，问题是有时本就不易富集出，如何取舍</p>
</li>
<li><p>GO：p，FDR，Enrichmentscore（越大越容易受到影响）</p>
</li>
<li><p><font color="green">fold change较大的基因</font>（up，down）</p>
</li>
<li><p>可能有用的蛋白，PPI？</p>
</li>
</ul>
<p>GO: 研究的基因哪些通路？是否变化</p>
<p><strong>KEGG筛选方法：</strong></p>
<ul>
<li>先看KEGG的聚类分析结果（感兴趣研究方向有关的基因是不是有差异）→ GO分为三个分枝，先看BP分枝（感兴趣研究方向有关的基因是不是有差异）→挑选和我们研究比较相关的→后期验证：选FC比较大，验证成功率会高一些</li>
<li>根据Rich factor值、Qvalue值或<font color="green">富集到此通路上的基因个数来衡量KEGG的富集程度</font>，找到富集最显著的通路</li>
<li>找自己感兴趣的：高原反应-&gt;呼吸功能相关通路，免疫系统-&gt;炎症因子、TNF相关通路</li>
<li>从通路中去找到<font color="green">表达倍数显著的基因进行验证</font>，进一步解释相关分子表达机制</li>
</ul>
<p><strong>目标表示</strong></p>
<p>HOTAIR出没于胞核（CC），参与了组蛋白甲基化调控引发癌基因沉默（BP），具体是结合PRC2复合物以及LSD1（MF）</p>
<hr>
<p><strong>转录组数据中筛选关键基因</strong></p>
<p>筛选关键基因的方法有3类：</p>
<p>1.表达量﹢功能富集</p>
<p>2.表达量﹢实验</p>
<p>3.表达量﹢序列</p>
<p>上面的三种方法不难看出，筛选关键基因的<font color="green">核心</font>是<font color="green">表达量</font>，其实转录组的核心就是以表达量为核心展开其他分析的，然后再附加其他一些信息，找出目标基因；最后将分析结果与研究目的巧妙融合，如果再做一些基因功能实验验证（高分必备，可不做），一篇高质量的文章就ok了。</p>
<p><strong>1.表达量﹢功能富集</strong></p>
<p>Zhu T, Wang X, Xu Z, Xu J, Li R, et al. (2020) Screening of key genes responsible for Pennisetum setaceum ‘Rubrum’ leaf color using tranome sequencing. PLOS ONE 15(11): e0242618.</p>
<p>该文研究对象狼尾草观赏草植物，<font color="green">高光</font>环产紫色叶子，<font color="green">低光</font>产浅紫色或绿色叶子。该文鉴定与<font color="green">叶片着色相关的关键基因</font>，并阐明参与狼尾草叶子的颜色变化的分子机制。</p>
<p>差异表达基因分析总共鉴定了19043个DEGs，与T0（未处理阶段的叶子）阶段的表达相比，在T1（遮阴12天后新叶子完全变绿的阶段）阶段上调和下调的基因分别为10761和8642。<font color="green">KEGG富集分析发现，显著富集的通路主要有类黄酮的生物合成，黄酮和黄酮醇的生物合成以及类胡萝卜素的生物合成</font>。<font color="red">基因筛选(显著KEGG内的基因筛选？)</font>发现存在与<strong>叶绿素代谢</strong>有关的31个差异表达基因，其中21个与叶绿素的生物<strong>合成</strong>有关，有10个与叶绿素的<strong>降解</strong>有关，以及3个与叶绿素<strong>降解调控</strong>有关的转录因子，<strong>花青素的合成和积</strong>累有31个关键酶基因，4个可能参与<strong>花色苷代谢调控</strong>的转录因子（图1所示） 。</p>
<p><img src="/blog/2021/12/20/2021_12_20_GO_KEGG_post/selectDEG.png" alt="selectDEG"></p>
<p>快速筛选出感兴趣的基因：基因长度、基因在样品中的表达量、<strong>差异倍数</strong>、<strong>注释信息</strong>等。</p>
<p><font color="green">找显著通路里的基因。做一个信息表。</font></p>
<p><strong>2.表达量﹢实验</strong></p>
<p>Wang A, Chao T, Ji Z, Xuan R, Liu S, Guo M, Wang G, Wang J. 2020. Tranome analysis reveals potential immune function-related regulatory genes/pathways of female Lubo goat submandibular glands at different developmental stages. PeerJ 8:e9947.</p>
<p>课题组前期的基因功能实验或文献查阅来借助别人的已经验证过的基因功能结果，之后再根据表达量筛选关键基因。</p>
<p>转录组研究的目的就是寻找与实验设计相关的关键基因，一般来说研究某生理现象都先要阅读大量文献来判断该实验的可行性。如转录组分析揭示了雌性鲁波<strong>山羊下颌腺</strong>在<strong>不同发育阶段</strong>的潜在<strong>免疫功能相关调节基因</strong>或途径</p>
<p>该文研究的目的是通过<strong>转录组测序</strong>来<strong>定位</strong>差异表达基因（DEG）在<strong>三个不同阶段的表达谱</strong>，预测在<strong>不同发育阶段</strong>的<strong>下颌下腺的免疫功能</strong>。由于<strong>人、小鼠、大鼠、牛</strong>的下颌腺都检测到了<strong>相关抗体</strong>，并且研究发现了下颌腺中的<strong>类红细胞分化因子、内皮素、肝细胞生长因子（HGF）、转移性生长因子（MGF）、转化生长因子-α（TGF-α）和其他因子</strong>。所以在<strong>后续的基因筛选中会重点关注相关因子的表达基因</strong>。</p>
<p>从上面例子中可以发现一个<strong>套路</strong>，先查阅模式生物中该方面的研究结果，然后再结合自己的研究项目筛选出基因，并且<strong>重点关注模式生物中已知的功能基因有没有较大的差异倍数</strong>。</p>
<hr>
<p>ref：</p>
<p><a href="https://zhuanlan.zhihu.com/p/78093534">https://zhuanlan.zhihu.com/p/78093534</a></p>
<p><a href="https://www.sohu.com/a/437865907_278730">https://www.sohu.com/a/437865907_278730</a></p>
<hr>
<h1 id="转录组图形专题之差异基因相关图形"><a href="#转录组图形专题之差异基因相关图形" class="headerlink" title="转录组图形专题之差异基因相关图形"></a>转录组图形专题之差异基因相关图形</h1><p>雷达图、热图、柱状图、韦恩图、火山图</p>
<p><a href="https://www.sohu.com/a/428207189_278730">https://www.sohu.com/a/428207189_278730</a></p>
<h1 id="全套的富集分析相关图形详解"><a href="#全套的富集分析相关图形详解" class="headerlink" title="全套的富集分析相关图形详解"></a>全套的富集分析相关图形详解</h1><p>柱形图，气泡图，圈图，z-score图，网络图</p>
<p><a href="https://www.sohu.com/a/436470973_278730">https://www.sohu.com/a/436470973_278730</a></p>
]]></content>
      <categories>
        <category>GO</category>
        <category>KEGG</category>
      </categories>
      <tags>
        <tag>O_Sativa</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux command awk</title>
    <url>/blog/2021/12/17/2021_12_17_Linux_awk_command/</url>
    <content><![CDATA[<h2 id="Linux-command-【awk】"><a href="#Linux-command-【awk】" class="headerlink" title="Linux command 【awk】"></a>Linux command 【awk】</h2><span id="more"></span>

<h1 id="Linux-awk-命令"><a href="#Linux-awk-命令" class="headerlink" title="Linux awk 命令"></a>Linux awk 命令</h1><p><a href="https://www.runoob.com/linux/linux-command-manual.html"><img src="https://www.runoob.com/images/up.gif" alt="Linux 命令大全"> Linux 命令大全</a></p>
<p>AWK 是一种<font color="green">处理文本文件</font>的语言，是一个强大的文本分析工具。</p>
<p>之所以叫 AWK 是因为其取了三位创始人 Alfred <strong>A</strong>ho，Peter <strong>W</strong>einberger, 和 Brian <strong>K</strong>ernighan 的 Family Name 的首字符。</p>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk [选项参数] <span class="string">&#x27;script&#x27;</span> var=value file(s)</span><br><span class="line">或</span><br><span class="line">awk [选项参数] -f scriptfile var=value file(s)</span><br></pre></td></tr></table></figure>

<p><strong>选项参数说明：</strong></p>
<ul>
<li>-F fs or –field-separator fs<br>指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如<font color="green">-F:</font>。</li>
<li>-v var=value or –asign var=value<br>赋值一个用户定义变量。</li>
<li>-f scripfile or –file scriptfile<br>从脚本文件中读取awk命令。</li>
<li>-W posix<br>打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符<strong>和</strong>=不能代替^和^=；fflush无效?</li>
<li>-W version or –version<br>打印<font color="green">bug报告信息</font>的版本。</li>
</ul>
<hr>
<h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>log.txt文本内容如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">2 this is a <span class="built_in">test</span></span><br><span class="line">3 Are you like awk</span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">10 There are orange,apple,mongo</span></span><br></pre></td></tr></table></figure>

<p>用法一：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;[pattern] action&#125;&#x27;</span> &#123;filenames&#125;   <span class="comment"># 行匹配语句 awk &#x27;&#x27; 只能用单引号</span></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 每行按空格或TAB分割，输出文本中的1、4项</span></span><br><span class="line"> $ awk <span class="string">&#x27;&#123;print $1,$4&#125;&#x27;</span> log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 a</span><br><span class="line"> 3 like</span><br><span class="line"> This<span class="string">&#x27;s</span></span><br><span class="line"><span class="string"> 10 orange,apple,mongo</span></span><br><span class="line"><span class="string"> # 格式化输出</span></span><br><span class="line"><span class="string"> $ awk &#x27;</span>&#123;<span class="built_in">printf</span> <span class="string">&quot;%-8s %-10s\n&quot;</span>,<span class="variable">$1</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string"> ---------------------------------------------</span></span><br><span class="line"><span class="string"> 2        a</span></span><br><span class="line"><span class="string"> 3        like</span></span><br><span class="line"><span class="string"> This&#x27;</span>s</span><br><span class="line"> 10       orange,apple,mongo</span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<p><font color="green">用法二：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk -F  <span class="comment">#-F相当于内置变量FS, 指定分割字符</span></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用&quot;,&quot;分割</span></span><br><span class="line"> $  awk -F, <span class="string">&#x27;&#123;print $1,$2&#125;&#x27;</span>   log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 this is a <span class="built_in">test</span></span><br><span class="line"> 3 Are you like awk</span><br><span class="line"> This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string"> 10 There are orange apple</span></span><br><span class="line"><span class="string"> # 或者使用内建变量</span></span><br><span class="line"><span class="string"> $ awk &#x27;</span>BEGIN&#123;FS=<span class="string">&quot;,&quot;</span>&#125; &#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$2</span>&#125;<span class="string">&#x27;     log.txt</span></span><br><span class="line"><span class="string"> ---------------------------------------------</span></span><br><span class="line"><span class="string"> 2 this is a test</span></span><br><span class="line"><span class="string"> 3 Are you like awk</span></span><br><span class="line"><span class="string"> This&#x27;</span>s a <span class="built_in">test</span></span><br><span class="line"> 10 There are orange apple</span><br><span class="line"> <span class="comment">#! 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割</span></span><br><span class="line"> $ awk -F <span class="string">&#x27;[ ,]&#x27;</span>  <span class="string">&#x27;&#123;print $1,$2,$5&#125;&#x27;</span>   log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 this <span class="built_in">test</span></span><br><span class="line"> 3 Are awk</span><br><span class="line"> This<span class="string">&#x27;s a</span></span><br><span class="line"><span class="string"> 10 There apple</span></span><br></pre></td></tr></table></figure>

<p><font color="green">用法三：</font>-va -vb</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">awk -v  # 设置变量</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -va=1 <span class="string">&#x27;&#123;print $1,$1+a&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">2 3</span><br><span class="line">3 4</span><br><span class="line">This<span class="string">&#x27;s 1</span></span><br><span class="line"><span class="string">10 11</span></span><br><span class="line"><span class="string">$ awk -va=1 -vb=s &#x27;</span>&#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$1</span>+a,<span class="variable">$1b</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">2 3 2s</span></span><br><span class="line"><span class="string">3 4 3s</span></span><br><span class="line"><span class="string">This&#x27;</span>s 1 This<span class="string">&#x27;ss</span></span><br><span class="line"><span class="string">10 11 10s</span></span><br></pre></td></tr></table></figure>

<p>用法四：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk -f &#123;awk脚本&#125; &#123;文件名&#125;</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -f cal.awk log.txt</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><table>
<thead>
<tr>
<th align="left">运算符</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">= += -= *= /= %= ^= **=</td>
<td align="left">赋值</td>
</tr>
<tr>
<td align="left">?:</td>
<td align="left">C条件表达式</td>
</tr>
<tr>
<td align="left">||</td>
<td align="left">逻辑或</td>
</tr>
<tr>
<td align="left">&amp;&amp;</td>
<td align="left">逻辑与</td>
</tr>
<tr>
<td align="left">~ 和 !~</td>
<td align="left">匹配正则表达式和不匹配正则表达式</td>
</tr>
<tr>
<td align="left">&lt; &lt;= &gt; &gt;= != ==</td>
<td align="left">关系运算符</td>
</tr>
<tr>
<td align="left">空格</td>
<td align="left">连接</td>
</tr>
<tr>
<td align="left">+ -</td>
<td align="left">加，减</td>
</tr>
<tr>
<td align="left">* / %</td>
<td align="left">乘，除与求余</td>
</tr>
<tr>
<td align="left">+ - !</td>
<td align="left">一元加，减和逻辑非</td>
</tr>
<tr>
<td align="left">^ ***</td>
<td align="left">求幂</td>
</tr>
<tr>
<td align="left">++ –</td>
<td align="left">增加或减少，作为前缀或后缀</td>
</tr>
<tr>
<td align="left">$</td>
<td align="left">字段引用</td>
</tr>
<tr>
<td align="left">in</td>
<td align="left">数组成员</td>
</tr>
</tbody></table>
<p>过滤第一列大于2的行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1&gt;2&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">3 Are you like awk</span><br><span class="line">This&#x27;s a test</span><br><span class="line">10 There are orange,apple,mongo</span><br></pre></td></tr></table></figure>

<p>过滤第一列等于2的行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1==2 &#123;print $1,$3&#125;&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">2 is</span><br></pre></td></tr></table></figure>

<p><font color="green">过滤第一列大于2并且第二列等于’Are’的行</font></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1&gt;2 &amp;&amp; $2==&quot;Are&quot; &#123;print $1,$2,$3&#125;&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">3 Are you</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="内建变量"><a href="#内建变量" class="headerlink" title="内建变量"></a>内建变量</h2><table>
<thead>
<tr>
<th align="left">变量</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">$n</td>
<td align="left">当前记录的<font color="green">第n个字段</font>，字段间由FS分隔</td>
</tr>
<tr>
<td align="left"><font color="red">$0</font></td>
<td align="left"><font color="green">完整的输入记录</font></td>
</tr>
<tr>
<td align="left">ARGC</td>
<td align="left">命令行参数的数目</td>
</tr>
<tr>
<td align="left">ARGIND</td>
<td align="left">命令行中当前文件的位置(从0开始算)</td>
</tr>
<tr>
<td align="left">ARGV</td>
<td align="left">包含命令行参数的数组</td>
</tr>
<tr>
<td align="left">CONVFMT</td>
<td align="left">数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组</td>
</tr>
<tr>
<td align="left">ERRNO</td>
<td align="left">最后一个系统错误的描述</td>
</tr>
<tr>
<td align="left">FIELDWIDTHS</td>
<td align="left">字段宽度列表(用空格键分隔)</td>
</tr>
<tr>
<td align="left">FILENAME</td>
<td align="left">当前文件名</td>
</tr>
<tr>
<td align="left"><strong>FNR</strong></td>
<td align="left">各文件分别计数的行号</td>
</tr>
<tr>
<td align="left"><strong>FS</strong></td>
<td align="left">字段分隔符(默认是任何空格)</td>
</tr>
<tr>
<td align="left">IGNORECASE</td>
<td align="left">如果为真，则进行忽略大小写的匹配</td>
</tr>
<tr>
<td align="left"><strong>NF</strong></td>
<td align="left">一条记录的字段的数目</td>
</tr>
<tr>
<td align="left"><strong>NR</strong></td>
<td align="left">已经读出的记录数，就是行号，从1开始</td>
</tr>
<tr>
<td align="left">OFMT</td>
<td align="left">数字的输出格式(默认值是%.6g)</td>
</tr>
<tr>
<td align="left"><strong>OFS</strong></td>
<td align="left">输出字段分隔符，默认值与输入字段分隔符一致。</td>
</tr>
<tr>
<td align="left"><strong>ORS</strong></td>
<td align="left">输出记录分隔符(默认值是一个换行符)</td>
</tr>
<tr>
<td align="left">RLENGTH</td>
<td align="left">由match函数所匹配的字符串的长度</td>
</tr>
<tr>
<td align="left">RS</td>
<td align="left">记录分隔符(默认是一个换行符)</td>
</tr>
<tr>
<td align="left">RSTART</td>
<td align="left">由match函数所匹配的字符串的第一个位置</td>
</tr>
<tr>
<td align="left">SUBSEP</td>
<td align="left">数组下标分隔符(默认值是/034)</td>
</tr>
</tbody></table>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#看各变量值</span></span><br><span class="line">$ awk <span class="string">&#x27;BEGIN&#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,&quot;FILENAME&quot;,&quot;ARGC&quot;,&quot;FNR&quot;,&quot;FS&quot;,&quot;NF&quot;,&quot;NR&quot;,&quot;OFS&quot;,&quot;ORS&quot;,&quot;RS&quot;;printf &quot;---------------------------------------------\n&quot;&#125; &#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;&#x27;</span>  log.txt</span><br><span class="line">FILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS</span><br><span class="line">---------------------------------------------</span><br><span class="line">log.txt    2    1         5    1</span><br><span class="line">log.txt    2    2         5    2</span><br><span class="line">log.txt    2    3         3    3</span><br><span class="line">log.txt    2    4         4    4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出顺序号 NR, 匹配文本行号</span></span><br><span class="line">$ awk <span class="string">&#x27;&#123;print NR,FNR,$1,$2,$3&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">1 1 2 this is</span><br><span class="line">2 2 3 Are you</span><br><span class="line">3 3 This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">4 4 10 There are</span></span><br><span class="line"><span class="string"># 指定输出分割符</span></span><br><span class="line"><span class="string">$  awk &#x27;</span>&#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$2</span>,<span class="variable">$5</span>&#125;<span class="string">&#x27; OFS=&quot; $ &quot;  log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">2 $ this $ test</span></span><br><span class="line"><span class="string">3 $ Are $ awk</span></span><br><span class="line"><span class="string">This&#x27;</span>s $ a $</span><br><span class="line">10 $ There $</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="使用正则，字符串匹配"><a href="#使用正则，字符串匹配" class="headerlink" title="使用正则，字符串匹配"></a><font color="green">使用正则，字符串匹配</font></h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出第二列包含 &quot;th&quot;，并打印第二列与第四列</span></span><br><span class="line">$ awk <span class="string">&#x27;$2 ~ /th/ &#123;print $2,$4&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">this a</span><br><span class="line"><span class="comment">#$0是b.txt每一行全部字段，-i &#123;&#125; a.txt 一行一行赋值给 &#123;&#125;</span></span><br><span class="line">cat a.txt | xargs -i awk <span class="string">&#x27;BEGIN&#123;FS=&quot;\t&quot;&#125; $0 ~/&#123;&#125;/ &#123; print &#125;&#x27;</span> b.txt &gt; c.txt</span><br></pre></td></tr></table></figure>

<p><strong>~ 表示模式开始。// 中是模式。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出包含 &quot;re&quot; 的行</span></span><br><span class="line">$ awk <span class="string">&#x27;/re/ &#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">3 Are you like awk</span><br><span class="line">10 There are orange,apple,mongo</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="忽略大小写"><a href="#忽略大小写" class="headerlink" title="忽略大小写"></a>忽略大小写</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk <span class="string">&#x27;BEGIN&#123;IGNORECASE=1&#125; /this/&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">2 this is a <span class="built_in">test</span></span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="模式取反"><a href="#模式取反" class="headerlink" title="模式取反"></a>模式取反</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">this is</span><br><span class="line">Are you</span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">There are</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">$ awk &#x27;</span><span class="variable">$2</span> !~ /th/ &#123;<span class="built_in">print</span> <span class="variable">$2</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">Are like</span></span><br><span class="line"><span class="string">a</span></span><br><span class="line"><span class="string">There orange,apple,mongo</span></span><br><span class="line"><span class="string">$ awk &#x27;</span>!/th/ &#123;<span class="built_in">print</span> <span class="variable">$2</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">Are like</span></span><br><span class="line"><span class="string">a</span></span><br><span class="line"><span class="string">There orange,apple,mongo</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="awk脚本"><a href="#awk脚本" class="headerlink" title="awk脚本"></a>awk脚本</h2><p>关于 awk 脚本，我们需要注意两个关键词 BEGIN 和 END。</p>
<ul>
<li>BEGIN{ 这里面放的是<font color="green">执行前</font>的语句 }</li>
<li>END {这里面放的是处理完<font color="green">所有的行后要执行</font>的语句 }</li>
<li>{这里面放的是处理<font color="green">每一行时</font>要执行的语句}</li>
</ul>
<p>假设有这么一个文件（学生成绩表）：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ cat score.txt</span><br><span class="line">Marry   2143 78 84 77</span><br><span class="line">Jack    2321 66 78 45</span><br><span class="line">Tom     2122 48 77 71</span><br><span class="line">Mike    2537 87 97 95</span><br><span class="line">Bob     2415 40 57 62</span><br></pre></td></tr></table></figure>

<p>我们的 awk 脚本如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ cat cal.awk</span><br><span class="line"><span class="comment">#!/bin/awk -f</span></span><br><span class="line"><span class="comment">#运行前</span></span><br><span class="line">BEGIN &#123;</span><br><span class="line">    math = 0</span><br><span class="line">    english = 0</span><br><span class="line">    computer = 0</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n&quot;</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;---------------------------------------------\n&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#运行中</span></span><br><span class="line">&#123;</span><br><span class="line">    math+=<span class="variable">$3</span></span><br><span class="line">    english+=<span class="variable">$4</span></span><br><span class="line">    computer+=<span class="variable">$5</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;%-6s %-6s %4d %8d %8d %8d\n&quot;</span>, <span class="variable">$1</span>, <span class="variable">$2</span>, <span class="variable">$3</span>,<span class="variable">$4</span>,<span class="variable">$5</span>, <span class="variable">$3</span>+<span class="variable">$4</span>+<span class="variable">$5</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#运行后</span></span><br><span class="line">END &#123;</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;---------------------------------------------\n&quot;</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;  TOTAL:%10d %8d %8d \n&quot;</span>, math, english, computer</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;AVERAGE:%10.2f %8.2f %8.2f\n&quot;</span>, math/NR, english/NR, computer/NR</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们来看一下执行结果：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -f cal.awk score.txt</span><br><span class="line">NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL</span><br><span class="line">---------------------------------------------</span><br><span class="line">Marry  2143     78       84       77      239</span><br><span class="line">Jack   2321     66       78       45      189</span><br><span class="line">Tom    2122     48       77       71      196</span><br><span class="line">Mike   2537     87       97       95      279</span><br><span class="line">Bob    2415     40       57       62      159</span><br><span class="line">---------------------------------------------</span><br><span class="line">  TOTAL:       319      393      350</span><br><span class="line">AVERAGE:     63.80    78.60    70.00</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="另外一些实例"><a href="#另外一些实例" class="headerlink" title="另外一些实例"></a>另外一些实例</h2><p>AWK 的 hello world 程序为：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">BEGIN &#123; <span class="built_in">print</span> <span class="string">&quot;Hello, world!&quot;</span> &#125;</span><br></pre></td></tr></table></figure>

<p>计算文件大小</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ ls -l *.txt | awk <span class="string">&#x27;&#123;sum+=$5&#125; END &#123;print sum&#125;&#x27;</span></span><br><span class="line">--------------------------------------------------</span><br><span class="line">666581</span><br></pre></td></tr></table></figure>

<p>从文件中找出<font color="green">长度大于 80 的行</font>：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;length&gt;80&#x27;</span> log.txt</span><br></pre></td></tr></table></figure>

<p>打印九九乘法表</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">seq 9 | sed <span class="string">&#x27;H;g&#x27;</span> | awk -v RS=<span class="string">&#x27;&#x27;</span> <span class="string">&#x27;&#123;for(i=1;i&lt;=NF;i++)printf(&quot;%dx%d=%d%s&quot;, i, NR, i*NR, i==NR?&quot;\n&quot;:&quot;\t&quot;)&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>更多内容：</p>
<ul>
<li><a href="https://www.runoob.com/w3cnote/awk-work-principle.html">AWK 工作原理</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-arrays.html">AWK 数组</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-if-loop.html">AWK 条件语句与循环</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-user-defined-functions.html">AWK 用户自定义函数</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-built-in-functions.html">AWK 内置函数</a></li>
<li><a href="https://www.runoob.com/w3cnote/8-awesome-awk-built-in-variables.html">8 个有力的 Awk 内建变量</a></li>
<li><a href="http://www.gnu.org/software/gawk/manual/gawk.html">AWK 官方手册</a></li>
</ul>
</blockquote>
<p><strong>awk、sed、grep更适合的方向：</strong></p>
<ul>
<li> grep 更适合单纯的查找或匹配文本</li>
<li> sed 更适合编辑匹配到的文本</li>
<li> awk 更适合格式化文本，对文本进行较复杂格式处理</li>
</ul>
<p>关于awk内建变量个人见解，简单易懂</p>
<p>解释一下变量：</p>
<p>变量：分为内置变量和自定义变量;输入分隔符FS和输出分隔符OFS都属于内置变量。</p>
<p>内置变量就是awk预定义好的、内置在awk内部的变量，而自定义变量就是用户定义的变量。</p>
<ul>
<li> FS(Field Separator)：输入字段分隔符， 默认为空白字符</li>
<li> OFS(Out of Field Separator)：输出字段分隔符， 默认为空白字符</li>
<li> RS(Record Separator)：输入记录分隔符(输入换行符)， 指定输入时的换行符</li>
<li> ORS(Output Record Separate)：输出记录分隔符（输出换行符），输出时用指定符号代替换行符</li>
<li> NF(Number for Field)：当前行的字段的个数(即当前行被分割成了几列)</li>
<li> NR(Number of Record)：行号，当前处理的文本行的行号。</li>
<li> FNR：各文件分别计数的行号</li>
<li> ARGC：命令行参数的个数</li>
<li> ARGV：数组，保存的是命令行所给定的各参数</li>
</ul>
<p><strong>自定义变量的方法</strong></p>
<ul>
<li> 方法一：-v varname=value ，变量名区分字符大小写。</li>
<li> 方法二：在program中直接定义。</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux command xargs</title>
    <url>/blog/2021/12/17/2021_12_17_Linux_xargs_command/</url>
    <content><![CDATA[<h2 id="Linux-command-【xargs】"><a href="#Linux-command-【xargs】" class="headerlink" title="Linux command 【xargs】"></a>Linux command 【xargs】</h2><span id="more"></span>

<h1 id="Linux-xargs-命令"><a href="#Linux-xargs-命令" class="headerlink" title="Linux xargs 命令"></a>Linux xargs 命令</h1><p><a href="https://www.runoob.com/linux/linux-command-manual.html"><img src="/blog/Linux.command/up.gif" alt="Linux 命令大全"> Linux 命令大全</a></p>
<p>xargs（英文全拼： eXtended ARGuments）是给<font color="green">命令传递参数</font>的一个过滤器，也是<font color="green">组合多个命令</font>的一个工具。</p>
<p>xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。</p>
<p>xargs 也可以将单行或多行文本输入转换为其他格式，例如<font color="green">多行变单行，单行变多行</font>。</p>
<p>xargs 默认命令是 echo，这意味着通过<font color="green">管道传递给 xargs 的输入包含换行和空白</font>，通过 xargs 的处理，<font color="green">换行和空白将被空格取代</font>。</p>
<p>xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。</p>
<p>之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令，例如：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /sbin -perm +700 |ls -l       <span class="comment">#这个命令是错误的</span></span><br><span class="line">find /sbin -perm +700 |xargs ls -l   <span class="comment">#这样才是正确的</span></span><br></pre></td></tr></table></figure>

<p>xargs 一般是和管道一起使用。</p>
<p><strong>命令格式：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">somecommand |xargs -item  <span class="built_in">command</span></span><br></pre></td></tr></table></figure>

<p><strong>参数：</strong></p>
<ul>
<li>-a file 从文件中读入作为 stdin</li>
<li>-e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。</li>
<li>-p 当每次执行一个argument的时候询问一次用户。</li>
<li>-n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。</li>
<li>-t 表示先打印命令，然后再执行。</li>
<li><font color="green">-i 或是-I</font>，这得看linux支持了，将xargs的每项名称，一般是<font color="green">一行一行赋值给 {}，可以用 {} 代替</font>。</li>
<li>-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。</li>
<li>-s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。</li>
<li><font color="green">-L num 从标准输入一次读取 num 行送给 command 命令</font>。</li>
<li>-l 同 -L。</li>
<li>-d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。</li>
<li>-x exit的意思，主要是配合-s使用。。</li>
<li>-P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。</li>
</ul>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>xargs 用作替换工具，读取输入数据重新格式化后输出。</p>
<p>定义一个测试文件，内有多行文本数据：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt</span></span><br><span class="line"></span><br><span class="line">a b c d e f g</span><br><span class="line">h i j k l m n</span><br><span class="line">o p q</span><br><span class="line">r s t</span><br><span class="line">u v w x y z</span><br></pre></td></tr></table></figure>

<p><font color="green">多行输入单行输出：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt | xargs</span></span><br><span class="line">a b c d e f g h i j k l m n o p q r s t u v w x y z</span><br></pre></td></tr></table></figure>

<p><font color="green">-n 选项多行输出：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt | xargs -n3</span></span><br><span class="line"></span><br><span class="line">a b c</span><br><span class="line">d e f</span><br><span class="line">g h i</span><br><span class="line">j k l</span><br><span class="line">m n o</span><br><span class="line">p q r</span><br><span class="line">s t u</span><br><span class="line">v w x</span><br><span class="line">y z</span><br></pre></td></tr></table></figure>

<p>-d 选项可以自定义一个定界符：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># echo &quot;nameXnameXnameXname&quot; | xargs -dX</span></span><br><span class="line"></span><br><span class="line">name name name name</span><br></pre></td></tr></table></figure>

<p>结合 -n 选项使用：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># echo &quot;nameXnameXnameXname&quot; | xargs -dX -n2</span></span><br><span class="line"></span><br><span class="line">name name</span><br><span class="line">name name</span><br></pre></td></tr></table></figure>

<p>读取 stdin，将格式化后的参数传递给命令</p>
<p>假设一个命令为 sk.sh 和一个保存参数的文件 arg.txt：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#sk.sh命令内容，打印出所有参数。</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> $*</span><br></pre></td></tr></table></figure>

<p>arg.txt文件内容：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat arg.txt</span></span><br><span class="line"></span><br><span class="line">aaa</span><br><span class="line">bbb</span><br><span class="line">ccc</span><br></pre></td></tr></table></figure>

<p>xargs 的一个选项 -I，使用 -I 指定一个替换字符串 {}，这个字符串在 xargs 扩展时会被替换掉，当 -I 与 xargs 结合使用，每一个参数命令都会被执行一次：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat arg.txt | xargs -I &#123;&#125; ./sk.sh -p &#123;&#125; -l</span></span><br><span class="line"></span><br><span class="line">-p aaa -l</span><br><span class="line">-p bbb -l</span><br><span class="line">-p ccc -l</span><br></pre></td></tr></table></figure>

<p>复制所有图片文件到 /data/images 目录下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ls *.jpg | xargs -n1 -I &#123;&#125; cp &#123;&#125; /data/images</span><br></pre></td></tr></table></figure>

<p>xargs 结合 find 使用</p>
<p>用 rm 删除太多的文件时候，可能得到一个错误信息：**/bin/rm Argument list too long.** 用 xargs 去避免这个问题：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.log&quot;</span> -print0 | xargs -0 rm -f</span><br></pre></td></tr></table></figure>

<p>xargs -0 将 \0 作为定界符。</p>
<p>统计一个源代码目录中所有 php 文件的行数：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.php&quot;</span> -print0 | xargs -0 wc -l</span><br></pre></td></tr></table></figure>

<p>查找所有的 jpg 文件，并且压缩它们：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.jpg&quot;</span> -<span class="built_in">print</span> | xargs tar -czvf images.tar.gz</span><br></pre></td></tr></table></figure>

<p>xargs 其他应用</p>
<p>假如有<font color="green">一个文件包含了很多希望下载的 URL</font>，你能够使用 xargs下载所有链接：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat url-list.txt | xargs wget -c</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Oryza Sativa 【Gene ID】【GO】【KEGG】</title>
    <url>/blog/2021/12/16/2021_12_16_osa_GO_KEGG/</url>
    <content><![CDATA[<h2 id="Oryza-Sativa-【Gene-ID】【GO】【KEGG】"><a href="#Oryza-Sativa-【Gene-ID】【GO】【KEGG】" class="headerlink" title="Oryza Sativa 【Gene ID】【GO】【KEGG】"></a>Oryza Sativa 【Gene ID】【GO】【KEGG】</h2><span id="more"></span>

<h1 id="O-sativa-ID-区分"><a href="#O-sativa-ID-区分" class="headerlink" title="O_sativa ID 区分"></a>O_sativa ID 区分</h1><ul>
<li><p>MSU, <font color="red">RGAP7.0</font>(rice genome annotation project)：<strong>LOC_Os01g01010.1</strong>,  LOC_Osp#g#####，<strong>LOC_Os-Chr-g-number</strong></p>
</li>
<li><p><font color="red">RAP</font>(the rice annotation project), IRGSP-1.0: <strong>Os06t0664200</strong>，<strong>Os-Chr-g-number</strong></p>
</li>
<li><p><font color="red">KEGG支持</font>：osa：RefSeq ID（Gene ID：<strong>4334374</strong>）；dosa：RAP-DB ID（<strong>Os06t0664200-01</strong>）</p>
</li>
<li><p>疑问：RAP-DB ID为什么和IRGSP-1.0 ID多了个-01：RAP-Locus与RAP ID不同</p>
</li>
<li><p>clusterProfiler可能是目前KEGG富集分析最好的软件，因为能<strong>爬取最新的KEGG在线版数据库</strong>，而不是用不再更新的KEGG.db。</p>
</li>
<li><p>对于RGAP水稻的基因编号，如LOC_Os01g01010.1 我们要把它变成<code>Os06t0664200-01</code> RAP-ID的命名方式，符合<code>dosa</code>的要求。</p>
</li>
</ul>
<h2 id="转化id"><a href="#转化id" class="headerlink" title="转化id"></a>转化id</h2><ul>
<li><p>下载一个各个ID对应的文件：<a href="https://shigen.nig.ac.jp/rice/oryzabase/download/riceId%E3%80%82%E5%AF%B9%E4%BA%8ERGAP%E6%B0%B4%E7%A8%BB%E7%9A%84%E5%9F%BA%E5%9B%A0%E7%BC%96%E5%8F%B7%EF%BC%8C%E5%A6%82LOC_Os01g01010.1">https://shigen.nig.ac.jp/rice/oryzabase/download/riceId。对于RGAP水稻的基因编号，如LOC_Os01g01010.1</a> 把它变成<code>Os06t0664200-01</code> RAP-ID的命名方式，符合<code>dosa</code>的要求。</p>
</li>
<li><p>日本晴数据库：<a href="https://shigen.nig.ac.jp/rice/oryzabase">https://shigen.nig.ac.jp/rice/oryzabase</a></p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ grep LOC_Os01g01010.1  rice_id_20140620174522.txt</span><br><span class="line">Os01g0100100    Os01t0100100-01 J075199P03      301700  J075199P03              LOC_Os01g01010.1        AK242339</span><br><span class="line">cat LOC.txt | xargs -i awk <span class="string">&#x27;BEGIN&#123;FS=&quot;\t&quot;&#125;  $0 ~/&#123;&#125;/ &#123; print $2&#125;&#x27;</span> rice_id_20140620174522.txt &gt; RAP_id.txt</span><br></pre></td></tr></table></figure>



<hr>
<h1 id="超几何分布"><a href="#超几何分布" class="headerlink" title="超几何分布"></a>超几何分布</h1><p>它描述了从有限N个物件（其中包含M个指定种类的物件）中抽出n个物件，成功抽出该指定种类的物件的次数（不放回）。称为超几何分布。</p>
<p><a href="https://baike.baidu.com/item/%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83/4782968">https://baike.baidu.com/item/超几何分布/4782968</a></p>
<hr>
<h1 id="GO-enrichment：web"><a href="#GO-enrichment：web" class="headerlink" title="GO enrichment：web"></a>GO enrichment：web</h1><blockquote>
<p>网站：<a href="http://systemsbiology.cau.edu.cn/agriGOv2">http://systemsbiology.cau.edu.cn/agriGOv2</a>  华大</p>
</blockquote>
<h1 id="GO-enrichment：R-clusterProfiler"><a href="#GO-enrichment：R-clusterProfiler" class="headerlink" title="GO enrichment：R clusterProfiler"></a>GO enrichment：R clusterProfiler</h1><p><strong>X</strong> clusterprofiler不能用来做GO的富集分析，因为其20个物种中不包括水稻；</p>
<h2 id="获取Orgdb，"><a href="#获取Orgdb，" class="headerlink" title="获取Orgdb，"></a>获取Orgdb，</h2><p>AnnotationHub在线检索并抓取OrgDb</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; require(AnnotationHub)</span><br><span class="line">&gt; hub &lt;- AnnotationHub()</span><br><span class="line">&gt; query(hub, <span class="string">&quot;oryza sativa&quot;</span>)</span><br><span class="line">title</span><br><span class="line">  AH10561 | hom.Oryza_sativa.inp8.sqlite</span><br><span class="line">  AH55775 | org.Oryza_sativa_Japonica_Group.eg.sqlite</span><br><span class="line">&gt; rice &lt;- hub[[<span class="string">&#x27;AH55775&#x27;</span>]]</span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; <span class="built_in">length</span>(keys(rice))[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#通过检索，org.Oryza_sativa_Japonica_Group.eg.sqlite就是我们所要的OrgDb，可以通过相应的accession number, AH55775 抓取文件，并存入了rice对象中，它包含了32639个基因的注释</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">#这个OrgDb，包含有以下一些注释信息:</span></span><br><span class="line">&gt; columns(rice)</span><br><span class="line"> [<span class="number">1</span>] <span class="string">&quot;ACCNUM&quot;</span>      <span class="string">&quot;ALIAS&quot;</span>       <span class="string">&quot;CHR&quot;</span>         <span class="string">&quot;ENTREZID&quot;</span>    <span class="string">&quot;EVIDENCE&quot;</span></span><br><span class="line"> [<span class="number">6</span>] <span class="string">&quot;EVIDENCEALL&quot;</span> <span class="string">&quot;GENENAME&quot;</span>    <span class="string">&quot;GID&quot;</span>         <span class="string">&quot;GO&quot;</span>          <span class="string">&quot;GOALL&quot;</span></span><br><span class="line">[<span class="number">11</span>] <span class="string">&quot;ONTOLOGY&quot;</span>    <span class="string">&quot;ONTOLOGYALL&quot;</span> <span class="string">&quot;PMID&quot;</span>        <span class="string">&quot;REFSEQ&quot;</span>      <span class="string">&quot;SYMBOL&quot;</span></span><br><span class="line">  [<span class="number">16</span>] <span class="string">&quot;UNIGENE&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##我们可以使用bitr来转换ID，甚至于直接检索GO注释：</span></span><br><span class="line">&gt; require(clusterProfiler)</span><br><span class="line">&gt; bitr(keys(rice)[<span class="number">1</span>], <span class="string">&#x27;ENTREZID&#x27;</span>, <span class="built_in">c</span>(<span class="string">&quot;REFSEQ&quot;</span>, <span class="string">&quot;GO&quot;</span>, <span class="string">&quot;ONTOLOGY&quot;</span>), rice)</span><br><span class="line"><span class="string">&#x27;select()&#x27;</span> returned <span class="number">1</span>:many mapping between keys and columns</span><br><span class="line">  ENTREZID      REFSEQ         GO ONTOLOGY</span><br><span class="line"><span class="number">1</span>  <span class="number">3131385</span> NP_039457.2 GO:<span class="number">0005739</span>       CC</span><br><span class="line"><span class="number">2</span>  <span class="number">3131385</span> NP_039457.2 GO:<span class="number">0005763</span>       CC</span><br><span class="line"><span class="comment">##GO富集分析</span></span><br><span class="line">&gt; sample_genes &lt;- keys(rice)[<span class="number">1</span>:<span class="number">100</span>]</span><br><span class="line">&gt; head(sample_genes)</span><br><span class="line">[<span class="number">1</span>] <span class="string">&quot;3131385&quot;</span> <span class="string">&quot;3131390&quot;</span> <span class="string">&quot;3131391&quot;</span> <span class="string">&quot;3131392&quot;</span> <span class="string">&quot;3131393&quot;</span> <span class="string">&quot;3131394&quot;</span></span><br><span class="line"><span class="comment">##这里只是简单地使用ID列表中前100个ENTREZ基因ID，也可以使用其它的ID，通过借助于bitr进行转换，或者通过给enrichGO指定ID类型(keyType参数）。</span></span><br><span class="line">&gt; 有了OrgDb，使用起来，就跟文档中使用人类基因做为例子一样，用法一致，并且也可以通过clusterProfiler所提供的各种可视化函数对结果进行展示：</span><br><span class="line"></span><br><span class="line">&gt; require(clusterProfiler)</span><br><span class="line">&gt; res = enrichGO(sample_genes, OrgDb=rice, pvalueCutoff=<span class="number">1</span>, qvalueCutoff=<span class="number">1</span>)</span><br><span class="line">&gt; res</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># over-representation test</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#...@organism    Oryza sativa_Japonica_Group</span></span><br><span class="line"><span class="comment">#...@ontology    MF</span></span><br><span class="line"><span class="comment">#...@keytype     ENTREZID</span></span><br><span class="line"><span class="comment">#...@gene        chr [1:100] &quot;3131385&quot; &quot;3131390&quot; &quot;3131391&quot; &quot;3131392&quot; &quot;3131393&quot; &quot;3131394&quot; ...</span></span><br><span class="line"><span class="comment">#...pvalues adjusted by &#x27;BH&#x27; with cutoff &lt;1</span></span><br><span class="line"><span class="comment">#...28 enriched terms found</span></span><br><span class="line"><span class="string">&#x27;data.frame&#x27;</span>:   <span class="number">28</span> obs. of  <span class="number">9</span> variables:</span><br><span class="line"> $ ID         : chr  <span class="string">&quot;GO:0003735&quot;</span> <span class="string">&quot;GO:0005198&quot;</span> <span class="string">&quot;GO:0003723&quot;</span> <span class="string">&quot;GO:0016830&quot;</span> ...</span><br><span class="line"> $ Description: chr  <span class="string">&quot;structural constituent of ribosome&quot;</span> <span class="string">&quot;structural molecule activity&quot;</span> <span class="string">&quot;RNA binding&quot;</span> <span class="string">&quot;carbon-carbon lyase activity&quot;</span> ...</span><br><span class="line"> $ GeneRatio  : chr  <span class="string">&quot;7/12&quot;</span> <span class="string">&quot;7/12&quot;</span> <span class="string">&quot;2/12&quot;</span> <span class="string">&quot;1/12&quot;</span> ...</span><br><span class="line"> $ BgRatio    : chr  <span class="string">&quot;22/478&quot;</span> <span class="string">&quot;22/478&quot;</span> <span class="string">&quot;14/478&quot;</span> <span class="string">&quot;10/478&quot;</span> ...</span><br><span class="line"> $ pvalue     : num  <span class="number">1.08e-07</span> <span class="number">1.08e-07</span> <span class="number">4.45e-02</span> <span class="number">2.26e-01</span> <span class="number">3.24e-01</span> ...</span><br><span class="line"> $ p.adjust   : num  <span class="number">1.52e-06</span> <span class="number">1.52e-06</span> <span class="number">4.15e-01</span> <span class="number">1.00</span> <span class="number">1.00</span> ...</span><br><span class="line"> $ qvalue     : num  <span class="number">1.42e-06</span> <span class="number">1.42e-06</span> <span class="number">3.90e-01</span> <span class="number">9.40e-01</span> <span class="number">9.40e-01</span> ...</span><br><span class="line"> $ geneID     : chr  <span class="string">&quot;3131425/3131435/3131436/3131439/3131441/3131442/3131457&quot;</span> <span class="string">&quot;3131425/3131435/3131436/3131439/3131441/3131442/3131457&quot;</span> <span class="string">&quot;3131425/3131457&quot;</span> <span class="string">&quot;3131463&quot;</span> ...</span><br><span class="line"> $ Count      : int  <span class="number">7</span> <span class="number">7</span> <span class="number">2</span> <span class="number">1</span> <span class="number">3</span> <span class="number">1</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">1</span> ...</span><br></pre></td></tr></table></figure>



<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line">sly &lt;- ah[[<span class="string">&quot;AH61992&quot;</span>]]</span><br><span class="line">sly</span><br><span class="line">saveDb(sly,file=<span class="string">&quot;sly.orgdb&quot;</span>)</span><br><span class="line">laodDb(file=<span class="string">&quot;sly.orgdb&quot;</span>)</span><br></pre></td></tr></table></figure>



<p>plant_GSEA: MSU-&gt;Uniprot</p>
<p>david:Uniprot-&gt;Entrez_id</p>
<hr>
<h1 id="KEGG-enrichment：R-clusterProfiler"><a href="#KEGG-enrichment：R-clusterProfiler" class="headerlink" title="KEGG enrichment：R clusterProfiler"></a>KEGG enrichment：R clusterProfiler</h1><ol>
<li><p>enrichKEGG</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">enrichKEGG(gene, organism = <span class="string">&quot;hsa&quot;</span>, keyType = <span class="string">&quot;kegg&quot;</span>, pvalueCutoff = <span class="number">0.05</span>,</span><br><span class="line">  pAdjustMethod = <span class="string">&quot;BH&quot;</span>, universe, minGSSize = <span class="number">10</span>, maxGSSize = <span class="number">500</span>,</span><br><span class="line">  qvalueCutoff = <span class="number">0.2</span>, use_internal_data = <span class="literal">FALSE</span>)</span><br><span class="line"><span class="comment">#gene： 基因名，要和keyType对应</span></span><br><span class="line"><span class="comment">#organism: 需要参考 http://www.genome.jp/kegg/catalog/org_list.html</span></span><br><span class="line"><span class="comment">#keyType: 基因的命名方式， “kegg”, ‘ncbi-geneid’, ‘ncib-proteinid’ and ‘uniprot’选择其一</span></span><br><span class="line"><span class="comment">#enrichKEGG的一个关键在于理解它是如何获取数据的。在线爬取数据库，相当于在KEGG上手动输入基因名查询。</span></span><br><span class="line"><span class="comment">#所以，把enrichKEGG当做浏览器，试出合适的keytypes。</span></span><br></pre></td></tr></table></figure></li>
<li></li>
</ol>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library(clusterProfiler)</span><br><span class="line"><span class="comment"># 对于GID</span></span><br><span class="line">kk &lt;- enrichkegg(gid_list,organism=<span class="string">&#x27;osa&#x27;</span>,keyType = <span class="string">&#x27;kegg&#x27;</span>,pvalueCutoff=<span class="number">0.05</span>, pAdjustMethod=<span class="string">&#x27;BH&#x27;</span>,qvalueCutoff=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于RAP_ID</span></span><br><span class="line">kk &lt;- enrichkegg(rap_list,organism=<span class="string">&#x27;dosa&#x27;</span>,keyType = <span class="string">&#x27;kegg&#x27;</span>,pvalueCutoff=<span class="number">0.05</span>, pAdjustMethod=<span class="string">&#x27;BH&#x27;</span>,qvalueCutoff=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">write.table(ekk,<span class="string">&quot;kegg.txt&quot;</span>,sep = <span class="string">&quot;\t&quot;</span>,<span class="built_in">quote</span> = <span class="built_in">F</span>,row.names = <span class="built_in">F</span>)</span><br><span class="line">barplot(ekk,showCategory = <span class="number">15</span>,title = <span class="string">&quot;EnrichmentKEGG&quot;</span>)</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>若差异基因集（如500个）本身确实没有生物学功能偏好性，非常有可能无显著富集的kegg通路。</li>
</ol>
<p>修改代码，比如：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">kk.down &lt;- enrichKEGG(gene = gene_down,</span><br><span class="line">                        organism = <span class="string">&#x27;hsa&#x27;</span>, </span><br><span class="line">                        pvalueCutoff = <span class="number">0.9</span>,</span><br><span class="line">                        qvalueCutoff =<span class="number">0.9</span>)</span><br><span class="line"><span class="comment"># 需要自己差异分析筛选得到 gene_down 基因集 ，然后进行超几何分布检验</span></span><br><span class="line"><span class="comment">#再调整阈值</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li><p>或可去MSigDB（Molecular Signatures Database<a href="https://www.gsea-msigdb.org/gsea/msigdb%EF%BC%89%E7%9C%8B%E5%85%B6%E5%AE%83%E5%8A%9F%E8%83%BD%E5%9F%BA%E5%9B%A0%E9%9B%86%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E5%AF%8C%E9%9B%86%EF%BC%8CMSigDB%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B7%B2%E7%9F%A5%E7%9A%84%E5%9F%BA%E5%9B%A0%E9%9B%86%E5%90%88%EF%BC%9A%E5%8C%85%E6%8B%ACH%E5%92%8CC1-C7%E5%85%AB%E4%B8%AA%E7%B3%BB%E5%88%97%EF%BC%88Collection%EF%BC%89%EF%BC%8C%E6%A4%8D%E7%89%A9%E9%80%82%E7%94%A8%EF%BC%9F">https://www.gsea-msigdb.org/gsea/msigdb）看其它功能基因集是否可以富集，MSigDB数据库中定义了已知的基因集合：包括H和C1-C7八个系列（Collection），植物适用？</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/150744437">GSEA分析</a>，不依赖于差异分析本身,植物适用？</p>
</li>
</ol>
<hr>
<h1 id="KEGG数据库不会下载？了解下API！"><a href="#KEGG数据库不会下载？了解下API！" class="headerlink" title="KEGG数据库不会下载？了解下API！"></a>KEGG数据库不会下载？了解下API！</h1><ol>
<li><p>KEGG数据库并不提供免费、批量蛋白序列下载，其官方提供在线分析工具BlastKOALA（<a href="https://link.zhihu.com/?target=https://www.kegg.jp/blastkoala/">https://www.kegg.jp/blastkoala/</a>）等可用于KEGG数据库的注释分析。此外还有其他一些在线分析工具例如很常用的KAAS（<a href="https://link.zhihu.com/?target=https://www.genome.jp/tools/kaas/">https://www.genome.jp/tools/kaas/</a>）等。在线工具内部参数未知。</p>
</li>
<li><p>KEGG API（<a href="https://www.kegg.jp/kegg/rest/keggapi.html%EF%BC%89%E6%98%AF%E5%92%8CKEGG%E5%86%85%E6%A0%B8%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92%E7%9A%84%E7%A8%8B%E5%BA%8F%E7%95%8C%E9%9D%A2%EF%BC%8C%E5%85%81%E8%AE%B8%E7%94%A8%E6%88%B7%E5%9F%BA%E4%BA%8E%E8%AF%A5%E7%95%8C%E9%9D%A2%E6%A3%80%E7%B4%A2KEGG%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C[%E4%B8%8B%E8%BD%BD](https://zhuanlan.zhihu.com/p/76195765)">https://www.kegg.jp/kegg/rest/keggapi.html）是和KEGG内核数据库进行交互的程序界面，允许用户基于该界面检索KEGG数据库，[下载](https://zhuanlan.zhihu.com/p/76195765)</a></p>
<p>(1)<a href="https://mp.weixin.qq.com/s/YlJbkIg9It9On5HWRPPgmQ">https://mp.weixin.qq.com/s/YlJbkIg9It9On5HWRPPgmQ</a></p>
<p>(2)<a href="https://mp.weixin.qq.com/s/F3dRgHBI4a2atvz0O_pukA">https://mp.weixin.qq.com/s/F3dRgHBI4a2atvz0O_pukA</a></p>
<p>(3)<a href="https://mp.weixin.qq.com/s/oDDIlWXsLyTCh18bEEysmQ">https://mp.weixin.qq.com/s/oDDIlWXsLyTCh18bEEysmQ</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>GO</category>
        <category>KEGG</category>
      </categories>
      <tags>
        <tag>O_Sativa</tag>
      </tags>
  </entry>
  <entry>
    <title>KMeans</title>
    <url>/blog/2021/11/15/2021-11-15-kmeans/</url>
    <content><![CDATA[<p>监督学习</p>
<p>无监督学习：数据无标注甚至非结构化。KMeans…</p>
<span id="more"></span>



<h1 id="KMeans"><a href="#KMeans" class="headerlink" title="KMeans"></a>KMeans</h1><h2 id="简介-聚类与KMeans"><a href="#简介-聚类与KMeans" class="headerlink" title="简介-聚类与KMeans"></a>简介-聚类与KMeans</h2><blockquote>
<ul>
<li><strong>聚类（Clustering）</strong>：将数据对象分为多个类或者簇 (Cluster)，使同一簇对象间较高相似度，不同簇对象差别较大。</li>
<li><strong>划分（Partitioning）</strong>：聚类可基于划分，也可基于分层。划分即将对象划分成不同簇，而分层将对象分等级。</li>
<li><strong>排他（Exclusive）</strong>：一个数据对象，只能被划分到一个簇。如果一个数据对象可被划分到多个簇，则称为可重叠（Overlapping）。</li>
<li><strong>距离（Distance）</strong>：基于距离的聚类将距离近的相似对象聚在一起。基于<font color="red">概率分布模型的聚类？</font>在一组对象中，找到符合特定分布模型的对象的集合，不一定是距离最近的或者最相似的，而是能完美的呈现出概率分布模型所描述的模型。</li>
<li>欧氏距离：欧几里得度量二维和三维空间中的欧氏距离就是两点之间的实际距离</li>
</ul>
</blockquote>
<ul>
<li><p>与分类、序列标注不同，聚类事先并不知道任何样本标签，通过数据之间内在关系把样本划分为若干类别，使得同类别样本之间的相似度高，不同类别相似度低（增大类内聚，减少类间距）。</p>
</li>
<li><p>聚类属于非监督学习，K均值聚类最基础常用。基本思想，<font color="green">通过迭代寻找K个簇（Cluster），使聚类结果对应的损失函数最小</font>。终止条件是没有（或最小数目）对象被重新分配给不同的聚类，没有（或最小数目）聚类中心再发生变化，误差平方和局部最小。<font color="red">损失函数定义为各个样本距离所属簇中心点的误差平方和</font>：</p>
</li>
</ul>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/1.png"></p>
<p>xi代表第i个样本，ci是xi所属的簇，uci代表簇对应中心点，M是样本总数。</p>
<ul>
<li><p>？损失函数本质是衡量模型的拟合效果，有求解参数需求的算法，才会有损失函数。Kmeans 不求解什么参数，它的模型本质也没有在拟合数据，而是在对数据进行一 种探索。在决策树中有衡量分类效果的指标准确度<code>accuracy</code>，准确度所对应的损失叫做泛化误差，但不能通过最小化泛化误差来求解某个模型中需要的信息，只是希望模型的效果上表现出来的泛化误差 很小。因此决策树，KNN 等算法，是绝对没有损失函数的。</p>
</li>
<li><table>
<thead>
<tr>
<th>距离度量对比</th>
<th>质心</th>
<th>Inertia</th>
</tr>
</thead>
<tbody><tr>
<td>欧几里得距离</td>
<td>均值</td>
<td>最小化每个样本点到质心的欧式距离之和</td>
</tr>
<tr>
<td>曼哈顿距离</td>
<td>中位数</td>
<td>最小化每个样本点到质心的曼哈顿距离之和</td>
</tr>
<tr>
<td>余弦距离</td>
<td>均值</td>
<td>最小化每个样本点到质心的余弦距离之和</td>
</tr>
</tbody></table>
</li>
<li><p>  上述问题是<font color="green">NP-Hard</font>问题。一般是采用坐标下降（Coordinate Decendet）方法求解。坐标下降法属于非梯度优化方法，每一步迭代中沿着一个坐标轴方向探索，通过循环使用不同的坐标达到求解目标函数的局部最小值。 </p>
</li>
</ul>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/4.png"></p>
<p>如上图，假设两维度x，y：</p>
<ol>
<li>首先选择初始位置(x,y)，假设x未知将y的值代入目标函数中，令目标函数导数0，求得此时最佳x值。</li>
<li>又假设y未知将刚求得x的值代入目标函数，令目标函数导数0，求得此时最佳y。</li>
<li>重复执行第1步第2步，目标函数逐渐接近极小值点，直到达到了极小值点停止。</li>
</ol>
<p>收敛的过程如红色箭头所示。更多维度时，同理，一次只对一个维度最优化。</p>
<p>坐标下降法一般要求目标函数是可微的凸函数(局部最小值即全局最小值?)，此时求得的极小值才能是全局最小值。</p>
<p>使用K-Means前，可先用PCA使各个变量间尽可能独立。否则如两变量间有较强关联性，函数收敛速度会非常慢。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>KMeans的核心目标是将给定的数据集划分成K个簇（K是超参），并给出每个样本数据对应的中心点。具体步骤非常简单，可以分为4步：</p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/2.png"></p>
<p><strong>KMeans最核心的部分就是先固定中心点，调整每个样本所属的类别来减少J；再固定每个样本的类别，调整中心点继续减小J 。两个过程交替循环， J 单调递减直到最（极）小值，中心点和样本划分的类别同时收敛。</strong></p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/3.png"></p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/5.png"></p>
<h1 id="优缺点优化策略"><a href="#优缺点优化策略" class="headerlink" title="优缺点优化策略"></a>优缺点优化策略</h1><p>KMenas优点：</p>
<ul>
<li>高效可伸缩，计算复杂度 为<font color="green">O(NKt)</font>接近于线性（N是数据量，K是聚类总数，t是迭代轮数）。</li>
<li><font color="green">收敛速度快</font>，原理通俗易懂，可解释性强。</li>
</ul>
<p>KMeans明显缺点：</p>
<ul>
<li>受<font color="green">初始值</font>和<font color="green">异常</font>影响，聚类结果可能不是全局最优而是<font color="green">局部最优</font>。</li>
<li><font color="green">K</font>是超参数，按<font color="green">经验选择</font></li>
<li><font color="green">样本点只能划分到单一的类中</font></li>
<li>只能发现球状的簇。</li>
<li>初始值对结果影响较大，可能每次聚类结果都不一样。</li>
</ul>
<p>根据以上特点，我们可以从下面几个角度对算法做调优</p>
<ol>
<li><strong>数据预处理：归一化和异常点过滤</strong></li>
</ol>
<p><strong>KMeans本质是基于欧式距离度量的数据划分方法，均值和方差大的维度将对数据聚类结果产生决定性影响。</strong>聚类前对数据（<strong>具体的说是每一个维度的特征</strong>）做<font color="green">归一化</font>和<font color="green">单位统一</font>至关重要。<font color="green">异常值</font>会对均值计算产生较大影响，导致<strong>中心偏移</strong>，<font color="green">噪声点最好能提前过滤</font>。</p>
<p><strong>2.合理选择K值</strong></p>
<p>K值的选择一般基于实验和多次实验结果。例如采用<strong>手肘法</strong>，尝试不同K值并将对应的损失函数画成折线。手肘法认为图上的<strong>拐点就是K的最佳值</strong>（上图对应K=3）。</p>
<p><strong>Gap Statistic方法</strong>。只需要找到最大的Gap Statistic对应的K(自动)。</p>
<p>沿用第一节中<font color="green">损失函数</font>记为 Dk，当分为K类时，Gap Statistic定义为： Gap(k)=E(logDk)-logDk 。 E(logDk)是logDk的期望，一般由<font color="green">蒙特卡洛模拟</font>产生。在<font color="green">样本所在的区域内按照均匀分布随机地产生和原始样本数一样多的随机样本</font>，对这个<font color="green">随机样本做KMeans</font>，得到一个<font color="green">Dk</font>，<font color="green">重复多次</font>计算出 E(logDk)的近似值。</p>
<p><strong>Gap(K) 的物理含义是<font color="green">随机样本的损失与实际样本的损失之差</font>。Gap越<font color="green">大</font>说明聚类的效果越好</strong>。随着K的变化Gap(K)几乎维持一条直线保持不变。说明这些样本间没有明显的类别关系，<font color="green">数据分布几乎和均匀分布一致</font>，近似随机。此时聚类没有意义。</p>
<p><strong>3.改进初始值的选择</strong></p>
<p>采取随机选择K个中心，<font color="green">可能导致不同中心点距离很近</font>，需<font color="green">更多的迭代次数才能收敛</font>。如在选择初始中心点时<strong>不同的中心尽可能远离</strong>，效果更好。这类算法中，以K-Means++算法最具影响力。</p>
<p><strong>4.采用核函数?</strong></p>
<p>主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的空间进行聚类。非线性映射增加了数据点线性可分的概率（与SVM中使用核函数思想类似）对于非凸的数据分布可以达到更为准确的聚类结果。</p>
<ol start="5">
<li>从EM算法解释KMeans</li>
</ol>
<p>EM（Expectation-Maximum）算法即期望最大化算法，是最常见的隐变量估计方法。EM算法是一种迭代优化策略，每一次迭代都分为两步：期望步（E）、极大步（M）。<strong>EM算法的提出最初是为了解决数据缺失情况下的参数估计问题</strong>，基本思想是首先根据已有的观测数据，通过极大似然估计估计出模型的参数；再根据上一步估计出的参数值估计缺失数据的值；最后根据估计出的缺失数据和原有的观测数据重新对参数值进行估计，反复迭代直到收敛。</p>
<hr>
<p>K均值聚类是使用<a href="https://baike.baidu.com/item/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95/10180861">最大期望算法</a>（Expectation-Maximization algorithm）求解的<a href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/8878468">高斯混合模型</a>（Gaussian Mixture Model, GMM）在<a href="https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/829892">正态分布</a>的协方差为单位矩阵，且隐变量的后验分布为一组<a href="https://baike.baidu.com/item/%E7%8B%84%E6%8B%89%E5%85%8B%CE%B4%E5%87%BD%E6%95%B0/5760582">狄拉克δ函数</a>时所得到的特例?</p>
<p>Python</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeansClusterer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,ndarray,cluster_num</span>):</span></span><br><span class="line">        self.ndarray = ndarray</span><br><span class="line">        self.cluster_num = cluster_num</span><br><span class="line">        self.points=self.__pick_start_point(ndarray,cluster_num)</span><br><span class="line">         </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cluster</span>(<span class="params">self</span>):</span></span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.cluster_num):</span><br><span class="line">            result.append([])</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> self.ndarray:</span><br><span class="line">            distance_min = sys.maxsize</span><br><span class="line">            index=-<span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.points)):                </span><br><span class="line">                distance = self.__distance(item,self.points[i])</span><br><span class="line">                <span class="keyword">if</span> distance &lt; distance_min:</span><br><span class="line">                    distance_min = distance</span><br><span class="line">                    index = i</span><br><span class="line">            result[index] = result[index] + [item.tolist()]</span><br><span class="line">        new_center=[]</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">            new_center.append(self.__center(item).tolist())</span><br><span class="line">        <span class="comment"># 中心点未改变，说明达到稳态，结束递归</span></span><br><span class="line">        <span class="keyword">if</span> (self.points==new_center).<span class="built_in">all</span>():</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">         </span><br><span class="line">        self.points=np.array(new_center)</span><br><span class="line">        <span class="keyword">return</span> self.cluster()</span><br><span class="line">             </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__center</span>(<span class="params">self,<span class="built_in">list</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;计算一组坐标的中心点</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 计算每一列的平均值</span></span><br><span class="line">        <span class="keyword">return</span> np.array(<span class="built_in">list</span>).mean(axis=<span class="number">0</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__distance</span>(<span class="params">self,p1,p2</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;计算两点间距</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        tmp=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(p1)):</span><br><span class="line">            tmp += <span class="built_in">pow</span>(p1[i]-p2[i],<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">pow</span>(tmp,<span class="number">0.5</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__pick_start_point</span>(<span class="params">self,ndarray,cluster_num</span>):</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> cluster_num &lt;<span class="number">0</span> <span class="keyword">or</span> cluster_num &gt; ndarray.shape[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;簇数设置有误&quot;</span>)</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># 随机点的下标</span></span><br><span class="line">        indexes=random.sample(np.arange(<span class="number">0</span>,ndarray.shape[<span class="number">0</span>],step=<span class="number">1</span>).tolist(),cluster_num)</span><br><span class="line">        points=[]</span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexes:</span><br><span class="line">            points.append(ndarray[index].tolist())</span><br><span class="line">        <span class="keyword">return</span> np.array(points)</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="KMeans-and-gaussian-mixture-model"><a href="#KMeans-and-gaussian-mixture-model" class="headerlink" title="KMeans and gaussian mixture model"></a>KMeans and gaussian mixture model</h2><p>数据表示：kmeans单个点对cluster建模（假设各clus数据是圆形或高位球形）。GMM，使用高斯分布表示</p>
<p>数据先验：kmeans，假设各clus先验概率一样，实际clus数据量可能不均匀。clusA10000，B100，新样本不考虑与AB相似度，属于A概率大。GMM对数据先验进行建模。</p>
<p>相似度衡量：Kmeans的欧式距离假设各个维度对相似度衡量作用一样。GMM相似度衡量使用后验概率通过引入协方差矩阵，对各个维度数据的不同重要性建模。</p>
<p>数据分配：kmeans各样本只属于相似度最高clus（hard clusting），GMM使用后验概率对各个clus按比例分配（fuzzy clustering？）。</p>
<hr>
<h2 id="k-means-聚类算法"><a href="#k-means-聚类算法" class="headerlink" title="k-means++聚类算法"></a>k-means++聚类算法</h2><p><code>KMeans</code>算法，<code>KMeans</code>在聚类之前首先需初始化k个簇中心，因此 <code>KMeans</code> 算法对初值敏感，对于不同的初始值，会导致不同聚类结果。若初始化随机，很有可能 k簇中心都在同一个簇，这种情况 <code>KMeans</code> 很大程度上都不会收敛到全局最小。</p>
<p>为优化选择初始质心的方法，2007 年 Arthur,等 三人发表了论文“k-means++: <code>The advantages of careful seeding</code>，<code>sklearn.cluster.KMeans</code> 中默认参数为 <code>init=&#39;k-means++&#39;</code> ，其算法原理为在初始化簇中心时，逐个选取 k个簇中心，且离其他簇中心越远的样本越有可能被选为下个簇中心。</p>
<p>算法步骤：</p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/6.png"></p>
<hr>
<p>ref：</p>
<p><a href="https://zhuanlan.zhihu.com/p/184686598">https://zhuanlan.zhihu.com/p/184686598</a></p>
<p><a href="https://www.cnblogs.com/gaochundong/p/kmeans_clustering.html">https://www.cnblogs.com/gaochundong/p/kmeans_clustering.html</a></p>
<p><a href="https://www.zhihu.com/question/31296149">https://www.zhihu.com/question/31296149</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/342052190#:~:text=KMeans%20">https://zhuanlan.zhihu.com/p/342052190#:~:text=KMeans%20</a></p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-4【Macs2/3 Installation】</title>
    <url>/blog/2021/10/29/ATAC-seq-4-macs3-install/</url>
    <content><![CDATA[<h3 id="Macs2-3-installation-Debug-Record"><a href="#Macs2-3-installation-Debug-Record" class="headerlink" title="Macs2/3 installation Debug Record"></a>Macs2/3 installation Debug Record</h3><span id="more"></span>

<p>macs2 installation record<br>install conda<br>creat work environment<br>install numpy1.17<br>python setup.py install –prefix …./software/MACS</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR1#############################################</span><br><span class="line">#MACS3/fermi-lite/ksw.c:31:26: fatal error: lib/x86/sse2.h: No such file or directory</span><br><span class="line"># #include &quot;lib/x86/sse2.h&quot;                      ^</span><br><span class="line">#compilation terminated.</span><br><span class="line">#error: command &#x27;gcc&#x27; failed with exit status 1</span><br><span class="line">######################################################################################</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/macs3-project/MACS/issues/473">https://github.com/macs3-project/MACS/issues/473</a><br>zip downloaded from github zip is not complete in the deep dir<br>git clone <a href="https://github.com/macs3-project/MACS.git">https://github.com/macs3-project/MACS.git</a> –recursive<br>or download absent files</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR2#############################################</span><br><span class="line">Checking .pth file support in ..../software/MACS2/lib/python3.8/site-packages/</span><br><span class="line">..../.conda/envs/atacseq/bin/python -E -c pass</span><br><span class="line">TEST FAILED: ..../software/MACS2/lib/python3.8/site-packages/ does NOT support .pth files</span><br><span class="line">bad install directory or PYTHONPATH</span><br><span class="line"></span><br><span class="line">You are attempting to install a package to a directory that is not</span><br><span class="line">on PYTHONPATH and which Python does not read &quot;.pth&quot; files from.  The</span><br><span class="line">installation directory you specified (via --install-dir, --prefix, or</span><br><span class="line">the distutils default setting) was:</span><br><span class="line"></span><br><span class="line">    ..../software/MACS2/lib/python3.8/site-packages/</span><br><span class="line"></span><br><span class="line">and your PYTHONPATH environment variable currently contains:</span><br><span class="line"></span><br><span class="line">    &#x27;&#x27;</span><br><span class="line"></span><br><span class="line">Here are some of your options for correcting the problem:</span><br><span class="line"></span><br><span class="line">* You can choose a different installation directory, i.e., one that is</span><br><span class="line">  on PYTHONPATH or supports .pth files</span><br><span class="line"></span><br><span class="line">* You can add the installation directory to the PYTHONPATH environment</span><br><span class="line">  variable.  (It must then also be on PYTHONPATH whenever you run</span><br><span class="line">  Python and want to use the package(s) you are installing.)</span><br><span class="line"></span><br><span class="line">* You can set up the installation directory to support &quot;.pth&quot; files by</span><br><span class="line">  using one of the approaches described here:</span><br><span class="line"></span><br><span class="line">  https://setuptools.readthedocs.io/en/latest/deprecated/easy_install.html#custom-installation-locations</span><br></pre></td></tr></table></figure>

<p>[ok]export PYTHONPATH=${PYTHONPATH}:…./software/MACS2/lib/python3.9/site-packages/</p>
<p>directly set PYTHONPATH=…./software/MACS2/lib/python3.9/site-packages/ in ~/.bashrc was failed.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR3#############################################</span><br><span class="line">error: package directory &#x27;MACS2&#x27; does not exist</span><br><span class="line">#######################################################################################</span><br></pre></td></tr></table></figure>
<p>zip Dir was not complete, tried .tar.gz </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR4#############################################</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;..../software/MACS3/bin/macs3&quot;, line 4, in &lt;module&gt;</span><br><span class="line">    __import__(&#x27;pkg_resources&#x27;).run_script(&#x27;MACS3==3.0.0a6&#x27;, &#x27;macs3&#x27;)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3243, in &lt;module&gt;</span><br><span class="line">    def _initialize_master_working_set():</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3226, in _call_aside</span><br><span class="line">    f(*args, **kwargs)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3255, in _initialize_master_working_set</span><br><span class="line">    working_set = WorkingSet._build_master()</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 568, in _build_master</span><br><span class="line">    ws.require(__requires__)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 886, in require</span><br><span class="line">    needed = self.resolve(parse_requirements(requirements))</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 772, in resolve</span><br><span class="line">    raise DistributionNotFound(req, requirers)</span><br><span class="line">pkg_resources.DistributionNotFound: The &#x27;Cython&gt;=0.29&#x27; distribution was not found and is required by MACS3``</span><br></pre></td></tr></table></figure>

<p><code>conda install Cython=0.29</code></p>
<p><a href="https://pypi.org/project/cykhash/">https://pypi.org/project/cykhash/</a><br><code>pip install cykhash</code><br>Collecting cykhash<br>  Using cached cykhash-1.0.2-cp39-cp39-linux_x86_64.whl<br>Installing collected packages: cykhash<br>Successfully installed cykhash-1.0.2</p>
<p>python setup.py install –prefix …./software/MACS2</p>
<p>success</p>
]]></content>
      <categories>
        <category>ATAC-seq</category>
        <category>Software</category>
      </categories>
      <tags>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-5【PeakCalling-MACS2】</title>
    <url>/blog/2021/10/29/ATAC-seq-5-macs2-info/</url>
    <content><![CDATA[<h2 id="MACS2-detail"><a href="#MACS2-detail" class="headerlink" title="MACS2 detail"></a>MACS2 detail</h2><span id="more"></span>


<h3 id="粗略介绍MACS基本原理。"><a href="#粗略介绍MACS基本原理。" class="headerlink" title="粗略介绍MACS基本原理。"></a>粗略介绍MACS基本原理。</h3><p>TF在基因组上的结合是随机过程，基因组的每个位置都有机会结合某个TF，只是概率不一样，peak出现的位置，是TF结合热点，而peak-calling就为了找这些热点。</p>
<p>如何定义热点？通俗讲，热点是这样一些位置，这些位置多次被测得的read所覆盖（我们测的是一个细胞群体，read出现次数多，说明该位置被TF结合的几率大）。read数达到多少才叫多？就要用到统计检验。假设TF在基因组上的分布没有任何规律，那么测序得到的read在基因组上的分布也必然是随机的，某个碱基上覆盖的read的数目应服从二项分布。和抽小球的过程类似。当n很大，p很小时，二项分布近似用泊松分布替代，在这里：<br><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/1.png"></p>
<p>拉姆达是泊松分布唯一参数，n是测序read总数目，l是单个read长度，s是基因组大小。有了分布，可以算出在某个置信概率（如0.00001）下，随机情况下，某个碱基上可以覆盖的read数目的最小值，当实际观察到的read数目超过这个值（单侧检验）时，认为该碱基是TF的一个结合热点。反过来，针对每一个read数目，我们也可以算出对应的置信概率P。</p>
<p>但这只是简化模型，实际情况复杂好多。由于测序、mapping过程内在<font color="red">偏好性</font>，以及不同染色质间的差异性，相比全基因组，某些碱基可能内在地会被更多的read所覆盖，这种情况得到的很多peak可能都是假的。MACS考虑到这点，<font color="red">当对某个碱基进行假设检验，MACS只考虑该碱基附近染色质区段（如10k），此时上述公式中n表示附近10k区间内的read数目，s被置为10k</font>。当有对照组（Control，相比实验组没有用抗体捕获TF或用了一个通用抗体）存在，利用Control组的数据构建泊松分布，<font color="red">没有Control时，利用实验组，稍大一点的局部区间（比如50k）</font>的数据构建泊松分布。</p>
<p>还有一个问题，read只是跟随着TF一起沉淀下来的DNA fragment的末端，read的位置并不是真实的TF结合位置。所以在peak-calling之前，延伸read是必须的。不同TF大小不一样，对read延伸的长度也理应不同.测得的<font color="red">read最终其实会近似地平均分配到正负链</font>，对于一个TF结合热点，read在附近正负链上会近似地形成<font color="red">“双峰”</font>。MACS会以<font color="red">某个window size扫描基因组，统计每个window里面read的富集程度，然后抽取（比如1000个）合适的（read富集程度适中，过少，无法建立模型，过大，可能反映的只是某种偏好性）window作样本，建立“双峰模型”</font>。最后，两个峰之间的距离就被认为是<font color="red">TF的长度D，每个read将延伸D/2</font>。见下图：</p>
<p><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/2.png"></p>
<p>当有对照组，MACS会进行两次peak calling。第一次以实验组（Treatment）为实验组，对照组为对照组，第二次颠倒，以实验组为对照组，对照组为实验组。之后，MACS对每一个P计算了相应的FDR（False Discovery Rate）值：</p>
<p><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/3.png"></p>
<p>表示第二次peak calling（颠倒的）得到的置信概率小于P的peak的个数。表示第一次peak calling得到的置信概率小于P的peak的个数。FDR综合利用了实验组和对照组的信息，显然，FDR越小越好。</p>
<h3 id="MACS-peak-calling-pipeline："><a href="#MACS-peak-calling-pipeline：" class="headerlink" title="MACS peak-calling pipeline："></a>MACS peak-calling pipeline：</h3><p>在某些情况下，如对组蛋白修饰的ChIP-seq数据peak-calling时，“双峰模型”会建立失败，<font color="red">因为组蛋白修饰往往并不是孤立存在的，可能很长一段染色质区间都被同一个组蛋白修饰占据，组蛋白修饰的peak并不典型。</font>这时，只要多加一个参数：</p>
<p><font color="red">–nomodel –shiftsize=number</font></p>
<p>–nomodel将<font color="red">略过“双峰模型”建立的过程</font>，而<font color="red">–shiftsize将人为指定reads延伸的长度</font>。<font color="red">一个核小体上大概缠绕着147bpDNA</font>，在对组蛋白修饰做peak-calling时可以指定：</p>
<p><font color="red">–nomodel –shiftsize=73</font></p>
<p>CTCF_peaks.bed详细列出了每一个peak的位置信息和可信度（最后一列：)，BED文件格式详见：<a href="http://genome.ucsc.edu/FAQ/FAQformat.html#format1">http://genome.ucsc.edu/FAQ/FAQformat.html#format1</a></p>
<p>其他常用参数：-bw number 建立“双峰模型”过程中window size的一半，默认300bp.<br><font color="red">-p Pvalue</font>设定peak置信概率的临界值（threshold），默认0.00001?(macs2 callpeak -h: pvalue not set, dont use p and q value at the same time)，对于H3k36me3、H3k27me3、H3k9me3等具有“非常规”特征的peak（broad peak）而言，此参数可以稍微设大一点，比如0.001。</p>
<p>-m number1,number2 建立“双峰模型”用到，设定挑选的window上reads的富集程度（<font color="red">fold enrichment</font>，相对全基因组而言），默认10,30。</p>
<p>-slocal=number -llocal=number 共同确定MACS动态计算时所考察的局部区间的长度。默认参数，-slocal=1000 -llocal=10000。除了建立“双峰模型”，在寻找peak过程中，MACS依然会以2倍于-bw的window扫描基因组，对于当前window而言（-slocal,-llocal取默认参数）：</p>
<p>-w/-B 建立wig或BED格式的raw signal（最高精确到每个碱基上reads的覆盖情况）文件，默认每条染色体建一个。</p>
<p>-S 只建立一个raw signal文件。</p>
<p>-space 与-w搭配使用，确定wig文件的分辨率，默认10bp。</p>
<hr>
<p>link：<a href="https://www.plob.org/article/7227.html">https://www.plob.org/article/7227.html</a></p>
]]></content>
      <categories>
        <category>ATAC-seq</category>
        <category>Software</category>
      </categories>
      <tags>
        <tag>software</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-3【hbctraining_pipeline】</title>
    <url>/blog/2021/10/26/ATAC-seq-3-hbctraining/</url>
    <content><![CDATA[<h2 id="https-github-com-hbctraining-In-depth-NGS-Data-Analysis-Course-tree-master-sessionV-lessons"><a href="#https-github-com-hbctraining-In-depth-NGS-Data-Analysis-Course-tree-master-sessionV-lessons" class="headerlink" title="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons"></a><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a></h2><span id="more"></span>

<p>算法，参数，输出。</p>
<h2 id="Peak-calling"><a href="#Peak-calling" class="headerlink" title="Peak calling"></a>Peak calling</h2><p><img src="https://img-blog.csdnimg.cn/f2741798d4f04f708412c97b2e6ef045.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>ChIP-seq实验，从比对文件中观察到<code>正/负链</code>上以<code>结合位点为中心</code>的非对称reads<br>密度。<br>For ChIP-seq experiments, what we observe from the alignment files is a strand asymmetry with read densities on the +/- strand, centered around the binding site. <code>The 5’ ends of the selected fragments</code> will form <code>groups</code> on the positive- and negative-strand. The <code>distributions</code> of these groups are then assessed using <code>statistical measures</code> and <code>compared against background</code> (input or mock IP samples) to determine if the site of enrichment is likely to be a real binding site.</p>
<p><img src="https://img-blog.csdnimg.cn/a5f4429afb3348be91f68d90d4011065.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="加粗样式"><br><code>ChIP-seq analysis algorithms</code> are specialized in identifying one of <code>two types of enrichment</code> (or have specific methods for each): <code>broad peaks or broad domains</code> (i.e. <code>histone modifications that cover entire gene bodies</code>) or <code>narrow peaks</code> ( <code>transcription factor binding</code>). <code>Narrow peaks are easier to detect</code> as we are looking for regions that have higher amplitude and are easier to distinguish from the background, compared to broad or dispersed marks. There are also <code>‘mixed’ binding profiles</code> which can be hard for algorithms to discern. An example of this is the binding properties of <code>PolII</code>, which binds at promotor and across the length of the gene resulting in mixed signals (<code>narrow and broad</code>).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">NOTE：ChIP-seq的分析方法可以鉴定两种类型的富集模式：broad domains和narrow peaks。broad domains，如组蛋白修饰在整个基因body区域的分布；narrow peak，如转录因子的结合。narrow peak相对于broad 或者分散的marks更易被检测到。也有一些混合的结合图谱，如PolII包括narrow和broad信号。</span><br></pre></td></tr></table></figure>
<h2 id="MACS2"><a href="#MACS2" class="headerlink" title="MACS2"></a>MACS2</h2><p>MACS2是最常用的call peaks工具。 The MACS algorithm captures the influence of <code>genome complexity</code> to evaluate the significance of enriched ChIP regions。全称<code>Model-based Analysis of ChIP-Seq</code>，最初设计用来<code>鉴定转录因子结合位点</code>（also suited for <code>larger</code> regions），也可用于<code>其他类型</code>的富集方式测序。<br>MACS通过整合<code>序列标签位置信息</code>和<code>方向</code>信息提高<code>结合位点</code>的<code>空间分辨率</code>（ <code>improves</code> the <code>spatial resolution of binding sites</code> through <code>combining the information of both sequencing tag position and orientation</code>）。单独使用或加对照（ <code>increases specificity</code> of the peak calls）。<br><img src="https://img-blog.csdnimg.cn/3929b0f60a01477ea09402760205f200.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_17,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h3 id="1-Remove-redundancy"><a href="#1-Remove-redundancy" class="headerlink" title="1. Remove redundancy"></a>1. Remove redundancy</h3><p><code>Why worry about duplicates?</code> <code>Reads with the same start position</code> are <code>considered duplicates</code>. These duplicates can arise from experimental artifacts, but can also contribute to genuine ChIP-signal. (相同起点的reads被认为是duplicates，可能由于实验误差造成，<code>也可能是ChIP信号</code>)</p>
<ul>
<li><code>坏 duplicates</code>: If initial starting <code>material is low</code> this can lead to <code>overamplification</code> of this material before sequencing. Any <code>biases in PCR</code> will compound this problem and can lead to <code>artificially enriched regions</code>. Also <code>blacklisted (repeat) regions</code> with ultra high signal will also be high in duplicates. <code>Masking these regions</code> prior to analysis can help remove this problem。 实验材料量少，过度扩增，PCR偏差，人为富集区域。<code>blacklist（重复）区域？怎么获得</code>，屏蔽该区域。</li>
<li><code>好 duplicates</code>: You can expect some <code>biological duplicates with ChIP-seq</code> since you are only sequencing a small <code>part of the genome</code>. This number can increase if your depth of coverage is excessive or if your protein only binds to few sites. If there are a good proportion of biological dupicates, <code>removal</code> can lead to an <code>underestimation of the ChIP signal</code>. 有ChIP-seq意义的生物学意义duplicates ，测序基因组小部分。覆盖深度过多，蛋白质与少数位点结合，duplicates会增加。去除此类会导致对ChIP信号的低估。</li>
<li>Consider your <code>enrichment efficiency</code> and <code>sequencing depth</code>. Try to <code>discriminate</code> via genome browser of your non-deduplicated data. Bona fide peaks will have <code>multiple overlapping</code> reads with <code>offsets</code>, while samples with only PCR duplicates will stack up perfectly without offsets. A possible solution to distinguishing biological duplicate from PCR artifact would be to include UMIs into your experimental setup. 考虑<code>富集效率</code>和<code>测序深度</code>。通过<code>基因组浏览器区别</code>。<code>真正的峰</code>会有多个<code>重叠reads和偏移量</code>，<code>PCR重复没有偏移量</code>。如何区分：实验设计考虑<a href="https://www.sohu.com/a/471483238_120055884">UMIs</a>（<code>UMI将被用于合并PCR复制物</code>）。</li>
<li>Retain duplicates for differential binding analysis. 保留duplicates 用于差异结合分析 <code>why</code>？retain和keep区别？</li>
<li>If you are expecting binding in repetitive regions, use paired-end sequencing and keep duplicates. 研究重复区域，使用pariedend测序并<code>保持重复？</code></li>
<li>call peak之前就remove dup<h3 id="2-0-Shift-size-d"><a href="#2-0-Shift-size-d" class="headerlink" title="2.0 Shift size d"></a>2.0 <code>Shift size d</code></h3></li>
<li>真实结合位点周围的tag density应显示<code>双峰富集</code>(<code>成对峰</code>)。MACS利用这种双峰模式 <code>empirically model the shifting size</code>，精确定位结合位点。</li>
<li>为了找到<code>成对峰</code>来<code>构建模型</code>，MACS首先<code>扫描整个数据集</code>，寻找<code>高度显著富集区域</code>。只利用ChIP样本，给定超声大小sonication size(<code>bandwidth</code>)和high-confidence fold-enrichment(<code>mfold</code>)， MACS <code>slides two bandwidth windows</code> across the genome to find <code>regions with tags more than mfold enriched</code> relative to a <code>random tag genome distribution</code>.</li>
<li>MACS<code>随机抽取1000个高质量峰</code>，<code>分离正链和负链标签</code>，aligns them by the midpoint between their centers。The <code>distance between the modes of the two peaks in the alignment is defined as ‘d’</code> and represents the estimated fragment length. MACS shifts all the tags by d/2 toward the 3’ ends to the most likely protein-DNA interaction sites.<br><img src="https://img-blog.csdnimg.cn/eeefe600965542478444f761de31db17.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
</ul>
<h3 id="2-Select-1000-regions-with-a-10-to-30-fold-enrichment-relative-to-the-genome-background"><a href="#2-Select-1000-regions-with-a-10-to-30-fold-enrichment-relative-to-the-genome-background" class="headerlink" title="2. Select 1000 regions with a 10- to 30-fold enrichment relative to the genome background"></a>2. Select 1000 regions with a 10- to 30-fold enrichment relative to the genome background</h3><h3 id="3-Build-model-and-estimate-DNA-fragment-size-d"><a href="#3-Build-model-and-estimate-DNA-fragment-size-d" class="headerlink" title="3. Build model and estimate DNA fragment size d"></a>3. Build model and estimate DNA fragment size d</h3><h3 id="4-Shift-reads-toward-3’end-by-d"><a href="#4-Shift-reads-toward-3’end-by-d" class="headerlink" title="4. Shift reads toward 3’end by d"></a>4. Shift reads toward 3’end by d</h3><h3 id="5-Scale-two-libraries-if-have-control"><a href="#5-Scale-two-libraries-if-have-control" class="headerlink" title="5. Scale two libraries(if have control)"></a>5. Scale two libraries(if have control)</h3><p>For experiments in which <code>sequence depth differs</code> between input and treatment samples, MACS linearly scales the total control tag count to be the same as the total ChIP tag count. The default behaviour is for the <code>larger sample to be scaled down</code>. </p>
<h3 id="6-0-Effective-genome-length"><a href="#6-0-Effective-genome-length" class="headerlink" title="6.0 Effective genome length"></a>6.0 Effective genome length</h3><p>To calculate λBG from tag count, MAC2 requires the <code>effective genome size or the size of the genome that is mappable</code>. Mappability is related to the <code>uniqueness of the k-mers</code> at a particular position the genome. <code>Low-complexity</code> and <code>repetitive regions</code> have <code>low uniqueness</code>, which means <code>low mappability</code>. Therefore we need to provide the effective genome length to correct for the loss of true signals in low-mappable regions. 提供<code>有效基因组长度</code>，以<code>纠正低定位区域真实信号丢失</code>。<br><img src="https://img-blog.csdnimg.cn/5571c4b228cb4706805ba0853c546c3c.png" alt="在这里插入图片描述"><br><code>如何获得？</code>The MACS2 software has some <code>pre-computed values</code> for <code>commonly used</code> organisms (human, mouse, worm and fly，<code>rice？</code>). more accurate values? The <code>deepTools</code> docs has additional pre-computed values for more recent builds but also has some good materials on <code>how to go about computing</code> it.</p>
<h3 id="6-Call-candidate-peaks-relative-to-genome-background"><a href="#6-Call-candidate-peaks-relative-to-genome-background" class="headerlink" title="6. Call candidate peaks relative to genome background"></a>6. Call candidate peaks relative to genome background</h3><p>After MACS <code>shifts every tag by d/2</code>, it then <code>slides across the genome</code> using a window size of <code>2d</code> to <code>find candidate peaks</code>.  The <code>tag distribution</code> along the genome can be modeled by a <code>Poisson distribution</code>.  The Poisson is a one parameter model, where the parameter <code>λ is the expected number of reads in that window</code>.</p>
<h3 id="7-Calculate-dynamic-λ-for-candidate-peaks"><a href="#7-Calculate-dynamic-λ-for-candidate-peaks" class="headerlink" title="7. Calculate dynamic λ for candidate peaks"></a>7. Calculate dynamic λ for candidate peaks</h3><p><img src="https://img-blog.csdnimg.cn/eaac9c4b4c294be3b8b3b3caf7c35a21.png" alt="在这里插入图片描述"><br>泊松分布的参数λ是单位时间(或单位面积)内随机事件的平均发生次数。 泊松分布的期望和方差均为λ.<br>Instead of using a uniform λ estimated from the whole genome, MACS uses a <code>dynamic parameter, λlocal</code>, defined for <code>each candidate peak</code>. The lambda parameter is estimated from the control sample and is deduced by taking the maximum value across <code>various window sizes</code>:</p>
<blockquote>
<p>λlocal = max(λBG, λ1k, λ5k, λ10k).</p>
</blockquote>
<p>In this way lambda <code>captures the influence of local biases</code>, and is robust against occasional low tag counts at small local regions. Possible sources for these biases include local chromatin structure, DNA amplification and sequencing bias, and genome copy number variation. 通过使用动态lambda捕获局部偏差的影响，并且对小局部区域中<code>偶尔出现的low tag counts</code>表现较好。<code>偏差可能来源</code>包括局部染色质结构、DNA扩增和测序偏差以及基因组拷贝数变化。<br><img src="https://img-blog.csdnimg.cn/3c7c645b299e45b2b7975d6327d421bc.png" alt="在这里插入图片描述"><br>A region is considered to have a <code>significant tag enrichment</code> if the <code>p-value &lt; 10e-5</code> (可设置). This is a Poisson distribution p-value based on λ.</p>
<p>Overlapping enriched peaks are merged, and each tag position is <code>extended ‘d’ bases？</code> from its center. The location in the <code>peak with the highest fragment pileup堆积</code>, hereafter referred to as the summit峰顶, is <code>predicted as the precise binding location</code>. The <code>ratio between the ChIP-seq tag count and λlocal？</code> is reported as the fold enrichment.</p>
<h3 id="8-Calculate-P-value-and-filter-candidate-peaks"><a href="#8-Calculate-P-value-and-filter-candidate-peaks" class="headerlink" title="8. Calculate P value and filter candidate peaks"></a>8. Calculate P value and filter candidate peaks</h3><h3 id="9-Calculate-FDR-by-exchanging-treatment-and-control"><a href="#9-Calculate-FDR-by-exchanging-treatment-and-control" class="headerlink" title="9. Calculate FDR by exchanging treatment and control"></a>9. Calculate FDR by exchanging treatment and control</h3><p>Each peak is considered an independent test and thus, when we encounter thousands of significant peaks detected in a sample we have a multiple testing problem. In <code>MACSv1.4</code>, the FDR was determined <code>empirically by exchanging the ChIP and control samples</code>. However, in <code>MACS2</code>, p-values are now corrected for multiple comparison using the <code>Benjamini-Hochberg correction</code>.</p>
<h2 id="MACS2-参数"><a href="#MACS2-参数" class="headerlink" title="MACS2 参数"></a>MACS2 参数</h2><h3 id="1-Input-file-options"><a href="#1-Input-file-options" class="headerlink" title="1. Input file options"></a>1. Input file options</h3><ul>
<li><code>-t</code> : The IP data file (this is the only REQUIRED parameter for MACS) 实验组</li>
<li><code>-c</code> : Control or mock data 对照</li>
<li><code>-f</code> : 输入文件格式，默认值“AUTO” ，bam sam bed</li>
<li><code>-g</code> :  <code>mappable genome size</code> which is defined as the genome size which can be sequenced; some precompiled values provided.</li>
<li>hs: 2.7e9人类基因组有效大小(UCSC human hg18 assembly)<h3 id="2-Output-arguments"><a href="#2-Output-arguments" class="headerlink" title="2. Output arguments"></a>2. Output arguments</h3></li>
<li><code>-outdir</code> : 输出文件夹</li>
<li><code>-n</code> : 文件前缀</li>
<li><code>-B/--bdg</code> : store the fragment pileup, control lambda, -log10pvalue and -log10qvalue scores in bedGraph files 输出bedgraph格式的文件<h3 id="3-Shifting-model-arguments"><a href="#3-Shifting-model-arguments" class="headerlink" title="3. Shifting model arguments"></a>3. Shifting model arguments</h3></li>
<li><code>-s</code> : <code>size of sequencing tags</code>. Default, MACS will use the <code>first 10 sequences</code> from your input treatment file to determine it</li>
<li><code>--bw</code> : The bandwidth which is used to <code>scan the genome</code> ONLY for model building. Can be set to the expected sonication fragment size.</li>
<li><code>--mfold</code> : <code>upper and lower limit</code> for model building</li>
<li><code>--nomodel</code>：<code>和extsize、shift是配套使用</code>，有这个参数才可设置extsize和shift。</li>
<li><code>--extsize</code>：当设置了nomodel时，MACS会用–extsize这个参数从<code>5&#39;-&gt;3&#39;方向扩展reads修复fragments</code>。如转录因子结合范围200bp，设置这个参数是200。</li>
<li><code>--shift</code>：当设置了–nomodel，MACS用这个参数从<code>5&#39; 端移动剪切</code>，然后用–extsize延伸，如果–shift是负值表示从3’端方向移动。建议ChIP-seq数据集这个值保持默认值为0？，对于检测富集剪切位点如DNAseq数据集设置为EXTSIZE的一半。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">想找富集剪切位点，如DNAse-seq，所有5&#x27;端的序列reads应该从两个方向延伸，如果想设置移动的窗口是200bp，参数设置如下：</span><br><span class="line">--nomodel --shift -100 --extsize 200</span><br><span class="line">对nucleosome-seq数据，用核小体大小的一半进行extsize,所以参数设置如下：</span><br><span class="line">--nomodel --shift 37 --extsize 73</span><br></pre></td></tr></table></figure>

<p><code>ATAC-seq</code>关心的是在哪切断，断点才是peak的中心，所以使用shift模型，–shift -75或-100<br>对人细胞系ATAC-seq 数据call peak的参数设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak -t H1hesc.final.bam -n sample --shift -100 --extsize 200 --nomodel -B --SPMR -g hs --outdir Macs2_out 2&gt; sample.macs2.log</span><br></pre></td></tr></table></figure>

<h3 id="4-Peak-calling-arguments"><a href="#4-Peak-calling-arguments" class="headerlink" title="4. Peak calling arguments"></a>4. Peak calling arguments</h3><ul>
<li><code>-q</code> : q-value (minimum FDR) cutoff <code>q value默认值是0.05，与pvalue不能同时使用。</code></li>
<li><code>-p</code> : p-value cutoff (instead of q-value cutoff)</li>
<li><code>--nolambda</code> : do not consider the local bias/lambda at peak candidate regions。不要考虑在峰值候选区域的局部偏差/λ</li>
<li><code>--broad</code> : broad peak calling，narrow peak和broad peak</li>
</ul>
<p> Relaxing the <code>q-value</code> does not behave as expected in this case since it is partially tied to peak widths. Ideally, if you <code>relaxed the thresholds</code>, you would simply get <code>more peaks</code> but with MACS2 relaxing thresholds also results in <code>wider peaks</code>. q值与峰宽有一定的联系。理想情况下，如果放宽阈值，您将简单地获得更多的峰值，但是使用MACS2放松阈值也会导致更宽的峰值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak -t bowtie2/H1hesc_Nanog_Rep1_aln.bam \</span><br><span class="line">	-c bowtie2/H1hesc_Input_Rep1_aln.bam \</span><br><span class="line"> 	-f BAM -g 1.3e+8 \</span><br><span class="line">	-n Nanog-rep1 \</span><br><span class="line">	--outdir macs2 2&gt; macs2/Nanog-rep1-macs2.log</span><br></pre></td></tr></table></figure>


<h2 id="MACS2-Output-files"><a href="#MACS2-Output-files" class="headerlink" title="MACS2 Output files"></a>MACS2 Output files</h2><h3 id="narrowPeak"><a href="#narrowPeak" class="headerlink" title="narrowPeak"></a>narrowPeak</h3><p>A narrowPeak (<code>.narrowPeak</code>) file is used by the ENCODE project to provide <code>called peaks of signal enrichment</code> based on pooled, normalized (interpreted) data. It is a <code>BED 6+4 format</code>, which means the <code>first 6 columns of a standard BED file</code> with <code>4 additional</code> fields:<br><img src="https://img-blog.csdnimg.cn/7bd1ca4fcb3847daacc450a91989b5cd.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h3 id="WIG-format"><a href="#WIG-format" class="headerlink" title="WIG format"></a>WIG format</h3><p>Wiggle format (WIG) allows the <code>display</code> of continuous-valued data in a track format. Wiggle format is <code>line-oriented</code>. It is composed of declaration lines and data lines, and require a separate wiggle track definition line. There are two options for formatting wiggle data: variableStep and fixedStep. These formats were developed to allow the file to be written as compactly as possible.</p>
<h3 id="BedGraph-format"><a href="#BedGraph-format" class="headerlink" title="BedGraph format"></a>BedGraph format</h3><p>The BedGraph format also allows display of continuous-valued data in track format. This display type is useful for probability scores and transcriptome data. This track type is similar to the wiggle (WIG) format, but unlike the wiggle format, data exported in the bedGraph format are preserved in their original state. For the purposes of visualization, these can be interchangeable.</p>
<ul>
<li><p><code>_peaks.narrowPeak</code>: BED6+4 format file which contains the peak locations together with peak summit, pvalue and qvalue。<code>BED6+4格式，可以上传到UCSC浏览。</code></p>
<ul>
<li>1：染色体号</li>
<li>2：peak起始位点</li>
<li>3：结束位点</li>
<li>4：peak name</li>
<li>5：int(-10*log10qvalue)</li>
<li>6 ：正负链</li>
<li>7：fold change</li>
<li>8：-log10pvalue</li>
<li>9：-log10qvalue</li>
<li>10：relative summit position to peak start（？）</li>
</ul>
</li>
<li><p><code>_peaks.xls</code>: a tabular file which contains information about called peaks. Additional information includes pileup and fold enrichment。<code>含peak信息的tab分割的文件，前几行显示callpeak命令</code>。</p>
<ul>
<li>染色体号</li>
<li>peak起始位点</li>
<li>peak结束位点</li>
<li>peak区域长度</li>
<li>peak的峰值位点（summit position）</li>
<li>peak 峰值的高度（pileup height at peak summit, -log10(pvalue) for the peak summit）</li>
<li>peak的富集倍数（相对于random Poisson distribution with local lambda）</li>
<li>XLS里的坐标和bed格式的坐标还不一样，起始坐标需要减1才与narrowPeak的起始坐标一样。</li>
</ul>
</li>
<li><p><code>_summits.bed</code>: peak summits locations for every peak. To find the motifs at the binding sites, this file is recommended。BED格式的文件，包含peak的summits位置，第5列是-log10pvalue。如果想找motif，推荐使用此文件。</p>
</li>
<li><p><code>_model.R</code>: an R script which you can use to produce a PDF image about the model based on your data and cross-correlation plot</p>
</li>
<li><p><code>_control_lambda.bdg</code>: bedGraph format for input sample</p>
</li>
<li><p><code>_treat_pileup.bdg</code>: bedGraph format for treatment sample。bedGraph格式，可以导入UCSC或者转换为bigwig格式。两种bfg文件：treat_pileup, and control_lambda.</p>
</li>
<li><p><code>NAME_peaks.broadPeak</code>： BED6+3格式与narrowPeak类似，只是没有第10列。</p>
</li>
</ul>
<p>R作图the first plot illustrates the distance between the modes from which the shift size was determined？<br><img src="https://img-blog.csdnimg.cn/3d941b11b37c4b7687b11e6766a9daff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_13,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>The second plot is the cross-correlation plot. This is a graphical representation of the Pearson correlation of positive- and negative- strand tag densities, shifting the strands relative to each other by increasing distance？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xls文件</span><br><span class="line">文件包含信息还是比较多的，和narrowPeak唯一不同的是peak的起始位置需要减1才是bed格式的文件，另外还包含fold_enrichment 和narrowPeak的fold change 对应，-log10pvalue,-log10qvalue,peak长度，peak 峰值位置等。</span><br><span class="line">narrowPeak文件</span><br><span class="line">和xls文件信息类似</span><br><span class="line">summits.bed文件</span><br><span class="line">包含峰的位置信息和-log10pvalue</span><br><span class="line">bdg文件</span><br><span class="line">bdg文件适合导入UCSC或IGV进行谱图可视化，或者转换为bigwig格式再进行可视化。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
  <entry>
    <title>单倍型基因组组装算法hifiasm</title>
    <url>/blog/2021/10/20/hifiasm/</url>
    <content><![CDATA[<h2 id="Nat-Methods-等位基因组组装算法hifiasm（20210202）"><a href="#Nat-Methods-等位基因组组装算法hifiasm（20210202）" class="headerlink" title="Nat. Methods|等位基因组组装算法hifiasm（20210202）"></a>Nat. Methods|等位基因组组装算法hifiasm（20210202）</h2><p>paper：    <a href="https://pubmed.ncbi.nlm.nih.gov/33526886/">Haplotype-resolved de novo assembly using phased assembly graphs with hifiasm</a><br>该研究提出一种全新的单倍型基因组组装算法hifiasm，能够有效地对<font color="red">大型复杂基因组生成高质量的单倍型组装结果</font>。</p>
<span id="more"></span>

<h3 id="单倍型组装难点"><a href="#单倍型组装难点" class="headerlink" title="单倍型组装难点"></a>单倍型组装难点</h3><p>单倍型基因组组装是研究基因组结构与变异的最理想方式。由于技术的局限，大多数组装算法倾向于将不同单倍型有损的压缩成一条混合的代表性序列。对于自然界中主流的二倍体和多倍体样本而言，这类方法损失了大量的单倍型信息。这使得长久以来，研究人员难以对高杂合、高重复的基因组进行深入的分析。</p>
<p>为了解决这个难题，一些组装算法首先生成混合的代表性序列，接着从代表性序列中恢复出不同的单倍型信息。但是，由于代表性序列本身已经丢失了大量的信息，这类方法难以获得高质量的单倍型组装结果。</p>
<p>近期的组装算法通过额外的信息，如家系(Trio binning)或者Hi-C等数据，预先全局性的将待组装的测序读段划分到不同单倍型，再进行分别组装，从而试图获得高质量的单倍型组装结果。但是对于低杂合的样本而言，这种方法难以做到完美的预先划分，因此容易产生组装错误。</p>
<h3 id="Hifiasm-算法"><a href="#Hifiasm-算法" class="headerlink" title="Hifiasm 算法"></a>Hifiasm 算法</h3><p>在本研究中，研究人员提出了一种全新的针对PacBio HiFi (High-Fidelity reads) 数据的单倍型组装算法hifiasm。该算法有两项重要创新。</p>
<p>第一，提出了单倍型敏感的组装思路，使得在组装的全过程中能够无损的保留单倍型信息，同时也极大的提升了对基因组高重复和复杂区域的解析能力。</p>
<p>第二，提出了Graph-binning的分型策略，其利用组装图的结构信息对全局分型结果进行校正，从而极大地提高了单倍型组装的质量。Graph-binning不对待组装的测序读段进行预先全局划分，因此能够克服划分错误带来组装问题。</p>
<h3 id="组装结果"><a href="#组装结果" class="headerlink" title="组装结果"></a>组装结果</h3><p>研究人员在不同的数据集上测试了hifiasm算法。对于不同大小，不同杂合度和不同单倍型数量的动物和植物基因组，hifiasm能够产生质量最高的组装结果。尤其值得注意的是，hifiasm仅用三天时间，就完成27Gb超大加州红杉基因组的组装，并且组装结果的连续性7倍于其他算法。</p>
<p>对于人类基因组，hifiasm也能取得最好的效果。相比于现有算法，hifiasm所产生的组装结果连续性最高，同时也正确解析了最多的复杂和高重复区域，如MHC (主要组织相容性复合体)和centromere (着丝端粒)。尤其对于人类二倍体样本HG002和HG00733，hifiasm产生的组装结果的连续性3倍于其他算法，并成功保留了最多的变异信息。</p>
<p><a href="http://www.evolution.ynu.edu.cn/info/1016/1208.htm">http://www.evolution.ynu.edu.cn/info/1016/1208.htm</a></p>
]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>Assemble</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-2【Harvard FAS Informatics】</title>
    <url>/blog/2021/10/14/ATAC-seq-2-harvard/</url>
    <content><![CDATA[<h2 id="ATAC-seq数据质量评估注意"><a href="#ATAC-seq数据质量评估注意" class="headerlink" title="ATAC-seq数据质量评估注意"></a>ATAC-seq数据质量评估注意</h2><span id="more"></span>

<p><code>ENCODE</code>的ATACseq<a href="https://www.encodeproject.org/atac-seq/">数据标准</a>。</p>
<h3 id="Uniform-Processing-Pipeline-Restrictions"><a href="#Uniform-Processing-Pipeline-Restrictions" class="headerlink" title="Uniform Processing Pipeline Restrictions"></a>Uniform Processing Pipeline Restrictions</h3><ul>
<li>The <code>read length</code> prior to any trimming should be a minimum of <code>45 base pairs</code>.</li>
<li>Sequencing may be <code>paired</code>- or <code>single</code>-ended, <code>sequencing type</code> is specified and <code>paired sequences</code> are indicated.</li>
<li>All <code>Illumina platforms</code> are supported for use in the uniform pipeline, though <code>data from different platforms should be processed separately</code>; colorspace (<code>SOLiD</code>) reads are <code>not</code> supported. </li>
<li><code>Barcodes</code>, if present in the fastq, must be <code>indicated</code>.</li>
<li><code>Library insert size</code> range must be <code>indicated</code>. <h3 id="Current-Standards"><a href="#Current-Standards" class="headerlink" title="Current Standards"></a>Current Standards</h3></li>
</ul>
<ol>
<li>必须有两次或更多次<code>生物学重复</code>（稀有样本也必须做两次<code>技术重复</code>）</li>
<li>每次重复要有25million非冗余，非线粒体，能够回帖的fragment（单端25 million reads，<code>双端50 million reads</code>=25 million fragment）</li>
<li>回帖率&gt;95%, &gt;80%可接受。</li>
<li>用<code>IDR(Irreproducible Discovery Rate)</code>计算重复一致性，rescue和self consisty ratios 都&gt;2</li>
<li>用以下指标控制PCR扩增对文库复杂性的影响： <code>Non-Redundant Fraction (NRF)</code> and PCR Bottlenecking Coefficients 1 and 2, or PBC1 and PBC2：NRF&gt;0.9, PBC1&gt;0.9, PBC2&gt;3</li>
<li>peak文件必须满足如下要求：<blockquote>
<p>每个重复peak数&gt;150000，&gt;100000可接受（ENCODE的ATAC-seq的peak file没法用）<br>IDR peak&gt;70000,&gt;50000可接受<br>要存在无核小体区NFR<br>存在单核小体峰，好的ATACseq数据应包含核小体，既能看开放染色质，又能看核小体</p>
</blockquote>
</li>
<li>The fraction of reads in called peak regions(FRip score)&gt;0.3,&gt;0.2 可以接受。对于稀有样本不要求FRiP但TSS富集还是要作为关键的衡量信噪比的指标。</li>
<li>TSS富集分数阈值与参考基因组相关。</li>
</ol>
<h2 id="ATACseq-主干分析流程"><a href="#ATACseq-主干分析流程" class="headerlink" title="ATACseq 主干分析流程"></a>ATACseq 主干分析流程</h2><p>reference：<br><strong>1.文章</strong>：<a href="https://peerj.com/articles/4040/">https://peerj.com/articles/4040/</a><br><strong>2.CHIPseq课程</strong>：<a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a><br><strong>3.Harvard FAS Informatics - ATAC-seq Guidelines</strong>：<a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">https://informatics.fas.harvard.edu/atac-seq-guidelines.html</a></p>
<h2 id="Harvard-FAS-Informatics-ATAC-seq-Guidelines"><a href="#Harvard-FAS-Informatics-ATAC-seq-Guidelines" class="headerlink" title="Harvard FAS Informatics - ATAC-seq Guidelines"></a><a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">Harvard FAS Informatics - ATAC-seq Guidelines</a></h2><h3 id="Experimental-design"><a href="#Experimental-design" class="headerlink" title="Experimental design"></a>Experimental design</h3><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4374986/">Detailed protocol</a></p>
<ul>
<li>Replicates</li>
<li>Controls：一般<code>不设置对照</code>。作用有限，费用。没有转座酶处理的样本测序</li>
<li>PCR amplification：<code>尽可能少</code>地使用<code>PCR循环</code>来扩增样本，减少干扰</li>
<li>Sequencing depth：最佳测序深度取决于<code>参考基因组的大小</code>和<code>预期染色质的开放程度</code>。人类样本的研究推荐每个样本超过5000万个reads。</li>
<li>Sequencing mode：(1) ATACseq推荐使用paired-end。paired-end sequencing, helps to <code>reduce these alignment ambiguities</code>. (2) we are interested in <code>knowing both ends of the DNA fragments generated by the assay</code>, since the ends indicate where the transposase inserted. (3) <strong><code>PCR duplicates are identified more accurately</code></strong>.  PCR duplicates are <code>artifacts of the procedure</code>, and they should be removed as part of the analysis pipeline . <code>Computational programs that remove PCR duplicates typically identify duplicates based on comparing ends of aligned reads</code>. With <strong><code>single-end reads</code></strong>, there is <code>only one position to compare</code>, and so any <code>reads whose 5&#39; ends match are considered duplicates</code>. Thus, <code>many false positives</code> may result, and perfectly <code>good reads are removed</code> from further analysis. <strong><code>Paired-end sequencing</code></strong>, <code>both ends of the original DNA fragments are defined</code>. <code>To be declared a duplicate, both ends of one fragment need to match both ends of another fragment</code>, which is far <code>less likely to occur by chance</code>. Therefore, paired-end sequencing leads to <code>fewer false positives</code>.</li>
<li>Mitochondria: 众所周知ATAC-seq数据通常包含很大比例的<code>来自线粒体DNA的reads</code>（<em>线粒体DNA是裸露的，也可以被Tn5酶识别切割，植物叶绿体</em>）。线粒体基因组中没有ATAC-seq感兴趣的峰，这些reads在计算中被丢弃，浪费测序资源。可在测序前使用洗涤剂<a href="https://www.nature.com/articles/nmeth.4396">去除样本中的线粒体</a>。</li>
</ul>
<h3 id="Quality-control"><a href="#Quality-control" class="headerlink" title="Quality control"></a>Quality control</h3><h4 id="FastQC"><a href="#FastQC" class="headerlink" title="FastQC"></a>FastQC</h4><p>Process a file of <code>20 million reads</code> in about <code>5 minutes</code> with less than <code>250MB memory</code> used. Quality scores, GC levels, PCR duplicates, and adapter content.</p>
<h4 id="Adapter-removal"><a href="#Adapter-removal" class="headerlink" title="Adapter removal"></a>Adapter removal</h4><p>For reads derived from <code>short DNA fragments</code>, the <code>3&#39; ends may contain portions of the Illumina sequencing adapter</code>.  </p>
<h5 id="Cutadapt"><a href="#Cutadapt" class="headerlink" title="Cutadapt"></a><a href="https://cutadapt.readthedocs.io/en/stable/guide.html">Cutadapt</a></h5><h5 id="NGmerge"><a href="#NGmerge" class="headerlink" title="NGmerge"></a><a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2579-2">NGmerge</a></h5><p>Unlike cutadapt, NGmerge <code>does not require</code> that the <code>adapter sequences</code> be provided, <code>nor</code> does it <code>require a parameter for the minimum length of adapter to match</code> (in fact, it <code>does not perform adapter matching</code> at all).For input files of <code>20 million paired reads</code>, NGmerge should run in <code>less than one hour on a single core</code>, with minimal memory usage.<br><img src="https://img-blog.csdnimg.cn/e2669cfa1a184ec2b7026fe528f9c97a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p>
<h5 id="Just-adapter-removal"><a href="#Just-adapter-removal" class="headerlink" title="Just adapter removal"></a>Just adapter removal</h5><p>Other than adapter removal, we <code>do not recommend any trimming of the reads.</code> Such adjustments can complicate later steps, such as the identification of PCR duplicates.</p>
<h3 id="Alignment"><a href="#Alignment" class="headerlink" title="Alignment"></a>Alignment</h3><p>Two of the most popular alignment program are BWA and <code>Bowtie2</code>.</p>
<h4 id="Genome-indexing"><a href="#Genome-indexing" class="headerlink" title="Genome indexing"></a>Genome indexing</h4><p>For many model organisms, the genome and pre-built reference indexes are available from <a href="https://support.illumina.com/sequencing/sequencing_software/igenome.html">iGenomes</a>.<br>Otherwise, Bowtie2 indexes are made from a FASTA genome file using the program <code>bowtie2-build</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2-build  &lt;genome.fa&gt;  &lt;genomeIndexName&gt;</span><br></pre></td></tr></table></figure>
<h4 id="Alignment-1"><a href="#Alignment-1" class="headerlink" title="Alignment"></a>Alignment</h4><p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml">Bowtie2 parameters</a>. Here are a few that <code>may benefit the alignment of an ATAC-seq dataset</code> :</p>
<p><code>-X &lt;int&gt;</code> : Maximum DNA fragment length (<code>default 500bp</code>). If you anticipate that you may have DNA fragments <code>longer than</code> the default value, you should <code>increase</code> this parameter accordingly; otherwise, alignments from such fragments are considered not properly paired (see Fig. 3B below).<br><code>--very-sensitive</code> : Bowtie2 has a number of alignment and effort parameters that interact in complex (and sometimes unexpected) ways. Preset collections of these parameters are provided for convenience; the default is –sensitive, but <code>better alignment results</code> are frequently achieved with –very-sensitive.<br><code>-k &lt;int&gt;</code> : Maximum number of alignments to report per read. By default, Bowtie2 reports at most one alignment per read, and if multiple equivalent alignments exist, it chooses one randomly.<br><code>-p &lt;int&gt;</code> : Number of <code>cores</code> on which to run</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2  --very-sensitive  -k 10  -x &lt;genomeIndexName&gt;  -1 &lt;name&gt;_1.fastq.gz  -2 &lt;name&gt;_2.fastq.gz  \</span><br><span class="line">  |  samtools view  -u  -  \</span><br><span class="line">  |  samtools sort  -n  -o &lt;BAM&gt;  -</span><br></pre></td></tr></table></figure>
<ul>
<li>For input files of <code>20 million</code> paired reads, this command takes around <code>five hours</code> on Cannon(1 core too slow). One could specify eight cores for Bowtie2 with <code>-p 8</code> and adjust the request in the <code>SLURM script</code> to <code>#SBATCH -n 10</code> (that is, <code>eight</code> cores for <code>Bowtie2</code> and <code>one each</code> for <code>SAMtools view</code> and <code>sort</code>). </li>
<li>Bowtie2 also provides (via stderr) a summary of the mapping results, separated according to uniqueness and alignment type.</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/9f961cf3106f4c99b6e85bd1c3f6e373.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"><br> Alignment types for paired-end reads. <strong>A</strong>: Properly paired alignments (“<code>concordant</code>“) have the reads <code>aligned in opposite orientations</code> on the <code>same reference</code> sequence (chromosome). The reads <code>may overlap</code> to some extent (bottom). <strong>B</strong>: A read alignment (for <code>R1</code>) can be <code>unpaired</code> for several reasons: if the read’s mate (<code>R2</code>) is <code>unaligned</code> (<code>upper left</code>), <code>aligns to a different chromosome</code> (<code>upper right</code>), aligns in the <code>incorrect orientation</code> (<code>middle</code> cases), or aligns in the correct orientation but at an <code>invalid distance</code> (<code>bottom</code>). In all cases except the upper left, the R2 read alignment is also unpaired, and the read pair align discordantly (though Bowtie2 also requires uniqueness for such alignments to be counted as discordant).</p>
<p>Generich 版本</p>
<h3 id="Peak-calling"><a href="#Peak-calling" class="headerlink" title="Peak calling"></a>Peak calling</h3><h4 id="推荐新的Generich"><a href="#推荐新的Generich" class="headerlink" title="推荐新的Generich???"></a>推荐新的<a href="https://github.com/jsh58/Genrich"><code>Generich</code></a>???</h4><p>Genrich was designed to be able to <code>run all of the post-alignment steps</code> through <code>peak-calling with one command</code>. It also possesses a few <code>novel features</code>. Consider the following attributes:</p>
<ul>
<li><strong>Removal of mitochondrial reads</strong>. Genrich <code>disregards all alignments to the mitochondrial</code> chromosome with <code>-e chrM</code>.</li>
<li><strong>Removal of PCR duplicates</strong>. Genrich follows a <code>systematic procedure</code> to <code>remove PCR duplicates</code> with <code>-r</code>. Note that this evaluation <code>takes into account multimapping reads</code> (see next), which is <code>not provided by other alignment-based duplicate-removal programs</code>, such as <code>Picard&#39;s MarkDuplicates</code>.</li>
</ul>
<p><strong>Analysis of multimapping reads</strong>. 重复区域多的基因组可能导致非唯一mapping。 Non-uniquely aligned reads can be removed by filtering based on MAPQ scores with <code>samtools</code>, but this effectively renders certain genomic regions inaccessible to the assay. With Genrich, <code>reads with multiple alignments are analyzed</code> by adding a fractional count to each location. Genrich’s <code>statistical model</code> accommodates these values.<br>Along these same lines, Genrich considers the entire reference genome to be part of the assay. If there are chromosomes or genomic regions that should be excluded from analysis, these can be specified by <code>-e or -E</code>, and Genrich will adjust the <code>genome length calculation</code> accordingly. There is no need to <code>guesstimate an &quot;effective&quot; genome size</code> like with MACS2.<br><strong>Analysis of multiple replicates</strong>. When alignment files for multiple replicates are provided to Genrich, it <code>calls peaks for the replicates collectively</code>. <code>No more IDR</code>. Done.<br><strong>Interpretation of alignments suitable for ATAC-seq</strong>. Genrich provides an ATAC-seq analysis mode (-j) in which, rather than inferring the full fragments from the alignments, intervals are interpreted that are centered on transposase cut sites (the ends of each DNA fragment). Only properly paired alignments are analyzed by default, but there is an option to consider unpaired alignments as well (-y) (Fig. 4).</p>
<p><img src="https://img-blog.csdnimg.cn/abb30e7406834c91b7e456ff14e23742.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p>
<ul>
<li>Our previous recommendation was to run <code>MACS2</code> with <code>-f BAMPE</code>, which is similar to the <code>default analysis mode of Genrich</code> (<strong>inferring full fragments, rather than cut site intervals</strong>). Others have attempted to interpret cut site intervals with MACS2 by using the <code>--shif</code>t and <code>--extsize</code> arguments, but these arguments are ignored in <code>BAMPE</code> mode. They do work in the default (<code>BAM</code>) mode, but then, with paired-end reads, <code>most of the alignments are automatically discarded</code> (half of the properly paired alignments and all of the unpaired alignments; secondary alignments are never considered). Is it worse to interpret full fragments that may be less informative biologically, or to disregard more than half of the sequence data? A complicated question. The correct answer is: <strong>use Genrich.</strong><h4 id="Genrich"><a href="#Genrich" class="headerlink" title="Genrich"></a>Genrich</h4></li>
</ul>
<p><strong>most important parameters and options of Genrich for analyzing ATAC-seq：</strong> </p>
<p><code>-j</code> : ATAC-seq mode (<strong>must</strong> be specified)<br><code>-d &lt;int&gt;</code> : Expand cut sites to the given length (default 100bp)<br><code>-y</code> : Analyze <strong>unpaired</strong> alignments<br><code>-r</code> : Remove PCR duplicates<br><code>-e &lt;arg&gt;</code> : Chromosomes (reference sequences) to exclude. Can be a comma-separated list, e.g. <code>-e chrM,chrY</code>.<br><code>-E &lt;file&gt;</code> : Input BED file(s) of genomic regions to exclude, such as ‘N’ homopolymers or high mappability regions<br><code>-q &lt;float&gt;</code> : Maximum q-value (FDR-adjusted p-value) for peak calling (default 0.05). An unadjusted p-value threshold can be used instead with <code>-p &lt;float&gt;</code>.<br><code>-a &lt;float&gt;</code> : Minimum area under the curve (total significance) for a peak (default 20.0). <code>Increasing</code> this value results in <code>fewer</code> but <code>higher confidence</code> peaks.<br><code>-v</code> : Verbose mode</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Genrich  -t &lt;BAM&gt;  -o &lt;OUT&gt;  -j  -y  -r  -e chrM  -v</span><br></pre></td></tr></table></figure>

<ul>
<li>对于重复data,  <code>-t &lt;BAM1&gt;,&lt;BAM2&gt;</code>.</li>
<li>The output file produced by Genrich is in <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format12"><code>ENCODE narrowPeak format</code></a>, listing the genomic coordinates of each peak called and various statistics.</li>
<li>Speed： a single BAM containing <code>146.3 million alignments</code> was analyzed by Genrich in <code>10.5min</code> with <code>17.1GB of memory</code> . In general, input BAM(s) of more alignments take longer to analyze, but the memory usage should not increase greatly. Note that <code>Genrich is not multithreaded</code>, so it runs on a single core only.</li>
<li>Those who wish to explore the results of varying the <code>peak-calling parameters (-q/-p, -a, -l, -g)</code> should consider having Genrich produce a log file when it parses the SAM/BAM files (for example, with <code>-f &lt;LOG&gt;</code> added to the above command). Then, Genrich can call peaks directly from the log file with the <code>-P</code> option（调参数使用此法节省内存和时间）:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Genrich  -P  -f &lt;LOG&gt;  -o &lt;OUT2&gt;  -p 0.01  -a 200  -v</span><br></pre></td></tr></table></figure>

<h3 id="NEXT-Steps"><a href="#NEXT-Steps" class="headerlink" title="NEXT Steps"></a>NEXT Steps</h3><h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>For ATAC-seq in model organisms, the <code>peak file produced by Genrich</code> can be <code>uploaded</code> directly to the <a href="https://genome.ucsc.edu/cgi-bin/hgCustom">UCSC genome browser</a>. Add header.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">track type=narrowPeak</span><br></pre></td></tr></table></figure>
<p>An alternative visualization tool is the <a href="http://software.broadinstitute.org/software/igv/">Integrative Genomics Viewer (IGV)</a>. Peak files can be loaded directly (File → Load from File). <strong>Viewing BAM files with IGV requires that they be sorted by coordinate and indexed</strong> using <a href="http://www.htslib.org/doc/samtools.html">SAMtools</a>. However, the BAMs show the read alignments, <code>not the full fragments generated by the ATAC</code> <code>nor the cut site intervals</code> analyzed by Genrich. To view the intervals, one can use the optional output <code>BED file</code> produced by Genrich with <code>-b</code>.</p>
<h4 id="Comparing-peak-files"><a href="#Comparing-peak-files" class="headerlink" title="Comparing peak files"></a>Comparing peak files</h4><p>Determining genomic regions that are <code>common or different to a set of peak files</code> is best accomplished with <a href="http://bedtools.readthedocs.io/en/latest/index.html">BEDTools</a>, a suite of software tools that enables “genome arithmetic.”<br>For example, <a href="http://bedtools.readthedocs.io/en/latest/content/tools/intersect.html">bedtools intersect</a> determines regions that are <strong><code>common</code></strong> to two peak files. Finding <strong><code>differences</code></strong> between two peak files, such as control vs. experimental groups, is accomplished via <a href="http://bedtools.readthedocs.io/en/latest/content/tools/subtract.html">bedtools subtract</a>.</p>
<h4 id="Annotation"><a href="#Annotation" class="headerlink" title="Annotation"></a>Annotation</h4><p>It is helpful to know <code>what genomic features are near the peaks</code> called by Genrich. One program that is commonly used to annotate peaks is <a href="https://bioconductor.org/packages/release/bioc/html/ChIPseeker.html">ChIPseeker</a>. ChIPseeker was originally designed to be used in the analysis of ChIP-seq, but it works just <code>as well with ATAC-seq.</code><br>ChIPseeker <strong>requires</strong> that the <code>genome of interest be annotated with locations of genes and other features</code>. The <a href="https://bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html">ChIPseeker user guide</a> is extremely helpful in using this R/Bioconductor package.</p>
<h4 id="Motif-finding"><a href="#Motif-finding" class="headerlink" title="Motif finding"></a>Motif finding</h4><p><a href="http://homer.ucsd.edu/homer/introduction/basics.html">HOMER</a> is a suite of software designed for <a href="http://homer.ucsd.edu/homer/ngs/peakMotifs.html">motif discovery</a>. It takes a <code>peak file as input</code> and <code>checks for the enrichment</code> of both <code>known sequence motifs</code> and <code>de novo motifs</code>.</p>
<p>MACS2版本</p>
<h4 id="Alignment（same）"><a href="#Alignment（same）" class="headerlink" title="Alignment（same）"></a>Alignment（same）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2  --very-sensitive  -x &lt;genomeIndexName&gt;  -1 &lt;name&gt;_1.fastq.gz  -2 &lt;name&gt;_2.fastq.gz \</span><br><span class="line"> |  samtools view -u -  \</span><br><span class="line"> |  samtools sort -  &gt;  &lt;BAM&gt;</span><br></pre></td></tr></table></figure>

<h4 id="Alignment-adjustments"><a href="#Alignment-adjustments" class="headerlink" title="Alignment adjustments"></a>Alignment adjustments</h4><h5 id="Mitochondrial-reads"><a href="#Mitochondrial-reads" class="headerlink" title="Mitochondrial reads"></a>Mitochondrial reads</h5><ul>
<li>ATAC-seq datasets usually contain a large percentage of reads that are derived from mitochondrial DNA (<a href="http://seqanswers.com/forums/showthread.php?t=35318">discussion</a>). Using <a href="https://www.nature.com/articles/s41598-017-02547-w">CRISPR to reduce mitochondrial contamination</a>. Or recently <a href="https://www.nature.com/articles/nmeth.4396">Omni-ATAC method</a> uses detergents[洗涤剂] to remove mitochondria and is likely to be more accessible for most researchers ( <a href="https://www.biorxiv.org/content/10.1101/496521v1">bad computational workflow</a>).</li>
<li>Method 1 : <strong>Remove the mitochondrial genome from the reference genome before aligning the reads</strong>. In human/mouse genome builds, the mitochondrial genome is labeled ‘<code>chrM</code>‘. That sequence can be deleted from the reference prior to building the genome indexes. The downside of this approach is that the alignment numbers will look much worse; all of the mitochondrial reads will count as unaligned. [植物？]</li>
<li>Method 2 : <strong>Remove the mitochondrial reads after alignment</strong>. A python script, creatively named removeChrom, is available in the ATAC-seq module to accomplish this. For example, to remove all ‘chrM’ reads from a BAM file, one would run this:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -h  &lt;inBAM&gt;  |  removeChrom - - chrM  |  samtools view -b -  &gt;  &lt;outBAM&gt;</span><br></pre></td></tr></table></figure>
<h5 id="PCR-duplicates"><a href="#PCR-duplicates" class="headerlink" title="PCR duplicates"></a>PCR duplicates</h5><p> Picard’s <a href="http://broadinstitute.github.io/picard/command-line-overview.html#MarkDuplicates">MarkDuplicates</a>. The output file specified by <code>M=</code> lists counts of alignments analyzed and duplicates identified.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -jar $PICARD_TOOLS_HOME/picard.jar MarkDuplicates I=&lt;inBAM&gt; O=&lt;outBAM&gt; M=dups.txt REMOVE_DUPLICATES=true</span><br></pre></td></tr></table></figure>
<h5 id="Non-unique-alignments"><a href="#Non-unique-alignments" class="headerlink" title="Non-unique alignments"></a>Non-unique alignments</h5><p>重复区域多的参考序列可能导致reads多处mapping. 用samtools view的-q <code>去除非唯一比对</code>. For reads with multiple alignments, <code>Bowtie2</code> (or <code>BWA</code>) will <code>report only one alignment</code> (by <code>default</code>) and will assign it a low mapping quality (MAPQ) score, which is defined as -10 * log10Pr{mapping position is wrong}. To eliminate alignments with <code>MAPQ &lt; 10</code> (i.e., where <code>Bowtie2</code> has determined <code>Pr&#123;mapping position is wrong&#125; &gt; 0.1</code>), one would run the following:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -b  -q 10  &lt;inBAM&gt;  &gt;  &lt;outBAM&gt;</span><br></pre></td></tr></table></figure>

<h4 id="Peak-calling-1"><a href="#Peak-calling-1" class="headerlink" title="Peak calling"></a>Peak calling</h4><ul>
<li>Model-based Analysis of ChIP-Seq (<a href="https://github.com/taoliu/MACS">MACS2</a>) is a program for detecting regions of <code>genomic enrichment</code>. Though designed for ChIP-seq, it works just <code>as well on ATAC-seq and other genome-wide enrichment assays that have narrow peaks</code>. The main program in MACS2 is <code>callpeak</code>, and its options are described below. (Note that the latest version of MACS2 on Odyssey (v2.1.2_dev) is different from the updated official MACS2 release (v2.1.2), although the latter does incorporate many of the bug fixes made in the Odyssey <code>version？</code>.)</li>
<li>It is important to remember that the <code>read alignments indicate only a portion of the DNA fragments generated by the ATAC？</code>. Therefore, one must consider how one wants MACS2 to interpret the alignments.<h5 id="Alignments-to-analyze"><a href="#Alignments-to-analyze" class="headerlink" title="Alignments to analyze"></a>Alignments to analyze</h5></li>
<li>alignments分为两类：”<strong>properly paired</strong>“ and “<strong>singletons</strong>“ 。<code>-f</code> 选择其类型。</li>
<li><strong>Analyze only properly paired alignments, but ignore R2 reads and treat R1 reads as singletons</strong>. This is the default option (<code>-f AUTO</code>). MACS2 creates a model of the fragment lengths and extends the 3’ ends of the R1 reads to the calculated average length. An alternative is to skip this model building and instead extend each read to a specified length (e.g., <code>--nomodel --extsize 300</code> for 300bp fragments). The value of the length parameter is usually determined from the average size during library preparation (the default value is 200bp if no value is specified). However, <code>neither of these approaches utilizes the value of paired-end sequencing</code>, which defines both fragment ends.</li>
<li><strong>Analyze only properly paired alignments with <code>-f BAMPE</code></strong>. Here, the fragments are defined by the paired alignments’ ends, and there is <code>no modeling or artificial extension</code>. Singleton alignments are ignored. This is the <code>preferred option</code> for using only properly paired alignments.</li>
<li><strong>Analyze all alignments</strong>. For this approach, a python script, SAMtoBED, is available in the ATAC-seq module. This script converts the read alignments to BED intervals, treating the properly paired alignments as such and extending the singleton alignments as specified. There are <code>four options for the singletons</code>: ignore them, keep them as is, extend them to an arbitrary length (similar to the <code>--extsize</code> option of MACS2), or extend them to the average length calculated from the properly paired alignments. </li>
<li>Here is an example command, using the “extend to average length” option (<code>-x</code>):</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -h  &lt;BAM&gt;  |  SAMtoBED  -i -  -o &lt;BED&gt;  -x  -v</span><br></pre></td></tr></table></figure>
<p>The output from SAMtoBED is a <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format1">BED file</a> that should be analyzed by MACS2 with <code>-f BEDPE</code>.<br>(Note that the BEDTools program <a href="http://bedtools.readthedocs.io/en/latest/content/tools/bamtobed.html">
</a> cannot be used here, since its output is in a nonstandard BED format that MACS2 cannot analyze.)</p>
<ul>
<li>In deciding among these analysis options, it may help to consider the counts produced by Bowtie2, which indicate <code>how many alignments fall into each category</code>. For example, if most of the reads are aligned in proper pairs, it may be sufficient to use <code>option #2</code>. On the other hand, <code>option #3</code> is preferred if a substantial fraction of the reads consists of singletons.<h5 id="Other-arguments"><a href="#Other-arguments" class="headerlink" title="Other arguments"></a>Other arguments</h5></li>
<li>MACS2 is <code>not multithreaded</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak  -t &lt;BED&gt;  -f BEDPE  -n NAME  -g ce  --keep-dup all</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>-n &lt;str&gt;</code>    Name of the sample. The output files  name prefix.<br><code>-g &lt;int&gt;</code>    Effective genome size, the size of the organism’s genome that can be analyzed (not including Ns, repetitive sequences, etc.). This will be less than the actual genome size. Parameters are provided for some model organisms, and the <code>default value is hs</code> (for Homo sapiens), which corresponds to a value of 2.7e9.<br><code>-q &lt;float&gt;</code>    <code>Maximum q-value</code> (FDR-adjusted p-value) for peak calling (default <code>0.05</code>). Reducing this threshold will decrease the number of peaks identified by MACS2 but increase the confidence in the called peaks.<br><code>--keep-dup &lt;arg&gt;</code>    How to handle PCR duplicates (default: –keep-dup 1, i.e. remove all potential duplicates). If PCR duplicates have been removed by another program, such as Picard’s MarkDuplicates, then specify <code>--keep-dup all</code>.<br><code>--max-gap &lt;int&gt;</code>    Maximum gap between significant sites to cluster them together (default 50bp). (v2.1.2_dev only)<br><code>--min-length &lt;int&gt;</code>    Minimum length of a peak (default 100bp). (v2.1.2_dev only)</p>
</blockquote>
<h5 id="Output-files"><a href="#Output-files" class="headerlink" title="Output files"></a>Output files</h5><ul>
<li>NAME_peaks.xls</li>
<li>NAME_peaks.narrowPeak</li>
<li>NAME_summits.bed</li>
<li>The most useful file is <code>NAME_peaks.narrowPeak</code>, a plain-text <code>BED</code> file that lists the <code>genomic coordinates of each peak called</code>, along with various <code>statistics</code> (fold-change, p- and q-values, etc.).</li>
</ul>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-1【Background】</title>
    <url>/blog/2021/10/11/ATAC-seq-1-background/</url>
    <content><![CDATA[<h3 id="ATAC-seq意义"><a href="#ATAC-seq意义" class="headerlink" title="ATAC-seq意义"></a>ATAC-seq意义</h3><span id="more"></span>

<p><img src="https://img-blog.csdnimg.cn/2eb44c70d00b45bab31b0eb915e91cac.png" alt="在这里插入图片描述"></p>
<ul>
<li>为何同样DNA序列的细胞的表型会不同，为何肝细胞是肝细胞，神经细胞是神经细胞？是什么造成了他们生产蛋白不同，决定蛋白生成的RNA不同呢？原因可以用<code>表观遗传</code>来解释。<br><img src="https://img-blog.csdnimg.cn/9bf2e2d5d25a4e2eab27321b99b0b0b8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li>DNA转录成RNA过程复杂，包括：<code>染色质可及性</code>，<code>DNA修饰</code>，<code>组蛋白修饰</code>等等（选择性表达）。</li>
<li><code>染色质可及性即DNA开放区域</code>，尤为重要。<code>核小体</code>由<code>8个组蛋白</code>组成复合物，每个核小体约<code>147bpDNA</code>。转录时DNA将从核小体复合物松开。许多因素，如<code>染色质结构</code>、<code>核小体位置</code>和<code>组蛋白修饰</code>，在染色质的组织和可及性起重要作用。致密核小体结构被破坏后，<code>启动子、增强子、绝缘子、沉默子</code>等<code>顺式调控元件和反式作用因子可以接近</code>的特性，叫<code>染色质的可及性</code>，也叫<code>染色质开放性</code>(chromatin accessibility ），这段区域叫开放染色质（open chromatin） 。</li>
<li>什么是组蛋白修饰<ul>
<li>定义：组蛋白包含5个部分，按分子量大小分别称为<code>H1，H3，H2A，H2B和H4</code>。组蛋白在相关酶作用下发生<code>甲基化，乙酰化，磷酸化，腺苷酸化，泛素化，ADP核糖基化</code>等修饰</li>
<li><code>H3·H4乙酰化</code>形成<code>开放染色质结构</code>，<code>增加基因表达</code></li>
<li>组蛋白<code>甲基化</code>修饰多发生在<code>H3H4</code>，与基因<code>抑制及激活</code>相关，取决于被<code>修饰位置和程度</code></li>
<li>组蛋白<code>磷酸化</code>修饰一般与基因<code>活化</code>有关</li>
<li>组蛋白<code>泛素化</code>则是<code>启动基因表达</code></li>
</ul>
</li>
<li>2013年由斯坦福大学William J. Greenleaf和Howard Y. Chang实验室开发的ATAC-seq（<code>Assay</code> for <code>Transposase</code>-<code>Accessible</code> <code>Chromatin</code> with high throughput sequencing），一种捕获染色质可及性（染色质开放性）的测序方法。</li>
<li>ATAC-seq<code>检测染色质可及性</code>，<code>确定基因表达调控机制</code>。识别<code>启动子区域</code>、<code>潜在的增强子或抑制子</code>。<code>启动子</code>是靠近转录起始点(TSS)的DNA区域。包含<code>转录因子的结合位点</code>，转录因子招募RNA聚合酶。<code>增强子</code>是位于<code>启动子下游或上游1Mb</code>的DNA区域。<code>当转录因子与增强子结合，并与启动子区域接触时，该基因的转录增加</code>。相反<code>抑制子</code>会<code>减少或抑制基因表达</code>。</li>
<li>ATAC-seq的<code>峰</code>往往是<code>启动子</code>，<code>增强子序列</code>以及一些<code>反式调控因子</code>结合位点。</li>
<li>为找到开放染色质区，基因组被<code>TN5转座酶</code>处理。在ATAC-Seq中，<code>修饰后的TN5将与NextEra接头相对应的DNA序列插入到基因组的开放区域</code>，同时，DNA被转座酶活性剪切。</li>
<li>开放染色质的研究方法除了ATAC-seq，还有DNase-Seq，FAIRE-seq，MNase-seq 等。ATAC-Seq<code>所需样本少，建库快，重复性更高</code></li>
<li>技术：制备细胞悬液-&gt;裂解细胞膜，获取细胞核-&gt;采用Tn5进行酶切-&gt;回收DNA片段，PCR扩增建库-&gt;高通量测序-&gt;生信分析</li>
<li><img src="https://img-blog.csdnimg.cn/00f06cb4758b44c7a35b8c5c3ff74eda.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq</code>与<code>Chip-seq</code> call出来的<code>peak</code>代表的<code>意义不同</code>。<code>Chip-seq</code> peak是被<code>目的蛋白结合拉下来的DNA</code>，一般只有<code>一个峰</code>，而<code>ATAC-seq</code>是被<code>Tn5转座酶切开</code>、没有被组蛋白结合、染色质开放的DNA位点，<code>如果是TF结合的区域，一般会有一个山谷般的存在</code>。ChIP-seq和ATAC-seq在TF或者Tn5结合区域<code>都会形成一个双峰的reads结合模式</code>，但<code>判断peak的时会有不同的标准</code>。chip-seq是由于<code>TF一起沉淀下来的DNA fragment一般会大于TF的结合区域</code>，<code>read的位置并不是真实TF结合位置</code>，需要<code>向内shift</code>；而<code>ATAC-seq一般是往两边shift</code>。<br><img src="https://img-blog.csdnimg.cn/e501e5a398b34d0e8fd514fba8333cdb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq</code>与<code>Chip-seq</code>应用上的区别:</li>
<li>ATAC-Seq可<code>检测全基因组DNA结合蛋白</code>，<code>转录结合位点</code> ，一般用于<code>不知道特定的转录因子</code>，用此方法与其他方法结合<code>筛查感兴趣的特定调控因子</code>；</li>
<li>ChIP-Seq是已知转录因子，根据<code>感兴趣的转录因子设计抗体</code>去做ChIP实验<code>富集结合的DNA片段</code>。在测定转录因子的 ChIP-seq 中<code>独有的峰可能是先驱转录因子</code>，其<code>先结合到封闭染色质</code>，然后<code>招募染色质重塑因子或其他转录因子起始转录</code>。这些转录因子 <code>ATAC-seq检测不到</code>。</li>
<li>得到DNA片段后，为测序准备建库，包括<code>用完整的NextEra接头</code>和<code>纯化</code>、<code>PCR扩增</code>等。基于上述原因，<code>ATAC-Seq推荐使用双端配对</code>的方法。</li>
</ul>
<h3 id="ATACseq应用"><a href="#ATACseq应用" class="headerlink" title="ATACseq应用"></a>ATACseq应用</h3><ul>
<li><p>染色质<code>开放性图谱绘制</code>，表观基因组图谱</p>
</li>
<li><p>找<code>调控</code>生物学过程的<code>关键转录因子</code></p>
</li>
<li><p>找<code>哪个转录因子</code>调控了研究的基因</p>
</li>
<li><p>找转录因子调控的<code>靶基因</code></p>
</li>
<li><p>得到<code>不同组织或不同条件下对应可及性区域</code>。</p>
</li>
<li><p>得到核小体位置</p>
</li>
<li><p>生成转录因子结合区域的特征(footprinting)</p>
<h3 id="技术限制"><a href="#技术限制" class="headerlink" title="技术限制"></a>技术限制</h3></li>
<li><p>Tn5通过<code>插入剪断DNA 并将测序接头连接到剪断的两个DNA 片段的末端</code>，因此对于一个DNA 片段而言，其两端的接头连接是随机的，导致<code>同一片段两端的接头有50%的概率是同一接头</code>。而<code>只有连接不同接头的片段才可用于富集扩增及测序</code>，因此<code>一半的片段无法利用</code>； </p>
</li>
<li><p><code>大量剪断的DNA 由于片段过大，无法进行PCR富集</code>; </p>
</li>
<li><p>Tn5 的<code>活性</code>受反应溶液的组成及反应条件<code>影响</code>，仍然需要优化以便提高剪切效果； </p>
</li>
<li><p>ATAC-seq在<code>植物细胞存在以下难点</code>：<code>细胞壁</code>，<code>叶绿体线粒体等细胞器污染</code>，<code>缺少稳定遗传的细胞系</code>; </p>
</li>
</ul>
<h3 id="ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq"><a href="#ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq" class="headerlink" title="ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq"></a>ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq</h3><ul>
<li>整体的分析思路一致，<code>找富集区域</code>，对富集区域进行功能分析。</li>
<li>ChIP-Seq是<code>揭示特定转录因子</code>或<code>蛋白复合物</code>的结合区域，实际是<code>研究DNA和蛋白质的相互作用</code>，利用<code>抗体将蛋白质和DNA一起富集</code>，并对<code>富集的DNA测序</code>。</li>
<li>DNase-Seq、ATAC-Seq、FAIRE-Seq都<code>研究开放染色质区域</code>：</li>
<li>DNase-Seq用<code>DNase I内切酶识别</code>开放染色质区域，</li>
<li>ATAC-seq用<code>Tn5转座酶</code>，随后进行<code>富集扩增</code>；</li>
<li>FAIRE-Seq先超声裂解，后用酚-氯仿富集；</li>
<li>MNase-Seq鉴定核小体区域。 </li>
</ul>
<p>下图是不同测序方法获取的峰形：</p>
<p><img src="https://img-blog.csdnimg.cn/aea5161044eb40e1a1cc4c1a65d63cbb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>检测染色质可及性的方法中，ATAC-seq尤其受欢迎。<br><img src="https://img-blog.csdnimg.cn/96808dfcce9446298f1d0d4cc0db6eee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<ul>
<li>ATAC-seq的优点：<code>Tn5转座酶的高活性</code>使ATAC-seq简单，省时，而且只需500-50,000个细胞。灵敏度特异性与DNase-seq相当，优于FAIRE-seq。</li>
</ul>
<h3 id="整合分析"><a href="#整合分析" class="headerlink" title="整合分析"></a>整合分析</h3><ul>
<li>由于开放染色质是大多数TF结合的先决条件，因此<code>ATAC-seq峰通常与TF ChIP-seq峰重叠，但通常更宽</code>。因此，<code>TF ChIP-seq和ATAC-seq可以在同一实验系统中相互验证</code>彼此的质量和可靠性。 </li>
<li>ATAC-seq与 histone marker ChIP-seq集成，发现与活跃染色质标 H3K4me3，H3K4me1，H3K27ac等正相关，与不活跃的染色质标记 H3K27me3 负相关。 <code>？</code></li>
<li><code>ATAC-seq+RNA-seq</code>： 一般RNA-seq会优先于ATAC-seq先测，但<code>差异基因富集的基因通路只是一种相关性</code>。要分析出其中谁调控目的基因，可通过<code>ATAC-seq做motif分析</code>，<code>寻找潜在的调控因子</code>，然后再后续的<code>实验验证</code>或者<code>chip-seq验证</code>。/ 看ATAC上丰度高的DNA序列区域是否对应转录本表达量增加，找到对应转录本相关基因的上游调控序列，整体分析转录。对基因功能分析，结合实验表型，推测表达调控-表达-功能-表型。<br><img src="https://img-blog.csdnimg.cn/4a3016bfa5c74598a5b7d660fe1cfe84.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq+HiC</code>： 对于一些想了解<code>染色质高级结构对生命行为的作用</code>的时候，通常会需要用到ATAC-seq等技术，因为<code>Hi-C分析</code>得到高级结构compartmentA/B、TADs、Loops等信息，通常只是相关性，但通过ATAC-seq，可以<code>获得promoter、enhancer等信息</code>，更能知道高级结构是如何影响启动子、增强子从而影响基因表达的。<br><img src="https://img-blog.csdnimg.cn/e38ba32597a14ca7a5d4d6b2f36c1b73.png" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq+组蛋白修饰</code>： ATAC-seq预测一个位点的开放程度以及可能有某种转录因子的结合，但<code>不知道</code>该因子是<code>促进</code>基因表达，还是<code>抑制</code>，只通过<code>基因层面鉴定</code>来判断转录因子对基因的促进或者是不够的，它只是一种<code>相关性</code>。而这时候如果能提供像<code>H3K27ac这类激活型组蛋白</code>、<code>H3K27me3这类抑制型组蛋白</code>将能使数据结果可信。国内较早研究iPSCs的学者如裴端卿的工作可以看到，在解析iPSCs重编程中的染色质可及性的时候，不仅用到ATAC-seq来描述细胞的身份转变，还<code>通过H3K27ac指征该区域的激活</code>。其中一篇还通过<code>调控成纤维细胞关键基因启动子区去乙酰化修饰</code>，达到了促进重编程的进程。<br><img src="https://img-blog.csdnimg.cn/abb3dc6c3bb0476985a9f1b2e77c4fcc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>scATAC-seq+scRNA-seq</code>： 更前沿的技术一个细胞里同时进行RNA-seq和ATAC-seq，并且是单细胞水平的检测。SHARE-seq，能够实现在单细胞中同时高质量，高通量的检测基因表达和染色质可及性。该技术可以使用<code>染色质潜力算法</code>（chromatin potential），<code>用ATAC和RNA的差异来预测细胞的变化方向</code>。<code>相对于以往仅依赖于RNA的预测手段，染色质潜力能够大大提前预测的时间</code>。<br><img src="https://img-blog.csdnimg.cn/df76c6e5f3184d58a00a1fa53a398cd5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
</ul>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/27374332/">ATAC-seq与ChIP联合分析</a><br>研究课题为人小细胞肺癌促进癌症扩散转移的背景机制。主要比较原发性和肝转移性的小细胞肺癌细胞之间的差异。利用ATAC-seq，发现NFI家族转录因子富集在具有差异的染色质开放位点中，预示着NFI家族转录因子在调控肿瘤细胞转移中扮演着重要角色。在染色质高开放性位点区域伴随着Nfib拷贝数量增多，且Nfib在侵袭性原发性肿瘤和转移性肿瘤内高表达，Nfib表现出维持染色质及远端调控区域开放和促进神经基因表达的功能，说明了Nfib对促进癌细胞增殖和迁移具有重要的作用。</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/25679813/">motif分析转录因子结合蛋白</a>。对处于发育过程中的黑腹果蝇眼睛及其通过遗传诱导的肿瘤模型，利用ATAC-seq技术分析染色质开放区域已在活体中发现驱动肿瘤发育的转录因子及调控区域。然后对找到的染色质活性开放区域进行转录因子预测分析，发现了两个关键的转录因子，猜测它们可能与染色质图谱的变化有关。通过对候选的一个转录因子进行功能验证和靶标分析，发现其为肿瘤转录组中的一个关键的转录调控因子。</li>
</ul>
<hr>
<ul>
<li><strong>思考</strong>：</li>
<li>ATAC-Seq与ChIP-Seq的异同在哪里？</li>
<li>用和ChIP-Seq一样的参数Call peaks正确吗？</li>
<li>得到peaks后怎么进行质量评估？</li>
<li>样本内的重复怎么处理？</li>
<li>样本间的差异怎么分析？</li>
<li>怎么对peaks进行功能注释分析？</li>
<li>如何找motif?</li>
<li>ATAC-Seq和ChIP-Seq和RNA-Seq的整合分析怎么做？<br><img src="https://img-blog.csdnimg.cn/0920f7a6c41148b2825b189e709a5fbc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="ATAC-seq/CHIP-seq流程"></li>
</ul>
<p>待学习内容：</p>
<ol>
<li><p>ATAC-seq data analysis: from FASTQ to peaks</p>
</li>
<li><p>ATAC-seq Data Standards and Processing Pipeline in ENCODE</p>
</li>
<li><p>ATAC-seq数据分析实战</p>
</li>
<li><p>Harvard FAS Informatics - ATAC-seq Guidelines</p>
</li>
<li><p>Harvard Chan Bioinformatics Core (HBC)深度NGS数据分析课程，第5部分关于ChIP-Seq，整体思路和绝大部分分析方法适合ATAC-seq。</p>
<p>HBC深度NGS数据分析课程：<br><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course</a><br>第五部分ChIP-Seq课程：</p>
<p><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a></p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">参考文献：</span><br><span class="line">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1633159169&amp;ver=3349&amp;signature=*MwqLr1J-qdZoNiKVxF32vEKh5-6TRystOXAJ3UOZ3Pl8XTBIB8Ly95IJM0L2EzGFVWOM-TdKnuhnb0gfMfsUTfahWJ5i3hcM2TcR9UDFSVWuyYw7CONzMjsMaYQG2Ca&amp;new=1</span><br><span class="line">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1633159169&amp;ver=3349&amp;signature=rtYw5NsC62rUZvctQsUg3*w*NFFDdOHgSMu0pcp0HTQdCyqxpgril8yx7GWlJaID*lfd2HRLUWs59zuszSEFeean0jEwdRs4PzYy*T5b7nSpZRWqCs4SHcEQ2jyjDtwQ&amp;new=1</span><br></pre></td></tr></table></figure>

<hr>
<blockquote>
<p>1：ATAC-seq的背景介绍以及与ChIP-Seq的异同<br>2：原始数据的质控、比对和过滤<br>3：用MACS2软件call peaks<br>4：对ATAC-Seq/ChIP-seq的质量评估（一）——phantompeakqualtools<br>5：对ATAC-Seq/ChIP-seq的质量评估（二）——ChIPQC<br>6：重复样本的处理——IDR<br>7：用Y叔的ChIPseeker做功能注释<br>8：用网页版工具进行motif分析<br>9：差异peaks分析——DiffBind<br>10：ATAC-Seq、ChIP-Seq、RNA-Seq整合分析</p>
</blockquote>
<h3 id="简洁版ATACseq分析流程"><a href="#简洁版ATACseq分析流程" class="headerlink" title="简洁版ATACseq分析流程"></a>简洁版ATACseq分析流程</h3><ul>
<li>数据预处理<ul>
<li>（1）比对前质量控制FastQC</li>
<li>（2）原始序列比对 </li>
<li>（3）比对后处理和质量控制：去除重复序列，细胞器序列<ul>
<li>序列比对后，Picard/SAMtools收集unique mapping reads/rate，duplicated rate百分比和片段大小分布</li>
<li>成功的ATACseq实验应生成<code>片段大小分布图</code>（从<code>bam文件</code>得到），具有递减性和周期性的峰，对应于<code>无核小体区域</code>（NFR）（&lt;100bp）和<code>单核双核和三核</code>小体（200，400，600bp）。大多数Linker DNA大小介于10-80bp间，故大多数片段都会是<code>小于100bp</code>。每个Nucleosome的DNA大小为180bp，加上两边插入的冗余，会得到大约<code>200bp</code>长度的mono-nucleosome的DNA。</li>
<li><code>无核小体区域的片段应该在基因的转录起始位点（TSS）周围富集</code>，而<code>核小体结合区域片段TSS处形成低谷</code>，TSS周围<code>侧翼区域稍微富集</code>。<code>ATACseqQC评估</code>。</li>
</ul>
</li>
</ul>
</li>
<li>Peak-calling：从比对得到的bam文件找出reads覆盖区，就是峰出现的位置。</li>
<li>高级分析<ul>
<li>（1）peak 差异分析：寻找不同分组差异peaks</li>
<li>（2）peak注释：峰的注释可将染色质的可及性与基因调控联系。通常峰会被注释到最接近的基因或调控原件。获得最接近的基因列表后，使用GOKEGGReactome等数据库功能富集分析</li>
<li>（3）motif富集分析：得到每个peak region里motif的位置和频率，再和随机背景或其他条件比较，可做motif富集分析</li>
<li>（4）footprint分析 ：ATACseq中footprint指一个TF结合在DNA上，组织Tn5切割，在染色质开放区域留下一个相对缺失的位置。而TF周围的组蛋白因为TF造成空间的推挤反而形成开放度较高区域。</li>
</ul>
</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
</search>
