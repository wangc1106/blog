<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【CUT&amp;Tag-pipeline】</title>
    <url>/blog/2022/03/21/2022-03-21-CUTTag/</url>
    <content><![CDATA[<p><strong>CUT&amp;Tag Data Processing and Analysis Tutorial</strong></p>
<p>Ye Zheng, Kami Ahmad, Steven Henikoff [following NC]</p>
<p><a href="https://yezhengstat.github.io/CUTTag_tutorial/#223_Intepret_the_quality_check_results">https://yezhengstat.github.io/CUTTag_tutorial/#223_Intepret_the_quality_check_results</a></p>
<p><a href="https://www.jianshu.com/p/1a23656a0713">https://www.jianshu.com/p/1a23656a0713</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzUxNTkzODIzMg==&mid=2247484049&idx=2&sn=b74aa66a9c9e4bd36a8a1d50e2834226&chksm=f9ae4046ced9c950efee443e1f0692e37dbce2b856e4f2f841ecd723affcff9c67c698ebe2fa&scene=21#wechat_redirect">wechat</a></p>
<span id="more"></span>

<hr>
<h1 id="I-Introduction"><a href="#I-Introduction" class="headerlink" title="I. Introduction"></a>I. Introduction</h1><h2 id="1-1-Overview-of-CUT-amp-Tag"><a href="#1-1-Overview-of-CUT-amp-Tag" class="headerlink" title="1.1. Overview of CUT&amp;Tag"></a>1.1. Overview of CUT&amp;Tag</h2><p>All dynamic processes that take place on DNA in the eukaryotic nucleus occur in the context of a chromatin landscape that comprises nucleosomes and their modifications, transcription factors, and chromatin-associated complexes. A variety of chromatin features mark sites of activating and silencing transcriptional regulatory elements and chromatin domains that differ between cell types and change during development.</p>
<p>The mapping of chromatin features genome-wide has traditionally been performed using chromatin immunoprecipitation (ChIP), in which chromatin is <strong>cross-linked</strong> and <strong>solubilized</strong>, and an <strong>antibody</strong> to a <strong>protein or modification of interest</strong> is used to <strong>immunoprecipitate the bound DNA</strong> (<font color="green"><strong>Fig. 1a</strong></font>). Very little has changed in the way <strong>ChIP</strong> is most generally performed since it was first described <strong>35 years ago</strong>, and remains fraught with <strong>signal-to-noise issues</strong> and <strong>artifacts</strong>. An alternative chromatin profiling strategy is <strong>enzyme tethering in situ</strong> whereby the chromatin protein or modification of interest is targeted by an <strong>antibody or fusion protein</strong>. Then, the underlying DNA is marked or cleaved, and a succession of enzyme-tethering methods have been introduced over the past two decades. <font color="green"><strong>Cleavage Under Targets &amp; Tagmentation (CUT&amp;Tag)</strong></font> is a tethering method that uses a <font color="green"><strong>protein-A-Tn5 (pA-Tn5) transposome fusion protein</strong></font> (<font color="green"><strong>Fig. 1b</strong></font>). In CUT&amp;Tag, permeabilized cells or nuclei are incubated with antibody to a specified chromatin protein, and then <strong>pA-Tn5 loaded with mosaic end adaptors</strong> is successively tethered to antibody-bound sites. Activation of the transposome by adding magnesium ions[<strong>Mg2+</strong>] results in the <strong>integration of the adaptors into nearby DNA</strong>. These are then amplified to generate sequencing libraries. Antibody-tethered Tn5-based methods achieve high sensitivity owing to stringent washing of samples after pA-Tn5 tethering and the high efficiency of adaptor integration. The <font color="green"><strong>improved signal-to-noise</strong></font> relative to ChIP-seq translates to an order-of-magnitude reduction in the amount of sequencing required to map chromatin features, allowing sample pooling (typically up to 90 samples) for paired-end sequencing on Illumina NGS sequencers by barcoded PCR of libraries.</p>
<p><img src="/blog/2022/03/21/2022-03-21-CUTTag/1.png" alt="Figure 1. Differences between immunoprecipitation and in antibody-targeted chromatin profiling strategies. A. ChIP-seq experimental procedure. B. CUT&amp;Tag experimental procedure. Cells and nuclei are indicated in grey, chromatin as red nucleosomes, and a specific chromatin protein in green."></p>
<p>Cells and nuclei are indicated in grey, chromatin as red nucleosomes, and a specific chromatin protein in green.</p>
<h2 id="1-2-Objectives"><a href="#1-2-Objectives" class="headerlink" title="1.2. Objectives"></a>1.2. Objectives</h2><p>This tutorial is designed for processing and analyzing CUT&amp;Tag data following the <a href="https://www.protocols.io/view/bench-top-cut-amp-tag-bcuhiwt6/abstract">Bench top CUT&amp;Tag V.3 protocol</a> <strong>NC</strong>. The illustration data used in <strong>this tutorial</strong> is the profiling of <strong>histone modifications</strong> in the human lymphoma K562 cell line, but the tutorial is <strong>generally applicable to</strong> any chromatin protein, including <strong>transcription factors, RNA polymerase II</strong>, and epitope-tagged proteins.</p>
<h2 id="1-3-CUT-amp-Tag-data-processing-and-analysis-outline"><a href="#1-3-CUT-amp-Tag-data-processing-and-analysis-outline" class="headerlink" title="1.3 CUT&amp;Tag data processing and analysis outline."></a>1.3 CUT&amp;Tag data processing and analysis outline.</h2><p><img src="/blog/2022/03/21/2022-03-21-CUTTag/2.png" alt="Figure 2. CUT&amp;Tag data processing and analysis."></p>
<ol start="3">
<li><strong>Alignment</strong>: Bowtie2 alignment; Duplicates; Fragment size; Replicate reproducibility</li>
</ol>
<blockquote>
<p>Bowtie2, Samtools, Picard</p>
</blockquote>
<ol start="4">
<li><strong>Filtering and Conversion</strong>: Sam to bam; bam to bed</li>
</ol>
<blockquote>
<p>Samtools, Bedtools</p>
</blockquote>
<ol start="5">
<li><strong>Spike-in Calibration?:</strong> Sam to bam; Bam to bed</li>
</ol>
<blockquote>
<p>Bowtie2, Bedtools</p>
</blockquote>
<ol start="6">
<li><strong>Peak Calling:</strong> SEACR peak calling; Fragment propotion in peak regions(FRiPs)</li>
</ol>
<blockquote>
<p>SEACR, R: chromVAR</p>
</blockquote>
<ol start="7">
<li>Visualization: Genome browser; Heatmap</li>
</ol>
<blockquote>
<p>IGV, UCSC browser, Deeptools</p>
</blockquote>
<ol start="8">
<li>Different Analysis</li>
<li>Additional alternatives</li>
</ol>
<h2 id="1-4-Requirements"><a href="#1-4-Requirements" class="headerlink" title="1.4. Requirements"></a>1.4. Requirements</h2><ul>
<li>R (versions &gt;= 3.6)<ul>
<li>dplyr</li>
<li>stringr</li>
<li>ggplot2</li>
<li>viridis</li>
<li>GenomicRanges</li>
<li><strong>chromVAR</strong></li>
<li>DESeq2</li>
<li><strong>ggpubr</strong></li>
<li><strong>corrplot</strong></li>
<li>ChIPseqSpikeInFree [Optional]</li>
</ul>
</li>
</ul>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library(dplyr)</span><br><span class="line">library(stringr)</span><br><span class="line">library(ggplot2)</span><br><span class="line">library(viridis)</span><br><span class="line">library(GenomicRanges)</span><br><span class="line">library(chromVAR) <span class="comment">## For FRiP analysis and differential analysis</span></span><br><span class="line">library(DESeq2) <span class="comment">## For differential analysis section</span></span><br><span class="line">library(ggpubr) <span class="comment">## For customizing figures</span></span><br><span class="line">library(corrplot) <span class="comment">## For correlation plot</span></span><br></pre></td></tr></table></figure>

<ul>
<li>FastQC(version &gt;= 0.11.9)</li>
<li>Bowtie2 (version &gt;= 2.3.4.3)</li>
<li>samtools (version &gt;= 1.10)</li>
<li>bedtools (version &gt;= 2.29.1)</li>
<li>Picard (version &gt;= 2.18.29)</li>
<li><strong>SEACR (version &gt;= 1.3)</strong></li>
<li>deepTools (version &gt;= 2.0)</li>
</ul>
<h2 id="1-5-Data-Downloading"><a href="#1-5-Data-Downloading" class="headerlink" title="1.5. Data Downloading"></a>1.5. Data Downloading</h2><ol>
<li>Using <a href="https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/">SRA Toolkit</a></li>
<li>Download through <a href="file:///Users/yezheng/Downloads/downloading_fastq_GEO.pdf">European Nucleotide Archive</a>. New ENA Browser: <a href="https://www.ebi.ac.uk/ena/browser/view">https://www.ebi.ac.uk/ena/browser/view</a>. We are using this option as illustration.</li>
</ol>
<ul>
<li><strong>H3K27me3</strong>:<ul>
<li>SH_Hs_K27m3_NX_0918 as replicate 1: GEO accession: GSE145187, SRA entry: SRX8754646</li>
<li>SH_Hs_K27m3_Xpc_0107 as replicate 2: GEO accession: GSE145187, SRA entry: SRX7713678</li>
</ul>
</li>
<li><strong>H3K4me3</strong>:<ul>
<li>SH_Hs_K4m3_NX_0918 as replicate 1: GEO accession: GSE145187, SRA entry: SRX7713692</li>
<li>SH_Hs_K4m3_Xpc_0107 as replicate 2: GEO accession: GSE145187, SRA entry: SRX7713696</li>
</ul>
</li>
<li><strong>IgG</strong>:<ul>
<li>SH_Hs_IgG_1x_0924 as replicate 1:GEO accession: GSE145187, SRA entry: SRX8468909</li>
<li>SH_Hs_IgG_20181224 as replicate 2: GEO accession: GSM3680227, SRA entry: SRX5545346</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#example</span></span><br><span class="line">wget -O <span class="variable">$projPath</span>/data/IgG_rep2/IgG_rep2_R1_001.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR875/001/SRR8754611/SRR8754611_1.fastq.gz</span><br><span class="line">wget -O <span class="variable">$projPath</span>/data/IgG_rep2/IgG_rep2_R2_001.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR875/001/SRR8754611/SRR8754611_2.fastq.gz</span><br></pre></td></tr></table></figure>



<hr>
<h1 id="II-Data-Pre-processing"><a href="#II-Data-Pre-processing" class="headerlink" title="II. Data Pre-processing"></a>II. Data Pre-processing</h1><p>FASTQC</p>
<p><strong>Per base sequence content fails the FastQC quality check.</strong></p>
<p><strong>The discordant sequence content at the begining of the reads are common phenomenon for CUT&amp;Tag reads. Failing to pass the Per base seuqnence content does not mean your data failed.</strong></p>
<ul>
<li>It can be due to the Tn5 preference.</li>
<li>What you might be detecting is <font color="green">the 10-bp</font> periodicity that shows up as a sawtooth pattern in the length distribution. If so, <font color="blue"><strong>this is normal and will not affect alignment or peak calling</strong></font>. In any case we do not recommend trimming as the bowtie2 parameters that we list <font color="blue"><strong>will give accurate mapping information without trimming</strong></font>.</li>
</ul>
<h2 id="2-2-Merge-technical-replicates-lanes-if-needed-Optional"><a href="#2-2-Merge-technical-replicates-lanes-if-needed-Optional" class="headerlink" title="2.2. Merge technical replicates/lanes if needed [Optional]"></a>2.2. Merge technical replicates/lanes if needed [Optional]</h2><p>Sometimes, samples are often sequenced across <strong>multiple lanes for efficiency</strong> and can be pooled before alignment. <font color="blue">If you want to <strong>check the reproducibility</strong> between sequences of different lanes of the same sample</font>, you can skip this step and <strong>align</strong> each sequencing file (fastq file) <strong>respectively</strong>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#combination of the data</span></span><br><span class="line">cat <span class="variable">$&#123;projPath&#125;</span>/data/<span class="variable">$&#123;histName&#125;</span>/*_R1_*.fastq.gz &gt;<span class="variable">$&#123;projPath&#125;</span>/fastq/<span class="variable">$&#123;histName&#125;</span>_R1.fastq.gz</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="III-Alignment"><a href="#III-Alignment" class="headerlink" title="III. Alignment"></a>III. Alignment</h1><h2 id="3-1-Bowtie2-alignment-required"><a href="#3-1-Bowtie2-alignment-required" class="headerlink" title="3.1. Bowtie2 alignment [required]"></a>3.1. Bowtie2 alignment [required]</h2><p>The structure of <font color="blue"><strong>CUT&amp;Tag insert libraries</strong></font> with <font color="blue"><strong>Tn5 adapters</strong></font> and <font color="blue"><strong>barcoded PCR primers</strong></font> is shown below:</p>
<p><img src="/blog/2022/03/21/2022-03-21-CUTTag/3.png" alt="Figure 4. CUT&amp;Tag insert libraries with the sequence of adapters."></p>
<p>Our standard pipeline is to perform <font color="blue">single-index 25x25 PE Illumina sequencing??</font> on up to 90 pooled samples on a single HiSeq 2500 flowcell, where <font color="blue">each sample</font> has a <font color="blue">unique PCR primer barcode</font>. Amounts for <strong>each library</strong> are adjusted to provide <strong>~5 million</strong> paired-end reads, which provides high-quality profiling for abundant chromatin features with a specific and high-yield antibody. Less abundant features typically require fewer reads, while <strong>lower-quality antibodies</strong> may increase the number of reads needed for generating robust chromatin profiles. A thorough discussion of feature recall and <strong>sequencing depths for CUT&amp;Tag</strong> has been published (Kaya-Okur et al 2020).</p>
<h3 id="3-1-1-Alignment-to-ref"><a href="#3-1-1-Alignment-to-ref" class="headerlink" title="3.1.1 Alignment to ref."></a>3.1.1 Alignment to <font color="red">ref</font>.</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">bowtie2 \</span><br><span class="line">--end-to-end \</span><br><span class="line">--very-sensitive \</span><br><span class="line"><span class="comment">#runs a little faster, only consider alignment status of pairs per se</span></span><br><span class="line">--no-mixed \</span><br><span class="line"><span class="comment">#disablelooks for discordant alignments if it cannot find any concordant alignments. </span></span><br><span class="line">--no-discordant \</span><br><span class="line">--phred33 \</span><br><span class="line"><span class="comment">#-I The minimum fragment length for valid paired-end alignments. Default: 0</span></span><br><span class="line">-I 10 \</span><br><span class="line">-X 700 \</span><br><span class="line">-p <span class="variable">$&#123;cores&#125;</span> \</span><br><span class="line">-x <span class="variable">$&#123;ref&#125;</span> \</span><br><span class="line">-1 <span class="variable">$&#123;projPath&#125;</span>/fastq/<span class="variable">$&#123;histName&#125;</span>_R1.fastq.gz -2 <span class="variable">$&#123;projPath&#125;</span>/fastq/<span class="variable">$&#123;histName&#125;</span>_R2.fastq.gz \</span><br><span class="line">-S <span class="variable">$&#123;projPath&#125;</span>/alignment/sam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sam &amp;&gt; <span class="variable">$&#123;projPath&#125;</span>/alignment/sam/bowtie2_summary/<span class="variable">$&#123;histName&#125;</span>_bowtie2.txt</span><br></pre></td></tr></table></figure>

<p><code>--end-to-end --very-sensitive --no-mixed --no-discordant --phred33 -I 10 -X 700</code> for mapping of <strong>inserts 10-700 bp</strong> in length.</p>
<p><font color="red"><strong>Critical step</strong></font>: There is no need to trim reads from out standard 25x25 PE sequencing?, as adapter sequences will not be included in reads of inserts &gt;25 bp. However, for users <strong>performing longer sequencing</strong>, reads will need to be trimmed by Cutadapt and mapped by <code>--local --very-sensitive --no-mixed --no-discordant --phred33 -I 10 -X 700</code> to ignore any remaining adapter sequence at the 3’ ends of reads during mapping.</p>
<p><font color="red">–local</font> In this mode, Bowtie 2 does not require that the entire read align from one end to the other. Rather, some characters may be omitted (“soft clipped”) from the ends <strong>in order to achieve the greatest possible alignment score</strong>. The match bonus <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>is used in this mode, and the best possible alignment score is equal to the match bonus (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>) times the length of the read. Specifying <code>--local</code> and one of the presets (e.g. <code>--local --very-fast</code>) is equivalent to specifying the local version of the preset (<code>--very-fast-local</code>). This is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a>. <code>--end-to-end</code> is the default mode.</p>
<h3 id="3-1-2-Alignment-to-spike-in-genome-for-spike-in-calibration-optional-recommended"><a href="#3-1-2-Alignment-to-spike-in-genome-for-spike-in-calibration-optional-recommended" class="headerlink" title="3.1.2 Alignment to spike-in genome for spike-in calibration [optional/recommended]"></a>3.1.2 Alignment to <font color="red">spike-in genome</font> for spike-in calibration [optional/recommended]</h3><p>This section is <strong>optional</strong> but <strong>recommended</strong> depending on your experimental protocol.</p>
<p><font color="red"><strong>E. coli</strong> DNA is <strong>carried along with</strong> bacterially-produced <strong>pA-Tn5 protein</strong></font> and gets tagmented non-specifically during the reaction. <strong>The fraction of total reads that map to the E.coli genome</strong> <font color="blue"><strong>depends on</strong></font> the <strong>yield of epitope-targeted CUT&amp;Tag</strong>, and so <font color="blue"><strong>depends on</strong></font> the <strong>number of cells used and the abundance of that epitope in chromatin</strong>. Since a constant amount of pATn5 is added to CUT&amp;Tag reactions and brings along a fixed amount of E. coli DNA, E. coli reads can be used to <font color="red"><strong>normalize epitope abundance</strong></font> in a set of experiments. More discussion, please see Section V.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># download E.coli K12 MG1655</span></span><br><span class="line">bowtie2-build ecoli.fa ecoli</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line">spikeInRef=/path/to/index/eoli</span><br><span class="line">chromSize=<span class="string">&quot;hg38.chrom.size&quot;</span></span><br><span class="line"><span class="comment"># download ecoli K-12 substr.MG1655[INSDC:U00096.3;size:4.64M;]</span></span><br><span class="line">bowtie2-build path/to/Ecoli/fasta/Ecoli.fa /path/to/bowtie2Index/Ecoli</span><br><span class="line">bowtie2 --end-to-end --very-sensitive --no-overlap --no-dovetail --no-mixed --no-discordant --phred33 -I 10 -X 700 -p <span class="variable">$&#123;cores&#125;</span> -x <span class="variable">$&#123;spikeInRef&#125;</span> -1 _R1.fastq.gz -2 _R2.fastq.gz -S _bowtie2_spikeIn.sam &amp;&gt; log_bowtie2_spikeIn.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">#-f output alignments with bits</span></span><br><span class="line"><span class="comment">#-F Do not output alignments with any bits set in INT present in the FLAG field. INT can be specified in hex by beginning with 0x&#x27; (i.e. /^0x[0-9A-F]+/) or in octal by beginning with0&#x27; (i.e./^0 [0-7]+/) </span></span><br><span class="line"><span class="comment"># FLAGS 0x2 PROPER_PAIR each segment properly aligned according to the aligner</span></span><br><span class="line"><span class="comment"># FLAGS 0x4 UNMAP segment unmapped</span></span><br><span class="line">seqDepthDouble=`samtools view -F 0x04 _bowtie2_spikeIn.sam | wc -l`</span><br><span class="line">seqDepth=$((seqDepthDouble/<span class="number">2</span>))</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$seqDepth</span> &gt; _bowtie2_spikeIn.seqDepth</span><br></pre></td></tr></table></figure>

<ul>
<li>For spike-in normalization, reads are aligned to the <strong>E. coli genome U00096.3</strong> with two more parameters <code>--no-overlap</code>and <code>--no-dovetail</code>(<code>--end-to-end --very-sensitive --no-overlap --no-dovetail --no-mixed --no-discordant --phred33 -I 10 -X 700</code>) to avoid possible cross-mapping of the experimental genome to that of the carry-over E. coli DNA that is used for calibration.</li>
</ul>
<h3 id="3-1-3-Alignment-summary"><a href="#3-1-3-Alignment-summary" class="headerlink" title="3.1.3 Alignment summary"></a>3.1.3 Alignment summary</h3><p>For more detailed parameters explanation, users can refer to the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml">bowite2 manual</a>.</p>
<p>Bowtie2 alignment results summary is saved at <code>log</code> .</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2984630 reads; of these:</span><br><span class="line">  2984630 (100.00%) were paired; of these:</span><br><span class="line">    125110 (4.19%) aligned concordantly 0 times</span><br><span class="line">    2360430 (79.09%) aligned concordantly exactly 1 time</span><br><span class="line">    499090 (16.72%) aligned concordantly &gt;1 times</span><br><span class="line">95.81% overall alignment rate</span><br></pre></td></tr></table></figure>

<ul>
<li>2984640 is the <strong>sequencing depth?</strong>, i.e., total number of paired reads.</li>
<li>125110 is the number of read pairs that fail to be mapped.</li>
<li>2360430 + 499090 is the number of read paris that are successfully mapped.</li>
<li>95.81% is the overall alignment rate</li>
</ul>
<h2 id="3-2-Report-sequencing-mapping-summary-required"><a href="#3-2-Report-sequencing-mapping-summary-required" class="headerlink" title="3.2 Report sequencing mapping summary [required]"></a>3.2 Report sequencing mapping summary [required]</h2><p>Summarize the raw reads and uniquely mapping reads to report the efficiency of alignment. Alignment frequencies are expected to be &gt;80% for high-quality data. <strong>CUT&amp;Tag</strong> data typically has <font color="red"><strong>very low backgrounds</strong></font>, so as few as 1 million mapped fragments can give robust profiles for a histone modification in the human genome. Profiling of less-abundant transcription factors and chromatin proteins may require 10 times as many mapped fragments for downstream analysis.</p>
<p>We can evaluate the following metrics:</p>
<ul>
<li>Sequencing depth</li>
<li>Alignment rate</li>
<li>Number of mappable fragments</li>
<li>Duplication rate</li>
<li>Unique library size</li>
<li>Fragment size distribution</li>
</ul>
<h3 id="3-2-1-Sequencing-depth"><a href="#3-2-1-Sequencing-depth" class="headerlink" title="3.2.1 Sequencing depth"></a>3.2.1 Sequencing depth</h3><p>code in this part, <font color="red"><strong>no use</strong></font>. Summary all reads, mapped reads, and mapping ratio</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line"><span class="comment">## Path to the project and histone list</span></span><br><span class="line">projPath = <span class="string">&quot;///CUTTag_tutorial&quot;</span></span><br><span class="line">sampleList = <span class="built_in">c</span>(<span class="string">&quot;K27me3_rep1&quot;</span>, <span class="string">&quot;K27me3_rep2&quot;</span>, <span class="string">&quot;K4me3_rep1&quot;</span>, <span class="string">&quot;K4me3_rep2&quot;</span>, <span class="string">&quot;IgG_rep1&quot;</span>, <span class="string">&quot;IgG_rep2&quot;</span>)</span><br><span class="line">histList = <span class="built_in">c</span>(<span class="string">&quot;K27me3&quot;</span>, <span class="string">&quot;K4me3&quot;</span>, <span class="string">&quot;IgG&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Collect the alignment results from the bowtie2 alignment summary files</span></span><br><span class="line">alignResult = <span class="built_in">c</span>()</span><br><span class="line"><span class="keyword">for</span>(hist <span class="keyword">in</span> sampleList)&#123;</span><br><span class="line">  alignRes = read.table(paste0(projPath, <span class="string">&quot;/alignment/sam/bowtie2_summary/&quot;</span>, hist, <span class="string">&quot;_bowtie2.txt&quot;</span>), header = <span class="literal">FALSE</span>, fill = <span class="literal">TRUE</span>)</span><br><span class="line">  alignRate = substr(alignRes$V1[<span class="number">6</span>], <span class="number">1</span>, nchar(<span class="built_in">as.character</span>(alignRes$V1[<span class="number">6</span>]))-<span class="number">1</span>)</span><br><span class="line">  histInfo = strsplit(hist, <span class="string">&quot;_&quot;</span>)[[<span class="number">1</span>]]</span><br><span class="line">  alignResult = data.frame(Histone = histInfo[<span class="number">1</span>], Replicate = histInfo[<span class="number">2</span>], </span><br><span class="line">                           SequencingDepth = alignRes$V1[<span class="number">1</span>] %&gt;% <span class="built_in">as.character</span> %&gt;% <span class="built_in">as.numeric</span>, </span><br><span class="line">                           MappedFragNum_hg38 = alignRes$V1[<span class="number">4</span>] %&gt;% <span class="built_in">as.character</span> %&gt;% <span class="built_in">as.numeric</span> + alignRes$V1[<span class="number">5</span>] %&gt;% <span class="built_in">as.character</span> %&gt;% <span class="built_in">as.numeric</span>, </span><br><span class="line">                           AlignmentRate_hg38 = alignRate %&gt;% <span class="built_in">as.numeric</span>)  %&gt;% rbind(alignResult, .)</span><br><span class="line">&#125;</span><br><span class="line">alignResult$Histone = factor(alignResult$Histone, levels = histList)</span><br><span class="line">alignResult %&gt;% mutate(AlignmentRate_hg38 = paste0(AlignmentRate_hg38, <span class="string">&quot;%&quot;</span>))</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-Spike-in-alignment"><a href="#3-2-2-Spike-in-alignment" class="headerlink" title="3.2.2 Spike-in alignment"></a>3.2.2 Spike-in alignment</h3><p>Summary of bowtie2 log file</p>
<h3 id="3-2-3-Summarize-the-alignment-to-hg38-and-E-coli"><a href="#3-2-3-Summarize-the-alignment-to-hg38-and-E-coli" class="headerlink" title="3.2.3 Summarize the alignment to hg38 and E.coli"></a>3.2.3 Summarize the alignment to hg38 and E.coli</h3><p>Summary of bowtie2 log file(ref and ecoli)</p>
<h3 id="3-2-4-Visualizing-the-sequencing-depth-and-alignment-results"><a href="#3-2-4-Visualizing-the-sequencing-depth-and-alignment-results" class="headerlink" title="3.2.4 Visualizing the sequencing depth and alignment results"></a>3.2.4 Visualizing the sequencing depth and alignment results</h3><p><font color="red"><strong>No use</strong></font> . barplot learning</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Generate sequencing depth boxplot</span></span><br><span class="line">fig3A = alignResult %&gt;% ggplot(aes(x = Histone, y = SequencingDepth/1000000, fill = Histone)) +</span><br><span class="line">    geom_boxplot() +</span><br><span class="line">    geom_jitter(aes(color = Replicate), position = position_jitter(0.15)) +</span><br><span class="line">    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.9, option = <span class="string">&quot;magma&quot;</span>, alpha = 0.8) +</span><br><span class="line">    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +</span><br><span class="line">    theme_bw(base_size = 18) +</span><br><span class="line">    ylab(<span class="string">&quot;Sequencing Depth per Million&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>) + </span><br><span class="line">    ggtitle(<span class="string">&quot;A. Sequencing Depth&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>In a typical <strong>CUT&amp;Tag experiment</strong> targeting the abundant <strong>H3K27me3</strong> histone modification in <strong>65,000</strong> <strong>K562 cells</strong>, the <font color="red"><strong>percentage</strong> of <strong>E. coli</strong> reads range from ~<strong>0.01% to 10%</strong></font>. With <font color="red"><strong>fewer cells</strong> or <strong>less abundant epitopes</strong></font>, E. coli reads can comprise[<strong>more</strong>] as much as 70% or the total mapped reads. For <font color="red"><strong>IgG</strong> controls</font>, the percentage of <strong>E. coli</strong> reads is typically <font color="red"><strong>much higher</strong></font> than that for an abundant histone modification.</p>
<h2 id="3-3-Remove-duplicates-optional-required"><a href="#3-3-Remove-duplicates-optional-required" class="headerlink" title="3.3. Remove duplicates [optional/required]"></a>3.3. Remove duplicates [optional/required]</h2><p>CUT&amp;Tag integrates adapters into DNA in the vicinity of the antibody-tethered pA-Tn5, and the exact sites of integration are affected by the accessibility of surrounding DNA. For this reason fragments that share exact starting and ending positions are expected to be common, and <font color="red">such ‘duplicates’ <strong>may not be due to duplication during PCR</strong></font>. In practice, we have found that the <font color="red">apparent <strong>duplication rate is low for high quality CUT&amp;Tag datasets</strong></font>, and even the apparent ‘duplicate’ fragments are <strong>likely to be true fragments</strong>. Thus, we <font color="red"><strong>do not recommend removing</strong> the duplicates</font>. In experiments with very small amounts of material or where PCR duplication is suspected, duplicates can be removed. The following commands show how to check the duplication rate using <a href="https://broadinstitute.github.io/picard/">Picard</a>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line"><span class="comment">## depending on how you load picard and your server environment, the picardCMD can be different. Adjust accordingly.</span></span><br><span class="line">picardCMD=<span class="string">&quot;java -jar picard.jar&quot;</span></span><br><span class="line">mkdir -p <span class="variable">$projPath</span>/alignment/removeDuplicate/picard_summary</span><br><span class="line"></span><br><span class="line"><span class="comment">## Sort by coordinate</span></span><br><span class="line"><span class="variable">$picardCMD</span> SortSam I=<span class="variable">$projPath</span>/alignment/sam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sam O=<span class="variable">$projPath</span>/alignment/sam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sorted.sam SORT_ORDER=coordinate</span><br><span class="line"></span><br><span class="line"><span class="comment">## mark duplicates</span></span><br><span class="line"><span class="variable">$picardCMD</span> MarkDuplicates I=<span class="variable">$projPath</span>/alignment/sam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sorted.sam O=<span class="variable">$projPath</span>/alignment/removeDuplicate/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sorted.dupMarked.sam METRICS_FILE=<span class="variable">$projPath</span>/alignment/removeDuplicate/picard_summary/<span class="variable">$&#123;histName&#125;</span>_picard.dupMark.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">## remove duplicates</span></span><br><span class="line">picardCMD MarkDuplicates I=<span class="variable">$projPath</span>/alignment/sam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sorted.sam O=<span class="variable">$projPath</span>/alignment/removeDuplicate/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sorted.rmDup.sam REMOVE_DUPLICATES=<span class="literal">true</span> METRICS_FILE=<span class="variable">$projPath</span>/alignment/removeDuplicate/picard_summary/<span class="variable">$&#123;histName&#125;</span>_picard.rmDup.txt</span><br></pre></td></tr></table></figure>

<p>We summarize the apparent duplication rate and calculate the unique library size without duplicates.</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line"><span class="comment">## Summarize the duplication information from the picard summary outputs.</span></span><br><span class="line">library(magrittr)</span><br><span class="line">libry(dplyr)</span><br><span class="line">libry)(idyverse</span><br><span class="line">sampleList = <span class="built_in">c</span>(<span class="string">&quot;K27me3_rep1&quot;</span>, <span class="string">&quot;K27me3_rep2&quot;</span>, <span class="string">&quot;K4me3_rep1&quot;</span>, <span class="string">&quot;K4me3_rep2&quot;</span>, <span class="string">&quot;IgG_rep1&quot;</span>, <span class="string">&quot;IgG_rep2&quot;</span>)</span><br><span class="line">histList = <span class="built_in">c</span>(<span class="string">&quot;K27me3&quot;</span>, <span class="string">&quot;K4me3&quot;</span>, <span class="string">&quot;IgG&quot;</span>)</span><br><span class="line"></span><br><span class="line">dupResult = <span class="built_in">c</span>()</span><br><span class="line"><span class="keyword">for</span>(hist <span class="keyword">in</span> sampleList)&#123;</span><br><span class="line">  dupRes = read.table(paste0(projPath, <span class="string">&quot;/alignment/removeDuplicate/picard_summary/&quot;</span>, hist, <span class="string">&quot;_picard.rmDup.txt&quot;</span>), header = <span class="literal">TRUE</span>, fill = <span class="literal">TRUE</span>)</span><br><span class="line">  </span><br><span class="line">  histInfo = strsplit(hist, <span class="string">&quot;_&quot;</span>)[[<span class="number">1</span>]]</span><br><span class="line">  dupResult = data.frame(Histone = histInfo[<span class="number">1</span>], Replicate = histInfo[<span class="number">2</span>], MappedFragNum_hg38 = dupRes$READ_PAIRS_EXAMINED[<span class="number">1</span>] %&gt;% <span class="built_in">as.character</span> %&gt;% <span class="built_in">as.numeric</span>, DuplicationRate = dupRes$PERCENT_DUPLICATION[<span class="number">1</span>] %&gt;% <span class="built_in">as.character</span> %&gt;% <span class="built_in">as.numeric</span> * <span class="number">100</span>, EstimatedLibrarySize = dupRes$ESTIMATED_LIBRARY_SIZE[<span class="number">1</span>] %&gt;% <span class="built_in">as.character</span> %&gt;% <span class="built_in">as.numeric</span>) %&gt;% mutate(UniqueFragNum = MappedFragNum_hg38 * (<span class="number">1</span>-DuplicationRate/<span class="number">100</span>))  %&gt;% rbind(dupResult, .)</span><br><span class="line">&#125;</span><br><span class="line">dupResult$Histone = factor(dupResult$Histone, levels = histList)</span><br><span class="line">alignDupSummary = left_join(alignSummary, dupResult, by = <span class="built_in">c</span>(<span class="string">&quot;Histone&quot;</span>, <span class="string">&quot;Replicate&quot;</span>, <span class="string">&quot;MappedFragNum_hg38&quot;</span>)) %&gt;% mutate(DuplicationRate = paste0(DuplicationRate, <span class="string">&quot;%&quot;</span>))</span><br><span class="line">alignDupSummary</span><br></pre></td></tr></table></figure>

<p>计算总reads，比对到ref和ecoli的frag和ratio，计算<strong>duplicationrate，estimatedlibrarysize和uniqueFragNum</strong></p>
<ul>
<li>In these example datasets, the <strong>IgG</strong> control samples have <strong>relatively high duplication rates</strong>, since reads in this sample derive from <strong>non-specific tagmentation</strong> in the CUT&amp;Tag reactions. Therefore, <font color="red">it is appropriate to <strong>remove the duplicates</strong> from the <strong>IgG</strong> datasets before downstream analysis</font>.</li>
<li>The <font color="red"><strong>estimated library size</strong></font> are the estimated <strong>number of unique molecules in the library based on PE duplication</strong> calculated by <strong>Picard</strong>.</li>
<li>The estimated library sizes is proportional to the <strong>abundance of the targeted epitope</strong> and to the <strong>quality of the antibody</strong> used, while the estimated library sizes of <font color="red">IgG</font> samples are expected to be <font color="red">very low</font>.</li>
<li><strong>Unique fragment number</strong> is calculated by the MappedFragNum_hg38 * (1-DuplicationRate/100).</li>
</ul>
<p><font color="red"><strong>no use</strong>, code</font></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line"><span class="comment">## generate boxplot figure for the  duplication rate</span></span><br><span class="line">fig4A = dupResult %&gt;% ggplot(aes(x = Histone, y = DuplicationRate, fill = Histone)) +</span><br><span class="line">    geom_boxplot() +</span><br><span class="line">    geom_jitter(aes(color = Replicate), position = position_jitter(<span class="number">0.15</span>)) +</span><br><span class="line">    scale_fill_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>, option = <span class="string">&quot;magma&quot;</span>, alpha = <span class="number">0.8</span>) +</span><br><span class="line">    scale_color_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>) +</span><br><span class="line">    theme_bw(base_size = <span class="number">18</span>) +</span><br><span class="line">    ylab(<span class="string">&quot;Duplication Rate (*100%)&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>) </span><br><span class="line"><span class="comment">## generate boxplot figure for the  Estimated Library Size</span></span><br><span class="line">fig4B = dupResult %&gt;% ggplot(aes(x = Histone, y = EstimatedLibrarySize, fill = Histone)) +</span><br><span class="line">    geom_boxplot() +</span><br><span class="line">    geom_jitter(aes(color = Replicate), position = position_jitter(<span class="number">0.15</span>)) +</span><br><span class="line">    scale_fill_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>, option = <span class="string">&quot;magma&quot;</span>, alpha = <span class="number">0.8</span>) +</span><br><span class="line">    scale_color_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>) +</span><br><span class="line">    theme_bw(base_size = <span class="number">18</span>) +</span><br><span class="line">    ylab(<span class="string">&quot;Estimated Library Size&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>) </span><br><span class="line"><span class="comment">## generate boxplot figure for the  Unique Fragments</span></span><br><span class="line">fig4C = dupResult %&gt;% ggplot(aes(x = Histone, y = UniqueFragNum, fill = Histone)) +</span><br><span class="line">    geom_boxplot() +</span><br><span class="line">    geom_jitter(aes(color = Replicate), position = position_jitter(<span class="number">0.15</span>)) +</span><br><span class="line">    scale_fill_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>, option = <span class="string">&quot;magma&quot;</span>, alpha = <span class="number">0.8</span>) +</span><br><span class="line">    scale_color_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>) +</span><br><span class="line">    theme_bw(base_size = <span class="number">18</span>) +</span><br><span class="line">    ylab(<span class="string">&quot;# of Unique Fragments&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">ggarrange(fig4A, fig4B, fig4C, ncol = <span class="number">3</span>, common.legend = <span class="literal">TRUE</span>, legend=<span class="string">&quot;bottom&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3-4-Assess-mapped-fragment-size-distribution-Required"><a href="#3-4-Assess-mapped-fragment-size-distribution-Required" class="headerlink" title="3.4. Assess mapped fragment size distribution [Required]"></a>3.4. Assess mapped fragment size distribution [Required]</h2><p>CUT&amp;Tag inserts adapters on either side of chromatin particles in the vicinity of the tethered enzyme, although tagmentation within chromatin particles can also occur. So, CUT&amp;Tag reactions targeting a histone modification predominantly results in fragments that are nucleosomal lengths (~180 bp), or multiples of that length. CUT&amp;Tag targeting transcription factors predominantly produce nucleosome-sized fragments and variable amounts of shorter fragments, from neighboring nucleosomes and the factor-bound site, respectively. Tagmentation of DNA on the surface of nucleosomes also occurs, and plotting fragment lengths with single-basepair resolution reveal a 10-bp sawtooth periodicity, which is typical of successful CUT&amp;Tag experiments.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##== linux command ==##</span><br><span class="line">mkdir -p $projPath/alignment/sam/fragmentLen</span><br><span class="line"></span><br><span class="line">## Extract the 9th column from the alignment sam file which is the fragment length</span><br><span class="line">samtools view -F 0x04 $projPath/alignment/sam/$&#123;histName&#125;_bowtie2.sam | awk -F&#x27;\t&#x27; &#x27;function abs(x)&#123;return ((x &lt; 0.0) ? -x : x)&#125; &#123;print abs($9)&#125;&#x27; | sort | uniq -c | awk -v OFS=&quot;\t&quot; &#x27;&#123;print $2, $1/2&#125;&#x27; &gt;$projPath/alignment/sam/fragmentLen/$&#123;histName&#125;_fragmentLen.txt</span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line"><span class="comment">## Collect the fragment size information</span></span><br><span class="line">fragLen = <span class="built_in">c</span>()</span><br><span class="line"><span class="keyword">for</span>(hist <span class="keyword">in</span> sampleList)&#123;</span><br><span class="line">  </span><br><span class="line">  histInfo = strsplit(hist, <span class="string">&quot;_&quot;</span>)[[<span class="number">1</span>]]</span><br><span class="line">  fragLen = read.table(paste0(projPath, <span class="string">&quot;/alignment/sam/fragmentLen/&quot;</span>, hist, <span class="string">&quot;_fragmentLen.txt&quot;</span>), header = <span class="literal">FALSE</span>) %&gt;% mutate(fragLen = V1 %&gt;% <span class="built_in">as.numeric</span>, fragCount = V2 %&gt;% <span class="built_in">as.numeric</span>, Weight = <span class="built_in">as.numeric</span>(V2)/<span class="built_in">sum</span>(<span class="built_in">as.numeric</span>(V2)), Histone = histInfo[<span class="number">1</span>], Replicate = histInfo[<span class="number">2</span>], sampleInfo = hist) %&gt;% rbind(fragLen, .) </span><br><span class="line">&#125;</span><br><span class="line">fragLen$sampleInfo = factor(fragLen$sampleInfo, levels = sampleList)</span><br><span class="line">fragLen$Histone = factor(fragLen$Histone, levels = histList)</span><br><span class="line"><span class="comment">## Generate the fragment size density plot (violin plot)</span></span><br><span class="line">fig5A = fragLen %&gt;% ggplot(aes(x = sampleInfo, y = fragLen, weight = Weight, fill = Histone)) +</span><br><span class="line">    geom_violin(bw = <span class="number">5</span>) +</span><br><span class="line">    scale_y_continuous(breaks = seq(<span class="number">0</span>, <span class="number">800</span>, <span class="number">50</span>)) +</span><br><span class="line">    scale_fill_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>, option = <span class="string">&quot;magma&quot;</span>, alpha = <span class="number">0.8</span>) +</span><br><span class="line">    scale_color_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>) +</span><br><span class="line">    theme_bw(base_size = <span class="number">20</span>) +</span><br><span class="line">    ggpubr::rotate_x_text(angle = <span class="number">20</span>) +</span><br><span class="line">    ylab(<span class="string">&quot;Fragment Length&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">fig5B = fragLen %&gt;% ggplot(aes(x = fragLen, y = fragCount, color = Histone, group = sampleInfo, linetype = Replicate)) +</span><br><span class="line">  geom_line(size = <span class="number">1</span>) +</span><br><span class="line">  scale_color_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>, option = <span class="string">&quot;magma&quot;</span>) +</span><br><span class="line">  theme_bw(base_size = <span class="number">20</span>) +</span><br><span class="line">  xlab(<span class="string">&quot;Fragment Length&quot;</span>) +</span><br><span class="line">  ylab(<span class="string">&quot;Count&quot;</span>) +</span><br><span class="line">  coord_cartesian(xlim = <span class="built_in">c</span>(<span class="number">0</span>, <span class="number">500</span>))</span><br><span class="line"></span><br><span class="line">ggarrange(fig5A, fig5B, ncol = <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/blog/2022/03/21/2022-03-21-CUTTag/4.png"></p>
<ul>
<li>The smaller fragments (50-100 bp) can be due to that tethered Tn5 can tagment on the surface of a nucleosome as well as in linker regions(NFR?), so the <strong>small fragments might not be background.</strong></li>
</ul>
<h2 id="3-5-Assess-replicate-reproducibility"><a href="#3-5-Assess-replicate-reproducibility" class="headerlink" title="3.5 Assess replicate reproducibility"></a>3.5 Assess replicate reproducibility</h2><p>Data reproducibility between replicates is assessed by <strong>correlation</strong> analysis of <strong>mapped read counts</strong> across the genome. For the simplicity of implementation, we will postpone this analysis after Section IV when the file format has been converted into fragment bed files.</p>
<hr>
<h1 id="IV-Alignments-results-filtering-and-file-format-conversion"><a href="#IV-Alignments-results-filtering-and-file-format-conversion" class="headerlink" title="IV. Alignments results filtering and file format conversion"></a>IV. Alignments results filtering and file format conversion</h1><h2 id="4-1-Filtering-mapped-reads-by-the-mapping-quality-filtering-optinal"><a href="#4-1-Filtering-mapped-reads-by-the-mapping-quality-filtering-optinal" class="headerlink" title="4.1 Filtering mapped reads by the mapping quality filtering [optinal]"></a>4.1 Filtering mapped reads by the mapping quality filtering [<font color="red">optinal</font>]</h2><p>Some project may require more stringent filtering on the alignment quality score. This <a href="http://biofinysics.blogspot.com/2014/05/how-does-bowtie2-assign-mapq-scores.html">blog</a> detailedly discussed how does bowtie assign quality score with examples.</p>
<p>MAPQ(x) = -10 * log10(P(x is mapped wrongly)) = -10 * log10(p)</p>
<p>which ranges from 0 to 37, 40 or 42.</p>
<p><code>samtools view -q minQualityScore</code> will <strong>eliminate</strong> all the alignment results that are below the minQualityScore defined by user.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line">minQualityScore=2<span class="comment">#20?30?</span></span><br><span class="line">samtools view -q <span class="variable">$minQualityScore</span> <span class="variable">$&#123;projPath&#125;</span>/alignment/sam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sam &gt;<span class="variable">$&#123;projPath&#125;</span>/alignment/sam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.qualityScore<span class="variable">$minQualityScore</span>.sam</span><br></pre></td></tr></table></figure>

<ul>
<li>If you do implement this filtering, please replace the <code>$&#123;histName&#125;_bowtie2.sam</code> in the following steps by this filtered sam file <code>$&#123;histName&#125;_bowtie2.qualityScore$minQualityScore.sam</code>. <font color="red">Use the MAPQ20/30 reads</font></li>
</ul>
<h2 id="4-2-File-format-conversion-required"><a href="#4-2-File-format-conversion-required" class="headerlink" title="4.2 File format conversion [required]"></a>4.2 File format conversion [required]</h2><p>This section is <strong>required</strong> in preparation for the <font color="red">peak calling</font> and <font color="red">visualization</font> where there are a few filtering and file format conversion that need to be done.</p>
<p>For example, in MACS2, it has bed(shift extent mode) and pe mode</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line"><span class="comment">## Filter and keep the mapped read pairs</span></span><br><span class="line">samtools view -bS -F 0x4 <span class="variable">$projPath</span>/alignment/sam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.sam &gt;<span class="variable">$projPath</span>/alignment/bam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.mapped.bam</span><br><span class="line"></span><br><span class="line"><span class="comment">## Convert into bed file format</span></span><br><span class="line">bedtools bamtobed -i <span class="variable">$projPath</span>/alignment/bam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.mapped.bam -bedpe &gt;<span class="variable">$projPath</span>/alignment/bed/<span class="variable">$&#123;histName&#125;</span>_bowtie2.bed</span><br><span class="line"></span><br><span class="line"><span class="comment">## Keep the read pairs that are on the same chromosome and fragment length less than 1000bp.</span></span><br><span class="line">awk <span class="string">&#x27;$1==$4 &amp;&amp; $6-$2 &lt; 1000 &#123;print $0&#125;&#x27;</span> <span class="variable">$projPath</span>/alignment/bed/<span class="variable">$&#123;histName&#125;</span>_bowtie2.bed &gt;<span class="variable">$projPath</span>/alignment/bed/<span class="variable">$&#123;histName&#125;</span>_bowtie2.clean.bed</span><br><span class="line"></span><br><span class="line"><span class="comment">## Only extract the fragment related columns</span></span><br><span class="line">cut -f 1,2,6 <span class="variable">$projPath</span>/alignment/bed/<span class="variable">$&#123;histName&#125;</span>_bowtie2.clean.bed | sort -k1,1 -k2,2n -k3,3n  &gt;<span class="variable">$projPath</span>/alignment/bed/<span class="variable">$&#123;histName&#125;</span>_bowtie2.fragments.bed</span><br></pre></td></tr></table></figure>

<h2 id="4-3-Assess-replicate-reproducibility-continue-section-3-5"><a href="#4-3-Assess-replicate-reproducibility-continue-section-3-5" class="headerlink" title="4.3 Assess replicate reproducibility (continue section 3.5)"></a>4.3 Assess replicate reproducibility (continue section 3.5)</h2><p>To study the reproducibility between replicates and across conditions, the <strong>genome is split into 500 bp bins</strong>, and a <strong>Pearson correlation of the log2-transformed values</strong> of <strong>read counts in each bin</strong> is calculated between replicate datasets. Multiple replicates and IgG control datasets are displayed in a hierarchically clustered correlation matrix.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line"><span class="comment">## We use the mid point of each fragment to infer which 500bp bins does this fragment belong to.</span></span><br><span class="line">binLen=500</span><br><span class="line">awk -v w=<span class="variable">$binLen</span> <span class="string">&#x27;&#123;print $1, int(($2 + $3)/(2*w))*w + w/2&#125;&#x27;</span> <span class="variable">$projPath</span>/alignment/bed/<span class="variable">$&#123;histName&#125;</span>_bowtie2.fragments.bed | sort -k1,1V -k2,2n | uniq -c | awk -v OFS=<span class="string">&quot;\t&quot;</span> <span class="string">&#x27;&#123;print $2, $3, $1&#125;&#x27;</span> |  sort -k1,1V -k2,2n  &gt;<span class="variable">$projPath</span>/alignment/bed/<span class="variable">$&#123;histName&#125;</span>_bowtie2.fragmentsCount.bin<span class="variable">$binLen</span>.bed</span><br></pre></td></tr></table></figure>



<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== R command ==##</span></span><br><span class="line">reprod = <span class="built_in">c</span>()</span><br><span class="line">fragCount = <span class="literal">NULL</span></span><br><span class="line"><span class="keyword">for</span>(hist <span class="keyword">in</span> sampleList)&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(<span class="built_in">is.null</span>(fragCount))&#123;</span><br><span class="line">    </span><br><span class="line">    fragCount = read.table(paste0(projPath, <span class="string">&quot;/alignment/bed/&quot;</span>, hist, <span class="string">&quot;_bowtie2.fragmentsCount.bin500.bed&quot;</span>), header = <span class="literal">FALSE</span>) </span><br><span class="line">    colnames(fragCount) = <span class="built_in">c</span>(<span class="string">&quot;chrom&quot;</span>, <span class="string">&quot;bin&quot;</span>, hist)</span><br><span class="line">  </span><br><span class="line">  &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    </span><br><span class="line">    fragCountTmp = read.table(paste0(projPath, <span class="string">&quot;/alignment/bed/&quot;</span>, hist, <span class="string">&quot;_bowtie2.fragmentsCount.bin500.bed&quot;</span>), header = <span class="literal">FALSE</span>)</span><br><span class="line">    colnames(fragCountTmp) = <span class="built_in">c</span>(<span class="string">&quot;chrom&quot;</span>, <span class="string">&quot;bin&quot;</span>, hist)</span><br><span class="line">    fragCount = full_join(fragCount, fragCountTmp, by = <span class="built_in">c</span>(<span class="string">&quot;chrom&quot;</span>, <span class="string">&quot;bin&quot;</span>))</span><br><span class="line">    </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">M = cor(fragCount %&gt;% select(-<span class="built_in">c</span>(<span class="string">&quot;chrom&quot;</span>, <span class="string">&quot;bin&quot;</span>)) %&gt;% log2(), use = <span class="string">&quot;complete.obs&quot;</span>) </span><br><span class="line"></span><br><span class="line">corrplot(M, method = <span class="string">&quot;color&quot;</span>, outline = <span class="built_in">T</span>, addgrid.col = <span class="string">&quot;darkgray&quot;</span>, order=<span class="string">&quot;hclust&quot;</span>, addrect = <span class="number">3</span>, rect.col = <span class="string">&quot;black&quot;</span>, rect.lwd = <span class="number">3</span>,cl.pos = <span class="string">&quot;b&quot;</span>, tl.col = <span class="string">&quot;indianred4&quot;</span>, tl.cex = <span class="number">1</span>, cl.cex = <span class="number">1</span>, addCoef.col = <span class="string">&quot;black&quot;</span>, number.digits = <span class="number">2</span>, number.cex = <span class="number">1</span>, col = colorRampPalette(<span class="built_in">c</span>(<span class="string">&quot;midnightblue&quot;</span>,<span class="string">&quot;white&quot;</span>,<span class="string">&quot;darkred&quot;</span>))(<span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<p><img src="/blog/2022/03/21/2022-03-21-CUTTag/5.png"></p>
<hr>
<h1 id="V-Spike-in-calibration"><a href="#V-Spike-in-calibration" class="headerlink" title="V. Spike-in calibration"></a>V. Spike-in calibration</h1><p>This section is <strong>optional</strong> but <strong>recommended</strong> depending on your experimental protocol. We have shown the alignment to the spike-in genome in Section 3.1.2 and the spike-in alignment summary in Section 3.2.2.</p>
<p>The underlying assumption is that the ratio of fragments mapped to the primary genome to the E. coli genome is the same for a series of samples, each using the same number of cells. Because of this assumption, we do not normalize between experiments or between batches of purified pATn5, which can have very different amounts of carry-over E. coli DNA. Using a constant C to avoid small fractions in normalized data, we define a scaling factor S as</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">S = C / (fragments mapped to E. coli genome)</span><br></pre></td></tr></table></figure>

<p>Normalized coverage is then calculated as:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Normalized coverage = (primary_genome_coverage) * S</span><br></pre></td></tr></table></figure>

<p>The Constant is an arbitrary multiplier, typically 10,000. The resulting file will be comparatively small as a genomic coverage bedgraph file.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">&quot;<span class="variable">$seqDepth</span>&quot;</span> -gt <span class="string">&quot;1&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    </span><br><span class="line">    mkdir -p <span class="variable">$projPath</span>/alignment/bedgraph</span><br><span class="line"></span><br><span class="line">    scale_factor=`<span class="built_in">echo</span> <span class="string">&quot;10000 / <span class="variable">$seqDepth</span>&quot;</span> | bc -l`</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Scaling factor for <span class="variable">$histName</span> is: <span class="variable">$scale_factor</span>!&quot;</span></span><br><span class="line">    bedtools genomecov -<span class="built_in">bg</span> -scale <span class="variable">$scale_factor</span> -i <span class="variable">$projPath</span>/alignment/bed/<span class="variable">$&#123;histName&#125;</span>_bowtie2.fragments.bed -g <span class="variable">$chromSize</span> &gt; <span class="variable">$projPath</span>/alignment/bedgraph/<span class="variable">$&#123;histName&#125;</span>_bowtie2.fragments.normalized.bedgraph</span><br><span class="line">    </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<h2 id="5-1-Scaling-factor"><a href="#5-1-Scaling-factor" class="headerlink" title="5.1 Scaling factor"></a>5.1 Scaling factor</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line">scaleFactor = <span class="built_in">c</span>()</span><br><span class="line">multiplier = <span class="number">10000</span></span><br><span class="line"><span class="keyword">for</span>(hist <span class="keyword">in</span> sampleList)&#123;</span><br><span class="line">  spikeDepth = read.table(paste0(projPath, <span class="string">&quot;/alignment/sam/bowtie2_summary/&quot;</span>, hist, <span class="string">&quot;_bowtie2_spikeIn.seqDepth&quot;</span>), header = <span class="literal">FALSE</span>, fill = <span class="literal">TRUE</span>)$V1[<span class="number">1</span>]</span><br><span class="line">  </span><br><span class="line">  histInfo = strsplit(hist, <span class="string">&quot;_&quot;</span>)[[<span class="number">1</span>]]</span><br><span class="line">  scaleFactor = data.frame(scaleFactor = multiplier/spikeDepth, Histone = histInfo[<span class="number">1</span>], Replicate = histInfo[<span class="number">2</span>])  %&gt;% rbind(scaleFactor, .)</span><br><span class="line">&#125;</span><br><span class="line">scaleFactor$Histone = factor(scaleFactor$Histone, levels = histList)</span><br><span class="line">left_join(alignDupSummary, scaleFactor, by = <span class="built_in">c</span>(<span class="string">&quot;Histone&quot;</span>, <span class="string">&quot;Replicate&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>Histone<br>Replicate<br>SequencingDepth<br>MappedFragNum_hg38<br>AlignmentRate_hg38<br>MappedFragNum_spikeIn<br>AlignmentRate_spikeIn<br><strong>DuplicationRate</strong><br><strong>EstimatedLibrarySize</strong><br><strong>UniqueFragNum</strong><br><strong>scaleFactor</strong></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===##</span></span><br><span class="line"><span class="comment">## Generate sequencing depth boxplot</span></span><br><span class="line">fig6A = scaleFactor %&gt;% ggplot(aes(x = Histone, y = scaleFactor, fill = Histone)) +</span><br><span class="line">    geom_boxplot() +</span><br><span class="line">    geom_jitter(aes(color = Replicate), position = position_jitter(<span class="number">0.15</span>)) +</span><br><span class="line">    scale_fill_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>, option = <span class="string">&quot;magma&quot;</span>, alpha = <span class="number">0.8</span>) +</span><br><span class="line">    scale_color_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>) +</span><br><span class="line">    theme_bw(base_size = <span class="number">20</span>) +</span><br><span class="line">    ylab(<span class="string">&quot;Spike-in Scalling Factor&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">normDepth = inner_join(scaleFactor, alignResult, by = <span class="built_in">c</span>(<span class="string">&quot;Histone&quot;</span>, <span class="string">&quot;Replicate&quot;</span>)) %&gt;% mutate(normDepth = MappedFragNum_hg38 * scaleFactor)</span><br><span class="line"></span><br><span class="line">fig6B = normDepth %&gt;% ggplot(aes(x = Histone, y = normDepth, fill = Histone)) +</span><br><span class="line">    geom_boxplot() +</span><br><span class="line">    geom_jitter(aes(color = Replicate), position = position_jitter(<span class="number">0.15</span>)) +</span><br><span class="line">    scale_fill_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>, option = <span class="string">&quot;magma&quot;</span>, alpha = <span class="number">0.8</span>) +</span><br><span class="line">    scale_color_viridis(discrete = <span class="literal">TRUE</span>, begin = <span class="number">0.1</span>, end = <span class="number">0.9</span>) +</span><br><span class="line">    theme_bw(base_size = <span class="number">20</span>) +</span><br><span class="line">    ylab(<span class="string">&quot;Normalization Fragment Count&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>) + </span><br><span class="line">    coord_cartesian(ylim = <span class="built_in">c</span>(<span class="number">1000000</span>, <span class="number">130000000</span>))</span><br><span class="line">ggarrange(fig6A, fig6B, ncol = <span class="number">2</span>, common.legend = <span class="literal">TRUE</span>, legend=<span class="string">&quot;bottom&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/blog/2022/03/21/2022-03-21-CUTTag/6.png"></p>
<hr>
<h1 id="VI-Peak-calling"><a href="#VI-Peak-calling" class="headerlink" title="VI. Peak calling"></a>VI. Peak calling</h1><h2 id="6-1-SEACR"><a href="#6-1-SEACR" class="headerlink" title="6.1. SEACR"></a>6.1. SEACR</h2><p>The Sparse Enrichment Analysis for CUT&amp;RUN, <a href="https://github.com/FredHutch/SEACR/">SEACR</a>, package is designed to call peaks and enriched regions from chromatin profiling data with very low backgrounds (i.e., regions with no read coverage) that are typical for CUT&amp;Tag chromatin profiling experiments. SEACR requires bedGraph files from paired-end sequencing as input and defines peaks as contiguous blocks of basepair coverage that do not overlap with blocks of background signal delineated in the IgG control dataset. SEACR is effective for calling both narrow peaks from factor binding sites and broad domains characteristic of some histone modifications. The description of the method is published at <a href="https://epigeneticsandchromatin.biomedcentral.com/articles/10.1186/s13072-019-0287-4">Meers et al. 2019</a>, and the user’s manual is available on <a href="https://github.com/FredHutch/SEACR/">github</a>. Since we have normalized fragment counts with the E. coli read count, we set the normalization option of SEACR to “non”. Otherwise, the “norm” is recommended.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line">seacr=<span class="string">&quot;/fh/fast/gottardo_r/yezheng_working/Software/SEACR/SEACR_1.3.sh&quot;</span></span><br><span class="line">histControl=<span class="variable">$2</span></span><br><span class="line">mkdir -p <span class="variable">$projPath</span>/peakCalling/SEACR</span><br><span class="line"></span><br><span class="line">bash <span class="variable">$seacr</span> <span class="variable">$projPath</span>/alignment/bedgraph/<span class="variable">$&#123;histName&#125;</span>_bowtie2.fragments.normalized.bedgraph \</span><br><span class="line">     <span class="variable">$projPath</span>/alignment/bedgraph/<span class="variable">$&#123;histControl&#125;</span>_bowtie2.fragments.normalized.bedgraph \</span><br><span class="line">     non stringent <span class="variable">$projPath</span>/peakCalling/SEACR/<span class="variable">$&#123;histName&#125;</span>_seacr_control.peaks</span><br><span class="line"></span><br><span class="line">bash <span class="variable">$seacr</span> <span class="variable">$projPath</span>/alignment/bedgraph/<span class="variable">$&#123;histName&#125;</span>_bowtie2.fragments.normalized.bedgraph 0.01 non stringent <span class="variable">$projPath</span>/peakCalling/SEACR/<span class="variable">$&#123;histName&#125;</span>_seacr_top0.01.peaks</span><br></pre></td></tr></table></figure>

<h3 id="6-1-1-Number-of-peaks-called"><a href="#6-1-1-Number-of-peaks-called" class="headerlink" title="6.1.1 Number of peaks called"></a>6.1.1 Number of peaks called</h3><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line">peakN = <span class="built_in">c</span>()</span><br><span class="line">peakWidth = <span class="built_in">c</span>()</span><br><span class="line">peakType = <span class="built_in">c</span>(<span class="string">&quot;control&quot;</span>, <span class="string">&quot;top0.01&quot;</span>)</span><br><span class="line"><span class="keyword">for</span>(hist <span class="keyword">in</span> sampleList)&#123;</span><br><span class="line">  histInfo = strsplit(hist, <span class="string">&quot;_&quot;</span>)[[<span class="number">1</span>]]</span><br><span class="line">  <span class="keyword">if</span>(histInfo[<span class="number">1</span>] != <span class="string">&quot;IgG&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span>(type <span class="keyword">in</span> peakType)&#123;</span><br><span class="line">      peakInfo = read.table(paste0(projPath, <span class="string">&quot;/peakCalling/SEACR/&quot;</span>, hist, <span class="string">&quot;_seacr_&quot;</span>, type, <span class="string">&quot;.peaks.stringent.bed&quot;</span>), header = <span class="literal">FALSE</span>, fill = <span class="literal">TRUE</span>)  %&gt;% mutate(width = <span class="built_in">abs</span>(V3-V2))</span><br><span class="line">      peakN = data.frame(peakN = nrow(peakInfo), peakType = type, Histone = histInfo[<span class="number">1</span>], Replicate = histInfo[<span class="number">2</span>]) %&gt;% rbind(peakN, .)</span><br><span class="line">      peakWidth = data.frame(width = peakInfo$width, peakType = type, Histone = histInfo[<span class="number">1</span>], Replicate = histInfo[<span class="number">2</span>])  %&gt;% rbind(peakWidth, .)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">peakN %&gt;% select(Histone, Replicate, peakType, peakN)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">Histone<chr></chr></th>
<th align="left">Replicate<chr></chr></th>
<th align="left">peakType<chr></chr></th>
<th align="right">peakN<int></int></th>
</tr>
</thead>
<tbody><tr>
<td align="left">K27me3</td>
<td align="left">rep1</td>
<td align="left">control</td>
<td align="right">144906</td>
</tr>
<tr>
<td align="left">K27me3</td>
<td align="left">rep1</td>
<td align="left">top0.01</td>
<td align="right">5829</td>
</tr>
<tr>
<td align="left">K27me3</td>
<td align="left">rep2</td>
<td align="left">control</td>
<td align="right">74444</td>
</tr>
<tr>
<td align="left">K27me3</td>
<td align="left">rep2</td>
<td align="left">top0.01</td>
<td align="right">9642</td>
</tr>
<tr>
<td align="left">K4me3</td>
<td align="left">rep1</td>
<td align="left">control</td>
<td align="right">8709</td>
</tr>
<tr>
<td align="left">K4me3</td>
<td align="left">rep1</td>
<td align="left">top0.01</td>
<td align="right">878</td>
</tr>
</tbody></table>
<h3 id="6-1-2-Reproducibility-of-the-peak-across-biological-replicates"><a href="#6-1-2-Reproducibility-of-the-peak-across-biological-replicates" class="headerlink" title="6.1.2 Reproducibility of the peak across biological replicates"></a>6.1.2 Reproducibility of the peak across biological replicates</h3><p>Peak calling on replicate datasets is compared to define reproducible peaks. The top 1% of peaks (ranked by total signal in each block) are selected as high-confidence sites.</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line">histL = <span class="built_in">c</span>(<span class="string">&quot;K27me3&quot;</span>, <span class="string">&quot;K4me3&quot;</span>)</span><br><span class="line">repL = paste0(<span class="string">&quot;rep&quot;</span>, <span class="number">1</span>:<span class="number">2</span>)</span><br><span class="line">peakType = <span class="built_in">c</span>(<span class="string">&quot;control&quot;</span>, <span class="string">&quot;top0.01&quot;</span>)</span><br><span class="line">peakOverlap = <span class="built_in">c</span>()</span><br><span class="line"><span class="keyword">for</span>(type <span class="keyword">in</span> peakType)&#123;</span><br><span class="line">  <span class="keyword">for</span>(hist <span class="keyword">in</span> histL)&#123;</span><br><span class="line">    overlap.gr = GRanges()</span><br><span class="line">    <span class="keyword">for</span>(<span class="built_in">rep</span> <span class="keyword">in</span> repL)&#123;</span><br><span class="line">      peakInfo = read.table(paste0(projPath, <span class="string">&quot;/peakCalling/SEACR/&quot;</span>, hist, <span class="string">&quot;_&quot;</span>, <span class="built_in">rep</span>, <span class="string">&quot;_seacr_&quot;</span>, type, <span class="string">&quot;.peaks.stringent.bed&quot;</span>), header = <span class="literal">FALSE</span>, fill = <span class="literal">TRUE</span>)</span><br><span class="line">      peakInfo.gr = GRanges(peakInfo$V1, IRanges(start = peakInfo$V2, end = peakInfo$V3), strand = <span class="string">&quot;*&quot;</span>)</span><br><span class="line">      <span class="keyword">if</span>(<span class="built_in">length</span>(overlap.gr) &gt;<span class="number">0</span>)&#123;</span><br><span class="line">        overlap.gr = overlap.gr[findOverlaps(overlap.gr, peakInfo.gr)@from]</span><br><span class="line">      &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        overlap.gr = peakInfo.gr</span><br><span class="line">        </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    peakOverlap = data.frame(peakReprod = <span class="built_in">length</span>(overlap.gr), Histone = hist, peakType = type) %&gt;% rbind(peakOverlap, .)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">peakReprod = left_join(peakN, peakOverlap, by = <span class="built_in">c</span>(<span class="string">&quot;Histone&quot;</span>, <span class="string">&quot;peakType&quot;</span>)) %&gt;% mutate(peakReprodRate = peakReprod/peakN * <span class="number">100</span>)</span><br><span class="line">peakReprod %&gt;% select(Histone, Replicate, peakType, peakN, peakReprodNum = peakReprod, peakReprodRate)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">Histone<chr></chr></th>
<th align="left">Replicate<chr></chr></th>
<th align="left">peakType<chr></chr></th>
<th align="right">peakN<int></int></th>
<th align="right">peakReprodNum<int></int></th>
<th align="right">peakReprodRate<dbl></dbl></th>
</tr>
</thead>
<tbody><tr>
<td align="left">K27me3</td>
<td align="left">rep1</td>
<td align="left">control</td>
<td align="right">144906</td>
<td align="right">71692</td>
<td align="right">49.47483</td>
</tr>
<tr>
<td align="left">K27me3</td>
<td align="left">rep1</td>
<td align="left">top0.01</td>
<td align="right">5829</td>
<td align="right">5314</td>
<td align="right">91.16487</td>
</tr>
<tr>
<td align="left">K27me3</td>
<td align="left">rep2</td>
<td align="left">control</td>
<td align="right">74444</td>
<td align="right">71692</td>
<td align="right">96.30326</td>
</tr>
<tr>
<td align="left">K27me3</td>
<td align="left">rep2</td>
<td align="left">top0.01</td>
<td align="right">9642</td>
<td align="right">5314</td>
<td align="right">55.11305</td>
</tr>
</tbody></table>
<p>The reproducibility is calculated by</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`# peaks overlapping rep1 and rep2/# peaks of rep1 or rep2 * 100</span><br></pre></td></tr></table></figure>

<p>Therefore, it is sensitive to the total number of peaks called in each replicate.</p>
<h3 id="6-1-3-FRagment-proportion-in-Peaks-regions-FRiPs"><a href="#6-1-3-FRagment-proportion-in-Peaks-regions-FRiPs" class="headerlink" title="6.1.3 FRagment proportion in Peaks regions (FRiPs)."></a>6.1.3 FRagment proportion in Peaks regions (FRiPs).</h3><p>We calculate the fraction of reads in peaks (FRiPs) as a measure of signal-to-noise, and contrast it to FRiPs in the IgG control dataset for illustration. Although sequencing depths for CUT&amp;Tag are typically only 1-5 million reads, the low background of the method results in high FRiP scores.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##=== R command ===## </span><br><span class="line">library(chromVAR)</span><br><span class="line"></span><br><span class="line">bamDir = paste0(projPath, &quot;/alignment/bam&quot;)</span><br><span class="line">inPeakData = c()</span><br><span class="line">## overlap with bam file to get count</span><br><span class="line">for(hist in histL)&#123;</span><br><span class="line">  for(rep in repL)&#123;</span><br><span class="line">    peakRes = read.table(paste0(projPath, &quot;/peakCalling/SEACR/&quot;, hist, &quot;_&quot;, rep, &quot;_seacr_control.peaks.stringent.bed&quot;), header = FALSE, fill = TRUE)</span><br><span class="line">    peak.gr = GRanges(seqnames = peakRes$V1, IRanges(start = peakRes$V2, end = peakRes$V3), strand = &quot;*&quot;)</span><br><span class="line">    bamFile = paste0(bamDir, &quot;/&quot;, hist, &quot;_&quot;, rep, &quot;_bowtie2.mapped.bam&quot;)</span><br><span class="line">    fragment_counts &lt;- getCounts(bamFile, peak.gr, paired = TRUE, by_rg = FALSE, format = &quot;bam&quot;)</span><br><span class="line">    inPeakN = counts(fragment_counts)[,1] %&gt;% sum</span><br><span class="line">    inPeakData = rbind(inPeakData, data.frame(inPeakN = inPeakN, Histone = hist, Replicate = rep))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">frip = left_join(inPeakData, alignResult, by = c(&quot;Histone&quot;, &quot;Replicate&quot;)) %&gt;% mutate(frip = inPeakN/MappedFragNum_hg38 * 100)</span><br><span class="line">frip %&gt;% select(Histone, Replicate, SequencingDepth, MappedFragNum_hg38, AlignmentRate_hg38, FragInPeakNum = inPeakN, FRiPs = frip)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">Histone<chr></chr></th>
<th align="left">Replicate<chr></chr></th>
<th align="right">SequencingDepth<dbl></dbl></th>
<th align="right">MappedFragNum_hg38<dbl></dbl></th>
<th align="right">AlignmentRate_hg38<dbl></dbl></th>
<th align="right">FragInPeakNum<dbl></dbl></th>
<th align="left"><strong>FRiPs</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">K27me3</td>
<td align="left">rep1</td>
<td align="right">2984630</td>
<td align="right">2859520</td>
<td align="right">95.81</td>
<td align="right">2223813</td>
<td align="left">77.76875</td>
</tr>
<tr>
<td align="left">K27me3</td>
<td align="left">Rep2</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="left">40.68507</td>
</tr>
<tr>
<td align="left">K4me3</td>
<td align="left">rep1</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="left">91.60169</td>
</tr>
<tr>
<td align="left">K4me3</td>
<td align="left">Rep2</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="left">71.46116</td>
</tr>
</tbody></table>
<h3 id="6-1-4-Visualization-of-peak-number-peak-width-peak-reproducibility-and-FRiPs"><a href="#6-1-4-Visualization-of-peak-number-peak-width-peak-reproducibility-and-FRiPs" class="headerlink" title="6.1.4 Visualization of peak number, peak width, peak reproducibility and FRiPs."></a>6.1.4 Visualization of peak number, peak width, peak reproducibility and FRiPs.</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">fig7A = peakN %&gt;% ggplot(aes(x = Histone, y = peakN, fill = Histone)) +</span><br><span class="line">    geom_boxplot() +</span><br><span class="line">    geom_jitter(aes(color = Replicate), position = position_jitter(0.15)) +</span><br><span class="line">    facet_grid(~peakType) +</span><br><span class="line">    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.55, option = <span class="string">&quot;magma&quot;</span>, alpha = 0.8) +</span><br><span class="line">    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +</span><br><span class="line">    theme_bw(base_size = 18) +</span><br><span class="line">    ylab(<span class="string">&quot;Number of Peaks&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">fig7B = peakWidth %&gt;% ggplot(aes(x = Histone, y = width, fill = Histone)) +</span><br><span class="line">    geom_violin() +</span><br><span class="line">    facet_grid(Replicate~peakType) +</span><br><span class="line">    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.55, option = <span class="string">&quot;magma&quot;</span>, alpha = 0.8) +</span><br><span class="line">    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +</span><br><span class="line">    scale_y_continuous(trans = <span class="string">&quot;log&quot;</span>, breaks = c(400, 3000, 22000)) +</span><br><span class="line">    theme_bw(base_size = 18) +</span><br><span class="line">    ylab(<span class="string">&quot;Width of Peaks&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">fig7C = peakReprod %&gt;% ggplot(aes(x = Histone, y = peakReprodRate, fill = Histone, label = round(peakReprodRate, 2))) +</span><br><span class="line">    geom_bar(<span class="built_in">stat</span> = <span class="string">&quot;identity&quot;</span>) +</span><br><span class="line">    geom_text(vjust = 0.1) +</span><br><span class="line">    facet_grid(Replicate~peakType) +</span><br><span class="line">    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.55, option = <span class="string">&quot;magma&quot;</span>, alpha = 0.8) +</span><br><span class="line">    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +</span><br><span class="line">    theme_bw(base_size = 18) +</span><br><span class="line">    ylab(<span class="string">&quot;% of Peaks Reproduced&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">fig7D = frip %&gt;% ggplot(aes(x = Histone, y = frip, fill = Histone, label = round(frip, 2))) +</span><br><span class="line">    geom_boxplot() +</span><br><span class="line">    geom_jitter(aes(color = Replicate), position = position_jitter(0.15)) +</span><br><span class="line">    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.55, option = <span class="string">&quot;magma&quot;</span>, alpha = 0.8) +</span><br><span class="line">    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +</span><br><span class="line">    theme_bw(base_size = 18) +</span><br><span class="line">    ylab(<span class="string">&quot;% of Fragments in Peaks&quot;</span>) +</span><br><span class="line">    xlab(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">ggarrange(fig7A, fig7B, fig7C, fig7D, ncol = 2, nrow=2, common.legend = TRUE, legend=<span class="string">&quot;bottom&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/blog/2022/03/21/2022-03-21-CUTTag/7.png" alt="7"></p>
<hr>
<h1 id="VII-Visualization"><a href="#VII-Visualization" class="headerlink" title="VII. Visualization"></a>VII. Visualization</h1><p>Typically we are interested in visualizing a chromatin landscape in regions using a genome browser. The <a href="http://software.broadinstitute.org/software/igv/home">Integrative Genomic Viewer</a> provides a web app version and a local desktop version that are easy to use. The <a href="https://genome.ucsc.edu/">UCSC Genome Browser</a> provides the most comprehensive supplementary genome information.</p>
<h2 id="7-1-Browser-display-of-normalized-bedgraph-files"><a href="#7-1-Browser-display-of-normalized-bedgraph-files" class="headerlink" title="7.1. Browser display of normalized bedgraph files."></a>7.1. Browser display of normalized bedgraph files.</h2><p><img src="/blog/2022/03/21/2022-03-21-CUTTag/8.png" alt="7"></p>
<h2 id="7-2-Heatmap-visualization-on-specific-regions"><a href="#7-2-Heatmap-visualization-on-specific-regions" class="headerlink" title="7.2. Heatmap visualization on specific regions"></a>7.2. Heatmap visualization on specific regions</h2><p>We are also interested in looking at chromatin features at a list of annotated sites, for example histone modification signal at gene promoters.We will use the <code>computeMatrix</code> and <code>plotHeatmap</code> functions from <a href="https://deeptools.readthedocs.io/en/develop/">deepTools</a> to generate the heatmap.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line">mkdir -p <span class="variable">$projPath</span>/alignment/bigwig                                                                                                                                        </span><br><span class="line">samtools sort -o <span class="variable">$projPath</span>/alignment/bam/<span class="variable">$&#123;histName&#125;</span>.sorted.bam <span class="variable">$projPath</span>/alignment/bam/<span class="variable">$&#123;histName&#125;</span>_bowtie2.mapped.bam                                                     </span><br><span class="line">samtools index <span class="variable">$projPath</span>/alignment/bam/<span class="variable">$&#123;histName&#125;</span>.sorted.bam                                                                                                              </span><br><span class="line">bamCoverage -b <span class="variable">$projPath</span>/alignment/bam/<span class="variable">$&#123;histName&#125;</span>.sorted.bam -o <span class="variable">$projPath</span>/alignment/bigwig/<span class="variable">$&#123;histName&#125;</span>_raw.bw         </span><br></pre></td></tr></table></figure>

<h3 id="7-2-1-Heatmap-over-transcription-units"><a href="#7-2-1-Heatmap-over-transcription-units" class="headerlink" title="7.2.1 Heatmap over transcription units"></a>7.2.1 Heatmap over transcription units</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line">cores=8</span><br><span class="line">computeMatrix scale-regions -S <span class="variable">$projPath</span>/alignment/bigwig/K27me3_rep1_raw.bw \</span><br><span class="line">                               <span class="variable">$projPath</span>/alignment/bigwig/K27me3_rep2_raw.bw \</span><br><span class="line">                               <span class="variable">$projPath</span>/alignment/bigwig/K4me3_rep1_raw.bw \</span><br><span class="line">                               <span class="variable">$projPath</span>/alignment/bigwig/K4me3_rep2_raw.bw \</span><br><span class="line">                              -R <span class="variable">$projPath</span>/data/hg38_gene/hg38_gene.tsv \</span><br><span class="line">                              --beforeRegionStartLength 3000 \</span><br><span class="line">                              --regionBodyLength 5000 \</span><br><span class="line">                              --afterRegionStartLength 3000 \</span><br><span class="line">                              --skipZeros -o <span class="variable">$projPath</span>/data/hg38_gene/matrix_gene.mat.gz -p <span class="variable">$cores</span></span><br><span class="line"></span><br><span class="line">plotHeatmap -m <span class="variable">$projPath</span>/data/hg38_gene/matrix_gene.mat.gz -out <span class="variable">$projPath</span>/data/hg38_gene/Histone_gene.png --sortUsing sum</span><br></pre></td></tr></table></figure>

<p><img src="/blog/2022/03/21/2022-03-21-CUTTag/9.png" alt="7"></p>
<h3 id="7-2-2-Heatmap-on-CUT-amp-Tag-peaks"><a href="#7-2-2-Heatmap-on-CUT-amp-Tag-peaks" class="headerlink" title="7.2.2. Heatmap on CUT&amp;Tag peaks"></a>7.2.2. Heatmap on CUT&amp;Tag peaks</h3><p>We use the midpoint of the signal block returned from SEACR to align signals in heatmaps. The sixth column of the SEACR output is an entry in the form chr:start-end that represents the first and ending bases of the region with the maximum signal of the region. We first generate a new bed file containing this midpoint information in column 6 and use deeptools for the heatmap visualization.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#== linux command ==##</span></span><br><span class="line">awk <span class="string">&#x27;&#123;split($6, summit, &quot;:&quot;); split(summit[2], region, &quot;-&quot;); print summit[1]&quot;\t&quot;region[1]&quot;\t&quot;region[2]&#125;&#x27;</span> <span class="variable">$projPath</span>/peakCalling/SEACR/<span class="variable">$&#123;histName&#125;</span>_<span class="variable">$&#123;repName&#125;</span>_seacr_control.pe\</span><br><span class="line">aks.stringent.bed &gt;<span class="variable">$projPath</span>/peakCalling/SEACR/<span class="variable">$&#123;histName&#125;</span>_<span class="variable">$&#123;repName&#125;</span>_seacr_control.peaks.summitRegion.bed</span><br><span class="line"></span><br><span class="line">computeMatrix reference-point -S <span class="variable">$projPath</span>/alignment/bigwig/<span class="variable">$&#123;histName&#125;</span>_<span class="variable">$&#123;repName&#125;</span>_raw.bw \</span><br><span class="line">              -R <span class="variable">$projPath</span>/peakCalling/SEACR/<span class="variable">$&#123;histName&#125;</span>_<span class="variable">$&#123;repName&#125;</span>_seacr_control.peaks.summitRegion.bed \</span><br><span class="line">              --skipZeros -o <span class="variable">$projPath</span>/peakCalling/SEACR/<span class="variable">$&#123;histName&#125;</span>_<span class="variable">$&#123;repName&#125;</span>_SEACR.mat.gz -p <span class="variable">$cores</span> -a 3000 -b 3000 --referencePoint center</span><br><span class="line"></span><br><span class="line">plotHeatmap -m <span class="variable">$projPath</span>/peakCalling/SEACR/<span class="variable">$&#123;histName&#125;</span>_SEACR.mat.gz -out <span class="variable">$projPath</span>/peakCalling/SEACR/<span class="variable">$&#123;histName&#125;</span>_SEACR_heatmap.png --sortUsing sum --startLabel <span class="string">&quot;Peak Start&quot;</span> -\</span><br><span class="line">-endLabel <span class="string">&quot;Peak End&quot;</span> --xAxisLabel <span class="string">&quot;&quot;</span> --regionsLabel <span class="string">&quot;Peaks&quot;</span> --samplesLabel <span class="string">&quot;<span class="variable">$&#123;histName&#125;</span> <span class="variable">$&#123;repName&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="/blog/2022/03/21/2022-03-21-CUTTag/10.png" alt="7"></p>
<hr>
<h1 id="VIII-Differention-analysis"><a href="#VIII-Differention-analysis" class="headerlink" title="VIII. Differention analysis"></a>VIII. Differention analysis</h1><ul>
<li>DESeq2: <a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8">Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2</a></li>
</ul>
<p>Estimate variance-mean dependence in count data from high-throughput sequencing assays and test for differential expression based on a model using the negative binomial distribution.</p>
<h2 id="8-1-Create-the-peak-x-sample-matrix"><a href="#8-1-Create-the-peak-x-sample-matrix" class="headerlink" title="8.1. Create the peak x sample matrix."></a>8.1. Create the peak x sample matrix.</h2><p>Usually, the differential tests compare two or more conditions of the same histone modification. In this tutorial, limited by the demonstration data, we will illustrate the differential detection by comparing two replicates of H3K27me3 and two replicates of H3K4me3. We will use DESeq2 (<a href="http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#why-un-normalized-counts">complete tutorial</a>) as illustration.</p>
<h3 id="8-1-1-Create-a-master-peak-list-merging-all-the-peaks-called-for-each-sample"><a href="#8-1-1-Create-a-master-peak-list-merging-all-the-peaks-called-for-each-sample" class="headerlink" title="8.1.1 Create a master peak list merging all the peaks called for each sample."></a>8.1.1 Create a master peak list merging all the peaks called for each sample.</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line">mPeak = GRanges()</span><br><span class="line"><span class="comment">## overlap with bam file to get count</span></span><br><span class="line"><span class="keyword">for</span>(hist <span class="keyword">in</span> histL)&#123;</span><br><span class="line">  <span class="keyword">for</span>(rep <span class="keyword">in</span> repL)&#123;</span><br><span class="line">    peakRes = read.table(paste0(projPath, <span class="string">&quot;/peakCalling/SEACR/&quot;</span>, hist, <span class="string">&quot;_&quot;</span>, rep, <span class="string">&quot;_seacr_control.peaks.stringent.bed&quot;</span>), header = FALSE, fill = TRUE)</span><br><span class="line">    mPeak = GRanges(seqnames = peakRes<span class="variable">$V1</span>, IRanges(start = peakRes<span class="variable">$V2</span>, end = peakRes<span class="variable">$V3</span>), strand = <span class="string">&quot;*&quot;</span>) %&gt;% append(mPeak, .)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">masterPeak = reduce(mPeak)</span><br></pre></td></tr></table></figure>

<h3 id="8-1-2-Get-the-fragment-counts-for-each-peak-in-the-master-peak-list"><a href="#8-1-2-Get-the-fragment-counts-for-each-peak-in-the-master-peak-list" class="headerlink" title="8.1.2 Get the fragment counts for each peak in the master peak list."></a>8.1.2 Get the fragment counts for each peak in the master peak list.</h3><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line">library(DESeq2)</span><br><span class="line">bamDir = paste0(projPath, <span class="string">&quot;/alignment/bam&quot;</span>)</span><br><span class="line">countMat = matrix(<span class="literal">NA</span>, <span class="built_in">length</span>(masterPeak), <span class="built_in">length</span>(histL)*<span class="built_in">length</span>(repL))</span><br><span class="line"><span class="comment">## overlap with bam file to get count</span></span><br><span class="line">i = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span>(hist <span class="keyword">in</span> histL)&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="built_in">rep</span> <span class="keyword">in</span> repL)&#123;</span><br><span class="line">    </span><br><span class="line">    bamFile = paste0(bamDir, <span class="string">&quot;/&quot;</span>, hist, <span class="string">&quot;_&quot;</span>, <span class="built_in">rep</span>, <span class="string">&quot;_bowtie2.mapped.bam&quot;</span>)</span><br><span class="line">    fragment_counts &lt;- getCounts(bamFile, masterPeak, paired = <span class="literal">TRUE</span>, by_rg = <span class="literal">FALSE</span>, format = <span class="string">&quot;bam&quot;</span>)</span><br><span class="line">    countMat[, i] = counts(fragment_counts)[,<span class="number">1</span>]</span><br><span class="line">    i = i + <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">colnames(countMat) = paste(<span class="built_in">rep</span>(histL, <span class="number">2</span>), <span class="built_in">rep</span>(repL, each = <span class="number">2</span>), sep = <span class="string">&quot;_&quot;</span>)</span><br></pre></td></tr></table></figure>



<h2 id="8-2-Sequencing-depth-normalization-and-differential-enriched-peaks-detection"><a href="#8-2-Sequencing-depth-normalization-and-differential-enriched-peaks-detection" class="headerlink" title="8.2. Sequencing depth normalization and differential enriched peaks detection"></a>8.2. Sequencing depth normalization and differential enriched peaks detection</h2><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##=== R command ===## </span></span><br><span class="line">selectR = which(rowSums(countMat) &gt; <span class="number">5</span>) <span class="comment">## remove low count genes</span></span><br><span class="line">dataS = countMat[selectR,]</span><br><span class="line">condition = factor(<span class="built_in">rep</span>(histL, each = <span class="built_in">length</span>(repL)))</span><br><span class="line">dds = DESeqDataSetFromMatrix(countData = dataS,</span><br><span class="line">                              colData = DataFrame(condition),</span><br><span class="line">                              design = ~ condition)</span><br><span class="line">DDS = DESeq(dds)</span><br><span class="line">normDDS = counts(DDS, normalized = <span class="literal">TRUE</span>) <span class="comment">## normalization with respect to the sequencing depth</span></span><br><span class="line">colnames(normDDS) = paste0(colnames(normDDS), <span class="string">&quot;_norm&quot;</span>)</span><br><span class="line">res = results(DDS, independentFiltering = <span class="literal">FALSE</span>, altHypothesis = <span class="string">&quot;greaterAbs&quot;</span>)</span><br><span class="line"></span><br><span class="line">countMatDiff = cbind(dataS, normDDS, res)</span><br><span class="line">head(countMatDiff)</span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">DataFrame with <span class="number">6</span> rows and <span class="number">14</span> columns</span><br><span class="line">  K27me3_rep1 K4me3_rep1 K27me3_rep2 K4me3_rep2 K27me3_rep1_norm</span><br><span class="line">    &lt;numeric&gt;  &lt;numeric&gt;   &lt;numeric&gt;  &lt;numeric&gt;        &lt;numeric&gt;</span><br><span class="line"><span class="number">1</span>           <span class="number">6</span>          <span class="number">2</span>           <span class="number">1</span>          <span class="number">6</span>         <span class="number">1.408657</span></span><br><span class="line"><span class="number">2</span>           <span class="number">1</span>          <span class="number">0</span>         <span class="number">242</span>        <span class="number">182</span>         <span class="number">0.234776</span></span><br><span class="line"><span class="number">3</span>           <span class="number">0</span>          <span class="number">0</span>         <span class="number">176</span>         <span class="number">88</span>         <span class="number">0.000000</span></span><br><span class="line"><span class="number">4</span>           <span class="number">0</span>          <span class="number">0</span>         <span class="number">274</span>        <span class="number">194</span>         <span class="number">0.000000</span></span><br><span class="line"><span class="number">5</span>           <span class="number">3</span>          <span class="number">4</span>           <span class="number">0</span>          <span class="number">1</span>         <span class="number">0.704328</span></span><br><span class="line"><span class="number">6</span>           <span class="number">0</span>          <span class="number">1</span>         <span class="number">109</span>         <span class="number">59</span>         <span class="number">0.000000</span></span><br><span class="line">  K4me3_rep1_norm K27me3_rep2_norm K4me3_rep2_norm  baseMean log2FoldChange</span><br><span class="line">        &lt;numeric&gt;        &lt;numeric&gt;       &lt;numeric&gt; &lt;numeric&gt;      &lt;numeric&gt;</span><br><span class="line"><span class="number">1</span>        <span class="number">0.620403</span>            <span class="number">4.170</span>         <span class="number">18.2724</span>   <span class="number">6.11787</span>       <span class="number">3.496854</span></span><br><span class="line"><span class="number">2</span>        <span class="number">0.000000</span>         <span class="number">1009.141</span>        <span class="number">554.2634</span> <span class="number">390.90978</span>      <span class="number">12.510325</span></span><br><span class="line"><span class="number">3</span>        <span class="number">0.000000</span>          <span class="number">733.921</span>        <span class="number">267.9955</span> <span class="number">250.47905</span>      <span class="number">13.297304</span></span><br><span class="line"><span class="number">4</span>        <span class="number">0.000000</span>         <span class="number">1142.581</span>        <span class="number">590.8082</span> <span class="number">433.34733</span>      <span class="number">14.089840</span></span><br><span class="line"><span class="number">5</span>        <span class="number">1.240806</span>            <span class="number">0.000</span>          <span class="number">3.0454</span>   <span class="number">1.24763</span>       <span class="number">0.846266</span></span><br><span class="line"><span class="number">6</span>        <span class="number">0.310202</span>          <span class="number">454.530</span>        <span class="number">179.6788</span> <span class="number">158.62986</span>      <span class="number">11.189689</span></span><br><span class="line">      lfcSE      stat      pvalue        padj</span><br><span class="line">  &lt;numeric&gt; &lt;numeric&gt;   &lt;numeric&gt;   &lt;numeric&gt;</span><br><span class="line"><span class="number">1</span>   <span class="number">1.19893</span>  <span class="number">2.916635</span> <span class="number">3.53829e-03</span> <span class="number">4.22134e-02</span></span><br><span class="line"><span class="number">2</span>   <span class="number">1.50039</span>  <span class="number">8.338074</span> <span class="number">7.55102e-17</span> <span class="number">2.18197e-15</span></span><br><span class="line"><span class="number">3</span>   <span class="number">1.58547</span>  <span class="number">8.386969</span> <span class="number">4.98837e-17</span> <span class="number">1.50548e-15</span></span><br><span class="line"><span class="number">4</span>   <span class="number">1.55196</span>  <span class="number">9.078730</span> <span class="number">1.09850e-19</span> <span class="number">6.73560e-18</span></span><br><span class="line"><span class="number">5</span>   <span class="number">2.18326</span>  <span class="number">0.387617</span> <span class="number">6.98300e-01</span> <span class="number">9.72755e-01</span></span><br><span class="line"><span class="number">6</span>   <span class="number">1.53046</span>  <span class="number">7.311313</span> <span class="number">2.64545e-13</span> <span class="number">4.33546e-12</span></span><br></pre></td></tr></table></figure>

<ul>
<li>DESeq2 requires the input matrix should be un-normalized counts or estimated counts of sequencing reads.</li>
<li>DESeq2 model internally corrects for library size.</li>
<li><strong>countMatDiff</strong> summarizes the differential analysis results:<ul>
<li>First 4 columns: raw reads counts after filtering the peak regions with low counts</li>
<li>Second 4 columns: normalized read counts eliminating library size difference.</li>
<li>Remaining columns: differential detection results.</li>
</ul>
</li>
</ul>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Kaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S: CUT&amp;Tag for efficient epigenomic profiling of small samples and single cells. Nature Communications 2019 10:1930 (PMID:31036827).</span><br><span class="line"></span><br><span class="line">Meers, M.P., Tenenbaum, D. &amp; Henikoff, S. Peak calling by Sparse Enrichment Analysis for CUT&amp;RUN chromatin profiling. Epigenetics &amp; Chromatin 12, 42 (2019). https://doi.org/10.1186/s13072-019-0287-4</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="IX-Additional-Alternatives"><a href="#IX-Additional-Alternatives" class="headerlink" title="IX. Additional Alternatives"></a>IX. Additional Alternatives</h1><h2 id="9-1-ChIPseqSpikeInFree-for-normalizing-data-without-spike-in-DNA-Optional"><a href="#9-1-ChIPseqSpikeInFree-for-normalizing-data-without-spike-in-DNA-Optional" class="headerlink" title="9.1 ChIPseqSpikeInFree for normalizing data without spike-in DNA [Optional]"></a>9.1 ChIPseqSpikeInFree for normalizing data without spike-in DNA [Optional]</h2><p><a href="https://academic.oup.com/bioinformatics/article/36/4/1270/5578481">ChIPseqSpikeInFree: a ChIP-seq normalization approach to reveal global changes in histone modifications without spike-in</a> is a novel ChIP-seq normalization method to effectively determine scaling factors for samples across various conditions and treatments, which does not rely on exogenous spike-in chromatin or peak detection to reveal global changes in histone modification occupancy. The installation details can be found on <a href="https://github.com/stjude/ChIPseqSpikeInFree">github</a>.</p>
<ul>
<li><a href="https://github.com/stjude/ChIPseqSpikeInFree#interpretation-of-scaling-factor-table">Interpretation of the ChIPseqSpikeInFree output.</a></li>
<li><a href="https://github.com/stjude/ChIPseqSpikeInFree#how-to-use-chipseqspikein-scaling-factor">How to use ChIPseqSpikeInFree scaling factor.</a></li>
</ul>
<h2 id="9-2-Other-peak-calling-methods"><a href="#9-2-Other-peak-calling-methods" class="headerlink" title="9.2. Other peak calling methods."></a>9.2. Other peak calling methods.</h2><ul>
<li>MACS2: <a href="https://genomebiology.biomedcentral.com/articles/10.1186/gb-2008-9-9-r137">Model-based Analysis of ChIP-Seq (MACS)</a>. Installation details can be found <a href="https://github.com/taoliu/MACS/wiki">here</a>.</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">##== linux command ==##</span></span><br><span class="line">histName=<span class="string">&quot;K27me3&quot;</span></span><br><span class="line">controlName=<span class="string">&quot;IgG&quot;</span></span><br><span class="line"></span><br><span class="line">mkdir -p <span class="variable">$projPath</span>/peakCalling</span><br><span class="line">macs2 callpeak -t <span class="variable">$&#123;projPath&#125;</span>/alignment/bam/<span class="variable">$&#123;histName&#125;</span>_rep1_bowtie2.mapped.bam \</span><br><span class="line">      -c <span class="variable">$&#123;projPath&#125;</span>/alignment/bam/<span class="variable">$&#123;controlName&#125;</span>_rep1_bowtie2.mapped.bam \</span><br><span class="line">      -g hs -f BAMPE -n macs2_peak_q0.1 --outdir <span class="variable">$projPath</span>/peakCalling/MACS2 -q 0.1 --keep-dup all 2&gt;<span class="variable">$&#123;projPath&#125;</span>/peakCalling/MACS2/macs2Peak_summary.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>dPeak: <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003246">dPeak: High Resolution Identification of Transcription Factor Binding Sites from PET and SET ChIP-Seq Data</a></li>
<li>MOSAiCS: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4608541/">A Statistical Framework for the Analysis of ChIP-Seq Data</a></li>
</ul>
<h2 id="9-3-Other-packages-for-differential-analysis-of-binding-sites"><a href="#9-3-Other-packages-for-differential-analysis-of-binding-sites" class="headerlink" title="9.3 Other packages for differential analysis of binding sites"></a>9.3 Other packages for differential analysis of binding sites</h2><ul>
<li>Limma: <a href="https://academic.oup.com/nar/article/43/7/e47/2414268">limma powers differential expression analyses for RNA-sequencing and microarray studies</a></li>
</ul>
<p>Limma is an R package for the analysis of gene expression microarray data, especially the use of linear models for analysing designed experiments and the assessment of differential expression. Limma provides the ability to analyse comparisons between many RNA targets simultaneously in arbitrary complicated designed experiments. Empirical Bayesian methods are used to provide stable results even when the number of arrays is small. Limma can be extended to study differential fragment enrichment analysis within peak regions. Notably, limma can deal with both fixed effect model and random effect model.</p>
<ul>
<li>edgeR: <a href="https://academic.oup.com/nar/article/40/10/4288/2411520">Differential Expression Analysis of Multifactor RNA-Seq Experiments With Respect to Biological Variation</a></li>
</ul>
<p>Differential expression analysis of RNA-seq expression profiles with biological replication. Implements a range of statistical methodology based on the negative binomial distributions, including empirical Bayes estimation, exact tests, generalized linear models and quasi-likelihood tests. As well as RNA-seq, it be applied to differential signal analysis of other types of genomic data that produce read counts, including ChIP-seq, ATAC-seq, Bisulfite-seq, SAGE and CAGE. edgeR can deal with multifactor problem.</p>
<h1 id="X-Troubleshooting-Generating-your-data"><a href="#X-Troubleshooting-Generating-your-data" class="headerlink" title="X. Troubleshooting: Generating your data"></a>X. Troubleshooting: Generating your data</h1><p>This workflow can be followed with your own data and will generate a standardized set of quality-control reports. However, many sequencing facilities do not perform 25x25 PE sequencing, and alternate parameters for trimming and mapping are provided here. Control datasets for non-specific antibody (IgG) profiling or ATAC-seq profiling of your material can also be used for optional analysis detailed here.</p>
<p>Stringent washing with 300 mM NaCl is critical to limit the affinity of Tn5 for exposed DNA. We describe here the need for controlling background Tn5 affinities and describe how our CUT&amp;Tag protocol effectively suppresses this artifact for unambiguous mapping of chromatin epitopes. We present a protocol that can process either native or fixed nuclei and includes alternative methods for DNA isolation. To illustrate the method, we describe a typical experiment, including evaluation of the results using a new metric for peak-calling information. Further, we validate a single-tube format for CUT&amp;Tag that requires no DNA isolation but instead uses tagmented material directly for library amplification. We document critical steps for the CUT&amp;Tag protocol, informed by our experiences, helping users establish this method in their research.</p>
<hr>
<p>Cite:<a href="https://yezhengstat.github.io/CUTTag_tutorial/#">https://yezhengstat.github.io/CUTTag_tutorial/#</a> Zheng Y et al (2020). Protocol.io</p>
]]></content>
      <categories>
        <category>CUT&amp;Tag</category>
      </categories>
      <tags>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>【ATAC-seq-pipeline】</title>
    <url>/blog/2022/03/20/2022-03-20-ATAC-seq-6/</url>
    <content><![CDATA[<p>ATAC-seq信息分析流程主要分为以下几个部分：数据质控、序列比对、峰检测、motif分析、峰注释、富集分析.</p>
<p>an <strong>a</strong>ssay for <strong>t</strong>ransposase-<strong>a</strong>ccessible <strong>c</strong>hromatin using <strong>seq</strong>uencing </p>
<span id="more"></span>

<hr>
<p><a href="https://www.biostars.org/p/442707/">?</a></p>
<p><a href="https://www.biostars.org/p/413626/">?</a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3455685">Data processing1:Johns Hopkins University School of Medicine</a>    2019 mar</p>
<p>ATAC-seq data were <strong>aligned</strong> using <strong>Bowtie2</strong> (Version 2.3.2 t -X 2000 <strong>–no-mixed –no-discordant</strong>) </p>
<p> <strong>duplicate</strong> reads were removed (<strong>picard</strong> MarkDuplicates)</p>
<p>Peaks were called using <strong>MACS2</strong> (Version 2.1.1.20160309 callpeak <strong>–nomodel –keep-dup all –shift −100 –extsize 200</strong> –call-summits) (Zhang et al., 2008). </p>
<p>Peaks were then <strong>filtered for fold-change &gt;2 and -log(qvalue) &gt;2</strong>. </p>
<p><strong>deepTools</strong> was used to visualize ATAC-seq peaks on the browser (bamCoverage -bs 1 –normalizeUsing <strong>RPKM</strong>).<br>Genome_build: <strong>mm10</strong><br>Supplementary_files_format_and_content: narrowPeak and .bw</p>
<p><a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM5502736">Data processing2:University of California, San Diego</a>  2022 Jan<br>Sequenced reads were trimmed for adaptor sequence, and masked for low-complexity or low-quality sequence, then mapped to hg38 whole genome using <strong>bowtie</strong> v2.3.5.1 with parameters -q -p 4 -e 100 -y -a -m 10 –best –strata<br>For <strong>RNA-seq data</strong>: Transcripts per Million (<strong>TPM</strong>) were calculated using a protocol from <strong>Chepelev et al</strong>., Nucleic Acids Research, 2009. In short, exons from all isoforms of a gene were merged to create one meta-transcript. The number of reads falling in the exons of this meta-transcript were counted and normalized by the size of the meta-transcript and by the size of the library.<br>For <strong>ATAC-seq data</strong>: peaks were called using <strong>Genrich</strong> version 0.6.1 with the following setting: -j -y -r -e chrM -v.</p>
<p><strong>Bigwig</strong> file generated using bamCoverage version 3.3.2 with the following setting: <strong>—binSize 20 —normalizeUsing BPM —smoothLength 60 —centerReads</strong>. Heatmap, genomic tracker and scatter map generated using EaSeq version 1.111.<br>For <strong>ChIP-seq data</strong>: peaks were called using <strong>MACS3</strong> version 3.0.0a6 with the following setting: -g hs -f BAM. Bigwig file generated using bamCoverage version 3.3.2 with the following setting: <strong>—binSize 20 —normalizeUsing BPM —smoothLength 60 —centerReads</strong>. Heatmap, genomic tracker and scatter map generated using EaSeq version 1.111.<br>For <strong>CUT&amp;Tag-seq data</strong>: peaks were called using <strong>SEACR</strong> version 1.3 with the following setting: <strong>-norm strigent</strong>. </p>
<p>Bigwig file generated using bamCoverage version 3.3.2 with the following setting: <strong>—binSize 20 —normalizeUsing BPM —smoothLength 60 —centerReads</strong>. Heatmap, genomic tracker and scatter map generated using <strong>EaSeq</strong> version 1.111.<br>Genome_build: <strong>hg38</strong><br>Supplementary_files_format_and_content: For RNA-seq: tab-delimited text files include TPM values for each Sample<br>Supplementary_files_format_and_content: For ATAC-seq, ChIP-seq and CUT&amp;Tag-seq: bigwid files for display in hg38 genome browser track</p>
<p><a href="https://https.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM4432199">Data processing3:Hong Kong University of Science and Technology</a>  2020 may</p>
<p>For ChIP-seq, Base-calling is done by bcl2-fastq<br>For sequencing alignment and duplicate removal, sequencing data were mapped to the mm10 mice genome assembly by using the <strong>BWA</strong>. Duplicates were marked and removed using the <strong>Picard</strong> tools MarkDuplicates function with the parameter, REMOVE_DUPLICATES=TRUE.<br>For <strong>peak identification</strong>, the <strong>HOMER</strong> (Heinz et al., 2010) maketagdirectory function was used to combine sequencing data from the biological replicates, and the <strong>findPeaks</strong> function was used to identify binding/accessible regions with the following parameters: -style factor (for PU.1 ChIP-seq), <strong>-style histone</strong> (for H3K4me3 ChIP-seq), and <strong>-style histone -minDist 200</strong> (for ATAC-seq). Regions were annotated by the <strong>annotatePeaks.pl</strong> function. deepTools bamCoverage function and visualized in igv browser (Robinson et al., 2011).<br><strong>Read count in the binding/accessible regions</strong> was <strong>quantified</strong> by the <strong>bedtools</strong> (Quinlan and Hall, 2010) <strong>multicov</strong> function. Differential binding/accessible regions (p &lt; 0.05) were calculated using R.<br>Genome_build: mm10<br>Supplementary_files_format_and_content: bigWig files were generated using <strong>Bamcoverage –normalizeUsing CPM –binSize 10</strong><br>For scRNA-seq,Base-calling is done by bcl2-fastq<br>The sequencing data were aligned, quantified, and clustered using Cell Ranger (version 3.0) as previously described (Zheng et al., 2017).<br>Genome_build: mm10<br>Supplementary_files_format_and_content: Matrix of read count, barcode were generated using cell ranger v3</p>
<p><a href="https://https.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM4160552">Data processing 4:Johns Hopkins University School of Medicine</a> 2020 Jan</p>
<p>ATAC-seq data were <strong>aligned</strong> to the GRCm38 genome using <strong>HISAT2</strong> version 2.1.0 (hisat2 -t -X 2000 –no-mixed –no-discordant) and then duplicate reads were removed (<strong>picard</strong> MarkDuplicates). Peaks were called using <strong>MACS2</strong> version 2.1.2 (<strong>callpeak -f BAM –nomodel –keep-dup all –shift −100 –extsize 200</strong>) (Zhang et al., 2008). Peaks were then filtered for <strong>fold-change &gt;2 and -log(qvalue) &gt;2</strong>. deepTools was used to visualize ATAC-seq peaks on the browser (bamCoverage <strong>-bs 1 –extendReads –ignoreDuplicates –normalizeUsing CPM</strong>).<br>Genome_build: mm10</p>
<p>GEO ATAC-seq?????</p>
<p>GEO CUT&amp;Tag??????</p>
<p><a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE101940">2018Arab</a></p>
<hr>
<p><a href="https://www.jianshu.com/p/dc0c49bfcd41;https://seqhealth.biomart.cn/news/2995703.htm;https://zhuanlan.zhihu.com/p/146068902;https://www.jianshu.com/p/09e05bcd6981">Ref1</a></p>
<blockquote>
<p><strong>一、数据过滤与质量评估</strong></p>
</blockquote>
<p>fastp fastqc</p>
<blockquote>
<p><strong>二、比对</strong></p>
</blockquote>
<p>Bowtie2,bwa</p>
<p>后续分析reads需要唯一比对且去重复的，比对结果通过<strong>MAPQ</strong>值提取唯一比对reads，可以用picard、sambamba等去除dup，最终得到唯一比对且去重复的bam</p>
<p>质体序列去除。samtools提取，将不含质体的染色体写到chrlist文件[Chr1….12]，一条染色体一行</p>
<p><code>samtools view -b A1.bam $chrlist &gt; A1.del_MT_PT.bam</code></p>
<blockquote>
<p><strong>三、reads在染色体上分布的可视化</strong></p>
</blockquote>
<p>bam转bigWig（bw），IGV展示(no shift)。deeptools可实现bw格式转化和可视化展示</p>
<p><code>bamCoverage -b A1.bam -o A1.bw</code></p>
<p>deeptools展示reads在特定区域的分布，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">computeMatrix reference-point   \ # reference-pioint表示计算一个参照点附近的reads分布，与之相对的是scale-regions，计算一个区域附近的reads分布</span><br><span class="line">--referencePoint TSS   \#以输入的bed文件的起始位置作为参照点</span><br><span class="line">-S  A1.bw \ #可以是一个或多个bw文件</span><br><span class="line">-R  gene.bed \ #基因组位置文件</span><br><span class="line">-b 3000   \ #计算边界为参考点上游3000bp</span><br><span class="line">-a 3000   \ #计算边界为参考点下游3000bp，与-b合起来就是绘制参考点上下游3000bp以内的reads分布</span><br><span class="line">-o  A1.matrix.mat.gz \ #输出作图数据名称</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\#图形绘制</span><br><span class="line">plotHeatmap \</span><br><span class="line">-m  new_A1.matrix.mat.gz \ #上一步生成的作图数据</span><br><span class="line">-out A1.pdf \ # 输出图片名称</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>四、Peak calling</strong></p>
</blockquote>
<p>MACS2检测DNA片断富集区域，是ATAC-seq call peak的<strong>主流软件</strong>。峰检出原理：首先将所有的reads都向3’方向延伸插入片段长度，然后将基因组进行滑窗，计算该窗口的dynamic λ，λ的计算公式为：λlocal = λBG（λBG是指背景区域上的reads数目），然后利用泊松分布模型的公式计算该窗口的显著性P值，最后对每一个窗口的显著性P值进行FDR校正。默认校正后的P值（即qvalue）小于或者等于0.05的区域为peak区域。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak \</span><br><span class="line">-t A1.uni.dedup.bam \ #bam文件</span><br><span class="line">-n A1 \ # 输出文件前缀名</span><br><span class="line">--shift -100 \ #extsize的一半乘以-1</span><br><span class="line">--extsize 200 \ #一般是核小体大小</span><br><span class="line">--call-summits #检测峰顶信息</span><br><span class="line"></span><br><span class="line">#注：以上参数参考文献（Jie Wang，et.al.2018.“ATAC-Seq analysis reveals a widespread decrease of chromatin accessibility in age-related macular degeneration.”Nature Communications）</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>五、motif分析</strong></p>
</blockquote>
<p>ATAC的peak是染色质开放区域，染色质开放区域预示着转录因子结合，对peak区进行motif分析很有意义。常见的motif分析软件有homer和MEME。以homer软件为例 motif分析：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">findMotifsGenome.pl \</span><br><span class="line">A1_peaks.bed \ #用于进行motif分析的bed文件</span><br><span class="line">genome.fa  \ #参考基因组fa文件</span><br><span class="line">A1  \ #输出文件前缀</span><br><span class="line">-size  given \ #使用给定的bed区域位置进行分析，如果填-size -100,50则是用给定bed中间位置的上游100bp到下游50bp的区域进行分析</span><br></pre></td></tr></table></figure>



<p>homer分析motif的原理及结果参见：<a href="http://homer.ucsd.edu/homer/motif/index.html">http://homer.ucsd.edu/homer/motif/index.html</a></p>
<p>根据motif与已知转录因子的富集情况可以绘制气泡图，从而可以看到样本与已知转录因子的富集显著性。</p>
<p><img src="/blog/2022/03/20/2022-03-20-ATAC-seq-6/1.png" alt="img"></p>
<blockquote>
<p><strong>六、差异分析</strong></p>
</blockquote>
<p>差异peak是染色质开放性差异位点，ChIP-seq和ATAC-seq都可用<strong>DiffBind</strong>差异分析。DiffBind通过bam文件和peak的bed文件计算<strong>peak区域标准化的readcount</strong>，可选择edgeR、DESeq2等模型进行差异分析。</p>
<blockquote>
<p><strong>七、峰注释</strong></p>
</blockquote>
<p>peak区域与基因联系，通过对peak注释找到peak相关基因。常见的peak注释软件有ChIPseeker、homer、PeakAnnotator等。以ChIPseeker为例，安装ChIPseeker包和GenomicFeatures包，然后分析</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">library(ChIPseeker)</span><br><span class="line">library(GenomicFeatures)</span><br><span class="line">txdb&lt;- makeTxDbFromGFF(‘gene.gtf’)#生成txdb对象，如果研究物种没有已知的TxDb,可以用GenomicFeatures中的函数生成</span><br><span class="line">peakfile &lt;-readPeakFile(‘A1_peaks.narrowPeak’)#导入需要注释的peak文件</span><br><span class="line">peakAnno &lt;- annotatePeak(peakfile,tssRegion=c(-2000, 2000), TxDb=txdb)</span><br><span class="line">\# 用peak文件和txdb进行peak注释，这里可以通过tssRegion定义TSS区域的区间</span><br><span class="line">对peak注释的结果可视化展示：</span><br><span class="line">p &lt;- plotAnnoPie(peakAnno)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>八、富集分析</strong></p>
</blockquote>
<p>peak相关基因使用goseq、topGO等R包GO富集分析，用kobas进行kegg富集分析，也可用DAVID在线工具富集分析。挑选感兴趣的GO term或pathway进一步<strong>筛选候选基因</strong>。</p>
<hr>
<p><a href="https://seqhealth.biomart.cn/news/2995703.htm">Ref2</a></p>
<p>澳大利亚莫纳什大学的Yan F.等人于2020年2月在Genome Biology上发表综述《From reads to insight: a hitchhiker’s guide to ATAC-seq data analysis》</p>
<p>哺乳动物DNA通过三个主要层次尺度 高度压缩：</p>
<ul>
<li>第一层是核小体，DNA缠绕在核小体单体上；</li>
<li>第二层是染色质，核小体单体互相缠绕形成染色质；</li>
<li>第三层是染色体，染色质进一步压缩为染色体。</li>
</ul>
<p>DNA压缩的三个尺度及其相互作用共同造就了基因表达调控。</p>
<p>ATAC-seq使用基因工程改造的<strong>超高活性Tn5转座酶</strong>（Hyperactive Transposase Tn5），Tn5酶<strong>预载</strong>测序文库构建的Adaptor（<strong>P5和P7</strong>）。Tn5酶切割开放染色质区域，在酶切位点留下9 bp粘性末端，并将两种Adaptor连接到切口的粘性末端；随后DNA片段扩增形成文库测序。下图中<strong>NFR fragments</strong>是开放染色质中核小体间的<strong>Linker DNA片段</strong>，由Peak Calling的Peak鉴定；<strong>蓝色Footprint是转录因子足迹</strong>，对应<strong>转录因子足迹分析</strong>；核小体单体（Mononucleosome）结合DNA片段则反映核小体位置信息，对应<strong>核小体占位分析</strong>。</p>
<p><img src="/blog/2022/03/20/2022-03-20-ATAC-seq-6/2.png" alt="img"></p>
<p>由于ATAC-seq和ChIP-seq数据相似性较高，综述针对ATAC-seq分析现有软件全面介绍和评估。</p>
<p><img src="/blog/2022/03/20/2022-03-20-ATAC-seq-6/3.png" alt="img"></p>
<blockquote>
<p> 质控</p>
</blockquote>
<p>FastQC。ATAC-seq文库采用<strong>Illumina Nextera建库</strong>，<strong>接头和Truseq文库不一样</strong>，cutadapt、AdapterRemoval v2、Skewer或trimmomatic(去Nextera接头)。</p>
<blockquote>
<p>序列比对</p>
</blockquote>
<p>过滤后FastQC。<strong>BWA-MEM</strong>和<strong>Bowtie2</strong>两个软件的soft-clip策略保留突出和没有比对上的碱基，可<strong>增加</strong>在参考序列唯1比对的序列数目（<strong>Unique比对率</strong>）。哺乳动物，**Unique比对率大于80%**的数据是比较成功的ATAC-seq文库。</p>
<blockquote>
<p>比对后处理和质控</p>
</blockquote>
<p>Picard和SAMtools软件统计Unique比对率、重复reads比例和片段大小分布。</p>
<p><strong>Mapping后去除干扰reads</strong>：</p>
<ol>
<li>配对错误和比对质量较低的reads剔除</li>
<li><strong>线粒体基因组没有染色质组装</strong>，处于开放状态，<strong>更容易被Tn5酶切割</strong>，线粒体序列去除</li>
<li>ENCODE数据库黑名单区域（blacklisted regions）包含一些异常、read覆盖度很高的区域，区域reads去除</li>
<li>由PCR建库产生、重复率过高的reads需要去除。</li>
</ol>
<p>此外，<strong>测序文库插入片段大小分布</strong>也可用来判断ATAC-seq实验质量。插入片段大小理论分布为：NFR fragments（&lt;100 bp）、核小体单体（<del>200 bp）、核小体二聚体（</del>400 bp）和核小体三聚体（~600 bp）</p>
<blockquote>
<p>核心分析 peak calling</p>
</blockquote>
<p>ENCODE选择MACS2作为ATAC-seq标准Peak Calling。与ChIP-seq不同，<strong>由于Tn5酶切割的随机性和成本</strong>，ATAC-seq没<strong>有Input对照</strong>。ATAC-seq数据包含<strong>NFR reads</strong>和<strong>DNA与核小体结合区域reads</strong>，而<font color="red">ATAC-seq关注<strong>NFR部分reads</strong></font>，不能直接用所有reads Peak Calling。一种方式把NFR reads单独提取分析；<font color="red">另一种方式采用<strong>shift-extend</strong>分析</font>，这种方法尝试对Tn5酶切口的末端平滑化事件进行计数（见下图）。第二种更通用，因为这种方法<strong>几乎适用所有为ChIP-seq数据开发的Peak Calling软件，且不受插入片段大小影响</strong>。</p>
<p><img src="/blog/2022/03/20/2022-03-20-ATAC-seq-6/4.png" alt="img"></p>
<p>ChIP-seq Peak Calling软件根据原理分两大类：<font color="red"><strong>Count-based</strong>和<strong>Shaped-based</strong></font>。Count-based的软件更易于使用和解释结果。这些软件采用<font color="red">不同统计方法比较<strong>目标区域和随机背景区域</strong>的<strong>reads分布</strong>形状</font>，常用包括：</p>
<ul>
<li>假设片段分布为泊松分布：<strong>MACS2、HOMER、SICER/epic2</strong></li>
<li>假设片段分布为零膨胀负二项分布：<strong>ZINBA</strong></li>
<li>核密度估计来判断片段分布：<strong>F-seq、PeakDEck</strong></li>
<li>不使用片段分布假设但通过软件打分：<strong>SPP</strong></li>
<li>混合模型：<strong>JAMM</strong></li>
</ul>
<p>其中F-seq, ZINBA 不更新<br><font color="red">Shaped-based</font>直接或者间接<font color="red">利用reads<strong>密度分布信息</strong>Peak Calling</font>，包括和等软件，暂时没用于ATAC-seq。目前专门为ATAC-seq开发的Peak Calling软件只有<strong>HMMRATAC</strong>。该软件通过三状态半监督隐马尔科夫模型算法把基因组分成高信号强度的活性染色质区域、中等信号强度的核小体区域和低信号强度的背景区域。计算量偏大，耗时较长，<font color="red"><strong>结果比MACS2更好</strong></font>，同时提供核小体位置信息。</p>
<p><img src="/blog/2022/03/20/2022-03-20-ATAC-seq-6/5.png" alt="img"></p>
<p><font color="red"><strong>MACS2 pair-end 和MACS2 shift-extend哪个好?</strong></font></p>
<p>Count-based软件差异不大，但Shaped-based结果非常不同。<font color="red"><strong>目前仍没有综合性指标评估Peak Calling软件的结果表现。</strong></font><br>以上分析Peak Calling软件结果，但是并没有针对存在生物学重复的Peak Calling结果可信度进行探讨。</p>
<p><strong>Peak Calling可信度</strong>: <strong>IDR</strong>（Irreproducibility Discovery Rate）是指不可重现的发现率，用于测量生物学重复中的可重现性。ATAC-seq比较一对经过排序的regions/peaks，计算反映其重复性的值。IDR分析结果的Peak是可信度更高的Peak。建议每组样品2个及以上生物学重复。</p>
<blockquote>
<p> ATAC-seq高级分析</p>
</blockquote>
<p>ATAC-seq主要功能是揭示转录调控各个方面，可4种水平对结果分析和解释：1. Peak注释和差异Peak分析；2. Motif分析；3. 核小体占位分析；4. 转录因子足迹分析。</p>
<p><font color="green"><strong>Peak注释和差异Peak分析</strong></font></p>
<p>Peak与其最近基因或调控元件的Peak注释，<strong>HOMER、ChIPseeker</strong>和<strong>ChIPpeakAnno</strong>三个软件都可把Peak分配到最近或重叠的基因、外显子、内含子、启动子、5’UTR、3’UTR和其它基因组功能区。随后用Gene Ontology（GO）、KEGG和Reactome等数据库做Peak关联基因功能富集分析。<strong>ChIPseeker</strong>和<strong>ChIPpeakAnno</strong>软件具有可视化功能。<br>目前没有专门为ATAC-seq开发的差异Peak分析软件。差异Peak分析首先通过<strong>寻找候选区域</strong>（共有Peak或根据bin划分的基因组），然后<strong>标准化</strong>，再对落在<strong>区域内的片段计数</strong>，最后在相同坐标内与其它处理条件的样本进行<strong>统计学比较</strong>。在以共有Peak为基础分析的软件中，<strong>HOMER、DBChIP</strong>和<strong>DiffBind</strong>依赖RNA-seq差异表达基因分析中使用的R包计算差异Peak，例如<strong>edgeR、DESeq</strong>和<strong>DESeq2</strong>等，都要求生物学重复。</p>
<p><strong>HOMER</strong>把所有生物学重复样品数据合并到一起减少差异peak的假阳性结果。<strong>DBChIP</strong>和<strong>DiffBind</strong>通过取交集或并集的方法得到共有Peak，取交集会忽略一些样本或特殊的Peak，而取并集使假阳性增多。</p>
<p>另外不依赖RNA-seq分析R包的软件包括<strong>PePr、DiffReps</strong>和<strong>ChIPDiff</strong>，还有一种<strong>edgeR</strong>包的扩展软件<strong>csaw</strong>，这些软件使用滑窗（Sliding window）方法进行分析，但是得到的<strong>结果假阳性率很高</strong>，需要设置严格的FDR。<br>文章推荐Peak注释与差异分析软件：<strong>HOMER/ChIPseeker/ChIPpeakAnno + csaw</strong><br>康科Peak注释与差异分析软件：<strong>Bedtools</strong> + <strong>edgeR</strong></p>
<p><font color="green"><strong>Motif分析</strong></font></p>
<p>开放染色质区域一般可结合特定转录因子进而影响转录，转录因子结合识别的DNA序列即为motif，人体大约<strong>1600种转录因子</strong>，其中一半多已有明确报道的motif。对motif的分析包括<strong>motif富集分析</strong>和<strong>转录因子Footprint（足迹）分析</strong>。</p>
<p>Motif富集分析</p>
<p>目前很多motif数据库，使用最普遍的是<strong>JASPAR数据库</strong>，该数据库收录多物种的motif数据，可以通过APIs或者Bioconductor的R包下载相关数据。此外，CIS-BP和TRANSFAC数据库收录<strong>真核生物</strong>转录因子的motif信息，HOCOMOCO数据库则专门收录了<strong>人和小鼠</strong>的motif，RegulonDB为大肠杆菌的motif数据库。<br><strong>HOMER、MEME-AME、MEME-CentriMo</strong> <strong>DAStk</strong></p>
<p><font color="green"><strong>转录因子足迹分析</strong></font></p>
<p>另一种ATAC-seq<strong>解释转录因子调控方式</strong>的是足迹分析。<font color="red">转录因子足迹指一个转录因子结合在DNA，<strong>阻止Tn5酶切割</strong>，在<strong>染色质开放区域留</strong>下一个<strong>相对缺失的位置</strong></font>。</p>
<p>做足迹分析三个问题需要解决：</p>
<p>1）由于建库时Tn5酶切时会产生9 bp的粘性末端切口，经过末端修复补齐后，原始reads在预处理时需要经过移位才可以准确检测到Footprint；</p>
<p>2）Tn5酶切具有5’端偏好性；</p>
<p>3）某些瞬时结合的转录因子足迹信号较弱。</p>
<p>足迹分析软件根据算法分为两大类：de novo和Motif-centric。</p>
<p>de novo类型的软件通过理论计算鉴别转录因子足迹信息，消除Tn5酶切时的5’偏好性。目前只有<strong>HINT-ATAC</strong>可以处理ATAC-seq数据特有的偏好性。</p>
<p>Motif-centric方法主要关注已知TF的结合位点，主要软件有<strong>MILLIPEDE、DeFCoM</strong>等。</p>
<p>联合ChIP-seq数据的Motif-centric方法在足迹分析上优于de nove的方法，但是这些ChIP-seq数据来源于特定的转录因子和特定的细胞类型，通用性不强。而de novo的方法在一些低质量和新发现的一些motif上具有优势。</p>
<p>文章推荐转录因子足迹分析软件：<strong>HINT-ATAC</strong><br>康测科技转录因子足迹分析软件：<strong>HOMER + Bedtools自编脚本</strong></p>
<p><font color="green"><strong>核小体占位分析</strong></font></p>
<p>核小体单体可以结合大约147 bp的DNA，在标准ATAC-seq文库中，较长的插入片段对应DNA与核小体结合的区域。ATAC-seq数据核小体结合区域比染色质开放区域reads<strong>覆盖度更低</strong>，所以相比MNase-seq，ATAC-seq的核小体占位分析<strong>难度更高</strong>。一般情况，为MNase-seq开发的软件（比如<strong>DNAPOS2、PuFFIN、iNPS</strong>和<strong>NucTools</strong>）可用于ATAC-seq。专门为ATAC-seq开发的软件包括<strong>NuleoATAC</strong>和<strong>HMMRATAC</strong>。<strong>NuleoATAC</strong>比<strong>DANPOS2</strong>结果表现更好，而<strong>HMMRATAC</strong>可以同时完成Peak Calling和核小体占位分析。<br>文章推荐核小体占位分析软件：<strong>NuleoATAC</strong> <strong>/HMMRATAC</strong><br>康测科技核小体占位分析软件：<strong>Samtools自编脚本</strong></p>
<blockquote>
<p> ATAC-seq与多组学数据联合分析</p>
</blockquote>
<ol>
<li><strong>转录因子ChIP-seq</strong>：大部分转录因子结合染色质开放区域，所以ATAC-seq的Peak可能和转录因子ChIP-seq的Peak存在部分重叠，而且ATAC-seq得到的Peak长度往往更长，因此ATAC-seq数据和转录因子ChIP-seq数据可以<font color="red"><strong>相互验证</strong></font>。转录因子在<strong>ChIP-seq中独有</strong>的Peak暗示这个转录因子<strong>可能结合在异染色质区域</strong>的<strong>驱动型转录因子</strong>（Pioneer TFs），<font color="red"><strong>驱动型转录因子</strong>随后招募<strong>染色质重塑复合体</strong>以及其它转录因子开始转录</font>。联合分析报道ChIP-seq数据可更准确地分析转录因子的足迹。</li>
<li><strong>组蛋白修饰ChIP-seq</strong>：ATAC-seq同样可以和<font color="red"><strong>组蛋白修饰ChIP-seq</strong></font>联合分析，其中<font color="red">转录<strong>激活</strong>性修饰（H3K4me3，H3K4me1和H3K27ac等）</font>与染<strong>色质开放程度呈正相关</strong>，<font color="red">转录<strong>抑制</strong>性修饰（H3K27me3）</font>与染色质开放程度呈<strong>负相关</strong>。联合已知的<strong>增强子和启动子之间的相互作用</strong>数据也可以帮助<strong>构建调控网络</strong>。</li>
<li><strong>RNA-seq</strong>：ATAC-seq通过联合RNA-seq发现哪些<font color="red">差异表达的基因</font>是<font color="red">受染色质可及性调控的</font>，进一步推测这些差异表达基因<font color="red">哪些是受开放染色质中<strong>具有motif和footprint</strong>的转录因子调控</font>，因此ATAC-seq与RNA-seq的联合分析有助于破译<strong>基因调控网络</strong>和细胞异质性。</li>
</ol>
<p>通过鉴定染色质开放区域并<strong>结合motif信息和基因表达信息</strong>，建立<strong>转录因子-靶基因</strong>的互作网络。</p>
<blockquote>
<p>总结</p>
</blockquote>
<p>该review系统描述ATAC-seq生信分析主要流程，并推荐相关软件：<strong>FastQC</strong>质控；<strong>trimmomatic</strong>去除低质量碱基和接头序列；<strong>BWA-MEM</strong>比对；<strong>MACS2</strong> Peak Calling；<strong>csaw</strong>差异Peak分析；<strong>MEME-CentriMo</strong>寻找motif以及富集分析；<strong>ChIPseeker</strong> Peak注释和可视化；<strong>HMMRATAC</strong>分析核小体占位；<strong>HINT-ATAC</strong>转录因子Footprint分析。</p>
<p>康测科技稍有不同：引入<strong>IDR</strong>判断Peak可信度；差异Peak分析使用<strong>bedtools</strong>和单独的<strong>edgeR</strong>包结合自编脚本提高差异Peak分析中参数设置自由度，得到准确度和可信度更高的分析结果。</p>
<p><img src="/blog/2022/03/20/2022-03-20-ATAC-seq-6/6.png" alt="img"></p>
<hr>
<p><a href="https://www.jianshu.com/p/09e05bcd6981">Ref3</a></p>
<blockquote>
<p>比对</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">bowtie2  -p 5  --very-sensitive -X 2000 -x  <span class="variable">$bowtie2_index</span> -1 <span class="variable">$fq1</span> -2 <span class="variable">$fq2</span> |samtools sort  -O bam  -@ 5 -o - &gt; <span class="variable">$&#123;sample&#125;</span>.raw.bam</span><br><span class="line"></span><br><span class="line">samtools index <span class="variable">$&#123;sample&#125;</span>.raw.bam</span><br><span class="line">bedtools bamtobed -i <span class="variable">$&#123;sample&#125;</span>.raw.bam  &gt; <span class="variable">$&#123;sample&#125;</span>.raw.bed</span><br><span class="line">samtools flagstat <span class="variable">$&#123;sample&#125;</span>.raw.bam  &gt; <span class="variable">$&#123;sample&#125;</span>.raw.stat</span><br><span class="line"><span class="comment"># https://github.com/biod/sambamba/issues/177</span></span><br><span class="line"><span class="comment"># 三种不同的去重复软件</span></span><br><span class="line"><span class="comment"># 这里选用sambamba来去重复</span></span><br><span class="line">sambamba markdup --overflow-list-size 600000  --tmpdir=<span class="string">&#x27;./&#x27;</span>  -r <span class="variable">$&#123;sample&#125;</span>.raw.bam  <span class="variable">$&#123;sample&#125;</span>.rmdup.bam</span><br><span class="line">samtools index   <span class="variable">$&#123;sample&#125;</span>.rmdup.bam</span><br><span class="line">samtools flagstat  <span class="variable">$&#123;sample&#125;</span>.rmdup.bam &gt; <span class="variable">$&#123;sample&#125;</span>.rmdup.stat</span><br><span class="line"></span><br><span class="line"><span class="comment">## ref:https://www.biostars.org/p/170294/ </span></span><br><span class="line"><span class="comment">## Calculate %mtDNA:</span></span><br><span class="line">mtReads=$(samtools idxstats  <span class="variable">$&#123;sample&#125;</span>.rmdup.bam | grep <span class="string">&#x27;chrM&#x27;</span> | cut -f 3)</span><br><span class="line">totalReads=$(samtools idxstats  <span class="variable">$&#123;sample&#125;</span>.rmdup.bam | awk <span class="string">&#x27;&#123;SUM += $3&#125; END &#123;print SUM&#125;&#x27;</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;==&gt; mtDNA Content:&#x27;</span> $(bc &lt;&lt;&lt; <span class="string">&quot;scale=2;100*<span class="variable">$mtReads</span>/<span class="variable">$totalReads</span>&quot;</span>)<span class="string">&#x27;%&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 保留两条reads比对到同一条染色体(Proper paired) ，还有高质量的比对结果(Mapping quality&gt;=30)</span></span><br><span class="line"><span class="comment">## 顺便过滤 线粒体reads</span></span><br><span class="line">samtools view  -h  -f 2 -q 30    <span class="variable">$&#123;sample&#125;</span>.rmdup.bam   |grep -v chrM |samtools sort  -O bam  -@ 5 -o - &gt; <span class="variable">$&#123;sample&#125;</span>.last.bam</span><br><span class="line"></span><br><span class="line">samtools index   <span class="variable">$&#123;sample&#125;</span>.last.bam</span><br><span class="line">samtools flagstat  <span class="variable">$&#123;sample&#125;</span>.last.bam &gt; <span class="variable">$&#123;sample&#125;</span>.last.stat</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转bed 文件 用MACS2 shift extend model</span></span><br><span class="line">bedtools bamtobed -i <span class="variable">$&#123;sample&#125;</span>.last.bam  &gt; <span class="variable">$&#123;sample&#125;</span>.bed</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Deeptools 可视化</p>
</blockquote>
<p><strong>bam转bw</strong></p>
<p><a href="https://deeptools.readthedocs.io/en/develop/content/tools/bamCoverage.html">bamCoverage</a></p>
<p><font color="red"><strong>–normalizeUsing</strong></font></p>
<p>Possible choices: RPKM, CPM, BPM, RPGC, None</p>
<p>Use one of the entered methods to normalize the number of reads per bin. By <strong>default, no normalization</strong> is performed. <strong>RPKM</strong> = Reads Per Kilobase per Million mapped reads; <strong>CPM</strong> = Counts Per Million mapped reads, same as CPM in RNA-seq; <strong>BPM</strong> = Bins Per Million mapped reads, same as <strong>TPM</strong> in RNA-seq; <strong>RPGC</strong> = reads per genomic content (1x normalization); Mapped reads <strong>are considered after blacklist filtering?</strong> (if applied). </p>
<p>RPKM (per bin) = number of reads per bin / (number of mapped reads (in millions) * bin length (kb)). </p>
<p>CPM (per bin) = number of reads per bin / number of mapped reads (in millions). BPM (per bin) = number of reads per bin / sum of all reads per bin (in millions). </p>
<p>RPGC (per bin) = number of reads per bin / scaling factor for 1x average coverage. None = the default and equivalent to not setting this option at all. This scaling factor, in turn, is determined from the sequencing depth: (total number of mapped reads * fragment length) / effective genome size. The scaling factor used is the inverse of the sequencing depth computed for the sample to match the 1x coverage. This option requires –effectiveGenomeSize. Each read is considered independently, if you want to only count one mate from a pair in paired-end data, then use the –samFlagInclude/–samFlagExclude options. (Default: None)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span>  ~/project/atac/deeptools_result</span><br><span class="line"></span><br><span class="line"><span class="comment">###构建索引</span></span><br><span class="line">ls  *.bam  |xargs -i samtools index &#123;&#125;</span><br><span class="line"><span class="comment">###将最终的bam转换成bigwig文件</span></span><br><span class="line">ls *last.bam |<span class="keyword">while</span> <span class="built_in">read</span> id;<span class="keyword">do</span></span><br><span class="line">nohup bamCoverage -b <span class="variable">$&#123;id&#125;</span> -p 5 --normalizeUsing RPKM  -o <span class="variable">$&#123;id%%.*&#125;</span>.last.bw &amp;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment">###将去重的bam转换成bigwig文件</span></span><br><span class="line"><span class="comment"># cd dup </span></span><br><span class="line">ls  *.bam  |xargs -i samtools index &#123;&#125; </span><br><span class="line">ls *rmdup.bam |<span class="keyword">while</span> <span class="built_in">read</span> id;<span class="keyword">do</span></span><br><span class="line">nohup bamCoverage --normalizeUsing CPM -b <span class="variable">$id</span> -o <span class="variable">$&#123;id%%.*&#125;</span>.rm.bw &amp; </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p><strong>查看TSS附件信号强度（激活marker，27ac）</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## both -R and -S can accept multiple files </span></span><br><span class="line">mkdir -p  ~/project/atac/tss</span><br><span class="line"><span class="built_in">cd</span>   ~/project/atac/tss </span><br><span class="line"><span class="comment"># source activate atac # 由于我这里自己系统有就没调用了</span></span><br><span class="line">computeMatrix reference-point  --referencePoint TSS  -p 15  \</span><br><span class="line">-b 10000 -a 10000    \</span><br><span class="line">-R ~/project/atac/mm10_Refgene/Refseq.bed  \</span><br><span class="line">-S ~/project/atac/deeptools_result/*.bw  \</span><br><span class="line">--skipZeros  -o matrix1_test_TSS.gz  \</span><br><span class="line">--outFileSortedRegions regions1_test_genes.bed</span><br><span class="line"></span><br><span class="line"><span class="comment">##     both plotHeatmap and plotProfile will use the output from   computeMatrix</span></span><br><span class="line">plotHeatmap -m matrix1_test_TSS.gz  -out test_Heatmap.png</span><br><span class="line">plotHeatmap -m matrix1_test_TSS.gz  -out test_Heatmap.pdf --plotFileFormat pdf  --dpi 720  </span><br><span class="line">plotProfile -m matrix1_test_TSS.gz  -out test_Profile.png</span><br><span class="line">plotProfile -m matrix1_test_TSS.gz  -out test_Profile.pdf --plotFileFormat pdf --perGroup --dpi 720 </span><br></pre></td></tr></table></figure>

<p><strong>查看基因body的信号强度（抑制marker，27me3）</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#source activate atac</span></span><br><span class="line">mkdir Body</span><br><span class="line"><span class="built_in">cd</span> ~/project/atac/Body</span><br><span class="line">computeMatrix scale-regions  -p 15  \</span><br><span class="line">-R ~/project/atac/mm10_Refgene/Refseq.bed  \</span><br><span class="line">-S ~/project/atac/deeptools_result/*.bw  \</span><br><span class="line">-b 10000 -a 10000  \</span><br><span class="line">--skipZeros -o matrix1_test_body.gz</span><br><span class="line"><span class="comment"># plotHeatmap -m matrix1_test_body.gz  -out ExampleHeatmap1.png</span></span><br><span class="line">plotHeatmap -m matrix1_test_body.gz  -out test_body_Heatmap.png</span><br><span class="line">plotProfile -m matrix1_test_body.gz  -out test_body_Profile.png</span><br><span class="line">plotProfile -m matrix1_test_body.gz -out test_Body_Profile.pdf --plotFileFormat pdf --perGroup --dpi 720</span><br></pre></td></tr></table></figure>

<ul>
<li>–regionBodyLength #调整genebody区域</li>
<li>–binSize</li>
</ul>
<blockquote>
<p>call peak</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#macs2 callpeak -t 2-cell-1.bed  -g mm --nomodel --shift -100 --extsize 200  -n 2-cell-1 --outdir ../peaks/</span></span><br><span class="line"><span class="built_in">cd</span> ~/project/atac/peaks/</span><br><span class="line">ls *.bed | <span class="keyword">while</span> <span class="built_in">read</span> id ;<span class="keyword">do</span> (macs2 callpeak -t <span class="variable">$id</span>  -g mm --nomodel --<span class="built_in">shift</span>  -100 --extsize 200  -n <span class="variable">$&#123;id%%.*&#125;</span> --outdir ./) ;<span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p> 计算插入片段长度，FRiP值，IDR计算重复情况</p>
</blockquote>
<ul>
<li>非冗余非线粒体能够比对的fragment、比对率、NRF、PBC1、PBC2、peak数、无核小体区NFR、TSS富集、FRiP 、IDR重复的一致性！</li>
</ul>
<p><strong>统计indel插入长度的分布</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建提取bam文件的第九列indel插入长度信息的sh文件 indel_length.sh，内容如下：</span></span><br><span class="line">cat config.last_bam |<span class="keyword">while</span> <span class="built_in">read</span> id;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">arr=(<span class="variable">$id</span>)</span><br><span class="line">sample=<span class="variable">$&#123;arr[0]&#125;</span></span><br><span class="line">sample_name=<span class="variable">$&#123;arr[1]&#125;</span></span><br><span class="line">samtools view <span class="variable">$sample</span> |awk <span class="string">&#x27;&#123;print $9&#125;&#x27;</span>  &gt; <span class="variable">$&#123;sample_name&#125;</span>_length.txt</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">#indel_length_distribution.sh</span></span><br><span class="line">md=commandArgs(trailingOnly=<span class="literal">TRUE</span>); </span><br><span class="line">input=cmd[<span class="number">1</span>]; output=cmd[<span class="number">2</span>]; </span><br><span class="line">a=<span class="built_in">abs</span>(<span class="built_in">as.numeric</span>(read.table(input)[,<span class="number">1</span>])); </span><br><span class="line">png(file=output);</span><br><span class="line">hist(a,</span><br><span class="line">main=<span class="string">&quot;Insertion Size distribution&quot;</span>,</span><br><span class="line">ylab=<span class="string">&quot;Read Count&quot;</span>,xlab=<span class="string">&quot;Insert Size&quot;</span>,</span><br><span class="line">xaxt=<span class="string">&quot;n&quot;</span>,</span><br><span class="line">breaks=seq(<span class="number">0</span>,<span class="built_in">max</span>(a),by=<span class="number">10</span>)</span><br><span class="line">); </span><br><span class="line"></span><br><span class="line">axis(side=<span class="number">1</span>,</span><br><span class="line">at=seq(<span class="number">0</span>,<span class="built_in">max</span>(a),by=<span class="number">100</span>),</span><br><span class="line">labels=seq(<span class="number">0</span>,<span class="built_in">max</span>(a),by=<span class="number">100</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">dev.off() </span><br></pre></td></tr></table></figure>

<p><strong>FRiP值的计算：fraction of reads in called peak regions</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">bedtools intersect -a 2-cell-1.bed -b 2-cell-1_peaks.narrowPeak |wc -l</span><br><span class="line">148210</span><br><span class="line">wc  -l 2-cell-1.bed</span><br><span class="line">5105850 </span><br><span class="line"><span class="comment"># 故2-cell-1的FRiP为</span></span><br><span class="line">148210/5105850 = 0.0292</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/project/atac/peaks</span><br><span class="line">ls *narrowPeak|<span class="keyword">while</span>  <span class="built_in">read</span> id;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$id</span></span><br><span class="line">bed=$(basename <span class="variable">$id</span> <span class="string">&quot;_peaks.narrowPeak&quot;</span>).bed</span><br><span class="line"><span class="comment">#ls  -lh $bed </span></span><br><span class="line">Reads=$(bedtools intersect -a <span class="variable">$bed</span> -b <span class="variable">$id</span> |wc -l|awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>)</span><br><span class="line">totalReads=$(wc -l <span class="variable">$bed</span>|awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$Reads</span>  <span class="variable">$totalReads</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;==&gt; FRiP value:&#x27;</span> $(bc &lt;&lt;&lt; <span class="string">&quot;scale=2;100*<span class="variable">$Reads</span>/<span class="variable">$totalReads</span>&quot;</span>)<span class="string">&#x27;%&#x27;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p>Fraction of reads in peaks (FRiP) - Fraction of all mapped reads that fall into the called peak regions, i.e. usable reads in significantly enriched peaks divided by all usable reads. In general, FRiP scores correlate positively with the number of regions. (Landt et al, Genome Research Sept. 2012, 22(9): 1813–1831)<br><strong>使用R包看不同peaks文件的overlap情况</strong></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">options(BioC_mirror=<span class="string">&quot;https://mirrors.ustc.edu.cn/bioc/&quot;</span>) </span><br><span class="line">options(<span class="string">&quot;repos&quot;</span> = <span class="built_in">c</span>(CRAN=<span class="string">&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;</span>))</span><br><span class="line">source(<span class="string">&quot;http://bioconductor.org/biocLite.R&quot;</span>) </span><br><span class="line">library(<span class="string">&#x27;BiocInstaller&#x27;</span>)</span><br><span class="line"><span class="comment"># biocLite(&quot;ChIPpeakAnno&quot;)</span></span><br><span class="line"><span class="comment"># biocLite(&quot;ChIPseeker&quot;)</span></span><br><span class="line">library(ChIPseeker)</span><br><span class="line">library(ChIPpeakAnno)</span><br><span class="line">setwd(<span class="string">&quot;E://desktop/sept/ATAC-seq_practice/find_peaks_overlaping/&quot;</span>)</span><br><span class="line">list.files(<span class="string">&#x27;./&#x27;</span>,<span class="string">&quot;*.narrowPeak&quot;</span>)</span><br><span class="line">tmp = lapply(list.files(<span class="string">&#x27;./&#x27;</span>,<span class="string">&quot;*.narrowPeak&quot;</span>),<span class="keyword">function</span>(x)&#123;</span><br><span class="line">  <span class="built_in">return</span>(readPeakFile(file.path(<span class="string">&#x27;./&#x27;</span>, x)))</span><br><span class="line">  &#125;)</span><br><span class="line">tmp</span><br><span class="line">ol &lt;- findOverlapsOfPeaks(tmp[[<span class="number">1</span>]],tmp[[<span class="number">2</span>]]) <span class="comment"># 这里选取的是第一个文件和第二个文件，即cell.1_peak_1和cell.2_peak</span></span><br><span class="line">png(<span class="string">&#x27;overlapVenn.png&#x27;</span>)</span><br><span class="line">makeVennDiagram(ol)</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure>

<p><strong>IDR 计算，同时考虑peaks间的overlap，和富集倍数的一致性</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">conda  create -n py3 -y   python=3 idr</span><br><span class="line">conda activate py3</span><br><span class="line">idr -h </span><br><span class="line">idr --samples  2-cell-1_peaks.narrowPeak 2-cell-2_peaks.narrowPeak  --plot</span><br><span class="line"></span><br><span class="line"><span class="comment">###############---</span></span><br><span class="line">idr --samples SRR2927018_peaks.narrowPeak SRR3545580_peaks.narrowPeak \</span><br><span class="line">--input-file-type narrowPeak \</span><br><span class="line">--rank p.value \</span><br><span class="line">--output-file group2-idr \</span><br><span class="line">--plot \</span><br><span class="line">--log-output-file group2.idr.log</span><br><span class="line"></span><br><span class="line">ls -lh group*|cut -d <span class="string">&quot; &quot;</span> -f 5-</span><br><span class="line"><span class="comment"># 740K Apr 19 22:00 group1-idr</span></span><br><span class="line"><span class="comment">#  205 Apr 19 22:00 group1.idr.log</span></span><br><span class="line"><span class="comment"># 341K Apr 19 22:00 group1-idr.png</span></span><br><span class="line"><span class="comment"># 315K Apr 19 22:00 group2-idr</span></span><br><span class="line"><span class="comment">#  202 Apr 19 22:00 group2.idr.log</span></span><br><span class="line"><span class="comment"># 218K Apr 19 22:00 group2-idr.png</span></span><br><span class="line">cat group1.idr.log</span><br><span class="line"><span class="comment"># Initial parameter values: [0.10 1.00 0.20 0.50]</span></span><br><span class="line"><span class="comment"># Final parameter values: [0.59 1.05 0.62 0.79]</span></span><br><span class="line"><span class="comment"># Number of reported peaks - 5869/5869 (100.0%)</span></span><br><span class="line"><span class="comment"># Number of peaks passing IDR cutoff of 0.05 - 1571/5869 (26.8%)</span></span><br><span class="line"></span><br><span class="line">cat group2.idr.log</span><br><span class="line"><span class="comment"># Initial parameter values: [0.10 1.00 0.20 0.50]</span></span><br><span class="line"><span class="comment"># Final parameter values: [0.35 1.06 0.47 0.50]</span></span><br><span class="line"><span class="comment"># Number of reported peaks - 2505/2505 (100.0%)</span></span><br><span class="line"><span class="comment"># Number of peaks passing IDR cutoff of 0.05 - 38/2505 (1.5%)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输出标则表示：</span></span><br><span class="line">左上： Rep1 peak ranks vs Rep2 peak ranks，没有通过特定IDR阈值的peaks显示为红色。 右上：Rep1 log10 peak scores vs Rep2 log10 peak scores，没有通过特定IDR阈值的peaks显示为红色。 下面两个图： Peak rank vs IDR scores，箱线图展示了IDR值的分布，默认情况下，IDR值的阈值为-1E-6。</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注释</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">options(BioC_mirror=<span class="string">&quot;https://mirrors.ustc.edu.cn/bioc/&quot;</span>) </span><br><span class="line">options(<span class="string">&quot;repos&quot;</span> = c(CRAN=<span class="string">&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;</span>))</span><br><span class="line"><span class="built_in">source</span>(<span class="string">&quot;http://bioconductor.org/biocLite.R&quot;</span>) </span><br><span class="line">library(<span class="string">&#x27;BiocInstaller&#x27;</span>)</span><br><span class="line">biocLite(<span class="string">&quot;ChIPpeakAnno&quot;</span>)</span><br><span class="line">library(ChIPpeakAnno)</span><br><span class="line">setwd(<span class="string">&quot;E://desktop/sept/ATAC-seq_practice/peaks_annotaion/&quot;</span>)</span><br><span class="line">biocLite(<span class="string">&quot;TxDb.Mmusculus.UCSC.mm10.knownGene&quot;</span>)</span><br><span class="line">biocLite(<span class="string">&quot;org.Mm.eg.db&quot;</span>)</span><br><span class="line">txdb &lt;- TxDb.Mmusculus.UCSC.mm10.knownGene</span><br><span class="line">promoter &lt;- getPromoters(TxDb=txdb, </span><br><span class="line">                         upstream=3000, downstream=3000)</span><br><span class="line">files = list(cell_1_summits = <span class="string">&quot;2-cell-1_summits.bed&quot;</span>, cell_2_summits = <span class="string">&quot;2-cell-2_summits.bed&quot;</span>,</span><br><span class="line">                   cell_4_summits = <span class="string">&quot;2-cell-4_summits.bed&quot;</span>, cell_5_summits = <span class="string">&quot;2-cell-5_summits.bed&quot;</span>)</span><br><span class="line">peakAnno &lt;- annotatePeak(files[[1]], <span class="comment"># 分别改成2或者3或者4即可，分别对应四个文件</span></span><br><span class="line">                         tssRegion=c(-3000, 3000),</span><br><span class="line">                         TxDb=txdb, annoDb=<span class="string">&quot;org.Hs.eg.db&quot;</span>)</span><br><span class="line">plotAnnoPie(peakAnno)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">plotAnnoBar(peakAnno)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vennpie(peakAnno)</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">upsetplot(peakAnno)</span><br><span class="line">upsetplot(peakAnno, vennpie=TRUE)</span><br></pre></td></tr></table></figure>

<p><img src="/blog/2022/03/20/2022-03-20-ATAC-seq-6/8.png" alt="img"></p>
<p>ChIPseeker注释最近基因，peak离最近基因的距离分布</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">plotDistToTSS(peakAnno,</span><br><span class="line">              title=<span class="string">&quot;Distribution of transcription factor-binding loci\nrelative to TSS&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">peakAnnoList &lt;- lapply(files, annotatePeak, </span><br><span class="line">                       TxDb=txdb,tssRegion=c(-3000, 3000))</span><br><span class="line">plotAnnoBar(peakAnnoList)</span><br></pre></td></tr></table></figure>

<p>ChIPseeker提供了vennplot函数，看注释的最近基因在不同样本的overlap</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">genes &lt;- lapply(peakAnnoList, <span class="keyword">function</span>(i) </span><br><span class="line">    as.data.frame(i)<span class="variable">$geneId</span>)</span><br><span class="line">vennplot(genes[2:4], by=<span class="string">&#x27;Vennerable&#x27;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Motif 寻找 注释</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mkdir -p  ~/project/atac/motif</span></span><br><span class="line"><span class="built_in">cd</span>   ~/project/atac/motif</span><br><span class="line"><span class="comment"># source activate atac</span></span><br><span class="line">ls ../peaks/*.narrowPeak |<span class="keyword">while</span> <span class="built_in">read</span> id;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">file=$(basename <span class="variable">$id</span> )</span><br><span class="line">sample=<span class="variable">$&#123;file%%.*&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$sample</span> </span><br><span class="line">awk <span class="string">&#x27;&#123;print $4&quot;\t&quot;$1&quot;\t&quot;$2&quot;\t&quot;$3&quot;\t+&quot;&#125;&#x27;</span> <span class="variable">$id</span> &gt; <span class="variable">$&#123;sample&#125;</span>.homer_peaks.tmp</span><br><span class="line">nohup findMotifsGenome.pl <span class="variable">$&#123;sample&#125;</span>.homer_peaks.tmp  mm10 <span class="variable">$&#123;sample&#125;</span>_motifDir -len 8,10,12  &amp;</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p> 差异peaks分析</p>
</blockquote>
<p>diffbind, DESeq2</p>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>【bowtie2】</title>
    <url>/blog/2022/03/20/2022-03-20-bowtie2/</url>
    <content><![CDATA[<p><strong>Bowtie 2</strong> is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences. It is particularly good at aligning reads of about <strong>50 up to 100s or 1,000s</strong> of characters, and particularly <strong>good at aligning to relatively long</strong> (e.g. mammalian) genomes. Bowtie 2 indexes the genome with an <strong>FM Index</strong> to keep its <strong>memory footprint small</strong>: for the human genome, its memory footprint is typically around 3.2 GB. Bowtie 2 supports <strong>gapped</strong>, <strong>local</strong>, and <strong>paired-end</strong> alignment modes.</p>
<span id="more"></span>

<p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml">http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><a href="http://bowtie-bio.sf.net/bowtie2">Bowtie 2</a> is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences. It is particularly good at aligning reads of about 50 up to 100s of characters to relatively long (e.g. mammalian) genomes. Bowtie 2 indexes the genome with an <a href="http://en.wikipedia.org/wiki/FM-index">FM Index</a> (based on the <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler Transform</a> or <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">BWT</a>) to keep its memory footprint small: for the human genome, its memory footprint is typically around 3.2 gigabytes of RAM. Bowtie 2 supports gapped, local, and paired-end alignment modes. Multiple processors can be used simultaneously to achieve greater alignment speed.</p>
<p>Bowtie 2 outputs alignments in <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM</a> format, enabling interoperation with a large number of other tools (e.g. <a href="http://samtools.sourceforge.net/">SAMtools</a>, <a href="http://www.broadinstitute.org/gsa/wiki/index.php/The_Genome_Analysis_Toolkit">GATK</a>) that use SAM. Bowtie 2 is distributed under the <a href="http://www.gnu.org/licenses/gpl-3.0.html">GPLv3 license</a>, and it runs on the command line under Windows, Mac OS X and Linux and BSD.</p>
<p><a href="http://bowtie-bio.sf.net/bowtie2">Bowtie 2</a> is often the first step in pipelines for <font color="blue"><strong>comparative genomics</strong></font>, including for <font color="blue"><strong>variation calling, ChIP-seq, RNA-seq, BS-seq</strong></font>. <a href="http://bowtie-bio.sf.net/bowtie2">Bowtie 2</a> and <a href="http://bowtie-bio.sf.net/">Bowtie</a>(also called “<a href="http://bowtie-bio.sf.net/">Bowtie 1</a>“ here) are also tightly integrated into many other tools, some of which <a href="http://bowtie-bio.sourceforge.net/bowtie2/other_tools.shtml">are listed here</a>.</p>
<p>If you use <a href="http://bowtie-bio.sf.net/bowtie2">Bowtie 2</a> for your published research, please cite our work. Papers describing Bowtie 2 are:</p>
<ul>
<li>Langmead B, Wilks C, Antonescu V, Charles R. <a href="https://doi.org/10.1093/bioinformatics/bty648">Scaling read aligners to hundreds of threads on general-purpose processors</a>. <em>Bioinformatics</em>. 2018 Jul 18. doi: 10.1093/bioinformatics/bty648.</li>
<li>Langmead B, Salzberg SL. <a href="https://www.nature.com/articles/nmeth.1923">Fast gapped-read alignment with Bowtie 2</a>. <em>Nature Methods</em>. 2012 Mar 4;9(4):357-9. doi: 10.1038/nmeth.1923.</li>
</ul>
<h2 id="How-is-Bowtie-2-different-from-Bowtie-1"><a href="#How-is-Bowtie-2-different-from-Bowtie-1" class="headerlink" title="How is Bowtie 2 different from Bowtie 1?"></a>How is Bowtie 2 different from Bowtie 1?</h2><p><font color="blue"><strong>Bowtie 1</strong></font> was released in 2009 and was geared toward <strong>aligning the relatively short sequencing reads</strong> (up to <strong>25-50 nucl</strong>eotides) prevalent at the time. Since then, technology has improved both sequencing throughput (more nucleotides produced per sequencer per day) and read length (more nucleotides per read).</p>
<p>The chief differences between Bowtie 1 and Bowtie 2 are:</p>
<ol>
<li>For reads <strong>longer than about 50 bp</strong> Bowtie 2 is generally <strong>faster</strong>, more <strong>sensitive</strong>, and uses <strong>less memory</strong> than Bowtie 1. For relatively short reads (e.g. <strong>less than 50 bp) Bowtie 1</strong> is sometimes <strong>faster</strong> and/or more <strong>sensitive</strong>.</li>
<li>Bowtie 2 <strong>supports gapped alignment</strong> with affine gap penalties. Number of gaps and gap lengths are not restricted, except by way of the configurable scoring scheme. <strong>Bowtie 1</strong> finds just <strong>ungapped alignments</strong>.</li>
<li>Bowtie 2 <strong>supports</strong> <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#end-to-end-alignment-versus-local-alignment"><strong>local alignment</strong></a>, which doesn’t require reads to align end-to-end. Local alignments might be “trimmed” (“soft clipped”) at one or both extremes in a way that optimizes alignment score. Bowtie 2 <strong>also supports</strong> <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#end-to-end-alignment-versus-local-alignment">end-to-end alignment</a> which, like <strong>Bowtie 1, requires that the read align entirely.</strong></li>
<li>There is <strong>no upper limit on read length</strong> in <strong>Bowtie 2</strong>. Bowtie 1 had an upper limit of around 1000 bp.</li>
<li>Bowtie 2 <strong>allows</strong> alignments to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#ambiguous-characters">overlap ambiguous characters</a> (e.g. <code>N</code>s) in the reference. Bowtie 1 does not.</li>
<li>Bowtie 2 does away with Bowtie 1’s notion of alignment “stratum”, and its distinction between “Maq-like” and “end-to-end” modes. In Bowtie 2 all alignments <strong>lie along a continuous spectrum of alignment scores</strong> where the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#scores-higher-more-similar">scoring scheme</a>, <strong>similar to</strong> <a href="http://en.wikipedia.org/wiki/Needleman-Wunsch_algorithm">Needleman-Wunsch</a> and <a href="http://en.wikipedia.org/wiki/Smith_waterman">Smith-Waterman</a>.</li>
<li>Bowtie 2’s <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#aligning-pairs">paired-end alignment</a> is <strong>more flexible</strong>. E.g. for pairs that do not align in a paired fashion, Bowtie 2 attempts to <strong>find unpaired alignments for each mate</strong>.</li>
<li>Bowtie 2 <strong>reports</strong> a spectrum of <strong>mapping qualities</strong>, in contrast for Bowtie 1 which reports either 0 or high.</li>
<li>Bowtie 2 does not align <strong>colorspace reads?</strong>.</li>
</ol>
<p>Bowtie 2 is not a “drop-in” replacement for Bowtie 1. Bowtie 2’s command-line <strong>arguments and genome index format are both different</strong> from Bowtie 1’s.</p>
<h2 id="What-isn’t-Bowtie-2"><a href="#What-isn’t-Bowtie-2" class="headerlink" title="What isn’t Bowtie 2?"></a>What isn’t Bowtie 2?</h2><p>Bowtie 2 is geared toward aligning relatively short sequencing reads to long genomes. That said, it handles arbitrarily small reference sequences (e.g. amplicons) and very long reads (i.e. upwards of 10s or 100s of kilobases), though it is slower in those settings. It is optimized for the read lengths and error modes yielded by typical Illumina sequencers.</p>
<p>Bowtie 2 <strong>does not support</strong> alignment of colorspace reads. (Bowtie 1 does.)</p>
<h1 id="Obtaining-Bowtie-2"><a href="#Obtaining-Bowtie-2" class="headerlink" title="Obtaining Bowtie 2"></a>Obtaining Bowtie 2</h1><p>Bowtie 2 is available from various package managers, notably <a href="https://anaconda.org/bioconda/bowtie2">Bioconda</a>. With Bioconda installed, you should be able to install Bowtie 2 with <code>conda install bowtie2</code>.</p>
<p>Containerized versions of Bowtie 2 are also available via the <a href="https://biocontainers.pro/">Biocontainers</a> project (e.g. <a href="https://hub.docker.com/r/biocontainers/bowtie2/">via Docker Hub</a>).</p>
<p>You can also download Bowtie 2 sources and binaries from the <a href="https://sourceforge.net/projects/bowtie-bio/files/bowtie2/">Download</a> section of the Sourceforge site. <strong>Binaries</strong> are available for the <code>x86_64</code>architecture running Linux, Mac OS X, and Windows.  If you plan to <strong>compile Bowtie 2 yourself</strong>, make sure to get the <strong>source package</strong>, i.e., the filename that ends in “-source.zip”.</p>
<h2 id="Building-from-source"><a href="#Building-from-source" class="headerlink" title="Building from source"></a>Building from source</h2><p>Building from source</p>
<p>Unzip the <strong>-source.zip</strong>, change to the unzipped directory, and build the Bowtie 2 tools by running GNU <code>make</code> (usually with the command <code>make</code>, but sometimes with <code>gmake</code>) with no arguments. </p>
<p>The Bowtie 2 Makefile also includes recipes for basic automatic dependency management. Running <code>make static-libs &amp;&amp; make STATIC_BUILD=1</code>will issue a series of commands that will: 1. download <strong>zstd</strong> and <strong>zlib 2</strong>. compile them as static libraries 3. <strong>link the resulting libraries to the compiled Bowtie 2 binaries</strong></p>
<p>As of version 2.3.5 bowtie2 now <strong>supports aligning SRA reads</strong>. Prepackaged builds will include a package that supports SRA. If you’re building bowtie2 from source please make sure that the Java runtime is available on your system. You can then proceed with the build by running <code>make sra-deps &amp;&amp; make USE_SRA=1</code>.</p>
<h1 id="The-bowtie2-aligner"><a href="#The-bowtie2-aligner" class="headerlink" title="The bowtie2 aligner"></a>The <code>bowtie2</code> aligner</h1><p><code>bowtie2</code> takes a Bowtie 2 <strong>index</strong> and a set of sequencing <strong>read</strong> files and outputs a set of alignments in <strong>SAM</strong> format.</p>
<p>“Alignment” is the process by which we discover <strong>how and where the read sequences are similar to the reference</strong> sequence. An “alignment” is a result from this process, specifically: an alignment is a way of “lining up” some or all of the characters in the read with some characters from the reference in a way that reveals how they’re similar. For example:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Read:      GACTGGGCGATCTCGACTTCG</span><br><span class="line">           |||||  |||||||||| |||</span><br><span class="line">Reference: GACTG--CGATCTCGACATCG</span><br></pre></td></tr></table></figure>

<p>Where dash symbols represent <strong>gaps</strong> and <strong>vertical bars</strong> show where aligned characters <strong>match</strong>.</p>
<p>We use alignment to <strong>make an educated guess</strong> as to where a read originated with respect to the reference genome. <strong>It’s not always possible to determine this with certainty</strong>. For instance, if the reference genome contains several long stretches of As (<code>AAAAAAAAA</code> etc.) and the read sequence is a short stretch of As (<code>AAAAAAA</code>), we cannot know for certain exactly where in the sea of <code>A</code>s the read originated.</p>
<h2 id="End-to-end-alignment-versus-local-alignment"><a href="#End-to-end-alignment-versus-local-alignment" class="headerlink" title="End-to-end alignment versus local alignment"></a>End-to-end alignment versus local alignment</h2><p><font color="blue">By default, Bowtie 2 performs <strong>end-to-end</strong> read alignment</font>. That is, it searches for alignments involving all of the read characters. This is also called an “untrimmed” or “unclipped” alignment.</p>
<p>When the <font color="blue"><strong>–local option</strong></font> is specified, Bowtie 2 performs local read alignment. In this mode, Bowtie 2 <font color="blue">might “trim” or “clip” some read characters from one or both ends of the alignment</font> if doing so maximizes the alignment score.</p>
<h3 id="End-to-end-alignment-example"><a href="#End-to-end-alignment-example" class="headerlink" title="End-to-end alignment example"></a>End-to-end alignment example</h3><p>The following is an “end-to-end” alignment because it involves all the characters in the read. Such an alignment can be produced by Bowtie 2 in either end-to-end mode or in local mode.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Read:      GACTGGGCGATCTCGACTTCG</span><br><span class="line">Reference: GACTGCGATCTCGACATCG</span><br><span class="line"></span><br><span class="line">Alignment:</span><br><span class="line">  Read:      GACTGGGCGATCTCGACTTCG</span><br><span class="line">             |||||  |||||||||| |||</span><br><span class="line">  Reference: GACTG--CGATCTCGACATCG</span><br></pre></td></tr></table></figure>

<h3 id="Local-alignment-example"><a href="#Local-alignment-example" class="headerlink" title="Local alignment example"></a>Local alignment example</h3><p>The following is a “local” alignment because <font color="blue">some of the characters <strong>at the ends of the read do not participate</strong></font>. In this case, 4 characters are <font color="red"><strong>omitted</strong> (or “<strong>soft trimmed</strong>“ or “<strong>soft clipped</strong>“)</font> from the beginning and 3 characters are omitted from the end. This sort of alignment can be produced by Bowtie 2 <strong>only in local mode</strong>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Read:      ACGGTTGCGTTAATCCGCCACG</span><br><span class="line">Reference: TAACTTGCGTTAAATCCGCCTGG</span><br><span class="line"></span><br><span class="line">Alignment:</span><br><span class="line">  Read:      ACGGTTGCGTTAA-TCCGCCACG</span><br><span class="line">                 ||||||||| ||||||</span><br><span class="line">  Reference: TAACTTGCGTTAAATCCGCCTGG</span><br></pre></td></tr></table></figure>

<h2 id="Scores-higher-more-similar"><a href="#Scores-higher-more-similar" class="headerlink" title="Scores: higher = more similar"></a>Scores: higher = more similar</h2><p>An alignment score quantifies how similar the read sequence is to the reference sequence aligned to. The higher the score, the more similar they are. A score is <font color="blue"><strong>calculated</strong> by <strong>subtracting penalties</strong> for each difference (<strong>mismatch</strong>, <strong>gap</strong>, etc.)</font> and, in local alignment mode, adding bonuses for each match.</p>
<p>The scores can be configured with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a> (match bonus), <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-mp"><code>--mp</code></a> (mismatch penalty), <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-np"><code>--np</code></a> (penalty for having an N in either the read or the reference), <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rdg"><code>--rdg</code></a> (affine read gap penalty) and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rfg"><code>--rfg</code></a> (affine reference gap penalty) options.</p>
<h3 id="End-to-end-alignment-score-example-Default"><a href="#End-to-end-alignment-score-example-Default" class="headerlink" title="End-to-end alignment score example[Default]"></a>End-to-end alignment score example[Default]</h3><p>A <strong>mismatched</strong> base at a high-quality position in the read receives a penalty of <strong>-6</strong> by default. A length-2 read <strong>gap</strong> receives a penalty of -11 by default (<strong>-5 for the gap open</strong>, <strong>-3 for the first extension</strong>, -3 for the second extension). Thus, if 50 bp, one mismatch, one length-2 read gap, the overall score is -(6 + 11) = -<strong>17</strong>.</p>
<p>The <strong>best</strong> possible alignment <strong>score</strong> in end-to-end mode is <strong>0</strong>, which happens when there are <strong>no differences</strong> between the read and the reference. <font color="red"><strong>No match bonus</strong>. </font> </p>
<h3 id="Local-alignment-score-example"><a href="#Local-alignment-score-example" class="headerlink" title="Local alignment score example"></a>Local alignment score example</h3><p>A mismatched base at a high-quality position in the read receives a penalty of -6 by default. A length-2 read gap receives a penalty of -11 by default (-5 for the gap open, -3 for the first extension, -3 for the second extension). A base that <font color="red"><strong>matches receives a bonus of +2 be default</strong></font>. Thus, if 50 bp, one mismatch, one length-2 read gap, <strong>bonus, 2 * 49</strong>, minus the total penalty, 6 + 11, = <strong>81</strong>.</p>
<p>The best possible score in local mode equals the match bonus times the length of the read. This happens when there are no differences between the read and the reference.</p>
<h3 id="Valid-alignments-meet-or-exceed-the-minimum-score-threshold"><a href="#Valid-alignments-meet-or-exceed-the-minimum-score-threshold" class="headerlink" title="Valid alignments meet or exceed the minimum score threshold"></a><font color="red">Valid alignments meet or exceed the minimum score threshold</font></h3><p>For an alignment to be considered “valid” (i.e. “good enough”) by Bowtie 2, it must have an alignment score no less than the minimum score threshold. The threshold is configurable and is expressed as a function of the read length. In <font color="red"><strong>end-to-end</strong> alignment mode, the <strong>default minimum score threshold</strong></font> is <code>-0.6 + -0.6 * L</code>, where <code>L</code> is the read length. In <font color="red"><strong>local</strong> alignment mode, the <strong>default minimum score threshold</strong></font> is <code>20 + 8.0 * ln(L)</code>, where L is the read length. This can be configured with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-score-min"><code>--score-min</code></a> option. For details on how to set options like <code>--score-min</code> that correspond to functions, see the section on <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#setting-function-options">setting function options</a>.</p>
<h2 id="MAPQ-Mapping-quality-higher-more-unique"><a href="#MAPQ-Mapping-quality-higher-more-unique" class="headerlink" title="MAPQ,Mapping quality: higher = more unique"></a><font color="red">MAPQ</font>,Mapping quality: higher = more unique</h2><p>The aligner cannot always assign a read to its point of origin with high confidence. For instance, a read that originated inside a repeat element might align equally well to many occurrences of the element throughout the genome, leaving the aligner with no basis for preferring one over the others.</p>
<p>Aligners characterize their degree of confidence in the point of origin by reporting a mapping quality: a non-negative integer <font color="red"><strong>Q = -10 log10 p</strong></font>, where <font color="blue">p is an estimate of the probability that the alignment does not correspond to the read’s true point of origin</font>. Mapping quality is sometimes abbreviated <font color="red"><strong>MAPQ</strong></font>, and is recorded in the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM</a> <code>MAPQ</code> field.</p>
<p>Mapping quality is related to “uniqueness.” We say an alignment is unique if it has a much higher alignment score than all the other possible alignments. The bigger the gap between the best alignment’s score and the second-best alignment’s score, the more unique the best alignment, and the higher its mapping quality should be.</p>
<p><strong>Accurate mapping qualities</strong> are <strong>useful</strong> for <strong>downstream tools</strong> like <strong>variant callers</strong>. For instance, a variant caller might choose to ignore evidence from alignments with mapping quality less than, say, 10. A mapping quality of 10 or less indicates that there is at least a 1 in 10 chance that the read truly originated elsewhere.</p>
<h2 id="Aligning-pairs"><a href="#Aligning-pairs" class="headerlink" title="Aligning pairs"></a>Aligning pairs</h2><p>A “paired-end” or “mate-pair” read consists of pair of mates, called mate 1 and mate 2. Pairs come with a prior expectation about (a) the relative orientation of the mates, and (b) the distance separating them on the original DNA molecule. Exactly what expectations hold for a given dataset depends on the lab procedures used to generate the data. For example, a common lab procedure for producing pairs is Illumina’s Paired-end Sequencing Assay, which yields pairs with a <font color="blue"><strong>relative orientation of FR (“forward, reverse”)</strong></font> meaning that if <font color="blue">mate 1 came from the <strong>Watson strand</strong></font>, <font color="blue">mate 2 very likely came from the <strong>Crick strand</strong></font> and vice versa. Also, this protocol yields pairs where the expected genomic distance from end to end is about <strong>200-500 base pairs</strong>.</p>
<p>For simplicity, this manual uses the term “paired-end” to refer to any pair of reads with some expected relative orientation and distance. Depending on the protocol, these might actually be referred to as “paired-end” or “mate-paired.” Also, we always refer to the individual sequences making up the pair as “mates.”</p>
<h3 id="Paired-inputs"><a href="#Paired-inputs" class="headerlink" title="Paired inputs"></a>Paired inputs</h3><p>Bowtie 2, mate 1s mates using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-1"><code>-1</code></a> ,  mate 2s using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-2"><code>-2</code></a> argument. </p>
<h3 id="Paired-SAM-output"><a href="#Paired-SAM-output" class="headerlink" title="Paired SAM output"></a>Paired SAM output</h3><p>When Bowtie 2 prints a SAM alignment for a pair, it <font color="blue"><strong>prints two records</strong> (i.e. two lines of output), one for each mate(1&amp;2)</font>. In both records, some of the fields of the SAM record describe various properties of the alignment; for instance, the <font color="blue">7th and 8th</font> fields (<code>RNEXT</code> and <code>PNEXT</code> respectively) indicate the <font color="blue">reference <strong>name</strong> and <strong>position</strong> where the other mate aligned</font>, and the <font color="blue"><strong>9th</strong> field indicates the inferred length of the <strong>DNA fragment</strong></font> from which the two mates were sequenced. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for more details regarding these fields.</p>
<h3 id="Concordant-pairs-match-pair-expectations-discordant-pairs-don’t"><a href="#Concordant-pairs-match-pair-expectations-discordant-pairs-don’t" class="headerlink" title="Concordant pairs match pair expectations, discordant pairs don’t"></a><font color="red">Concordant pairs</font> match pair expectations, discordant pairs don’t</h3><p>A pair that aligns <font color="blue">with the <strong>expected relative mate orientation</strong> and with the <strong>expected range</strong> of distances between mates</font> is said to align “<font color="red"><strong>concordantly</strong></font>“. If both mates have unique alignments, but the alignments do not match paired-end expectations (i.e. the mates aren’t in the expected relative orientation, or aren’t within the expected distance range, or both), the pair is said to align “<font color="red"><strong>discordantly</strong></font>“. Discordant alignments may be of particular interest, for instance, when seeking <a href="http://www.ncbi.nlm.nih.gov/dbvar/content/overview/"><font color="red"><strong>structural variants</strong></font></a>.</p>
<p>The expected relative orientation of the mates is set using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-fr"><code>--ff</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-fr"><code>--fr</code></a>, or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-fr"><code>--rf</code></a> options. The <strong>expected range of inter-mates distances</strong> (as measured from the furthest extremes of the mates; also called “outer distance”) is set with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> options. Note that setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> far apart <font color="blue">makes Bowtie 2 slower</font>. See documentation for <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>.</p>
<p>To declare that a pair aligns discordantly, Bowtie 2 requires that both mates align uniquely. This is a conservative threshold, but this is often desirable when seeking structural variants.</p>
<p><font color="red">By default, Bowtie 2 searches for both concordant and discordant alignments</font>, though searching for discordant alignments can be <strong>disabled</strong> with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-no-discordant"><code>--no-discordant</code></a> option.</p>
<h3 id="Mixed-mode-paired-where-possible-unpaired-otherwise"><a href="#Mixed-mode-paired-where-possible-unpaired-otherwise" class="headerlink" title="Mixed mode: paired where possible, unpaired otherwise"></a>Mixed mode: paired where possible, unpaired otherwise</h3><p>If Bowtie 2 <font color="blue"><strong>cannot find</strong> a <strong>paired-end</strong> alignment for a <strong>pair</strong></font>, <font color="blue">by default it will go on to <strong>look for unpaired alignments</strong> for the constituent mates</font>. This is called “mixed mode.” To disable mixed mode, set the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-no-mixed"><code>--no-mixed</code></a> option.</p>
<p>Bowtie 2 <strong>runs a little faster</strong> in <code>--no-mixed</code> mode, but will only consider alignment status of pairs per se, not individual mates.</p>
<h3 id="Some-SAM-FLAGS-describe-paired-end-properties"><a href="#Some-SAM-FLAGS-describe-paired-end-properties" class="headerlink" title="Some SAM FLAGS describe paired-end properties"></a>Some <font color="red">SAM FLAGS</font> describe <font color="red">paired-end properties</font></h3><p>The SAM <code>FLAGS</code> field, the <font color="red"><strong>second field</strong></font> in a SAM record, has multiple bits that describe the paired-end nature of the read and alignment. </p>
<p>The first (least significant) bit (1 in decimal, 0x1 in hexadecimal) is set if the read is part of a pair. </p>
<p>The second bit (2 in decimal, 0x2 in hexadecimal) is set if <font color="blue">the read is part of a pair that aligned in a paired-end fashion</font>. </p>
<p>The fourth bit (8 in decimal, 0x8 in hexadecimal) is set if the read is part of a pair and the other mate in the pair had at least one valid alignment. </p>
<p>The sixth bit (32 in decimal, 0x20 in hexadecimal) is set if the read is part of a pair and the other mate in the pair aligned to the Crick strand (or, equivalently, if the reverse complement of the other mate aligned to the Watson strand). </p>
<p>The seventh bit (64 in decimal, 0x40 in hexadecimal) is set if the read is mate 1 in a pair. </p>
<p>The eighth bit (128 in decimal, 0x80 in hexadecimal) is set if the read is mate 2 in a pair. </p>
<p>See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for a more detailed description of the <code>FLAGS</code> field.</p>
<h3 id="Some-SAM-optional-fields-describe-more-paired-end-properties"><a href="#Some-SAM-optional-fields-describe-more-paired-end-properties" class="headerlink" title="Some SAM optional fields describe more paired-end properties"></a>Some SAM optional fields describe more paired-end properties</h3><p>The last several fields of each SAM record usually contain SAM optional fields, which are simply tab-separated strings conveying additional information about the reads and alignments. A SAM optional field is formatted like this: “XP:i:1” where “XP” is the <code>TAG</code>, “i” is the <code>TYPE</code> (“integer” in this case), and “1” is the <code>VALUE</code>. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for details regarding SAM optional fields.</p>
<h3 id="Mates-can-overlap-contain-or-dovetail-each-other"><a href="#Mates-can-overlap-contain-or-dovetail-each-other" class="headerlink" title="Mates can overlap, contain, or dovetail each other"></a>Mates can <font color="red">overlap, contain, or dovetail</font> each other</h3><p>The fragment and read lengths might be such that alignments for the two mates from a pair overlap each other. Consider this example:</p>
<p>(For these examples, assume we expect mate 1 to align to the left of mate 2.)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mate 1:    GCAGATTATATGAGTCAGCTACGATATTGTT</span><br><span class="line">Mate 2:                               TGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br><span class="line">Reference: GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br></pre></td></tr></table></figure>

<p>It’s also possible, though unusual, for one mate alignment to contain the other, as in these examples:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mate 1:    GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGC</span><br><span class="line">Mate 2:                               TGTTTGGGGTGACACATTACGC</span><br><span class="line">Reference: GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br><span class="line"></span><br><span class="line">Mate 1:                   CAGCTACGATATTGTTTGGGGTGACACATTACGC</span><br><span class="line">Mate 2:                      CTACGATATTGTTTGGGGTGAC</span><br><span class="line">Reference: GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br></pre></td></tr></table></figure>

<p>And it’s also possible, though unusual, for the mates to “dovetail”, with the mates seemingly extending “past” each other as in this example:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mate 1:                 GTCAGCTACGATATTGTTTGGGGTGACACATTACGC</span><br><span class="line">Mate 2:            TATGAGTCAGCTACGATATTGTTTGGGGTGACACAT                   </span><br><span class="line">Reference: GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br></pre></td></tr></table></figure>

<p>In some situations, it’s desirable for the aligner to consider all these cases as “concordant” as long as other paired-end constraints are not violated. <font color="red"><strong>Bowtie 2’s default</strong></font> behavior is to consider <font color="blue">overlapping and containing</font> as being consistent with <font color="blue">concordant</font> alignment. By default, <font color="blue">dovetailing is considered inconsistent with concordant alignment</font>.</p>
<p>These <font color="red"><strong>defaults can be overridden</strong></font>. Setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-no-overlap"><code>--no-overlap</code></a> causes Bowtie 2 to consider overlapping mates as non-concordant. Setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-no-contain"><code>--no-contain</code></a>causes Bowtie 2 to consider cases where one mate alignment contains the other as non-concordant. Setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail"><code>--dovetail</code></a> causes Bowtie 2 to consider cases where the mate alignments dovetail as concordant.</p>
<h2 id="Reporting"><a href="#Reporting" class="headerlink" title="Reporting"></a>Reporting</h2><p>The reporting mode governs how many alignments Bowtie 2 looks for, and how to report them. Bowtie 2 has three distinct reporting modes. The default reporting mode is similar to the default reporting mode of many other read alignment tools, including <a href="http://bio-bwa.sourceforge.net/">BWA</a>. It is also similar to Bowtie 1’s <code>-M</code>alignment mode.</p>
<p>In general, when we say that a read has an alignment, we mean that it has a <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#valid-alignments-meet-or-exceed-the-minimum-score-threshold">valid alignment</a>. When we say that a read has multiple alignments, we mean that it has multiple alignments that are valid and distinct from one another.</p>
<h3 id="Distinct-alignments-map-a-read-to-different-places"><a href="#Distinct-alignments-map-a-read-to-different-places" class="headerlink" title="Distinct alignments map a read to different places"></a>Distinct alignments map a read to different places</h3><p>Two alignments for the same individual read are “distinct” if they map the same read to different places. Specifically, we say that two alignments are distinct if there are no alignment positions where a particular read offset is aligned opposite a particular reference offset in both alignments with the same orientation. E.g. if the first alignment is in the forward orientation and aligns the read character at read offset 10 to the reference character at chromosome 3, offset 3,445,245, and the second alignment is also in the forward orientation and also aligns the read character at read offset 10 to the reference character at chromosome 3, offset 3,445,245, they are not distinct alignments.</p>
<p>Two alignments for the same pair are distinct if either the mate 1s in the two paired-end alignments are distinct or the mate 2s in the two alignments are distinct or both.</p>
<h3 id="Default-mode-search-for-multiple-alignments-report-the-best-one"><a href="#Default-mode-search-for-multiple-alignments-report-the-best-one" class="headerlink" title="Default mode: search for multiple alignments, report the best one"></a><font color="red">Default mode</font>: search for multiple alignments, <font color="red">report the best one</font></h3><p>By default, Bowtie 2 searches for distinct, valid alignments for each read. When it finds a valid alignment, it generally will continue to look for alignments that are nearly as good or better. It will eventually stop looking, either because it <font color="red">exceeded a limit placed on search effort</font> (see <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-D"><code>-D</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-R"><code>-R</code></a>) or because it already knows all it needs to know to report an alignment. <font color="blue">Information from the best alignments are used to estimate mapping quality</font> (the <code>MAPQ</code> <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM</a> field) and to set SAM optional fields, such as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-as"><code>AS:i</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-xs"><code>XS:i</code></a>. Bowtie 2 does not guarantee that the alignment reported is the best possible in terms of alignment score.</p>
<p>See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-D"><code>-D</code></a>, which puts an <strong>upper limit</strong> on the number of dynamic programming problems (i.e. seed extensions) that can “fail” in a row before Bowtie 2 stops searching. Increasing <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-D"><code>-D</code></a> makes Bowtie 2 <strong>slower</strong>, but increases the likelihood that it will report the correct alignment for a read that aligns many places.</p>
<p>See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-R"><code>-R</code></a>, which sets the maximum number of times Bowtie 2 will “re-seed” when attempting to align a read with repetitive seeds. Increasing <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-R"><code>-R</code></a>makes Bowtie 2 <strong>slower</strong>, but increases the likelihood that it will report the correct alignment for a read that aligns many places.</p>
<h3 id="k-mode-search-for-one-or-more-alignments-report-each"><a href="#k-mode-search-for-one-or-more-alignments-report-each" class="headerlink" title="-k mode: search for one or more alignments, report each"></a><font color="red">-k mode</font>: search for one or more alignments, report each</h3><p>In <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a> mode, Bowtie 2 <font color="red">searches for up to N distinct</font>, valid alignments for each read, where N equals the integer specified with the <code>-k</code> parameter. That is, if <code>-k 2</code> is specified, Bowtie 2 will search for at most 2 distinct alignments. It reports all alignments found, in descending order by alignment score. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM ‘secondary’ bit (which equals 256) set in its FLAGS field. Supplementary alignments will also be assigned a MAPQ of 255. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for details.</p>
<p>Bowtie 2 does not “find” alignments in any specific order, so for reads that have more than N distinct, valid alignments, Bowtie 2 does not guarantee that the N alignments reported are the best possible in terms of alignment score. Still, this mode can be effective and fast in situations where the user <font color="red">cares more about whether a read aligns (or aligns a certain number of times) than where exactly it originated</font>.</p>
<h3 id="a-mode-search-for-and-report-all-alignments"><a href="#a-mode-search-for-and-report-all-alignments" class="headerlink" title="-a mode: search for and report all alignments"></a>-a mode: search for and report all alignments</h3><p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-a"><code>-a</code></a> mode is similar to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a> mode except that there is <font color="red">no upper limit on the number of alignments Bowtie 2 should report</font>. Alignments are reported in descending order by alignment score. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM ‘secondary’ bit (which equals 256) set in its FLAGS field. Supplementary alignments will be assigned a MAPQ of 255. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for details.</p>
<p>Some tools are designed with this reporting mode in mind. Bowtie 2 is not! For very large genomes, this mode is <strong>very slow</strong>.</p>
<h3 id="Randomness-in-Bowtie-2"><a href="#Randomness-in-Bowtie-2" class="headerlink" title="Randomness in Bowtie 2"></a>Randomness in Bowtie 2</h3><p>Bowtie 2’s search for alignments for a given read is “randomized.” That is, when Bowtie 2 encounters <font color="blue">a set of equally-good choices, it uses a <strong>pseudo-random number</strong> to choose?</font>. For example, if Bowtie 2 discovers a set of 3 equally-good alignments and wants to decide which to report, it picks a pseudo-random integer 0, 1 or 2 and reports the corresponding alignment. Arbitrary choices can crop up at various points during alignment.</p>
<p>The pseudo-random number generator is re-initialized for every read, and the seed used to initialize it is a function of the read name, nucleotide string, quality string, and the value specified with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-seed"><code>--seed</code></a>. If you run the same version of Bowtie 2 on two reads with identical names, nucleotide strings, and quality strings, and if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-seed"><code>--seed</code></a> is <font color="blue">set the same for both runs, Bowtie 2 will produce the same output</font>; i.e., it will align the read to the same place, even if there are multiple equally good alignments. This is intuitive and desirable in most cases. <font color="red">Most users expect Bowtie to produce the <strong>same output</strong> when run twice on the <strong>same input</strong></font>.</p>
<p>However, when the user specifies the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-non-deterministic"><code>--non-deterministic</code></a> option, Bowtie 2 will use the current time to re-initialize the pseudo-random number generator. When this is specified, Bowtie 2 might report different alignments for identical reads. This is counter-intuitive for some users, but might be more appropriate in situations where the input consists of many identical reads.</p>
<h2 id="Multiseed-heuristic"><a href="#Multiseed-heuristic" class="headerlink" title="Multiseed heuristic"></a>Multiseed heuristic</h2><p>To rapidly narrow the number of possible alignments that must be considered, Bowtie 2 begins by extracting substrings (“seeds”) from the read and its reverse complement and aligning them in an ungapped fashion with the help of the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a>. This is “multiseed alignment” and it is similar to what <a href="http://genomebiology.com/2009/10/3/R25">Bowtie 1 does</a>, except Bowtie 1 attempts to align the entire read this way.</p>
<p>This initial step makes Bowtie 2 much faster than it would be without such a filter, but at the expense of missing some valid alignments. For instance, it is possible for a read to have a valid overall alignment but to have no valid seed alignments because each potential seed alignment is interrupted by too many mismatches or gaps.</p>
<p>The <font color="red">trade-off between <strong>speed</strong> and <strong>sensitivity/accuracy</strong> can be adjusted by setting the seed length</font> (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-L"><code>-L</code></a>), the interval between extracted seeds (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-i"><code>-i</code></a>), and the number of mismatches permitted per seed (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-N"><code>-N</code></a>). For more sensitive alignment, set these parameters to (a) make the seeds closer together, (b) make the seeds shorter, and/or (c) allow more mismatches. You can adjust these options one-by-one, though Bowtie 2 comes with some useful combinations of options prepackaged as “<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#presets-setting-many-settings-at-once">preset options</a>.”</p>
<p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-D"><code>-D</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-R"><code>-R</code></a> are also options that adjust the trade-off between speed and sensitivity/accuracy.</p>
<h3 id="FM-Index-memory-footprint"><a href="#FM-Index-memory-footprint" class="headerlink" title="FM Index memory footprint"></a>FM Index memory footprint</h3><p>Bowtie 2 uses the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a> to find ungapped alignments for seeds. This step accounts for the bulk of Bowtie 2’s memory footprint, as the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a>itself is typically the largest data structure used. For instance, the memory footprint of the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a> for the human genome is about 3.2 gigabytes of RAM.</p>
<h2 id="Ambiguous-characters"><a href="#Ambiguous-characters" class="headerlink" title="Ambiguous characters"></a>Ambiguous characters</h2><p>Non-whitespace characters besides A, C, G or T are considered “ambiguous.” N is a common ambiguous character that appears in reference sequences. Bowtie 2 considers all ambiguous characters in the reference (including <a href="http://www.bioinformatics.org/sms/iupac.html">IUPAC nucleotide codes</a>) to be Ns.</p>
<p>Bowtie 2 <font color="red"><strong>allows</strong> alignments to overlap ambiguous characters in the reference</font>. An alignment position that contains an ambiguous character in the read, reference, or both, is penalized according to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-np"><code>--np</code></a>. <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-n-ceil"><code>--n-ceil</code></a> sets an upper limit on the number of positions that may contain ambiguous reference characters in a valid alignment. The optional field <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-xn"><code>XN:i</code></a> reports the number of ambiguous reference characters overlapped by an alignment.</p>
<p>Note that the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed heuristic</a> cannot find <em>seed</em> alignments that overlap ambiguous reference characters. For an alignment overlapping an ambiguous reference character to be found, it must have one or more seed alignments that do not overlap ambiguous reference characters.</p>
<h2 id="Presets-setting-many-settings-at-once"><a href="#Presets-setting-many-settings-at-once" class="headerlink" title="Presets: setting many settings at once"></a>Presets: setting many settings at once</h2><p>Bowtie 2 comes with some useful combinations of parameters packaged into shorter “preset” parameters. For example, running Bowtie 2 with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-very-sensitive"><code>--very-sensitive</code></a> option is the same as running with options: <code>-D 20 -R 3 -N 0 -L 20 -i S,1,0.50</code>. The preset options that come with Bowtie 2 are <font color="red">designed to cover a wide area of the speed/sensitivity/accuracy trade-off space</font>, with the presets ending in <code>fast</code> generally being faster but less sensitive and less accurate, and the presets ending in <code>sensitive</code> generally being slower but <strong>more sensitive and more accurate</strong>. See the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#preset-options-in---end-to-end-mode">documentation for the preset options</a> for details.</p>
<p>As of Bowtie2 v2.4.0, individual preset values can be overridden by providing the specific options e.g. the configured seed length of 20 in the [<code>--very-senitive</code>] preset above can be changed to 25 by <strong>also specifying</strong> the <code>-L 25</code> parameter anywhere on the command line[masked -L 20].</p>
<h2 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h2><p>Some <font color="red"><strong>reads</strong></font> are skipped or “<font color="red"><strong>filtered out</strong></font>“ by Bowtie 2. For example, reads may be filtered out because they are extremely short or have a high proportion of ambiguous nucleotides. Bowtie 2 will still print a SAM record for such a read, but no alignment will be reported and the <code>YF:i</code> SAM optional field will be set to indicate the reason the read was filtered.</p>
<ul>
<li><code>YF:Z:LN</code>: the read was filtered because it had <font color="blue">length less than or equal</font> to the number of seed mismatches set with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-N"><code>-N</code></a> option.</li>
<li><code>YF:Z:NS</code>: the read was filtered because it <font color="blue">contains a number of ambiguous characters</font> (usually <code>N</code> or <code>.</code>) greater than the ceiling specified with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-n-ceil"><code>--n-ceil</code></a>.</li>
<li><code>YF:Z:SC</code>: the read was filtered because the read length and the match bonus (set with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>) are such that the read <font color="blue">can’t possibly earn an alignment score</font> greater than or equal to the threshold set with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-score-min"><code>--score-min</code></a></li>
<li><code>YF:Z:QC</code>: the read was filtered because it was <font color="blue">marked as failing quality control</font> and the user specified the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-qc-filter"><code>--qc-filter</code></a> option. This only happens when the input is in Illumina’s QSEQ format (i.e. when <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-qseq"><code>--qseq</code></a> is specified) and the last (11th) field of the read’s QSEQ record contains <code>1</code>.</li>
</ul>
<p>If a read could be filtered for more than one reason, the value <code>YF:Z</code> flag will reflect only one of those reasons.</p>
<h2 id="Alignment-summary"><a href="#Alignment-summary" class="headerlink" title="Alignment summary"></a>Alignment summary</h2><p>When Bowtie 2 finishes running, it prints messages summarizing what happened. These messages are printed to the “standard error” (“stderr”) filehandle. For datasets <font color="blue">consisting of unpaired reads</font>, the summary might look like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">20000 reads; of these:</span><br><span class="line">  20000 (100.00%) were unpaired; of these:</span><br><span class="line">    1247 (6.24%) aligned 0 times</span><br><span class="line">    18739 (93.69%) aligned exactly 1 time</span><br><span class="line">    14 (0.07%) aligned &gt;1 times</span><br><span class="line">93.77% overall alignment rate</span><br></pre></td></tr></table></figure>

<p>For datasets <font color="blue">consisting of pairs</font>, the summary might look like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10000 reads; of these:</span><br><span class="line">  10000 (100.00%) were paired; of these:</span><br><span class="line">    650 (6.50%) aligned concordantly 0 times</span><br><span class="line">    8823 (88.23%) aligned concordantly exactly 1 time</span><br><span class="line">    527 (5.27%) aligned concordantly &gt;1 times</span><br><span class="line">    ----</span><br><span class="line">    650 pairs aligned concordantly 0 times; of these:</span><br><span class="line">      34 (5.23%) aligned discordantly 1 time</span><br><span class="line">    ----</span><br><span class="line">    616 pairs aligned 0 times concordantly or discordantly; of these:</span><br><span class="line">      1232 mates make up the pairs; of these:</span><br><span class="line">        660 (53.57%) aligned 0 times</span><br><span class="line">        571 (46.35%) aligned exactly 1 time</span><br><span class="line">        1 (0.08%) aligned &gt;1 times</span><br><span class="line">96.70% overall alignment rate</span><br></pre></td></tr></table></figure>

<p>The indentation indicates how subtotals relate to totals.</p>
<h2 id="Wrapper-scripts"><a href="#Wrapper-scripts" class="headerlink" title="Wrapper scripts"></a>Wrapper scripts</h2><p>The <code>bowtie2</code>, <code>bowtie2-build</code> and <code>bowtie2-inspect</code> executables are actually wrapper scripts that call binary programs as appropriate. The wrappers shield users from having to distinguish between “small” and “large” index formats, discussed briefly in the following section. Also, the <code>bowtie2</code>wrapper provides some key functionality, like the ability to handle compressed inputs, and the functionality for <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-un"><code>--un</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-al"><code>--al</code></a> and related options.</p>
<p>It is recommended that you always run the bowtie2 wrappers and <strong>not run the binaries directly.</strong></p>
<h2 id="Small-and-large-indexes"><a href="#Small-and-large-indexes" class="headerlink" title="Small and large indexes"></a>Small and large indexes</h2><p><code>bowtie2-build</code> can index reference genomes of any size. For genomes less than about 4 billion nucleotides in length, <code>bowtie2-build</code> builds a “small” index using 32-bit numbers in various parts of the index. When the genome is longer, <code>bowtie2-build</code> builds a “large” index using 64-bit numbers. <font color="blue">Small indexes are stored in files with the <code>.bt2</code> extension, and large indexes are stored in files with the <code>.bt2l</code> extension. </font>The user need not worry about whether a particular index is small or large; the wrapper scripts will automatically build and use the appropriate index.</p>
<h2 id="Performance-tuning"><a href="#Performance-tuning" class="headerlink" title="Performance tuning"></a>Performance tuning</h2><ol>
<li><p>If your computer has multiple processors/cores, use <code>-p</code></p>
<p>The <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> option causes Bowtie 2 to launch a specified number of parallel search threads. Each thread runs on a different processor/core and all threads find alignments in parallel, increasing alignment throughput by approximately a multiple of the number of threads (though in practice, speedup is somewhat worse than linear).</p>
</li>
<li><p>If reporting many alignments per read, try reducing <code>bowtie2-build --offrate</code></p>
<p><font color="blue">If you are using <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a> or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-a"><code>-a</code></a> options and Bowtie 2 is reporting many alignments per read, using an index with a denser SA sample can speed things up considerably</font>. To do this, specify a smaller-than-default <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-o"><code>-o</code>/<code>--offrate</code></a> value when running <code>bowtie2-build</code>. A denser SA sample yields a larger index, but is also particularly effective at speeding up alignment when many alignments are reported per read.</p>
</li>
<li><p>If <code>bowtie2</code> “thrashes”, try increasing <code>bowtie2-build --offrate</code></p>
<p>If <code>bowtie2</code> runs very slowly on a relatively low-memory computer, try setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-o"><code>-o</code>/<code>--offrate</code></a> to a <em>larger</em> value when building the index. This decreases the memory footprint of the index.</p>
</li>
</ol>
<h2 id="Command-Line"><a href="#Command-Line" class="headerlink" title="Command Line"></a>Command Line</h2><h3 id="Alignment"><a href="#Alignment" class="headerlink" title="Alignment"></a><font color="red">Alignment</font></h3><p>Here are a few that may benefit the alignment of an <a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">ATAC-seq dataset on Cannon</a>:</p>
<table>
<thead>
<tr>
<th align="left">Argument</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>-X &lt;int&gt;</code></td>
<td align="left"><strong>Maximum DNA fragment length</strong> (default 500bp). If you anticipate that you may have DNA fragments longer than the default value, you should increase this parameter accordingly; otherwise, alignments from such fragments are considered not properly paired (see Fig. 3B below).</td>
</tr>
<tr>
<td align="left"><code>--very-sensitive</code></td>
<td align="left">Bowtie2 has a number of alignment and effort parameters that interact in complex (and sometimes unexpected) ways. Preset collections of these parameters are provided for convenience; the default is <code>--sensitive</code>, but <strong>better alignment results</strong> are frequently achieved with <code>--very-sensitive</code>.</td>
</tr>
<tr>
<td align="left"><code>-k &lt;int&gt;</code></td>
<td align="left">Maximum number of <strong>alignments to report per read</strong>. By default, Bowtie2 reports at most one alignment per read, and if multiple equivalent alignments exist, it chooses one randomly. Generate huge output</td>
</tr>
<tr>
<td align="left"><code>-p &lt;int&gt;</code></td>
<td align="left">Number of cores on which to run</td>
</tr>
</tbody></table>
<p>The output is a <a href="https://samtools.github.io/hts-specs/SAMv1.pdf">SAM file</a>, which contains alignment information for each input read. The SAM <strong>should be compressed to a binary format (BAM)</strong> and sorted by queryname with <a href="http://www.htslib.org/doc/samtools.html">SAMtools</a>. This is best accomplished by piping the output from Bowtie2 directly to <code>samtools view</code> and <code>samtools sort</code>, </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">module load bowtie2   <span class="comment"># if not already loaded</span></span><br><span class="line">module load samtools</span><br><span class="line">bowtie2  --very-sensitive  -k 10  -x &lt;genomeIndexName&gt;  -1 &lt;name&gt;_1.fastq.gz  -2 &lt;name&gt;_2.fastq.gz  \</span><br><span class="line">  |  samtools view  -u  -  \</span><br><span class="line">  |  samtools sort  -n  -o &lt;BAM&gt;  -</span><br></pre></td></tr></table></figure>

<p>For input files of <strong>20 million paired reads</strong>, this command takes around <strong>five hours</strong> on Cannon. This can be decreased by increasing the number of cores in the Bowtie2 command. For example, one could specify eight cores for Bowtie2 with <code>-p 8</code> and adjust the request in the SLURM script to <code>#SBATCH -n 10</code>(that is, <strong>eight cores for Bowtie2 and one each for SAMtools view and sort, simultaneously processing</strong>). The memory usage of Bowtie2 depends primarily on the genome length; enough must be requested to load the genome indexes.</p>
<p>Bowtie2 also provides (via <code>stderr</code>) a summary of the mapping results, separated according to uniqueness and alignment type (concordant, discordant, and non-concordant/non-discordant). In terms of alignment interpretation, it is conceptually easier to divide alignments into two <strong>basic categories: properly paired and unpaired</strong> (Fig. 3).</p>
<p><img src="/blog/2022/03/20/2022-03-20-bowtie2/1.png" alt="Alignment types"></p>
<p><strong>Figure 3. Alignment types for paired-end reads. A:</strong> Properly paired alignments (“concordant”) have the reads aligned in opposite orientations on the same reference sequence (chromosome). The reads may overlap to some extent (bottom).  <strong>B:</strong> A read alignment (for R1) can be unpaired for several reasons: if the read’s mate (R2) is unaligned (upper left), aligns to a different chromosome (upper right), aligns in the incorrect orientation (middle cases), or aligns in the correct orientation but at an invalid distance (bottom). In all cases except the upper left, the R2 read alignment is also unpaired, and the read pair align discordantly (though Bowtie2 also requires uniqueness for such alignments to be counted as discordant).</p>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2 [options]* -x &lt;bt2-idx&gt; &#123;-1 &lt;m1&gt; -2 &lt;m2&gt; | -U &lt;r&gt; | --interleaved &lt;i&gt; | --sra-acc &lt;acc&gt; | b &lt;bam&gt;&#125; -S [&lt;sam&gt;]</span><br></pre></td></tr></table></figure>

<h3 id="Main-arguments"><a href="#Main-arguments" class="headerlink" title="Main arguments"></a>Main arguments</h3><table>
<thead>
<tr>
<th><code>-x &lt;bt2-idx&gt;</code></th>
<th>The basename of the index for the reference genome.</th>
</tr>
</thead>
<tbody><tr>
<td><code>-1 &lt;m1&gt;</code></td>
<td>Comma-separated list of files containing mate 1s (filename usually includes <code>_1</code>), e.g. <code>-1 flyA_1.fq,flyB_1.fq</code>.</td>
</tr>
<tr>
<td><code>-2 &lt;m2&gt;</code></td>
<td>Comma-separated list of files containing mate 2s (filename usually includes <code>_2</code>), e.g. <code>-2 flyA_2.fq,flyB_2.fq</code>.</td>
</tr>
<tr>
<td><code>-U &lt;r&gt;</code></td>
<td>Comma-separated list of files containing unpaired reads to be aligned, e.g. <code>lane1.fq,lane2.fq,lane3.fq,lane4.fq</code>. Reads may be a mix of different lengths. If <code>-</code> is specified, <code>bowtie2</code> gets the reads from the “standard in” or “stdin” filehandle.</td>
</tr>
<tr>
<td><code>--interleaved</code></td>
<td>Reads interleaved FASTQ files where the first two records (8 lines) represent a mate pair.</td>
</tr>
<tr>
<td><code>--sra-acc</code></td>
<td>Reads are SRA accessions.</td>
</tr>
<tr>
<td><code>-b &lt;bam&gt;</code></td>
<td>Reads are unaligned BAM records sorted by read name. The <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-align-paired-reads"><code>--align-paired-reads</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-preserve-tags"><code>--preserve-tags</code></a> options affect the way Bowtie 2 processes records.</td>
</tr>
<tr>
<td><code>-S &lt;sam&gt;</code></td>
<td>File to write SAM alignments to. By default, alignments are written to the “standard out” or “stdout” filehandle (i.e. the console).</td>
</tr>
</tbody></table>
<h3 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h3><h4 id="Input-options"><a href="#Input-options" class="headerlink" title="Input options"></a>Input options</h4><table>
<thead>
<tr>
<th><code>-q</code></th>
<th>Reads (specified with <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code>, <code>&lt;s&gt;</code>) are FASTQ files. FASTQ files usually have extension <code>.fq</code> or <code>.fastq</code>. FASTQ is the default format. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-solexa-quals"><code>--solexa-quals</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-int-quals"><code>--int-quals</code></a>.</th>
</tr>
</thead>
<tbody><tr>
<td><code>--tab5</code></td>
<td>Each read or pair is on a single line. An unpaired read line is <code>[name]\t[seq]\t[qual]\n</code>. A paired-end read line is <code>[name]\t[seq1]\t[qual1]\t[seq2]\t[qual2]\n</code>. An input file can be a mix of unpaired and paired-end reads and Bowtie 2 recognizes each according to the number of fields, handling each as it should.</td>
</tr>
<tr>
<td><code>--tab6</code></td>
<td>Similar to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-tab5"><code>--tab5</code></a> except, for paired-end reads, the second end can have a different name from the first: <code>[name1]\t[seq1]\t[qual1]\t[name2]\t[seq2]\t[qual2]\n</code></td>
</tr>
<tr>
<td><code>--qseq</code></td>
<td>Reads (specified with <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code>, <code>&lt;s&gt;</code>) are QSEQ files. QSEQ files usually end in <code>_qseq.txt</code>. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-solexa-quals"><code>--solexa-quals</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-int-quals"><code>--int-quals</code></a>.</td>
</tr>
<tr>
<td><code>-f</code></td>
<td>Reads (specified with <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code>, <code>&lt;s&gt;</code>) are <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files. <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files usually have extension <code>.fa</code>, <code>.fasta</code>, <code>.mfa</code>, <code>.fna</code>or similar. <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files do not have a way of specifying quality values, so when <code>-f</code> is set, the result is as if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ignore-quals"><code>--ignore-quals</code></a> is also set.</td>
</tr>
<tr>
<td><code>-r</code></td>
<td>Reads (specified with <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code>, <code>&lt;s&gt;</code>) are files with one input sequence per line, without any other information (no read names, no qualities). When <code>-r</code> is set, the result is as if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ignore-quals"><code>--ignore-quals</code></a> is also set.</td>
</tr>
<tr>
<td><code>-F k:&lt;int&gt;,i:&lt;int&gt;</code></td>
<td>Reads are substrings (k-mers) extracted from a FASTA file <code>&lt;s&gt;</code>. Specifically, for every reference sequence in FASTA file <code>&lt;s&gt;</code>, Bowtie 2 aligns the k-mers at offsets 1, 1+i, 1+2i, … until reaching the end of the reference. Each k-mer is aligned as a separate read. Quality values are set to all Is (40 on Phred scale). Each k-mer (read) is given a name like <code>&lt;sequence&gt;_&lt;offset&gt;</code>, where <code>&lt;sequence&gt;</code> is the name of the FASTA sequence it was drawn from and <code>&lt;offset&gt;</code> is its 0-based offset of origin with respect to the sequence. Only single k-mers, i.e. unpaired reads, can be aligned in this way.</td>
</tr>
<tr>
<td><code>-c</code></td>
<td>The read sequences are given on command line. I.e. <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code> and <code>&lt;singles&gt;</code> are comma-separated lists of reads rather than lists of read files. There is no way to specify read names or qualities, so <code>-c</code> also implies <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ignore-quals"><code>--ignore-quals</code></a>.</td>
</tr>
<tr>
<td><code>-s/--skip &lt;int&gt;</code></td>
<td><strong>Skip (i.e. do not align) the first <code>&lt;int&gt;</code> reads or pairs in the input.</strong></td>
</tr>
<tr>
<td><code>-u/--qupto &lt;int&gt;</code></td>
<td><strong>Align the first <code>&lt;int&gt;</code> reads or read pairs from the input</strong> (after the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-s"><code>-s</code>/<code>--skip</code></a> reads or pairs have been skipped), then stop. Default: no limit.</td>
</tr>
<tr>
<td><code>-5/--trim5 &lt;int&gt;</code></td>
<td><strong>Trim <code>&lt;int&gt;</code> bases from 5’ (left) end</strong> of each read before alignment (default: <strong>0</strong>).</td>
</tr>
<tr>
<td><code>-3/--trim3 &lt;int&gt;</code></td>
<td><strong>Trim <code>&lt;int&gt;</code> bases from 3’ (right) end</strong> of each read before alignment (default: <strong>0</strong>).</td>
</tr>
<tr>
<td>`–trim-to [3:</td>
<td>5:]<int>`</int></td>
</tr>
<tr>
<td><code>--phred33</code></td>
<td>Input qualities are ASCII chars equal to the <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred quality</a> plus 33. This is also called the “Phred+33” encoding, which is <strong>used by the very latest Illumina pipelines.</strong></td>
</tr>
<tr>
<td><code>--phred64</code></td>
<td>Input qualities are ASCII chars equal to the <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred quality</a> plus 64. This is also called the “Phred+64” encoding.</td>
</tr>
<tr>
<td><code>--solexa-quals</code></td>
<td>Convert input qualities from <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Solexa</a> (which can be negative) to <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred</a> (which can’t). This scheme was used in older Illumina GA Pipeline versions (prior to 1.3). <strong>Default: off.</strong></td>
</tr>
<tr>
<td><code>--int-quals</code></td>
<td>Quality values are represented in the read input file as space-separated ASCII integers, e.g., <code>40 40 30 40</code>…, rather than ASCII characters, e.g., <code>II?I</code>…. Integers are treated as being on the <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred quality</a> scale unless <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-solexa-quals"><code>--solexa-quals</code></a> is also specified. <strong>Default: off.</strong></td>
</tr>
</tbody></table>
<h4 id="Preset-options-in-end-to-end-mode"><a href="#Preset-options-in-end-to-end-mode" class="headerlink" title="Preset options in --end-to-end mode"></a>Preset options in <code>--end-to-end</code> mode</h4><table>
<thead>
<tr>
<th><code>--very-fast</code></th>
<th>Same as: <code>-D 5 -R 1 -N 0 -L 22 -i S,0,2.50</code></th>
</tr>
</thead>
<tbody><tr>
<td><code>--fast</code></td>
<td>Same as: <code>-D 10 -R 2 -N 0 -L 22 -i S,0,2.50</code></td>
</tr>
<tr>
<td><code>--sensitive</code></td>
<td>Same as: <code>-D 15 -R 2 -N 0 -L 22 -i S,1,1.15</code> (default in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode)</td>
</tr>
<tr>
<td><code>--very-sensitive</code></td>
<td>Same as: <code>-D 20 -R 3 -N 0 -L 20 -i S,1,0.50</code></td>
</tr>
</tbody></table>
<h4 id="Preset-options-in-local-mode"><a href="#Preset-options-in-local-mode" class="headerlink" title="Preset options in --local mode"></a>Preset options in <code>--local</code> mode</h4><table>
<thead>
<tr>
<th><code>--very-fast-local</code></th>
<th>Same as: <code>-D 5 -R 1 -N 0 -L 25 -i S,1,2.00</code></th>
</tr>
</thead>
<tbody><tr>
<td><code>--fast-local</code></td>
<td>Same as: <code>-D 10 -R 2 -N 0 -L 22 -i S,1,1.75</code></td>
</tr>
<tr>
<td><code>--sensitive-local</code></td>
<td>Same as: <code>-D 15 -R 2 -N 0 -L 20 -i S,1,0.75</code> (default in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode)</td>
</tr>
<tr>
<td><code>--very-sensitive-local</code></td>
<td>Same as: <code>-D 20 -R 3 -N 0 -L 20 -i S,1,0.50</code></td>
</tr>
</tbody></table>
<h4 id="Alignment-options"><a href="#Alignment-options" class="headerlink" title="Alignment options"></a>Alignment options</h4><table>
<thead>
<tr>
<th><code>-N &lt;int&gt;</code></th>
<th>Sets the number of mismatches to allowed in a seed alignment during <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed alignment</a>. Can be set to 0 or 1. Setting this higher makes alignment slower (often much slower) but increases sensitivity. Default: 0.</th>
</tr>
</thead>
<tbody><tr>
<td><code>-L &lt;int&gt;</code></td>
<td><strong>Sets the length of the seed substrings to align</strong> during <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed alignment</a>. <font color="red"><strong>Smaller values make alignment slower but more sensitive</strong></font>. Default: the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-sensitive"><code>--sensitive</code></a> preset is used by default, which sets <code>-L</code> to 22 and 20 in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode and in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode.</td>
</tr>
<tr>
<td><code>-i &lt;func&gt;</code></td>
<td>Sets a function governing the interval between seed substrings to use during <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed alignment</a>. For instance, if the read has 30 characters, and seed length is 10, and the seed interval is 6, the seeds extracted will be:<code>Read:      TAGCTACGCTCTACGCTATCATGCATAAAC Seed 1 fw: TAGCTACGCT Seed 1 rc: AGCGTAGCTA Seed 2 fw:       CGCTCTACGC Seed 2 rc:       GCGTAGAGCG Seed 3 fw:             ACGCTATCAT Seed 3 rc:             ATGATAGCGT Seed 4 fw:                   TCATGCATAA Seed 4 rc:                   TTATGCATGA</code>Since it’s best to use longer intervals for longer reads, this parameter sets the interval as a function of the read length, rather than a single one-size-fits-all number. For instance, specifying <code>-i S,1,2.5</code> sets the interval function <code>f</code> to <code>f(x) = 1 + 2.5 * sqrt(x)</code>, where x is the read length. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#setting-function-options">setting function options</a>. If the function returns a result less than 1, it is rounded up to 1. Default: the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-sensitive"><code>--sensitive</code></a> preset is used by default, which sets <code>-i</code> to <code>S,1,1.15</code> in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a>mode to <code>-i S,1,0.75</code> in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode.</td>
</tr>
<tr>
<td><code>--n-ceil &lt;func&gt;</code></td>
<td>Sets a function governing the maximum number of ambiguous characters (usually <code>N</code>s and/or <code>.</code>s) allowed in a read as a function of read length. For instance, specifying <code>-L,0,0.15</code> sets the N-ceiling function <code>f</code> to <code>f(x) = 0 + 0.15 * x</code>, where x is the read length. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#setting-function-options">setting function options</a>. Reads exceeding this ceiling are <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#filtering">filtered out</a>. Default: <code>L,0,0.15</code>.</td>
</tr>
<tr>
<td><code>--dpad &lt;int&gt;</code></td>
<td>“Pads” dynamic programming problems by <code>&lt;int&gt;</code> columns on either side to allow gaps. Default: 15.</td>
</tr>
<tr>
<td><code>--gbar &lt;int&gt;</code></td>
<td>Disallow gaps within <code>&lt;int&gt;</code> positions of the beginning or end of the read. Default: 4.</td>
</tr>
<tr>
<td><code>--ignore-quals</code></td>
<td>When calculating a mismatch penalty, always consider the quality value at the mismatched position to be the highest possible, regardless of the actual value. I.e. input is treated as though all quality values are high. This is also the default behavior when the input doesn’t specify quality values (e.g. in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-f"><code>-f</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-r"><code>-r</code></a>, or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-c"><code>-c</code></a> modes).</td>
</tr>
<tr>
<td><code>--nofw/--norc</code></td>
<td>If <code>--nofw</code> is specified, <code>bowtie2</code> will not attempt to align unpaired reads to the forward (Watson) reference strand. If <code>--norc</code> is specified, <code>bowtie2</code> will not attempt to align unpaired reads against the reverse-complement (Crick) reference strand. In paired-end mode, <code>--nofw</code> and <code>--norc</code> pertain to the fragments; i.e. specifying <code>--nofw</code> causes <code>bowtie2</code> to explore only those paired-end configurations corresponding to fragments from the reverse-complement (Crick) strand. Default: both strands enabled.</td>
</tr>
<tr>
<td><code>--no-1mm-upfront</code></td>
<td>By default, Bowtie 2 will attempt to find either an exact or a 1-mismatch end-to-end alignment for the read <em>before</em> trying the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed heuristic</a>. Such alignments can be found very quickly, and many short read alignments have exact or near-exact end-to-end alignments. However, this can lead to unexpected alignments when the user also sets options governing the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed heuristic</a>, like <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-L"><code>-L</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-N"><code>-N</code></a>. For instance, if the user specifies <code>-N 0</code> and <code>-L</code> equal to the length of the read, the user will be surprised to find 1-mismatch alignments reported. This option prevents Bowtie 2 from searching for 1-mismatch end-to-end alignments before using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed heuristic</a>, which leads to the expected behavior when combined with options such as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-L"><code>-L</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-N"><code>-N</code></a>. This comes at the expense of speed.</td>
</tr>
<tr>
<td><code>--end-to-end</code></td>
<td>In this mode, Bowtie 2 requires that the entire read align from one end to the other, without any trimming (or “soft clipping”) of characters from either end. The match bonus <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a> always equals 0 in this mode, so all alignment scores are less than or equal to 0, and the greatest possible alignment score is 0. This is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a>. <code>--end-to-end</code> is the default mode.</td>
</tr>
<tr>
<td><code>--local</code></td>
<td>In this mode, Bowtie 2 does not require that the entire read align from one end to the other. Rather, some characters may be omitted (“soft clipped”) from the ends in order to achieve the greatest possible alignment score. The match bonus <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>is used in this mode, and the best possible alignment score is equal to the match bonus (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>) times the length of the read. Specifying <code>--local</code> and one of the presets (e.g. <code>--local --very-fast</code>) is equivalent to specifying the local version of the preset (<code>--very-fast-local</code>). This is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a>. <code>--end-to-end</code> is the default mode.</td>
</tr>
</tbody></table>
<h4 id="Scoring-options"><a href="#Scoring-options" class="headerlink" title="Scoring options"></a>Scoring options</h4><table>
<thead>
<tr>
<th><code>--ma &lt;int&gt;</code></th>
<th>Sets the match bonus. In <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode <code>&lt;int&gt;</code> is added to the alignment score for each position where a read character aligns to a reference character and the characters match. Not used in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode. Default: 2.</th>
</tr>
</thead>
<tbody><tr>
<td><code>--mp MX,MN</code></td>
<td>Sets the maximum (<code>MX</code>) and minimum (<code>MN</code>) mismatch penalties, both integers. A number less than or equal to <code>MX</code> and greater than or equal to <code>MN</code> is subtracted from the alignment score for each position where a read character aligns to a reference character, the characters do not match, and neither is an <code>N</code>. If <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ignore-quals"><code>--ignore-quals</code></a> is specified, the number subtracted quals <code>MX</code>. Otherwise, the number subtracted is <code>MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) )</code> where Q is the Phred quality value. Default: <code>MX</code> = 6, <code>MN</code> = 2.</td>
</tr>
<tr>
<td><code>--np &lt;int&gt;</code></td>
<td>Sets penalty for positions where the read, reference, or both, contain an ambiguous character such as <code>N</code>. Default: 1.</td>
</tr>
<tr>
<td><code>--rdg &lt;int1&gt;,&lt;int2&gt;</code></td>
<td>Sets the read gap open (<code>&lt;int1&gt;</code>) and extend (<code>&lt;int2&gt;</code>) penalties. A read gap of length N gets a penalty of <code>&lt;int1&gt;</code> + N * <code>&lt;int2&gt;</code>. Default: 5, 3.</td>
</tr>
<tr>
<td><code>--rfg &lt;int1&gt;,&lt;int2&gt;</code></td>
<td>Sets the reference gap open (<code>&lt;int1&gt;</code>) and extend (<code>&lt;int2&gt;</code>) penalties. A reference gap of length N gets a penalty of <code>&lt;int1&gt;</code> + N * <code>&lt;int2&gt;</code>. Default: 5, 3.</td>
</tr>
<tr>
<td><code>--score-min &lt;func&gt;</code></td>
<td>Sets a function governing the minimum alignment score needed for an alignment to be considered “valid” (i.e. good enough to report). This is a function of read length. For instance, specifying <code>L,0,-0.6</code> sets the minimum-score function <code>f</code> to <code>f(x) = 0 + -0.6 * x</code>, where <code>x</code> is the read length. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#setting-function-options">setting function options</a>. The default in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a>mode is <code>L,-0.6,-0.6</code> and the default in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode is <code>G,20,8</code>.</td>
</tr>
</tbody></table>
<h4 id="Reporting-options"><a href="#Reporting-options" class="headerlink" title="Reporting options"></a>Reporting options</h4><table>
<thead>
<tr>
<th><code>-k &lt;int&gt;</code></th>
<th>By default, <code>bowtie2</code> searches for distinct, valid alignments for each read. When it finds a valid alignment, it continues looking for alignments that are nearly as good or better. The best alignment found is reported (randomly selected from among best if tied). Information about the best alignments is used to estimate mapping quality and to set SAM optional fields, such as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-as"><code>AS:i</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-xs"><code>XS:i</code></a>.When <code>-k</code> is specified, however, <code>bowtie2</code> behaves differently. Instead, it searches for at most <code>&lt;int&gt;</code> distinct, valid alignments for each read. The search terminates when it can’t find more distinct valid alignments, or when it finds <code>&lt;int&gt;</code>, whichever happens first. All alignments found are reported in descending order by alignment score. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM ‘secondary’ bit (which equals 256) set in its FLAGS field. For reads that have more than <code>&lt;int&gt;</code> distinct, valid alignments, <code>bowtie2</code>does not guarantee that the <code>&lt;int&gt;</code> alignments reported are the best possible in terms of alignment score. <code>-k</code> is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-a"><code>-a</code></a>.Note: Bowtie 2 is not designed with large values for <code>-k</code> in mind, and when aligning reads to long, repetitive genomes large <code>-k</code> can be very, very slow.</th>
</tr>
</thead>
<tbody><tr>
<td><code>-a</code></td>
<td>Like <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a> but with no upper limit on number of alignments to search for. <code>-a</code> is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a>.Note: Bowtie 2 is not designed with <code>-a</code> mode in mind, and when aligning reads to long, repetitive genomes this mode can be very, very slow.</td>
</tr>
</tbody></table>
<h4 id="Effort-options"><a href="#Effort-options" class="headerlink" title="Effort options"></a>Effort options</h4><table>
<thead>
<tr>
<th><code>-D &lt;int&gt;</code></th>
<th>Up to <code>&lt;int&gt;</code> consecutive seed extension attempts can “fail” before Bowtie 2 moves on, using the alignments found so far. A seed extension “fails” if it does not yield a new best or a new second-best alignment. This limit is automatically adjusted up when -k or -a are specified. Default: 15.</th>
</tr>
</thead>
<tbody><tr>
<td><code>-R &lt;int&gt;</code></td>
<td><code>&lt;int&gt;</code> is the maximum number of times Bowtie 2 will “re-seed” reads with repetitive seeds. When “re-seeding,” Bowtie 2 simply chooses a new set of reads (same length, same number of mismatches allowed) at different offsets and searches for more alignments. A read is considered to have repetitive seeds if the total number of seed hits divided by the number of seeds that aligned at least once is greater than 300. Default: 2.</td>
</tr>
</tbody></table>
<h4 id="Paired-end-options"><a href="#Paired-end-options" class="headerlink" title="Paired-end options"></a>Paired-end options</h4><table>
<thead>
<tr>
<th><code>-I/--minins &lt;int&gt;</code></th>
<th>The minimum fragment length for valid paired-end alignments. E.g. if <code>-I 60</code> is specified and a paired-end alignment consists of two 20-bp alignments in the appropriate orientation with a 20-bp gap between them, that alignment is considered valid (as long as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> is also satisfied). A 19-bp gap would not be valid in that case. If trimming options <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-3"><code>-3</code></a> or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-5"><code>-5</code></a>are also used, the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> constraint is applied with respect to the untrimmed mates.The larger the difference between <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>, the slower Bowtie 2 will run. This is because larger differences between <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a>and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> require that Bowtie 2 scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), Bowtie 2 is very efficient.Default: 0 (essentially imposing no minimum)</th>
</tr>
</thead>
<tbody><tr>
<td><code>-X/--maxins &lt;int&gt;</code></td>
<td>The maximum fragment length for valid paired-end alignments. E.g. if <code>-X 100</code> is specified and a paired-end alignment consists of two 20-bp alignments in the proper orientation with a 60-bp gap between them, that alignment is considered valid (as long as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> is also satisfied). A 61-bp gap would not be valid in that case. If trimming options <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-3"><code>-3</code></a> or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-5"><code>-5</code></a> are also used, the <code>-X</code> constraint is applied with respect to the untrimmed mates, not the trimmed mates.The larger the difference between <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>, the slower Bowtie 2 will run. This is because larger differences between <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a>and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> require that Bowtie 2 scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), Bowtie 2 is very efficient.Default: 500.</td>
</tr>
<tr>
<td><code>--fr/--rf/--ff</code></td>
<td>The upstream/downstream mate orientations for a valid paired-end alignment against the forward reference strand. E.g., if <code>--fr</code> is specified and there is a candidate paired-end alignment where mate 1 appears upstream of the reverse complement of mate 2 and the fragment length constraints (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>) are met, that alignment is valid. Also, if mate 2 appears upstream of the reverse complement of mate 1 and all other constraints are met, that too is valid. <code>--rf</code> likewise requires that an upstream mate1 be reverse-complemented and a downstream mate2 be forward-oriented. <code>--ff</code> requires both an upstream mate 1 and a downstream mate 2 to be forward-oriented. Default: <code>--fr</code> (appropriate for Illumina’s Paired-end Sequencing Assay).</td>
</tr>
<tr>
<td><code>--no-mixed</code></td>
<td>By default, when <code>bowtie2</code> cannot find a concordant or discordant alignment for a pair, it then tries to find alignments for the individual mates. This option disables that behavior.</td>
</tr>
<tr>
<td><code>--no-discordant</code></td>
<td>By default, <code>bowtie2</code> looks for discordant alignments if it cannot find any concordant alignments. A discordant alignment is an alignment where both mates align uniquely, but that does not satisfy the paired-end constraints (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-fr"><code>--fr</code>/<code>--rf</code>/<code>--ff</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>). This option disables that behavior.</td>
</tr>
<tr>
<td><code>--dovetail</code></td>
<td>If the mates “dovetail”, that is if one mate alignment extends past the beginning of the other such that the wrong mate begins upstream, consider that to be concordant. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#mates-can-overlap-contain-or-dovetail-each-other">Mates can overlap, contain or dovetail each other</a>. Default: mates cannot dovetail in a concordant alignment.</td>
</tr>
<tr>
<td><code>--no-contain</code></td>
<td>If one mate alignment contains the other, consider that to be non-concordant. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#mates-can-overlap-contain-or-dovetail-each-other">Mates can overlap, contain or dovetail each other</a>. Default: a mate can contain the other in a concordant alignment.</td>
</tr>
<tr>
<td><code>--no-overlap</code></td>
<td>If one mate alignment overlaps the other at all, consider that to be non-concordant. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#mates-can-overlap-contain-or-dovetail-each-other">Mates can overlap, contain or dovetail each other</a>. Default: mates can overlap in a concordant alignment.</td>
</tr>
</tbody></table>
<h4 id="BAM-options"><a href="#BAM-options" class="headerlink" title="BAM options"></a>BAM options</h4><table>
<thead>
<tr>
<th><code>--align-paired-reads</code></th>
<th>Bowtie 2 will, by default, attempt to align unpaired BAM reads. Use this option to align paired-end reads instead.</th>
</tr>
</thead>
<tbody><tr>
<td><code>--preserve-tags</code></td>
<td>Preserve tags from the original BAM record by appending them to the end of the corresponding Bowtie 2 SAM output.</td>
</tr>
</tbody></table>
<h4 id="Output-options"><a href="#Output-options" class="headerlink" title="Output options"></a>Output options</h4><table>
<thead>
<tr>
<th><code>-t/--time</code></th>
<th>Print the wall-clock time required to load the index files and align the reads. This is printed to the “standard error” (“stderr”) filehandle. Default: off.</th>
</tr>
</thead>
<tbody><tr>
<td><code>--un &lt;path&gt; --un-gz &lt;path&gt; --un-bz2 &lt;path&gt; --un-lz4 &lt;path&gt;</code></td>
<td>Write unpaired reads that fail to align to file at <code>&lt;path&gt;</code>. These reads correspond to the SAM records with the FLAGS <code>0x4</code> bit set and neither the <code>0x40</code> nor <code>0x80</code> bits set. If <code>--un-gz</code> is specified, output will be gzip compressed. If <code>--un-bz2</code>or <code>--un-lz4</code> is specified, output will be bzip2 or lz4 compressed. Reads written in this way will appear exactly as they did in the input file, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the input.</td>
</tr>
<tr>
<td><code>--al &lt;path&gt; --al-gz &lt;path&gt; --al-bz2 &lt;path&gt; --al-lz4 &lt;path&gt;</code></td>
<td>Write unpaired reads that align at least once to file at <code>&lt;path&gt;</code>. These reads correspond to the SAM records with the FLAGS <code>0x4</code>, <code>0x40</code>, and <code>0x80</code> bits unset. If <code>--al-gz</code> is specified, output will be gzip compressed. If <code>--al-bz2</code> is specified, output will be bzip2 compressed. Similarly if <code>--al-lz4</code> is specified, output will be lz4 compressed. Reads written in this way will appear exactly as they did in the input file, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the input.</td>
</tr>
<tr>
<td><code>--un-conc &lt;path&gt; --un-conc-gz &lt;path&gt; --un-conc-bz2 &lt;path&gt; --un-conc-lz4 &lt;path&gt;</code></td>
<td>Write paired-end reads that fail to align concordantly to file(s) at <code>&lt;path&gt;</code>. These reads correspond to the SAM records with the FLAGS <code>0x4</code> bit set and either the <code>0x40</code> or <code>0x80</code> bit set (depending on whether it’s mate #1 or #2). <code>.1</code> and <code>.2</code>strings are added to the filename to distinguish which file contains mate #1 and mate #2. If a percent symbol, <code>%</code>, is used in <code>&lt;path&gt;</code>, the percent symbol is replaced with <code>1</code> or <code>2</code> to make the per-mate filenames. Otherwise, <code>.1</code> or <code>.2</code> are added before the final dot in <code>&lt;path&gt;</code> to make the per-mate filenames. Reads written in this way will appear exactly as they did in the input files, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the inputs.</td>
</tr>
<tr>
<td><code>--al-conc &lt;path&gt; --al-conc-gz &lt;path&gt; --al-conc-bz2 &lt;path&gt; --al-conc-lz4 &lt;path&gt;</code></td>
<td>Write paired-end reads that align concordantly at least once to file(s) at <code>&lt;path&gt;</code>. These reads correspond to the SAM records with the FLAGS <code>0x4</code> bit unset and either the <code>0x40</code> or <code>0x80</code> bit set (depending on whether it’s mate #1 or #2). <code>.1</code> and <code>.2</code> strings are added to the filename to distinguish which file contains mate #1 and mate #2. If a percent symbol, <code>%</code>, is used in <code>&lt;path&gt;</code>, the percent symbol is replaced with <code>1</code> or <code>2</code> to make the per-mate filenames. Otherwise, <code>.1</code> or <code>.2</code> are added before the final dot in <code>&lt;path&gt;</code> to make the per-mate filenames. Reads written in this way will appear exactly as they did in the input files, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the inputs.</td>
</tr>
<tr>
<td><code>--quiet</code></td>
<td>Print nothing besides alignments and serious errors.</td>
</tr>
<tr>
<td><code>--met-file &lt;path&gt;</code></td>
<td>Write <code>bowtie2</code> metrics to file <code>&lt;path&gt;</code>. Having alignment metric can be useful for debugging certain problems, especially performance issues. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met"><code>--met</code></a>. Default: metrics disabled.</td>
</tr>
<tr>
<td><code>--met-stderr &lt;path&gt;</code></td>
<td>Write <code>bowtie2</code> metrics to the “standard error” (“stderr”) filehandle. This is not mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met-file"><code>--met-file</code></a>. Having alignment metric can be useful for debugging certain problems, especially performance issues. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met"><code>--met</code></a>. Default: metrics disabled.</td>
</tr>
<tr>
<td><code>--met &lt;int&gt;</code></td>
<td>Write a new <code>bowtie2</code> metrics record every <code>&lt;int&gt;</code> seconds. Only matters if either <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met-stderr"><code>--met-stderr</code></a> or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met-file"><code>--met-file</code></a> are specified. Default: 1.</td>
</tr>
</tbody></table>
<h4 id="SAM-options"><a href="#SAM-options" class="headerlink" title="SAM options"></a>SAM options</h4><table>
<thead>
<tr>
<th><code>--no-unal</code></th>
<th>Suppress SAM records for reads that failed to align.</th>
</tr>
</thead>
<tbody><tr>
<td><code>--no-hd</code></td>
<td>Suppress SAM header lines (starting with <code>@</code>).</td>
</tr>
<tr>
<td><code>--no-sq</code></td>
<td>Suppress <code>@SQ</code> SAM header lines.</td>
</tr>
<tr>
<td><code>--rg-id &lt;text&gt;</code></td>
<td>Set the read group ID to <code>&lt;text&gt;</code>. This causes the SAM <code>@RG</code> header line to be printed, with <code>&lt;text&gt;</code> as the value associated with the <code>ID:</code> tag. It also causes the <code>RG:Z:</code> extra field to be attached to each SAM output record, with value set to <code>&lt;text&gt;</code>.</td>
</tr>
<tr>
<td><code>--rg &lt;text&gt;</code></td>
<td>Add <code>&lt;text&gt;</code> (usually of the form <code>TAG:VAL</code>, e.g. <code>SM:Pool1</code>) as a field on the <code>@RG</code> header line. Note: in order for the <code>@RG</code> line to appear, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rg-id"><code>--rg-id</code></a> must also be specified. This is because the <code>ID</code> tag is required by the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM Spec</a>. Specify <code>--rg</code> multiple times to set multiple fields. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM Spec</a> for details about what fields are legal.</td>
</tr>
<tr>
<td><code>--omit-sec-seq</code></td>
<td>When printing secondary alignments, Bowtie 2 by default will write out the <code>SEQ</code> and <code>QUAL</code> strings. Specifying this option causes Bowtie 2 to print an asterisk in those fields instead.</td>
</tr>
<tr>
<td><code>--soft-clipped-unmapped-tlen</code></td>
<td>Consider soft-clipped bases unmapped when calculating <code>TLEN</code>. Only available in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode.</td>
</tr>
<tr>
<td><code>--sam-no-qname-trunc</code></td>
<td>Suppress standard behavior of truncating readname at first whitespace at the expense of generating non-standard SAM</td>
</tr>
<tr>
<td><code>--xeq</code></td>
<td>Use <code>&#39;=&#39;/&#39;X&#39;</code>, instead of <code>&#39;M&#39;</code>, to specify matches/mismatches in SAM record</td>
</tr>
<tr>
<td><code>--sam-append-comment</code></td>
<td>Append FASTA/FASTQ comment to SAM record, where a comment is everything after the first space in the read name.</td>
</tr>
</tbody></table>
<h4 id="Performance-options"><a href="#Performance-options" class="headerlink" title="Performance options"></a>Performance options</h4><table>
<thead>
<tr>
<th><code>-o/--offrate &lt;int&gt;</code></th>
<th>Override the offrate of the index with <code>&lt;int&gt;</code>. If <code>&lt;int&gt;</code> is greater than the offrate used to build the index, then some row markings are discarded when the index is read into memory. This reduces the memory footprint of the aligner but requires more time to calculate text offsets. <code>&lt;int&gt;</code> must be greater than the value used to build the index.</th>
</tr>
</thead>
<tbody><tr>
<td><code>-p/--threads NTHREADS</code></td>
<td>Launch <code>NTHREADS</code> parallel search threads (default: 1). Threads will run on separate processors/cores and synchronize when parsing reads and outputting alignments. Searching for alignments is highly parallel, and speedup is close to linear. Increasing <code>-p</code> increases Bowtie 2’s memory footprint. E.g. when aligning to a human genome index, increasing <code>-p</code> from 1 to 8 increases the memory footprint by a few hundred megabytes. This option is only available if <code>bowtie</code> is linked with the <code>pthreads</code> library (i.e. if <code>BOWTIE_PTHREADS=0</code> is not specified at build time).</td>
</tr>
<tr>
<td><code>--reorder</code></td>
<td>Guarantees that output SAM records are printed in an order corresponding to the order of the reads in the original input file, even when <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> is set greater than 1. Specifying <code>--reorder</code> and setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> greater than 1 causes Bowtie 2 to run somewhat slower and use somewhat more memory than if <code>--reorder</code> were not specified. Has no effect if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> is set to 1, since output order will naturally correspond to input order in that case.</td>
</tr>
<tr>
<td><code>--mm</code></td>
<td>Use memory-mapped I/O to load the index, rather than typical file I/O. Memory-mapping allows many concurrent <code>bowtie</code> processes on the same computer to share the same memory image of the index (i.e. you pay the memory overhead just once). This facilitates memory-efficient parallelization of <code>bowtie</code> in situations where using <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> is not possible or not preferable.</td>
</tr>
</tbody></table>
<h4 id="Other-options"><a href="#Other-options" class="headerlink" title="Other options"></a>Other options</h4><table>
<thead>
<tr>
<th><code>--qc-filter</code></th>
<th>Filter out reads for which the QSEQ filter field is non-zero. Only has an effect when read format is <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-qseq"><code>--qseq</code></a>. Default: off.</th>
</tr>
</thead>
<tbody><tr>
<td><code>--seed &lt;int&gt;</code></td>
<td>Use <code>&lt;int&gt;</code> as the seed for pseudo-random number generator. Default: 0.</td>
</tr>
<tr>
<td><code>--non-deterministic</code></td>
<td>Normally, Bowtie 2 re-initializes its pseudo-random generator for each read. It seeds the generator with a number derived from (a) the read name, (b) the nucleotide sequence, (c) the quality sequence, (d) the value of the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-seed"><code>--seed</code></a>option. This means that if two reads are identical (same name, same nucleotides, same qualities) Bowtie 2 will find and report the same alignment(s) for both, even if there was ambiguity. When <code>--non-deterministic</code> is specified, Bowtie 2 re-initializes its pseudo-random generator for each read using the current time. This means that Bowtie 2 will not necessarily report the same alignment for two identical reads. This is counter-intuitive for some users, but might be more appropriate in situations where the input consists of many identical reads.</td>
</tr>
<tr>
<td><code>--version</code></td>
<td>Print version information and quit.</td>
</tr>
<tr>
<td><code>-h/--help</code></td>
<td>Print usage information and quit.</td>
</tr>
</tbody></table>
<h2 id="SAM-output"><a href="#SAM-output" class="headerlink" title="SAM output"></a>SAM output</h2><p>Following is a brief description of the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM</a> format as output by <code>bowtie2</code>. For more details, see the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM format specification</a>.</p>
<p>By default, <code>bowtie2</code> prints a SAM header with <code>@HD</code>, <code>@SQ</code> and <code>@PG</code> lines. When one or more <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rg"><code>--rg</code></a> arguments are specified, <code>bowtie2</code> will also print an <code>@RG</code> line that includes all user-specified <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rg"><code>--rg</code></a> tokens separated by tabs.</p>
<p>Each subsequent line describes an alignment or, if the read failed to align, a read. Each line is a collection of at least 12 fields separated by tabs; from left to right, the fields are:</p>
<ol>
<li><p>Name of read that aligned.</p>
<p>Note that the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> disallows whitespace in the read name. If the read name contains any whitespace characters, Bowtie 2 will truncate the name at the first whitespace character. This is similar to the behavior of other tools. The standard behavior of truncating at the first whitespace can be suppressed with <code>--sam-no-qname-trunc</code> at the expense of generating non-standard SAM.</p>
</li>
<li><p><font color="red">Sum of all applicable flags. Flags relevant to Bowtie are:</font></p>
<table>
<thead>
<tr>
<th><code>1</code></th>
<th>The read is one of a pair</th>
</tr>
</thead>
<tbody><tr>
<td><code>2</code></td>
<td>The alignment is one end of a proper paired-end alignment</td>
</tr>
<tr>
<td><code>4</code></td>
<td>The read has no reported alignments</td>
</tr>
<tr>
<td><code>8</code></td>
<td>The read is one of a pair and has no reported alignments</td>
</tr>
<tr>
<td><code>16</code></td>
<td>The alignment is to the reverse reference strand</td>
</tr>
<tr>
<td><code>32</code></td>
<td>The other mate in the paired-end alignment is aligned to the reverse reference strand</td>
</tr>
<tr>
<td><code>64</code></td>
<td>The read is mate 1 in a pair</td>
</tr>
<tr>
<td><code>128</code></td>
<td>The read is mate 2 in a pair</td>
</tr>
</tbody></table>
<p>Thus, an unpaired read that aligns to the reverse reference strand will have flag 16. A paired-end read that aligns and is the first mate in the pair will have flag 83 (= 64 + 16 + 2 + 1).</p>
</li>
<li><p>Name of reference sequence where alignment occurs</p>
</li>
<li><p>1-based offset into the forward reference strand where leftmost character of the alignment occurs</p>
</li>
<li><p>Mapping quality</p>
</li>
<li><p>CIGAR string representation of alignment</p>
</li>
<li><p>Name of reference sequence where mate’s alignment occurs. Set to <code>=</code> if the mate’s reference sequence is the same as this alignment’s, or <code>*</code>if there is no mate.</p>
</li>
<li><p>1-based offset into the forward reference strand where leftmost character of the mate’s alignment occurs. Offset is 0 if there is no mate.</p>
</li>
<li><p>Inferred fragment length. Size is negative if the mate’s alignment occurs upstream of this alignment. Size is 0 if the mates did not align concordantly. However, size is non-0 if the mates aligned discordantly to the same chromosome.</p>
</li>
<li><p>Read sequence (reverse-complemented if aligned to the reverse strand)</p>
</li>
<li><p>ASCII-encoded read qualities (reverse-complemented if the read aligned to the reverse strand). The encoded quality values are on the <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred quality</a> scale and the encoding is ASCII-offset by 33 (ASCII char <code>!</code>), similarly to a <a href="http://en.wikipedia.org/wiki/FASTQ_format">FASTQ</a> file.</p>
</li>
<li><p>Optional fields. Fields are tab-separated. <code>bowtie2</code> outputs zero or more of these optional fields for each alignment, depending on the type of the alignment:</p>
</li>
</ol>
<table>
<thead>
<tr>
<th><code>AS:i:&lt;N&gt;</code></th>
<th>Alignment score. Can be negative. Can be greater than 0 in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode (but not in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode). Only present if SAM record is for an aligned read.</th>
</tr>
</thead>
<tbody><tr>
<td><code>XS:i:&lt;N&gt;</code></td>
<td>Alignment score for the best-scoring alignment found other than the alignment reported. Can be negative. Can be greater than 0 in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode (but not in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode). Only present if the SAM record is for an aligned read and more than one alignment was found for the read. Note that, when the read is part of a concordantly-aligned pair, this score could be greater than <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-as"><code>AS:i</code></a>.</td>
</tr>
<tr>
<td><code>YS:i:&lt;N&gt;</code></td>
<td>Alignment score for opposite mate in the paired-end alignment. Only present if the SAM record is for a read that aligned as part of a paired-end alignment.</td>
</tr>
<tr>
<td><code>XN:i:&lt;N&gt;</code></td>
<td>The number of ambiguous bases in the reference covering this alignment. Only present if SAM record is for an aligned read.</td>
</tr>
<tr>
<td><code>XM:i:&lt;N&gt;</code></td>
<td>The number of mismatches in the alignment. Only present if SAM record is for an aligned read.</td>
</tr>
<tr>
<td><code>XO:i:&lt;N&gt;</code></td>
<td>The number of gap opens, for both read and reference gaps, in the alignment. Only present if SAM record is for an aligned read.</td>
</tr>
<tr>
<td><code>XG:i:&lt;N&gt;</code></td>
<td>The number of gap extensions, for both read and reference gaps, in the alignment. Only present if SAM record is for an aligned read.</td>
</tr>
<tr>
<td><code>NM:i:&lt;N&gt;</code></td>
<td>The edit distance; that is, the minimal number of one-nucleotide edits (substitutions, insertions and deletions) needed to transform the read string into the reference string. Only present if SAM record is for an aligned read.</td>
</tr>
<tr>
<td><code>YF:Z:&lt;S&gt;</code></td>
<td>String indicating reason why the read was filtered out. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#filtering">Filtering</a>. Only appears for reads that were filtered out.</td>
</tr>
<tr>
<td><code>YT:Z:&lt;S&gt;</code></td>
<td>Value of <code>UU</code> indicates the read was not part of a pair. Value of <code>CP</code> indicates the read was part of a pair and the pair aligned concordantly. Value of <code>DP</code> indicates the read was part of a pair and the pair aligned discordantly. Value of <code>UP</code> indicates the read was part of a pair but the pair failed to aligned either concordantly or discordantly.</td>
</tr>
<tr>
<td><code>MD:Z:&lt;S&gt;</code></td>
<td>A string representation of the mismatched reference bases in the alignment. See <a href="https://samtools.github.io/hts-specs/SAMtags.pdf">SAM Tags format specification</a> for details. Only present if SAM record is for an aligned read.</td>
</tr>
</tbody></table>
<h1 id="The-bowtie2-build-indexer"><a href="#The-bowtie2-build-indexer" class="headerlink" title="The bowtie2-build indexer"></a>The <code>bowtie2-build</code> indexer</h1><p><code>bowtie2-build</code> builds a Bowtie index from a set of DNA sequences. <code>bowtie2-build</code> outputs a set of 6 files with suffixes <code>.1.bt2</code>, <code>.2.bt2</code>, <code>.3.bt2</code>, <code>.4.bt2</code>, <code>.rev.1.bt2</code>, and <code>.rev.2.bt2</code>. In the case of a large index these suffixes will have a <code>bt2l</code> termination. These files together constitute the index: they are all that is needed to align reads to that reference. The original sequence <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files are no longer used by Bowtie 2 once the index is built.</p>
<p>Bowtie 2’s <code>.bt2</code> index format is different from Bowtie 1’s <code>.ebwt</code> format, and they are not compatible with each other.</p>
<p>Use of Karkkainen’s <a href="http://portal.acm.org/citation.cfm?id=1314852">blockwise algorithm</a> allows <code>bowtie2-build</code> to trade off between running time and memory usage. <code>bowtie2-build</code> has three options governing how it makes this trade: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-p"><code>-p</code>/<code>--packed</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmax"><code>--bmax</code></a>/<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a>, and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-dcv"><code>--dcv</code></a>. By default, <code>bowtie2-build</code> will automatically search for the settings that yield the best running time without exhausting memory. This behavior can be disabled using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>/<code>--noauto</code></a> option.</p>
<p>The indexer provides options pertaining to the “shape” of the index, e.g. <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-o"><code>--offrate</code></a> governs the fraction of <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler</a> rows that are “marked” (i.e., the density of the suffix-array sample; see the original <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a> paper for details). All of these options are potentially profitable trade-offs depending on the application. They have been set to defaults that are reasonable for most cases according to our experiments. See <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#performance-tuning">Performance tuning</a> for details.</p>
<p><code>bowtie2-build</code> can generate either <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#small-and-large-indexes">small or large indexes</a>. The wrapper will decide which based on the length of the input genome. If the reference does not exceed 4 billion characters but a large index is preferred, the user can specify <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-large-index"><code>--large-index</code></a> to force <code>bowtie2-build</code> to build a large index instead.</p>
<p>The Bowtie 2 index is based on the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a> of Ferragina and Manzini, which in turn is based on the <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler</a> transform. The algorithm used to build the index is based on the <a href="http://portal.acm.org/citation.cfm?id=1314852">blockwise algorithm</a> of Karkkainen.</p>
<h2 id="Command-Line-1"><a href="#Command-Line-1" class="headerlink" title="Command Line"></a>Command Line</h2><p>Usage:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2-build [options]* &lt;reference_in&gt; &lt;bt2_base&gt;</span><br></pre></td></tr></table></figure>

<h3 id="Main-arguments-1"><a href="#Main-arguments-1" class="headerlink" title="Main arguments"></a>Main arguments</h3><table>
<thead>
<tr>
<th><code>&lt;reference_in&gt;</code></th>
<th>A comma-separated list of <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files containing the reference sequences to be aligned to, or, if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-c"><code>-c</code></a> is specified, the sequences themselves. E.g., <code>&lt;reference_in&gt;</code> might be <code>chr1.fa,chr2.fa,chrX.fa,chrY.fa</code>, or, if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-c"><code>-c</code></a> is specified, this might be <code>GGTCATCCT,ACGGGTCGT,CCGTTCTATGCGGCTTA</code>.</th>
</tr>
</thead>
<tbody><tr>
<td><code>&lt;bt2_base&gt;</code></td>
<td>The basename of the index files to write. By default, <code>bowtie2-build</code> writes files named <code>NAME.1.bt2</code>, <code>NAME.2.bt2</code>, <code>NAME.3.bt2</code>, <code>NAME.4.bt2</code>, <code>NAME.rev.1.bt2</code>, and <code>NAME.rev.2.bt2</code>, where <code>NAME</code> is <code>&lt;bt2_base&gt;</code>.</td>
</tr>
</tbody></table>
<h3 id="Options-1"><a href="#Options-1" class="headerlink" title="Options"></a>Options</h3><table>
<thead>
<tr>
<th><code>-f</code></th>
<th>The reference input files (specified as <code>&lt;reference_in&gt;</code>) are <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files (usually having extension <code>.fa</code>, <code>.mfa</code>, <code>.fna</code> or similar).</th>
</tr>
</thead>
<tbody><tr>
<td><code>-c</code></td>
<td>The reference sequences are given on the command line. I.e. <code>&lt;reference_in&gt;</code> is a comma-separated list of sequences rather than a list of <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files.</td>
</tr>
<tr>
<td><code>--large-index</code></td>
<td>Force <code>bowtie2-build</code> to build a <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#small-and-large-indexes">large index</a>, even if the reference is less than ~ 4 billion nucleotides inlong.</td>
</tr>
<tr>
<td><code>-a/--noauto</code></td>
<td>Disable the default behavior whereby <code>bowtie2-build</code> automatically selects values for the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmax"><code>--bmax</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-dcv"><code>--dcv</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-p"><code>--packed</code></a> parameters according to available memory. Instead, user may specify values for those parameters. If memory is exhausted during indexing, an error message will be printed; it is up to the user to try new parameters.</td>
</tr>
<tr>
<td><code>-p/--packed</code></td>
<td>Use a packed (2-bits-per-nucleotide) representation for DNA strings. This saves memory but makes indexing 2-3 times slower. Default: off. This is configured automatically by default; use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>/<code>--noauto</code></a> to configure manually.</td>
</tr>
<tr>
<td><code>--bmax &lt;int&gt;</code></td>
<td>The maximum number of suffixes allowed in a block. Allowing more suffixes per block makes indexing faster, but increases peak memory usage. Setting this option overrides any previous setting for <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmax"><code>--bmax</code></a>, or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a>. Default (in terms of the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a> parameter) is <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a> 4 * number of threads. This is configured automatically by default; use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>/<code>--noauto</code></a> to configure manually.</td>
</tr>
<tr>
<td><code>--bmaxdivn &lt;int&gt;</code></td>
<td>The maximum number of suffixes allowed in a block, expressed as a fraction of the length of the reference. Setting this option overrides any previous setting for <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmax"><code>--bmax</code></a>, or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a>. Default: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a> 4 * number of threads. This is configured automatically by default; use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>/<code>--noauto</code></a> to configure manually.</td>
</tr>
<tr>
<td><code>--dcv &lt;int&gt;</code></td>
<td>Use <code>&lt;int&gt;</code> as the period for the difference-cover sample. A larger period yields less memory overhead, but may make suffix sorting slower, especially if repeats are present. Must be a power of 2 no greater than 4096. Default: 1024. This is configured automatically by default; use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>/<code>--noauto</code></a> to configure manually.</td>
</tr>
<tr>
<td><code>--nodc</code></td>
<td>Disable use of the difference-cover sample. Suffix sorting becomes quadratic-time in the worst case (where the worst case is an extremely repetitive reference). Default: off.</td>
</tr>
<tr>
<td><code>-r/--noref</code></td>
<td>Do not build the <code>NAME.3.bt2</code> and <code>NAME.4.bt2</code> portions of the index, which contain a bitpacked version of the reference sequences and are used for paired-end alignment.</td>
</tr>
<tr>
<td><code>-3/--justref</code></td>
<td>Build only the <code>NAME.3.bt2</code> and <code>NAME.4.bt2</code> portions of the index, which contain a bitpacked version of the reference sequences and are used for paired-end alignment.</td>
</tr>
<tr>
<td><code>-o/--offrate &lt;int&gt;</code></td>
<td>To map alignments back to positions on the reference sequences, it’s necessary to annotate (“mark”) some or all of the <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler</a> rows with their corresponding location on the genome. <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-o"><code>-o</code>/<code>--offrate</code></a> governs how many rows get marked: the indexer will mark every 2^<code>&lt;int&gt;</code> rows. Marking more rows makes reference-position lookups faster, but requires more memory to hold the annotations at runtime. The default is 5 (every 32nd row is marked; for human genome, annotations occupy about 340 megabytes).</td>
</tr>
<tr>
<td><code>-t/--ftabchars &lt;int&gt;</code></td>
<td>The ftab is the lookup table used to calculate an initial <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler</a> range with respect to the first <code>&lt;int&gt;</code>characters of the query. A larger <code>&lt;int&gt;</code> yields a larger lookup table but faster query times. The ftab has size 4^(<code>&lt;int&gt;</code>+1) bytes. The default setting is 10 (ftab is 4MB).</td>
</tr>
<tr>
<td><code>--seed &lt;int&gt;</code></td>
<td>Use <code>&lt;int&gt;</code> as the seed for pseudo-random number generator.</td>
</tr>
<tr>
<td><code>--cutoff &lt;int&gt;</code></td>
<td>Index only the first <code>&lt;int&gt;</code> bases of the reference sequences (cumulative across sequences) and ignore the rest.</td>
</tr>
<tr>
<td><code>-q/--quiet</code></td>
<td><code>bowtie2-build</code> is verbose by default. With this option <code>bowtie2-build</code> will print only error messages.</td>
</tr>
<tr>
<td><code>--threads &lt;int&gt;</code></td>
<td>By default <code>bowtie2-build</code> is using only one thread. Increasing the number of threads will speed up the index building considerably in most cases.</td>
</tr>
<tr>
<td><code>-h/--help</code></td>
<td>Print usage information and quit.</td>
</tr>
<tr>
<td><code>--version</code></td>
<td>Print version information and quit.</td>
</tr>
</tbody></table>
<h1 id="The-bowtie2-inspect-index-inspector"><a href="#The-bowtie2-inspect-index-inspector" class="headerlink" title="The bowtie2-inspect index inspector"></a>The <code>bowtie2-inspect</code> index inspector</h1><p><code>bowtie2-inspect</code> extracts information from a Bowtie index about what kind of index it is and what reference sequences were used to build it. When run without any options, the tool will output a <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> file containing the sequences of the original references (with all non-<code>A</code>/<code>C</code>/<code>G</code>/<code>T</code> characters converted to <code>N</code>s). It can also be used to extract just the reference sequence names using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-inspect-options-n"><code>-n</code>/<code>--names</code></a> option or a more verbose summary using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-inspect-options-s"><code>-s</code>/<code>--summary</code></a> option.</p>
<h2 id="Command-Line-2"><a href="#Command-Line-2" class="headerlink" title="Command Line"></a>Command Line</h2><p>Usage:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2-inspect [options]* &lt;bt2_base&gt;</span><br></pre></td></tr></table></figure>

<h3 id="Main-arguments-2"><a href="#Main-arguments-2" class="headerlink" title="Main arguments"></a>Main arguments</h3><table>
<thead>
<tr>
<th><code>&lt;bt2_base&gt;</code></th>
<th>The basename of the index to be inspected. The basename is name of any of the index files but with the <code>.X.bt2</code> or <code>.rev.X.bt2</code>suffix omitted. <code>bowtie2-inspect</code> first looks in the current directory for the index files, then in the directory specified in the <code>BOWTIE2_INDEXES</code> environment variable.</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="Options-2"><a href="#Options-2" class="headerlink" title="Options"></a>Options</h3><table>
<thead>
<tr>
<th><code>-a/--across &lt;int&gt;</code></th>
<th>When printing <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> output, output a newline character every <code>&lt;int&gt;</code> bases (default: 60).</th>
</tr>
</thead>
<tbody><tr>
<td><code>-n/--names</code></td>
<td>Print reference sequence names, one per line, and quit.</td>
</tr>
<tr>
<td><code>-s/--summary</code></td>
<td>Print a summary that includes information about index settings, as well as the names and lengths of the input sequences. The summary has this format:<code>Colorspace  &lt;0 or 1&gt; SA-Sample   1 in &lt;sample&gt; FTab-Chars  &lt;chars&gt; Sequence-1  &lt;name&gt;  &lt;len&gt; Sequence-2  &lt;name&gt;  &lt;len&gt; ... Sequence-N  &lt;name&gt;  &lt;len&gt;</code>Fields are separated by tabs. Colorspace is always set to 0 for Bowtie 2.</td>
</tr>
<tr>
<td><code>-o/--output &lt;filename&gt;</code></td>
<td>Save output to user-specified filename (default: stdout)</td>
</tr>
<tr>
<td><code>-v/--verbose</code></td>
<td>Print verbose output (for debugging).</td>
</tr>
<tr>
<td><code>--version</code></td>
<td>Print version information and quit.</td>
</tr>
<tr>
<td><code>-h/--help</code></td>
<td>Print usage information and quit.</td>
</tr>
</tbody></table>
<h1 id="Getting-started-with-Bowtie-2-Lambda-phage-example"><a href="#Getting-started-with-Bowtie-2-Lambda-phage-example" class="headerlink" title="Getting started with Bowtie 2: Lambda phage example"></a>Getting started with Bowtie 2: Lambda phage example</h1><p>Bowtie 2 comes with some example files to get you started. The example files are not scientifically significant; we use the <a href="http://en.wikipedia.org/wiki/Lambda_phage">Lambda phage</a> reference genome simply because it’s short, and the reads were generated by a computer program, not a sequencer. However, these files will let you start running Bowtie 2 and downstream tools right away.</p>
<p>First follow the manual instructions to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#obtaining-bowtie-2">obtain Bowtie 2</a>. Set the <code>BT2_HOME</code> environment variable to point to the new Bowtie 2 directory containing the <code>bowtie2</code>, <code>bowtie2-build</code> and <code>bowtie2-inspect</code> binaries. This is important, as the <code>BT2_HOME</code> variable is used in the commands below to refer to that directory.</p>
<h2 id="Indexing-a-reference-genome"><a href="#Indexing-a-reference-genome" class="headerlink" title="Indexing a reference genome"></a>Indexing a reference genome</h2><p>To create an index for the <a href="http://en.wikipedia.org/wiki/Lambda_phage">Lambda phage</a> reference genome included with Bowtie 2, create a new temporary directory (it doesn’t matter where), change into that directory, and run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$BT2_HOME/bowtie2-build $BT2_HOME/example/reference/lambda_virus.fa lambda_virus</span><br></pre></td></tr></table></figure>

<p>The command should print many lines of output then quit. When the command completes, the current directory will contain four new files that all start with <code>lambda_virus</code> and end with <code>.1.bt2</code>, <code>.2.bt2</code>, <code>.3.bt2</code>, <code>.4.bt2</code>, <code>.rev.1.bt2</code>, and <code>.rev.2.bt2</code>. These files constitute the index - you’re done!</p>
<p>You can use <code>bowtie2-build</code> to create an index for a set of <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files obtained from any source, including sites such as <a href="http://genome.ucsc.edu/cgi-bin/hgGateway">UCSC</a>, <a href="http://www.ncbi.nlm.nih.gov/sites/genome">NCBI</a>, and <a href="http://www.ensembl.org/">Ensembl</a>. When indexing multiple <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files, specify all the files using commas to separate file names. For more details on how to create an index with <code>bowtie2-build</code>, see the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#the-bowtie2-build-indexer">manual section on index building</a>. You may also want to bypass this process by obtaining a pre-built index. See <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#using-a-pre-built-index">using a pre-built index</a> below for an example.</p>
<h2 id="Aligning-example-reads"><a href="#Aligning-example-reads" class="headerlink" title="Aligning example reads"></a>Aligning example reads</h2><p>Stay in the directory created in the previous step, which now contains the <code>lambda_virus</code> index files. Next, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$BT2_HOME/bowtie2 -x lambda_virus -U $BT2_HOME/example/reads/reads_1.fq -S eg1.sam</span><br></pre></td></tr></table></figure>

<p>This runs the Bowtie 2 aligner, which aligns a set of unpaired reads to the <a href="http://en.wikipedia.org/wiki/Lambda_phage">Lambda phage</a> reference genome using the index generated in the previous step. The alignment results in SAM format are written to the file <code>eg1.sam</code>, and a short alignment summary is written to the console. (Actually, the summary is written to the “standard error” or “stderr” filehandle, which is typically printed to the console.)</p>
<p>To see the first few lines of the SAM output, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">head eg1.sam</span><br></pre></td></tr></table></figure>

<p>You will see something like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@HD VN:1.0  SO:unsorted</span><br><span class="line">@SQ SN:gi|9626243|ref|NC_001416.1|  LN:48502</span><br><span class="line">@PG ID:bowtie2  PN:bowtie2  VN:2.0.1</span><br><span class="line">r1  0   gi|9626243|ref|NC_001416.1| 18401   42  122M    *   0   0   TGAATGCGAACTCCGGGACGCTCAGTAATGTGACGATAGCTGAAAACTGTACGATAAACNGTACGCTGAGGGCAGAAAAAATCGTCGGGGACATTNTAAAGGCGGCGAGCGCGGCTTTTCCG  +&quot;@6&lt;:27(F&amp;5)9&quot;B):%B+A-%5A?2$HCB0B+0=D&lt;7E/&lt;.03#!.F77@6B==?C&quot;7&gt;;))%;,3-$.A06+&lt;-1/@@?,26&quot;&gt;=?*@&#x27;0;$:;??G+:#+(A?9+10!8!?()?7C&gt;  AS:i:-5 XN:i:0  XM:i:3  XO:i:0  XG:i:0  NM:i:3  MD:Z:59G13G21G26    YT:Z:UU</span><br><span class="line">r2  0   gi|9626243|ref|NC_001416.1| 8886    42  275M    *   0   0   NTTNTGATGCGGGCTTGTGGAGTTCAGCCGATCTGACTTATGTCATTACCTATGAAATGTGAGGACGCTATGCCTGTACCAAATCCTACAATGCCGGTGAAAGGTGCCGGGATCACCCTGTGGGTTTATAAGGGGATCGGTGACCCCTACGCGAATCCGCTTTCAGACGTTGACTGGTCGCGTCTGGCAAAAGTTAAAGACCTGACGCCCGGCGAACTGACCGCTGAGNCCTATGACGACAGCTATCTCGATGATGAAGATGCAGACTGGACTGC (#!!&#x27;+!$&quot;&quot;%+(+)&#x27;%)%!+!(&amp;++)&#x27;&#x27;&quot;#&quot;#&amp;#&quot;!&#x27;!(&quot;%&#x27;&quot;&quot;(&quot;+&amp;%$%*%%#$%#%#!)*&#x27;(#&quot;)(($&amp;$&#x27;&amp;%+&amp;#%*)*#*%*&#x27;)(%+!%%*&quot;$%&quot;#+)$&amp;&amp;+)&amp;)*+!&quot;*)!*!(&quot;&amp;&amp;&quot;*#+&quot;&amp;&quot;&#x27;(%)*(&quot;&#x27;!$*!!%$&amp;&amp;&amp;$!!&amp;&amp;&quot;(*&quot;$&amp;&quot;#&amp;!$%&#x27;%&quot;#)$#+%*+)!&amp;*)+(&quot;&quot;#!)!%*#&quot;*)*&#x27;)&amp;&quot;)($+*%%)!*)!(&#x27;(%&quot;&quot;+%&quot;$##&quot;#+((&#x27;!*(($*&#x27;!&quot;*(&#x27;&quot;+)&amp;%#&amp;$+(&#x27;**$$&amp;+*&amp;!#%)&#x27;)&#x27;(+(!%+ AS:i:-14    XN:i:0  XM:i:8  XO:i:0  XG:i:0  NM:i:8  MD:Z:0A0C0G0A108C23G9T81T46 YT:Z:UU</span><br><span class="line">r3  16  gi|9626243|ref|NC_001416.1| 11599   42  338M    *   0   0   GGGCGCGTTACTGGGATGATCGTGAAAAGGCCCGTCTTGCGCTTGAAGCCGCCCGAAAGAAGGCTGAGCAGCAGACTCAAGAGGAGAAAAATGCGCAGCAGCGGAGCGATACCGAAGCGTCACGGCTGAAATATACCGAAGAGGCGCAGAAGGCTNACGAACGGCTGCAGACGCCGCTGCAGAAATATACCGCCCGTCAGGAAGAACTGANCAAGGCACNGAAAGACGGGAAAATCCTGCAGGCGGATTACAACACGCTGATGGCGGCGGCGAAAAAGGATTATGAAGCGACGCTGTAAAAGCCGAAACAGTCCAGCGTGAAGGTGTCTGCGGGCGAT  7F$%6=$:9B@/F&#x27;&gt;=?!D?@0(:A*)7/&gt;9C&gt;6#1&lt;6:C(.CC;#.;&gt;;2&#x27;$4D:?&amp;B!&gt;689?(0(G7+0=@37F)GG=&gt;?958.D2E04C&lt;E,*AD%G0.%$+A:&#x27;H;?8&lt;72:88?E6((CF)6DF#.)=&gt;B&gt;D-=&quot;C&#x27;B080E&#x27;5BH&quot;77&#x27;:&quot;@70#4%A5=6.2/1&gt;;9&quot;&amp;-H6)=$/0;5E:&lt;8G!@::1?2DC7C*;@*#.1C0.D&gt;H/20,!&quot;C-#,6@%&lt;+&lt;D(AG-).?&amp;#0.00&#x27;@)/F8?B!&amp;&quot;170,)&gt;:?&lt;A7#1(A@0E#&amp;A.*DC.E&quot;)AH&quot;+.,5,2&gt;5&quot;2?:G,F&quot;D0B8D-6$65D&lt;D!A/38860.*4;4B&lt;*31?6  AS:i:-22    XN:i:0  XM:i:8  XO:i:0  XG:i:0  NM:i:8  MD:Z:80C4C16A52T23G30A8T76A41   YT:Z:UU</span><br><span class="line">r4  0   gi|9626243|ref|NC_001416.1| 40075   42  184M    *   0   0   GGGCCAATGCGCTTACTGATGCGGAATTACGCCGTAAGGCCGCAGATGAGCTTGTCCATATGACTGCGAGAATTAACNGTGGTGAGGCGATCCCTGAACCAGTAAAACAACTTCCTGTCATGGGCGGTAGACCTCTAAATCGTGCACAGGCTCTGGCGAAGATCGCAGAAATCAAAGCTAAGT(=8B)GD04*G%&amp;4F,1&#x27;A&gt;.C&amp;7=F$,+#6!))43C,5/5+)?-/0&gt;/D3=-,2/+.1?@-&gt;;)00!&#x27;3!7BH$G)HG+ADC&#x27;#-9F)7&lt;7&quot;$?&amp;.&gt;0)@5;4,!0-#C!15CF8&amp;HB+B==H&gt;7,/)C5)5*+(F5A%D,EA&lt;(&gt;G9E0&gt;7&amp;/E?4%;#&#x27;92)&lt;5+@7:A.(BG@BG86@.G AS:i:-1 XN:i:0  XM:i:1  XO:i:0  XG:i:0  NM:i:1  MD:Z:77C106 YT:Z:UU</span><br><span class="line">r5  0   gi|9626243|ref|NC_001416.1| 48010   42  138M    *   0   0   GTCAGGAAAGTGGTAAAACTGCAACTCAATTACTGCAATGCCCTCGTAATTAAGTGAATTTACAATATCGTCCTGTTCGGAGGGAAGAACGCGGGATGTTCATTCTTCATCACTTTTAATTGATGTATATGCTCTCTT  9&#x27;&#x27;%&lt;D)A03E1-*7=),:F/0!6,D9:H,&lt;9D%:0B(%&#x27;E,(8EFG$E89B$27G8F*2+4,-!,0D5()&amp;=(FGG:5;3*@/.0F-G#5#3-&gt;(&#x27;FDFEG?)5.!)&quot;AGADB3?6(@H(:B&lt;&gt;6!&gt;;&gt;6&gt;G,.&quot;?%  AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:138    YT:Z:UU</span><br><span class="line">r6  16  gi|9626243|ref|NC_001416.1| 41607   42  72M2D119M   *   0   0   TCGATTTGCAAATACCGGAACATCTCGGTAACTGCATATTCTGCATTAAAAAATCAACGCAAAAAATCGGACGCCTGCAAAGATGAGGAGGGATTGCAGCGTGTTTTTAATGAGGTCATCACGGGATNCCATGTGCGTGACGGNCATCGGGAAACGCCAAAGGAGATTATGTACCGAGGAAGAATGTCGCT 1H#G;H&quot;$E*E#&amp;&quot;*)2%66?=9/9&#x27;=;4)4/&gt;@%+5#@#$4A*!&lt;D==&quot;8#1*A9BA=:(1+#C&amp;.#(3#H=9E)AC*5,AC#E&#x27;536*2?)H14?&gt;9&#x27;B=7(3H/B:+A:8%1-+#(E%&amp;$$&amp;14&quot;76D?&gt;7(&amp;20H5%*&amp;CF8!G5B+A4F$7(:&quot;&#x27;?0$?G+$)B-?2&lt;0&lt;F=D!38BH,%=8&amp;5@+ AS:i:-13    XN:i:0  XM:i:2  XO:i:1  XG:i:2  NM:i:4  MD:Z:72^TT55C15A47  YT:Z:UU</span><br><span class="line">r7  16  gi|9626243|ref|NC_001416.1| 4692    42  143M    *   0   0   TCAGCCGGACGCGGGCGCTGCAGCCGTACTCGGGGATGACCGGTTACAACGGCATTATCGCCCGTCTGCAACAGGCTGCCAGCGATCCGATGGTGGACAGCATTCTGCTCGATATGGACANGCCCGGCGGGATGGTGGCGGGG -&quot;/@*7A0)&gt;2,AAH@&amp;&quot;%B)*5*23B/,)90.B@%=FE,E063C9?,:26$-0:,.,1849&#x27;4.;F&gt;FA;76+5&amp;$&lt;C&quot;:$!A*,&lt;B,&lt;)@&lt;&#x27;85D%C*:)30@85;?.B$05=@95DCDH&lt;53!8G:F:B7/A.E&#x27;:434&gt; AS:i:-6 XN:i:0  XM:i:2  XO:i:0  XG:i:0  NM:i:2  MD:Z:98G21C22   YT:Z:UU</span><br></pre></td></tr></table></figure>

<p>The first few lines (beginning with <code>@</code>) are SAM header lines, and the rest of the lines are SAM alignments, one line per read or mate. See the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#sam-output">Bowtie 2 manual section on SAM output</a> and the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for details about how to interpret the SAM file format.</p>
<h2 id="Paired-end-example"><a href="#Paired-end-example" class="headerlink" title="Paired-end example"></a>Paired-end example</h2><p>To align paired-end reads included with Bowtie 2, stay in the same directory and run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$BT2_HOME/bowtie2 -x lambda_virus -1 $BT2_HOME/example/reads/reads_1.fq -2 $BT2_HOME/example/reads/reads_2.fq -S eg2.sam</span><br></pre></td></tr></table></figure>

<p>This aligns a set of paired-end reads to the reference genome, with results written to the file <code>eg2.sam</code>.</p>
<h2 id="Local-alignment-example-1"><a href="#Local-alignment-example-1" class="headerlink" title="Local alignment example"></a>Local alignment example</h2><p>To use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#end-to-end-alignment-versus-local-alignment">local alignment</a> to align some longer reads included with Bowtie 2, stay in the same directory and run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$BT2_HOME/bowtie2 --local -x lambda_virus -U $BT2_HOME/example/reads/longreads.fq -S eg3.sam</span><br></pre></td></tr></table></figure>

<p>This aligns the long reads to the reference genome using local alignment, with results written to the file <code>eg3.sam</code>.</p>
<h2 id="Using-SAMtools-BCFtools-downstream"><a href="#Using-SAMtools-BCFtools-downstream" class="headerlink" title="Using SAMtools/BCFtools downstream"></a>Using SAMtools/BCFtools downstream</h2><p><a href="http://samtools.sourceforge.net/">SAMtools</a> is a collection of tools for manipulating and analyzing SAM and BAM alignment files. <a href="http://samtools.sourceforge.net/mpileup.shtml">BCFtools</a> is a collection of tools for calling variants and manipulating VCF and BCF files, and it is typically distributed with <a href="http://samtools.sourceforge.net/">SAMtools</a>. Using these tools together allows you to get from alignments in SAM format to variant calls in VCF format. This example assumes that <code>samtools</code> and <code>bcftools</code> are installed and that the directories containing these binaries are in your <a href="http://en.wikipedia.org/wiki/PATH_(variable)">PATH environment variable</a>.</p>
<p>Run the paired-end example:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$BT2_HOME/bowtie2 -x $BT2_HOME/example/index/lambda_virus -1 $BT2_HOME/example/reads/reads_1.fq -2 $BT2_HOME/example/reads/reads_2.fq -S eg2.sam</span><br></pre></td></tr></table></figure>

<p>Use <code>samtools view</code> to convert the SAM file into a BAM file. BAM is the binary format corresponding to the SAM text format. Run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -bS eg2.sam &gt; eg2.bam</span><br></pre></td></tr></table></figure>

<p>Use <code>samtools sort</code> to convert the BAM file to a sorted BAM file.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools sort eg2.bam -o eg2.sorted.bam</span><br></pre></td></tr></table></figure>

<p>We now have a sorted BAM file called <code>eg2.sorted.bam</code>. Sorted BAM is a useful format because the alignments are (a) compressed, which is convenient for long-term storage, and (b) sorted, which is conveneint for variant discovery. To generate variant calls in VCF format, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bcftools mpileup -f $BT2_HOME/example/reference/lambda_virus.fa eg2.sorted.bam | bcftools view -Ov - &gt; eg2.raw.bcf</span><br></pre></td></tr></table></figure>

<p>Then to view the variants, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bcftools view eg2.raw.bcf</span><br></pre></td></tr></table></figure>

<p>See the official SAMtools guide to <a href="http://samtools.sourceforge.net/mpileup.shtml">Calling SNPs/INDELs with SAMtools/BCFtools</a> for more details and variations on this process.</p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>alignment</tag>
      </tags>
  </entry>
  <entry>
    <title>【blast+】</title>
    <url>/blog/2022/03/20/2022-03-18-blast/</url>
    <content><![CDATA[<p>Short introduction to using NCBI blast tools from the command line</p>
<span id="more"></span>

<p><a href="https://www.ncbi.nlm.nih.gov/books/NBK279690/">BLAST® Command Line Applications User Manual</a></p>
<h2 id="Exercise-2-performing-a-basic-BLASTp-search"><a href="#Exercise-2-performing-a-basic-BLASTp-search" class="headerlink" title="Exercise 2: performing a basic BLASTp search"></a>Exercise 2: performing a basic BLASTp search</h2><p>BLAST+ search strategies are run by typing the type you want on the command line followed by the input options. This includes <strong>blastn, blastp, blastx, tblastn and tblastx</strong>. Ensure you know which search strategy is appropriate for your data and database type. You can find an extensive overview of these <a href="https://www.ncbi.nlm.nih.gov/books/NBK1734/">here</a>.</p>
<p>We will now search a few <strong>protein sequences against the database</strong> and <strong>retrieve the results</strong>. You can get download sample protein sequences for this tutorial <a href="https://raw.githubusercontent.com/conmeehan/conmeehan.github.io/master/proteins.fasta">here</a>. Save this page as proteins.fasta and put in the same directory as the pdbaa folder we downloaded earlier. We will perform a default BLASTp search on these to find out what proteins they are. The advantage of BLAST+ is that we can run BLASTp once using this file as an input and it will <strong>perform a search on all sequences within</strong>, meaning we <strong>do not have to do each sequence individually</strong>.</p>
<p>Navigate to the folder containing proteins.fasta. The <strong>pdbaa folder</strong> should be <strong>in this folder too.</strong> Type the following on the command line:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastp -query proteins.fasta -db pdbaa/pdbaa -out proteins_blastp.txt</span><br></pre></td></tr></table></figure>

<p>This will perform a blastp search, using all the sequences in proteins.fasta as queries, using the pdbaa database and output the results to proteins_blastp.txt. You will see the output looks quite like the website output with the overview first and the individual alignments next.</p>
<p>Q. Look at the file proteins_blastp.txt. What sequences do we appear to have?</p>
<p>There are many ways to modify how this is run. Type</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastp -help</span><br></pre></td></tr></table></figure>

<p>This will print to the screen a large amount of text, <strong>detailing all the flags (options) we can change during the BLAST search</strong>. We will modify some of these now.</p>
<h2 id="Exercise-3-modifying-the-defaults-and-output-types"><a href="#Exercise-3-modifying-the-defaults-and-output-types" class="headerlink" title="Exercise 3: modifying the defaults and output types"></a>Exercise 3: modifying the defaults and output types</h2><p>Often if we are working with <strong>many sequences</strong> we want to make it easier to <strong>get the best results</strong> in an easy to read format. We can do this by <strong>limiting the number of results returned</strong>. Often this is performed by changing the number of alignments displayed and/or the <strong>e-value cut-off</strong>.</p>
<p>Lets run BLASTp, keeping all the overviews but only displaying the top hit alignment. We change the number of alignments displayed with the <strong>-num_alignments</strong> flag. To <strong>keep only the top hit alignment</strong> we can use</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastp -query proteins.fasta -db db/pdbaa -out proteins_blastp_1align.txt -num_alignments 1</span><br></pre></td></tr></table></figure>

<p>If you look in this file we can see that all the descriptions are retained but <strong>now we only have 1 alignment per query sequence</strong>. Another way to limit the results is to set an <strong>e-value cut-off</strong>. In the help output of each program you can see the default e-value (listed under ‘general search options’). You can see it is quite high (10). We will retain only those hits with an e-value of <strong>1e-30 or higher.</strong> We use the <strong>-evalue</strong> flag for this. Lets combines the above alignment display restriction with an <strong>evalue restriction</strong>. This done by typing:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastp -query proteins.fasta -db db/pdbaa -out proteins_blastp_1align_1e-30.txt -num_alignments 1 -evalue 1e-30</span><br></pre></td></tr></table></figure>

<p>You can see now that we have a smaller number of hits, hopefully including only those we are certain are likely to be correct.</p>
<p>Often we <strong>dont need</strong> the output <strong>alignments</strong> but <strong>want all the details of each hit</strong> (e-value, bit score, percent identity etc) on 1 line. This is achieved by changing the <strong>output type</strong>. So far we have used the default output type but we can change this with the <strong>-outfmt</strong> flag. There are 11 output types (listed in the help output) but we <font color="blue"><strong>shall use type 6</strong></font>: tabular output. This gives you <strong>a line per hit with 12 columns</strong>:</p>
<ul>
<li>Query id</li>
<li><strong>Subject id</strong></li>
<li><strong>% identity</strong></li>
<li><strong>alignment length</strong></li>
<li><strong>mismatches</strong></li>
<li><strong>gap</strong> openings</li>
<li><strong>query start</strong></li>
<li><strong>query end</strong></li>
<li><strong>subject start</strong></li>
<li><strong>subject end</strong></li>
<li>e-value</li>
<li>bit score</li>
</ul>
<p>This saves a lot of space in the output but does not separate queries into separate sections. We no longer need to limit the number of alignments with this output format (as none are displayed) but we may still want to limit the e-value. We can do this by typing:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastp -query proteins.fasta -db db/pdbaa -out proteins_blastp_1e-30_table.txt -evalue 1e-30 -outfmt 6</span><br></pre></td></tr></table></figure>

<p>We can see the output is much more compressed with queries all together, only separated by the name in the first column. You may notice however that the subject name (column 2) is truncated, with the information we want having been cut off. This is a known problem in the tabular output that supposedly NCBI are working on. You can see we do happen to have the GI included in the description which we can search the NCBI website for. When we create our own database we may wish to try have short names so that this is less of a problem. There is a way to switch between some output types even after you have run the analysis which I will outline briefly later.</p>
<p>A small note ( we will not do an exercise on this): There are different types of BLAST searches within the basic types. For example in blastn you can perform standard blastn, megablast or discontiguous megablast. These options are changed with the <strong>-task</strong> flag. Note that megablast is the default for blastn, not standard blastn.</p>
<h2 id="Excerise-4-Extracting-the-sequences-from-a-BLAST-database"><a href="#Excerise-4-Extracting-the-sequences-from-a-BLAST-database" class="headerlink" title="Excerise 4: Extracting the sequences from a BLAST database"></a>Excerise 4: Extracting the sequences from a BLAST database</h2><p>If you want to extract the sequences that are contained in a BLAST database, you can use the <strong>blastdbcmd</strong> command to do this. Lets extract all the sequences from the pdb database we have downloaded. Navigate to the folder that contains the database file (pdbaa in the above examples) and run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastdbcmd -entry all -db pdbaa -out pdbaa.fasta</span><br></pre></td></tr></table></figure>

<p>This will extract all the sequences from the database named pdbaa and place them into a Fasta file named pdbaa.fasta.</p>
<h2 id="Exercise-5-creating-a-custom-database"><a href="#Exercise-5-creating-a-custom-database" class="headerlink" title="Exercise 5: creating a custom database"></a>Exercise 5: <font color="blue">creating a custom database</font></h2><p>Often we <strong>do not want to use all of NR</strong> or any of the pre-made databases supplied by NCBI. We may want to use <strong>a custom database of only species or genes we are interested in</strong>. If we have a fasta format file (unaligned) of these sequences we can create a database from this with the <strong>makeblastdb</strong> command. Lets create the pdb amino acid database from a fasta file, resulting in the database we already used.</p>
<p>Create a new folder called db2. Copy the file pdbaa.fasta you just created from the pdbaa folder to the db2 folder. Navigate into the db2 folder and create a protein database by typing:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">makeblastdb -in pdbaa.fasta -title pdbaa -dbtype prot -out pdbaa -parse_seqids</span><br></pre></td></tr></table></figure>

<p>The <strong>-in</strong> flag states the fasta file to create the database from, the <strong>-title</strong> flag gives the database a title, <strong>-dbtype</strong> says whether it is protein (prot) or nucleotide (nucl), <strong>-out</strong> is the name of the database and <strong>-parse_seqids</strong> states we want to <strong>retain the full names of each sequence</strong>. You will now see in db2 we have exactly the same files as in the db folder. We can use this as our database in exactly the same way we did for the original pdbaa database, just remember to use db2/pdbaa for the database instead of pdbaa/pdbaa.</p>
<h2 id="Exercise-6-BLASTing-against-a-remote-database"><a href="#Exercise-6-BLASTing-against-a-remote-database" class="headerlink" title="Exercise 6: BLASTing against a remote database"></a>Exercise 6: BLASTing against a remote database</h2><p>Instead of having to download the entirety of NR or other NCBI databases, we can BLAST against the version held on the website. This ensures we have the most up to date version but is also significantly slower. We use the <strong>-remote</strong>command to do this. Lets BLAST our sequences against NR held on the NCBI website by typing:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastp -query proteins.fasta -remote -db nr -out proteins_nr.txt -outfmt 6 -evalue 1e-30</span><br></pre></td></tr></table></figure>

<p>Q. Did weget the same sequences back from the nr database as we did from the pdb database?</p>
<h2 id="Exercise-7-Extracting-hits-from-the-BLAST-database"><a href="#Exercise-7-Extracting-hits-from-the-BLAST-database" class="headerlink" title="Exercise 7: Extracting hits from the BLAST database"></a>Exercise 7: Extracting hits from the BLAST database</h2><p>Once we have our BLAST results we may wish to go back and get the sequences for the hits from the database. For this we require a file of the sequence names of the hits (or parts of it, such as the section output from type 6 output) and the database used for the original BLAST (which must have been created with the -parse_seqids flag). Lets take 2 sequences from our hits against the pdbaa database. Copy the following into a file called hits.txt</p>
<table>
<thead>
<tr>
<th>gi</th>
<th>1942986</th>
<th>pdb</th>
<th>1OCC</th>
<th>A</th>
</tr>
</thead>
<tbody><tr>
<td>gi</td>
<td>40889823</td>
<td>pdb</td>
<td>1V54</td>
<td>A</td>
</tr>
</tbody></table>
<p>This is portions of 2 names of sequences we found to be good hits to our first query sequence. We will use the <strong>blastdbcmd</strong> program to get these sequences from the pdbaa database. Type:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastdbcmd -db db/pdbaa -dbtype prot -entry_batch hits.txt -outfmt %f -out hits.fasta </span><br></pre></td></tr></table></figure>

<p>This command is similar to in excerise 4 but instead of getting all the sequences in the database, we are <strong>getting a subselection</strong>. The <strong>-db</strong>, <strong>-dbtype</strong> and <strong>-out</strong> we have seen before, <strong>-entry_batch</strong> is the file containing the sequence names and <strong>-outfmt</strong> here says we want <strong>fasta formatted sequences (%f)</strong>. If you now open hits.fasta you should see the 2 sequences we requested.</p>
<h2 id="Exercise-8-Converting-output-format-types"><a href="#Exercise-8-Converting-output-format-types" class="headerlink" title="Exercise 8: Converting output format types"></a>Exercise 8: Converting output format types</h2><p>If you wish to change output formats after you have run a BLAST search we can use <strong>blast_formatter</strong>. This requires that the original run used <strong>-outfmt 11</strong> (archive type) and the database was made with the <strong>-parse_seqids</strong> flag. If we ran a BLAST such as</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastp -query proteins.fasta -db db/pdbaa -out protein_archive.txt -outfmt 11</span><br></pre></td></tr></table></figure>

<p>We could retrieve the results in out format 6 by typing</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blast_formatter -archive protein_archive.txt -outfmt 6 -out proteins_tabular.txt</span><br></pre></td></tr></table></figure>

<p><strong>Thus a good way to run BLAST+ is to use -outfmt 11 and then after that use blast_formatter to change the output to different formats as needed.</strong></p>
<hr>
<p><a href="https://github.com/enormandeau/ncbi_blast_tutorial">https://github.com/enormandeau/ncbi_blast_tutorial</a></p>
<h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><p>Get the compiled executables from this URL:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/</span><br></pre></td></tr></table></figure>

<p>Decompress the archive. </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tar xvfz ncbi-blast-2.9.0+-x64-linux.tar.gz</span><br></pre></td></tr></table></figure>

<p>Add the <code>bin</code> folder from the extracted archive to your path.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=&quot;/PATH/TO/ncbi-blast-2.9.0+/bin&quot;:$PATH</span><br></pre></td></tr></table></figure>

<h2 id="Example-sequences-to-use-with-the-tutorial"><a href="#Example-sequences-to-use-with-the-tutorial" class="headerlink" title="Example sequences to use with the tutorial"></a>Example sequences to use with the tutorial</h2><p>In order to test blast, you need a test fasta file. Use the following files that come with the tutorial:</p>
<ul>
<li><code>sequences.fasta</code></li>
<li><code>reference.fasta</code></li>
</ul>
<h2 id="Create-blast-database"><a href="#Create-blast-database" class="headerlink" title="Create blast database"></a>Create blast database</h2><p>The different blast tools require a formatted database to search against. In order to create the database, we use the <code>makeblastdb</code> tool:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">makeblastdb -in reference.fasta -title reference -dbtype nucl -out databases/reference</span><br></pre></td></tr></table></figure>

<p>This will create a list of files in the <code>databases</code> folder. These are all part of the blast database.</p>
<h2 id="Blast"><a href="#Blast" class="headerlink" title="Blast"></a>Blast</h2><p>We can now <font color="blue"><strong>blast our sequences against the database</strong></font>. In this case, both our query sequences and database sequences are DNA sequences, so we use the <code>blastn</code> tool:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastn -db databases/reference -query sequences.fasta -evalue 1e-3 -word_size 11 -outfmt 0 &gt; sequences.reference</span><br></pre></td></tr></table></figure>

<p>You can use different output formats with the <code>outmft</code> option:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-outfmt &lt;String&gt;</span><br><span class="line">  alignment view options:</span><br><span class="line">    0 = pairwise,</span><br><span class="line">    1 = query-anchored showing identities,</span><br><span class="line">    2 = query-anchored no identities,</span><br><span class="line">    3 = flat query-anchored, show identities,</span><br><span class="line">    4 = flat query-anchored, no identities,</span><br><span class="line">    5 = XML Blast output,</span><br><span class="line">    6 = tabular,</span><br><span class="line">    7 = tabular with comment lines,</span><br><span class="line">    8 = Text ASN.1,</span><br><span class="line">    9 = Binary ASN.1,</span><br><span class="line">   10 = Comma-separated values,</span><br><span class="line">   11 = BLAST archive format (ASN.1)</span><br></pre></td></tr></table></figure>

<h2 id="Blast-with-parallel"><a href="#Blast-with-parallel" class="headerlink" title="Blast with parallel"></a>Blast with parallel</h2><p>If you need to run your blasts faster (and who doesn’t?), you can maximise CPU usage with <code>gnu parallel</code>. You will find it <a href="http://ftp.gnu.org/gnu/parallel/parallel-latest.tar.bz2">at this link</a>.</p>
<p>Download the archive, extract it (with <code>tar xvfB parallel-latest.tar.bz2</code>) and install it with the following commands:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<p>We can now use <code>parallel</code> to speed up blast:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">time cat sequences.fasta | parallel -k --block 1k --recstart &#x27;&gt;&#x27; --pipe &#x27;blastn -db databases/reference -query - -evalue 1e-3 -word_size 11 -outfmt 0&#x27; &gt; sequences.reference</span><br></pre></td></tr></table></figure>

<h2 id="blast-distribution"><a href="#blast-distribution" class="headerlink" title="blast+ distribution"></a>blast+ distribution</h2><p>An exhaustive list of the programs that come with the blast+ distribution</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blastdb_aliastool</span><br><span class="line">blastdbcheck</span><br><span class="line">blastdbcmd</span><br><span class="line">blast_formatter</span><br><span class="line">blastn</span><br><span class="line">blastp</span><br><span class="line">blastx</span><br><span class="line">convert2blastmask</span><br><span class="line">deltablast</span><br><span class="line">dustmasker</span><br><span class="line">legacy_blast.pl</span><br><span class="line">makeblastdb</span><br><span class="line">makembindex</span><br><span class="line">makeprofiledb</span><br><span class="line">psiblast</span><br><span class="line">rpsblast</span><br><span class="line">rpstblastn</span><br><span class="line">segmasker</span><br><span class="line">tblastn</span><br><span class="line">tblastx</span><br><span class="line">update_blastdb.pl</span><br><span class="line">windowmasker</span><br></pre></td></tr></table></figure>

<hr>
<p><a href="https://ncbi.github.io/magicblast/cook/blastdb.html">https://ncbi.github.io/magicblast/cook/blastdb.html</a></p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>alignment</tag>
      </tags>
  </entry>
  <entry>
    <title>【CUT-Tag】【ATAC-seq】</title>
    <url>/blog/2022/03/18/2022-03-19-CUT-Tag/</url>
    <content><![CDATA[<p>CUT&amp;RUN CUT&amp;Tag ChIP-seq ATAC-seq</p>
<span id="more"></span>

<p><a href="https://www.bilibili.com/video/BV11K4y147fN?from=search&seid=6789892139579942949&spm_id_from=333.337.0.0">嘉因生物</a></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/1.png" alt="1"></p>
<p><strong>测序数据量</strong></p>
<p>参考ChIP-seq 20M/40M（2000万reads）（对PE50约为 6/12G）</p>
<p><strong>CUT&amp;Tag-去除测序接头</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/2.png" alt="1"></p>
<p><strong>去接头软件</strong></p>
<p>Trimmomatic；Cutadapt；fastp</p>
<p><strong>参考序列比对</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/3.png" alt="1"></p>
<p><strong>数据过滤</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/4.png" alt="1"></p>
<p><strong>CUT&amp;Tag片段长度分布</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/5.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/6.png" alt="1"></p>
<p><strong>CUT&amp;Tag-结合位点检测（PeakCalling）</strong></p>
<p>MACS2 主流</p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/7.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/8.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/9.png" alt="9"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/10.png" alt="1"></p>
<p>SEACR 结果没那么好</p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/11.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/12.png" alt="1"></p>
<p><strong>CUT&amp;Tag-结合位点信号分布</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/13.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/14.png" alt="1"></p>
<p><strong>CUT&amp;Tag-Peaks 功能性区域注释</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/15.png" alt="1"></p>
<p><strong>CUT&amp;Tag-Motif Analysis</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/16.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/17.png" alt="1"></p>
<p><strong>CUT&amp;Tag-其他分析</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/18.png" alt="1"></p>
<p><strong>CUT&amp;Tag-联合RNA-seq分析</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/19.png" alt="1"></p>
<p>BETA 功能1，2。3用hommer更多</p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/20.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/21.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/22.png" alt="1"></p>
<p>Activating/repressive function prediction</p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/23.png" alt="1"></p>
<p>Target gene</p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/24.png" alt="1"></p>
<p><strong>如何评估CUT&amp;Tag中IgG的作用</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/25.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/26.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/27.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/28.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/29.png" alt="1"></p>
<p>为何IgG信号和组蛋白信号同步出现？</p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/30.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/31.png" alt="1"></p>
<p><strong>CUT&amp;Tag-Quality Control</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/32.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/33.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/34.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/35.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/36.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/37.png" alt="1"></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/38.png" alt="1"></p>
<p>组蛋白，转录起始激活marker，在起始TSS高；<strong>抑制</strong>的<strong>marker</strong>H3K36me3在<strong>genebody区域比较高</strong></p>
<p><strong>UCSC tools工具</strong></p>
<p><img src="/blog/2022/03/18/2022-03-19-CUT-Tag/39.png" alt="1"></p>
<p><strong>Cistrome：ChIP-seq在线分析工具</strong></p>
<p>提前查数据 </p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/40.png" alt="1"></p>
<p><strong>Motif数据库JASPAR</strong></p>
<p><strong>Motif工具MEME</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/41.png" alt="1"></p>
<p><a href="https://www.bilibili.com/video/BV1py4y1a7L5/?spm_id_from=333.788.recommend_more_video.2">FraserGen</a></p>
<p>ATAC测序，Illumina PE150，测序数据量最终可用推荐：50M（开放区域），200M（TFfootprint）</p>
<p><strong>ATAC-seq项目展示 动物植物</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/42.png" alt="1"></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/43.png" alt="1"></p>
<p>注意trimmomatic 的NexteraPE-PE.fa;注意bowtie2 -X 最大插入片段长度设置1000/2000.</p>
<p><strong>插入片段长度统计</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/44.png" alt="1"></p>
<p><strong>-f 0x40 只统计reads1</strong>(统计一次indertsize)</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Rscript plotInsertSize.R insertSize.txt insertSize.png</span></span><br><span class="line"><span class="comment">#plotInsertSize.R</span></span><br><span class="line">cmd=commandArgs(trailingOnly=<span class="literal">TRUE</span>);</span><br><span class="line">input=cmd[<span class="number">1</span>];</span><br><span class="line">output=cmd[<span class="number">2</span>];</span><br><span class="line">d=read.table(input);</span><br><span class="line">png(file=output);</span><br><span class="line">hist(d$V1,mian=<span class="string">&quot;&quot;</span>,ylab=<span class="string">&quot;readCount&quot;</span>,xlab=<span class="string">&quot;insertsize&quot;</span>,xaxt=<span class="string">&quot;n&quot;</span>,breaks=seq(<span class="number">0</span>,<span class="built_in">max</span>(d$V1,by=<span class="number">1</span>)));</span><br><span class="line">axis();</span><br><span class="line">dev.off;</span><br></pre></td></tr></table></figure>

<p><strong>Peak calling principle for atac</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/45.png" alt="1"></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/46.png" alt="1"></p>
<p>Shift -75 往5‘端移动；<strong>nomodel 不建立双峰模型</strong>；**-SMPR对数据量标准化**</p>
<blockquote>
<p>单端测序时需要建立双峰模型推测DNA片段的长度。双端不需要</p>
<p>平移让Tn5切割断点处于reads正中心</p>
<p>-SMPR save signal per million reads</p>
</blockquote>
<p>BDG to BigWig【使用BDG转换的bigwig文件和bam转化bw，直接使用narrowpeak的区别是】</p>
<p>建议用bdg转换的bigwig文件，因为该文件做了平移shift和延伸extend</p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/47.png" alt="1"></p>
<p><strong>Data Quality Assesment</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/48.png" alt="1"></p>
<p><strong>Data Visualization</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/49.png" alt="1"></p>
<p><strong>Multiple Replicates</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/50.png" alt="1"></p>
<p>IDR所有点代表有overlap，红点表示富集倍数有差异，黑点表示富集倍数一致。IDR在动物里算出的结果较好，植物由于实验问题效果没那么好（不推荐？），植物直接overlap-peak。</p>
<p><strong>Peak annotation</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/51.png" alt="1"></p>
<p><strong>Motif analysis</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/52.png" alt="1"></p>
<p><strong>个性化分析</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/53.png" alt="1"></p>
<p>TF网络需要多组数据不同处理条件下</p>
<p><strong>联合分析</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/54.png" alt="1"></p>
<p>表达程度越高信号越高。</p>
<p><strong>案例</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/55.png" alt="1"></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/56.png" alt="1"></p>
<p>H3K27me3 genebody</p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/57.png" alt="1"></p>
<p>peak-to-gene link prediction【大样本量的ATAC和RNAseq关联分析】</p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/58.png" alt="1"></p>
<hr>
<p><strong>CUT&amp;Tag</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/59.png" alt="1"></p>
<p>ChIP实验新方法：CUT&amp;RUN 和 CUT&amp;Tag 周期快；材料需求少；数据信噪比高</p>
<p><strong>C</strong>leavage <strong>U</strong>nder <strong>T</strong>argets and <strong>R</strong>elease <strong>U</strong>sing <strong>N</strong>uclease</p>
<p><strong>C</strong>leavage <strong>U</strong>nder <strong>T</strong>argets and <strong>Tag</strong>mentation</p>
<p><strong>原理介绍</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/60.png" alt="1"></p>
<p>蛋白磁珠吸附核膜，细胞绑定在磁珠上。细胞膜穿孔，pAG-MNase进入，primary Ab抗体加入。多余抗体多余pAG-MNase洗掉，<strong>pAG-MNase and primary Ab binding</strong>。加入钙离子激活，靶向位点切割，整个基因组少部分位置切割【背景噪音高低取决于抗体质量好坏】。只有切割的小片段从小孔出来(大部分背景遗留在核内)。CUT&amp;RUN用的pAG-MNase依然要补平加接头，替换为Protein-A-Tn5则变为CUT&amp;Tag，一天以内完成的”ChIP”实验。</p>
<p><strong>实验流程</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/61.png" alt="1"></p>
<p>文库片段分布和ATAC类似（Tn5，核小体）</p>
<p>IgG阴性对照帮助判断到底是ChIP峰还是ATAC峰(实验是否成功)。植物难度大，植物用原生质体。植物推荐做chip就行？动物冻存组织可尝试，植物冻存不推荐。CUT技术是针对少量细胞的。少量细胞可能数据量少。CUT&amp;Tag缺点是由于Tn5只做开放区域，若是异染色质H3K9，H3K39三甲基化这种marker做不了</p>
<p><strong>CUT&amp;Tag数据分析</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/62.png" alt="1"></p>
<p><strong>提升CUT&amp;Tag数据关键</strong></p>
<p>抗体质量：ChIP-grade；Western验证；抗体批次效应</p>
<p>细胞质量：活细胞比例&gt;95%(native chromatin )；细胞均一性</p>
<p><strong>MACS软件</strong></p>
<p>数据噪音评估</p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/63.png" alt="1"></p>
<p><strong>！！！Peak calling for ATAC</strong></p>
<p> <img src="/blog/2022/03/18/2022-03-19-CUT-Tag/64.png" alt="1"></p>
<p><font color="red"><strong>对于ATAC，一条DNA fragment代表两个酶切位点信息，转bed格式。如果用bam文件会默认丢掉reads2</strong></font></p>
<p><strong>Code</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#step1 去接头</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#step2 建立index</span></span><br><span class="line">ref.fa</span><br><span class="line">genes.gtf</span><br><span class="line">bowtie2 build</span><br><span class="line">samtools faidx ref.fa</span><br><span class="line"></span><br><span class="line"><span class="comment">#step3 比对</span></span><br><span class="line">bowtie2 -x index/ref -X 1000 -1 R1.fq -2 R2.fq -S .sam</span><br><span class="line"></span><br><span class="line"><span class="comment">#step4 挑选可靠比对结果</span></span><br><span class="line">samtools view -b -f 2 -q 30 -0 pairs.bam .sam</span><br><span class="line"></span><br><span class="line"><span class="comment">#step5 去除PCR重复</span></span><br><span class="line">samtools sort -o pairs.sorted.bam pairs.bam</span><br><span class="line">picard.jar MarkDuplicates</span><br><span class="line"></span><br><span class="line"><span class="comment">#step6 查看mito pt 污染</span></span><br><span class="line">samtools index pairs.sorted.dedup.bam</span><br><span class="line">samtools idxstats pairs.sorted.dedup.bam</span><br><span class="line"></span><br><span class="line"><span class="comment">#step7 去除线粒体数据</span></span><br><span class="line">samtools view -h pairs.sorted.dedup.bam | grep -v <span class="string">&quot;chrM&quot;</span> | grep -v <span class="string">&quot;Pt&quot;</span> | samtools view -bS -o final.bam</span><br><span class="line"></span><br><span class="line"><span class="comment">#step8 统计插入片段长度分布</span></span><br><span class="line">Rscript plotInsertSize final.bam final.insertsize</span><br><span class="line"></span><br><span class="line"><span class="comment">#step9 peak calling</span></span><br><span class="line">bedtools bamtobed -1 final.bam &gt; final.bam.bed</span><br><span class="line"></span><br><span class="line">macs2 callpeak -t final.bam.bed -n rep1 --<span class="built_in">shift</span> -100 --extsize 200 --nomodel -B --SPMR -g 2e</span><br><span class="line"></span><br><span class="line"><span class="comment">#step10 TSS富集</span></span><br><span class="line"><span class="comment">#BDG to BigWig</span></span><br><span class="line"><span class="comment">#UCSC utitlities</span></span><br><span class="line"><span class="comment">#对bdg文件排序</span></span><br><span class="line">bedSort treat.bdg treat.sort.bdg</span><br><span class="line"><span class="comment">#生成基因组各条序列长度信息，直接从bam文件得到</span></span><br><span class="line">samtools view -H final.bam | perl -ne <span class="string">&#x27;if(/SN:(\S+)\s+LN:(\d+)/)&#123;print &quot;$1\t$2\n&quot;&#125;&#x27;</span> &gt; chrome.sizes</span><br><span class="line"><span class="comment">#生成bigwig文件</span></span><br><span class="line">bedClip -truncate treat.sort.bdg chrome.sizes stdout | perl -ane <span class="string">&#x27;print if($F[1]&lt;$F[2])&#x27;</span> &gt; treat.bdegraph</span><br><span class="line">bedGraphToBigWig treat.bdegraph chrome.sizes treat.bw</span><br><span class="line"></span><br><span class="line">computeMatrix reference-point -S Rep1.bw Rep2.bw -R .gtf -a 3000 -b 3000 -p 1 -o matrix.gz</span><br><span class="line">plotHeatmap -m matrix.gz -o heatmap.png --colorMap Reds</span><br><span class="line"></span><br><span class="line"><span class="comment">#step11 peak重复性</span></span><br><span class="line">bedtools intersect -a .peak -b .peak | wc -l</span><br><span class="line">bedtools intersect -a .peak -b .peak -f 0.5 -F 0.5 | wc -l</span><br><span class="line">idr -s rep1.peak rep2.peak -o idr --plot</span><br><span class="line"></span><br><span class="line"><span class="comment">#step12 peak在基因上的分布</span></span><br><span class="line">Rscript PeakAnnotation.R .gtf rep1.peak Rep1</span><br><span class="line"></span><br></pre></td></tr></table></figure>



















<hr>
<p>IgG？</p>
]]></content>
      <categories>
        <category>CUT-Tag</category>
      </categories>
      <tags>
        <tag>technology</tag>
      </tags>
  </entry>
  <entry>
    <title>Assembly Gene Annotation</title>
    <url>/blog/2022/03/18/2022-03-18-annotation/</url>
    <content><![CDATA[<p>Structural annotation and functional annotation</p>
<span id="more"></span>

<h1 id="Structural-annotation"><a href="#Structural-annotation" class="headerlink" title="Structural annotation"></a>Structural annotation</h1><p>The genome structural annotation was performed using Maker-P【38】: </p>
<p>(1) SNAP and Augustus as ab initio gene predictors;</p>
<p> (2) Exonerate as experimental based predictor with 454 and Illumina RNASeq reads and protein sequences from different protein【39】datasets. RNAseq Illumina data was mapped using Tophat2. tRNAs were annotatedusing tRNAscan (<a href="http://lowelab.ucsc.edu/tRNAscan-SE/">http://lowelab.ucsc.edu/tRNAscan-SE/</a>).</p>
<h1 id="Functional-annotation"><a href="#Functional-annotation" class="headerlink" title="Functional annotation"></a>Functional annotation</h1><p>The gene functional annotation was performed by sequence homology search with different protein datasets using BlastP【40】 and protein domains search【41】using InterProScan . Functional annotations were integrated using AHRD(<a href="https://github.com/groupschoof/AHRD">https://github.com/groupschoof/AHRD</a>). See Supplementary Note 1.</p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>Organelle assembly</title>
    <url>/blog/2022/03/18/2022-03-18-mito-chro/</url>
    <content><![CDATA[<p>organelle assembly</p>
<span id="more"></span>

<h1 id="Mitochondrial-Genome-Assembly"><a href="#Mitochondrial-Genome-Assembly" class="headerlink" title="Mitochondrial Genome Assembly"></a><strong>Mitochondrial Genome Assembly</strong></h1><h2 id="植物线粒体基因组-特点，成因和后果"><a href="#植物线粒体基因组-特点，成因和后果" class="headerlink" title="植物线粒体基因组 特点，成因和后果"></a><a href="https://www.zhihu.com/question/65471820#:~:text=%E6%A4%8D%E7%89%A9%E7%BA%BF%E7%B2%92%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E7%9A%84%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9%E6%98%AF%EF%BC%9A%20%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%A4%A7%E5%B0%8F%E5%92%8C%E7%BB%93%E6%9E%84%E5%8F%98%E5%BC%82%E5%B7%A8%E5%A4%A7%EF%BC%8C%E5%9F%BA%E5%9B%A0%E5%8D%B4%E6%9E%81%E5%BA%A6%E4%BF%9D%E5%AE%88%EF%BC%9B%E5%9F%BA%E5%9B%A0%E5%88%86%E5%B8%83%E9%9D%9E%E5%B8%B8%E7%A8%80%E7%96%8F%EF%BC%8C%E5%90%AB%E6%9C%89%E5%A4%A7%E9%87%8F%E9%9D%9E%E7%BC%96%E7%A0%81%E5%BA%8F%E5%88%97%EF%BC%9B%E5%AD%98%E5%9C%A8%E5%A4%A7%E9%87%8F%E7%9A%84RNA%E7%BC%96%E8%BE%91%E3%80%82,%E5%A4%A7%E9%83%A8%E5%88%86%E5%8A%A8%E7%89%A9%E7%9A%84%E7%8E%AF%E7%8A%B6%E7%BA%BF%E7%B2%92%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E7%9A%84%E5%A4%A7%E5%B0%8F%E7%BA%A615-17kb%EF%BC%8C%E4%B8%94%E7%BB%93%E6%9E%84%E7%9B%B8%E5%AF%B9%E4%BF%9D%E5%AE%88%EF%BC%8C%E5%9F%BA%E5%9B%A0%E6%8E%92%E5%88%97%E7%B4%A7%E5%87%91%EF%BC%8C%E8%BF%99%E4%BA%9B%E7%89%B9%E7%82%B9%E9%83%BD%E8%B7%9F%E6%A4%8D%E7%89%A9%E5%8F%B6%E7%BB%BF%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E7%9B%B8%E4%BB%BF%EF%BC%8C%E6%A4%8D%E7%89%A9%E7%9A%84%E5%8F%B6%E7%BB%BF%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%A4%A7%E5%B0%8F%E5%9C%A8100-200kb%E4%B9%8B%E9%97%B4%E3%80%82%20%E7%84%B6%E8%80%8C%E6%A4%8D%E7%89%A9%E7%BA%BF%E7%B2%92%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%8D%B4%E8%B7%9F%E5%89%8D%E4%B8%A4%E8%80%85%E6%9C%89%E7%9D%80%E8%BF%A5%E7%84%B6%E4%B8%8D%E5%90%8C%E7%9A%84%E7%89%B9%E6%80%A7%EF%BC%8C%E5%85%B6%E5%A4%A7%E5%B0%8F%E4%B8%80%E8%88%AC%E5%9C%A8200-750kb%E4%B9%8B%E9%97%B4%E3%80%82">植物线粒体基因组 特点，成因和后果</a></h2><p>植物线粒体基因组主要特点是：<strong>基因组大小和结构变异巨大，基因却极度保守；基因分布非常稀疏，含有大量非编码序列；存在大量的RNA编辑。</strong></p>
<ul>
<li><p>大部分<strong>动物环状线粒体基因组</strong>大小约<strong>15-17kb</strong>，且<strong>结构相对保守</strong>，<strong>基因排列紧凑</strong></p>
</li>
<li><p>动物线粒体跟<strong>植物叶绿体基因组相仿</strong>，<strong>植物叶绿体基因组</strong>大小在<strong>100-200kb之间</strong></p>
</li>
<li><p><strong>植物线粒体基因组</strong>却跟前两者迥然不同，大小在<strong>200-750kb</strong>之间。<strong>黄瓜</strong>线粒体基因组达<strong>1556kb</strong>。<strong>近缘</strong>物种间<strong>也差异巨大</strong>。如蝇子草属（<em>Silene</em>）中，夜花蝇子草（<em>S. noctiflora</em>）线粒体基因组<strong>6.728kb</strong>，而叉枝条蝇子草（<em>S. latifolia</em>）线粒体基因组<strong>253kb</strong>，<strong>同属</strong>植物差异30倍。即使<strong>同一物种</strong>，差异也显著。如白玉草（<em>S. vulgaris</em>），任何<strong>不同种群</strong>两两之间只有约一半的线粒体基因组序列相同。</p>
</li>
<li><p>植物线粒体<strong>基因组庞大</strong>，但<strong>编码基因却不多</strong>，排列稀疏。<strong>植物叶绿体基因组</strong>上约<strong>100个基因</strong>，但比叶绿体基因组大的<strong>拟南芥线粒体基因组</strong>，却只有约<strong>50多个基因</strong>，而人线粒体基因组37个基因。拟南芥<strong>线粒体基因数量</strong>不到人的<strong>两倍</strong>，其<strong>基因组大小</strong>却是<strong>22倍</strong>。植物线粒体基因组大部分是<strong>非编码序列</strong>，这些序列占到<strong>60%以上</strong>。这些非编码序列由<strong>重复片段、叶绿体基因组和和基因组转移而来</strong>的序列，甚至是<strong>基因水平转移</strong>获得的其它物种序列。如最<strong>古老的被子植物互叶梅</strong>（<em>Amborella trichopoda</em>）的线粒体基因组中，就有<strong>大量来自苔藓、绿藻和其它被子植物的序列片段</strong>（Rice, 2013）。</p>
</li>
<li><p>植物线粒体基因组<strong>结构变异巨大</strong>，线粒体<strong>基因</strong>却<strong>极度保守</strong>，在<strong>植物三套基因组中最保守演化速率最慢</strong>。黄瓜如此庞大线粒体基因组只比拟南芥多四个基因。由于植物线粒体基因<strong>非常保守，区分度不足</strong>，一般<strong>不选作系统学研究</strong>的<strong>分子标记</strong>。跟动物正好相反，<strong>动物的线粒体基因演化速率较快</strong>，所以在动物系统学研究中，是<strong>最常用的分子标记</strong>。</p>
</li>
<li><p><strong>是什么导致植物线粒体基因组如此庞大，如此多非编码序列？线粒体基因组基因保守原因是？目前理论是发生在线粒体非编码区和编码区的两套不同DNA修复机制。</strong></p>
</li>
<li><p>植物线粒体<strong>编码区</strong>进行的是<strong>碱基剪切修复</strong>（Base excision repair）和<strong>基因转换</strong>（gene conversion）介导的<strong>精确</strong>修复，而在非编码区进行的是<strong>非同源性末端连接</strong>（non-homologous end joining）和<strong>断裂诱导复制</strong>（Break-induced replication）介导的<strong>非精确</strong>修复（Christensen, 2013）</p>
</li>
</ul>
<p><img src="/blog/2022/03/18/2022-03-18-mito-chro/1.png" alt="img"></p>
<ul>
<li>编码区精确修复导致线粒体基因变异稀少，演化速率非常慢。非编码区非精确修复，修复过程带来很多外来序列，使得非编码区非常包容，不断吸收积累非编码序列</li>
<li>后果。植物线粒体基因组中大量非编码序列，其中很多重复片段，导致植物线粒体基因组 易重组。叶绿体基因组在细胞内常以完整环状存在，植物线粒体会重组形成线状结构，甚至很多大小不一的环。黄瓜有1.6M+84k+45k线粒体基因组(大小环)。完整测出的mito 远小于chro</li>
</ul>
<h2 id="植物线粒体基因组测序"><a href="#植物线粒体基因组测序" class="headerlink" title="植物线粒体基因组测序"></a>植物线粒体基因组测序</h2><p><a href="http://www.genepioneer.com/display.php?id=353">http://www.genepioneer.com/display.php?id=353</a></p>
<ul>
<li><p>动物线粒体基因组较小，通常在10-39kb，而植物线粒体基因组大小在200-750kb。植物线粒体基因组主要特点是：基因组大小和结构变异巨大；基因却极度保守；基因分布非常稀疏；含有大量非编码序列；存在大量的RNA编辑</p>
</li>
<li><p>公司套路：二代+三代植物线粒体基因组测序</p>
<ul>
<li><strong>基因组注释</strong>进行<strong>基因序列组成分析</strong>来研究<strong>物种功能特征</strong></li>
<li><strong>比较基因组学</strong>研究物<strong>种间基因组结构变化</strong>探讨物<strong>种的环境适应性特征</strong></li>
<li><strong>群体基因组研究</strong>内容更广：<strong>物种起源、亲缘分类、系统发育、谱系地理</strong>等</li>
</ul>
</li>
<li><p>公司常规分析</p>
<ul>
<li>线粒体基因组结构注释</li>
<li>线粒体基因组图谱</li>
<li>RSCU分析</li>
<li>散在重复序列分析</li>
<li>碱基偏移分析</li>
</ul>
</li>
<li><p>公司高级分析</p>
<ul>
<li>KaKs分析</li>
<li>线粒体结构比较分析</li>
<li>进化树分析</li>
<li>序列同源及共线性分析</li>
<li>基因水平转移分析</li>
</ul>
</li>
<li><p>案例1</p>
<ul>
<li><a href="doi.org/10.1186/s12862-020-1582-1">紫衫线粒体基因组</a>：8个蛋白基因转移到核基因组。对紫衫线粒体基因组测序，得到全长<font color="blue"><strong>468,924bp</strong></font>线粒体基因组序列与<strong>其它4个裸子植物谱系</strong>的<strong>线粒体基因组</strong>比较。结果表明裸子植物线粒体基因组在<strong>大小、结构、基因和内含子含量、外源序列、突变率</strong>等方面与<strong>被子植物</strong>线粒体基因组<strong>存在差异</strong>。</li>
<li><a href="DOI%EF%BC%9A10.7717/peerj.3148">红柳线粒体全基因组序列的组装与比较分析</a> : 组装得到全长<font color="blue"><strong>644,437bp</strong></font>完整的红柳线粒体 (mt) 序列。编码<font color="blue"><strong>58个独特基因</strong></font>（32个蛋白编码基因、23个tRNA基因和3个rRNA基因）。通过对35种杨树的23个蛋白编码基因<strong>系统发育分析</strong>，证明<strong>红柳是杨树的姊妹</strong>。</li>
</ul>
</li>
</ul>
<h2 id="software-2019review-DOI-10-16288-j-yczz-19-227"><a href="#software-2019review-DOI-10-16288-j-yczz-19-227" class="headerlink" title="[software-2019review](DOI: 10.16288/j.yczz.19-227)"></a>[software-2019review](DOI: 10.16288/j.yczz.19-227)</h2><ul>
<li>特殊且容易获取的遗传标记，高突变速率(not plant)、无基因重组、高拷贝数和母系遗传等</li>
<li>进化生物学、群体遗传学等揭示物种的起源和扩散历史发挥作用。核基因和线粒体表现不一致的谱系关系，特别是具有复杂的群体历史的类群(如<strong>基因交流</strong>、<strong>遗传漂变</strong>、<strong>偏向性迁徙</strong>和<strong>祖先谱系分拣</strong>等)。</li>
<li>有参：近缘物种的线粒体基因组或部分片段作为参考序列，从研究类群全基因组数据中捕获线粒体reads。(1)基于线粒体<strong>整个</strong>基因组的拼装策略；(2)基于线粒体<strong>片段</strong>的拼装策略。使用比对工具(如BWA)将总reads映射(mapping)到线粒体参考序列，根据<strong>序列的相似性捕获</strong>线粒体reads，然后使用不同序列延长策略对捕获的线粒体reads序列延伸，直到延长到完整的线粒体基因组长度。<strong>MIA</strong>用现代人线粒体基因组作参考研究尼安德特人。</li>
<li>denovo：线粒体contig分拣</li>
</ul>
<table>
<thead>
<tr>
<th>软件名称</th>
<th>是否需要参考序列/ 参考序列类型</th>
<th>适用 物种</th>
<th>输入文件格式、 类型</th>
<th>变异 注释</th>
<th>结构可 视化</th>
<th>运行 环境</th>
<th>编程 语言</th>
</tr>
</thead>
<tbody><tr>
<td>MIA</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>Fastq、SE reads和 PE reads</td>
<td>×</td>
<td>×</td>
<td>CUI</td>
<td>C/C++</td>
</tr>
<tr>
<td>MitoBamAnnotator</td>
<td>是/ rCRS</td>
<td>人</td>
<td>Bam</td>
<td>√</td>
<td>√</td>
<td>Web</td>
<td>Java</td>
</tr>
<tr>
<td>MitoSeek</td>
<td>是/rCRS和hg19</td>
<td>人</td>
<td>Bam</td>
<td>√</td>
<td>×</td>
<td>GUI</td>
<td>Perl</td>
</tr>
<tr>
<td>mtDNA- profiler</td>
<td>是/rCRS</td>
<td>人</td>
<td>Fasta</td>
<td>×</td>
<td>√</td>
<td>Web</td>
<td>Java</td>
</tr>
<tr>
<td>MITObim</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>Bam</td>
<td>×</td>
<td>×</td>
<td>CUI</td>
<td>Perl</td>
</tr>
<tr>
<td>Mit-o-matic</td>
<td>是/rCRS</td>
<td>人</td>
<td>Fastq、SE reads和 PE reads</td>
<td>√</td>
<td>√</td>
<td>Web/GUI</td>
<td>Java</td>
</tr>
<tr>
<td>MToolBox</td>
<td>是/rCRS和RSRS</td>
<td>人</td>
<td>Fastq/Bam/Sam、 SE reads和PE reads</td>
<td>√</td>
<td>×</td>
<td>Web/CUI</td>
<td>Python</td>
</tr>
<tr>
<td>ARC</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>Fastq、SE reads和 PE reads</td>
<td>×</td>
<td>×</td>
<td>Web/CUI</td>
<td>Python</td>
</tr>
<tr>
<td>Phy-Mer</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>Fasta/fastq/Bam、 SE reads和PE reads</td>
<td>×</td>
<td>√</td>
<td>CUI</td>
<td>Python</td>
</tr>
<tr>
<td>mtDNA- Server</td>
<td>是/rCRS和RSRS</td>
<td>人</td>
<td>Fastq/Bam/VCF、 SE reads和PE reads</td>
<td>√</td>
<td>√</td>
<td>Web</td>
<td>Java</td>
</tr>
<tr>
<td>IOGA</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>Fastq、SE reads和 PE reads</td>
<td>×</td>
<td>×</td>
<td>CUI</td>
<td>Python</td>
</tr>
<tr>
<td>NOVOPlasty</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>Fastq/fasta、SE reads 和PE reads</td>
<td>×</td>
<td>×</td>
<td>Web/CUI</td>
<td>Perl</td>
</tr>
<tr>
<td>Norgal</td>
<td>否</td>
<td>任意 物种</td>
<td>Fastq、SE reads和 PE reads</td>
<td>×</td>
<td>×</td>
<td>CUI</td>
<td>Python/ Java</td>
</tr>
<tr>
<td>Organelle- PBA</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>PacBio reads</td>
<td>×</td>
<td>×</td>
<td>CUI</td>
<td>Perl</td>
</tr>
<tr>
<td>MitoSuite</td>
<td>是/rCRS, RSRS, hg19, GRCh37和38</td>
<td>人</td>
<td>Bam/Sam</td>
<td>√</td>
<td>√</td>
<td>GUI</td>
<td>Python</td>
</tr>
<tr>
<td>ORG.Asm</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>Fastq、SE reads和 PE reads</td>
<td>×</td>
<td>×</td>
<td>CUI</td>
<td>Python</td>
</tr>
<tr>
<td>MitoZ</td>
<td>否</td>
<td>任意 物种</td>
<td>Fastq、SE reads和 PE reads</td>
<td>√</td>
<td>√</td>
<td>CUI</td>
<td>Python</td>
</tr>
<tr>
<td><strong>GetOrganelle</strong></td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>Fastq、SE reads和 PE reads</td>
<td>×</td>
<td>×</td>
<td><strong>CUI</strong></td>
<td>Python</td>
</tr>
<tr>
<td>Trimitomics</td>
<td>是/自定义参考序列</td>
<td>任意 物种</td>
<td>RNA-seq reads、 PE reads</td>
<td>×</td>
<td>×</td>
<td>Unknown</td>
<td>Unknown</td>
</tr>
</tbody></table>
<h2 id="软件GetOrganelle"><a href="#软件GetOrganelle" class="headerlink" title="软件GetOrganelle"></a>软件GetOrganelle</h2><p><a href="https://zhuanlan.zhihu.com/p/428949195">https://zhuanlan.zhihu.com/p/428949195</a></p>
<p><a href="https://github.com/Kinggerm/GetOrganelle">https://github.com/Kinggerm/GetOrganelle</a></p>
<p>GetOrganelle是中科院昆植所金建军和郁文彬老师共同开发的<strong>质体组装软件</strong>，<strong>2020-Genome Biology</strong>。</p>
<h3 id="核心流程"><a href="#核心流程" class="headerlink" title="核心流程"></a>核心流程</h3><p>1）通过“种子”序列获得部分目标相关reads；</p>
<p>2）延伸reads获得所有目标相关reads；</p>
<p>3）对reads进行从头组装得到组装图形；</p>
<p>4）过滤组装图形；</p>
<p>5）识别细胞器组分并自动导出所有可能的细胞器基因组结构。</p>
<p><img src="/blog/2022/03/18/2022-03-18-mito-chro/2.png" alt="flowchart"></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">conda create -n getorganelle</span><br><span class="line">conda activate getorganelle</span><br><span class="line">conda install getorganelle</span><br></pre></td></tr></table></figure>

<p><strong>下载参考序列库</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">get_organelle_config.py --add embplant_pt,embplant_mt</span><br><span class="line"><span class="comment">#embplant_pt(高等植物叶绿体)</span></span><br><span class="line"><span class="comment">#embplant_mt(高等植物线粒体)</span></span><br><span class="line"><span class="comment">#embplant_nr(高等植物核糖体 RNA)</span></span><br><span class="line"><span class="comment">#animal_mt (动物线粒体)</span></span><br><span class="line"><span class="comment">#fungus_mt (真菌线粒体)</span></span><br></pre></td></tr></table></figure>

<p>If connection keeps failing, please manually download the latest database from <a href="https://github.com/Kinggerm/GetOrganelleDB">GetOrganelleDB</a> and <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Initialization#option-2-initialization-from-local-files">initialization from local files</a>.</p>
<p>The database will be located at <code>~/.GetOrganelle</code> by default, which can be changed via the command line parameter <code>--config-dir</code>, or via the shell environment variable <code>GETORG_PATH</code> (see more <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Initialization">here</a>).</p>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-1 双端测序的R1</span><br><span class="line">-2 双端测序的R2</span><br><span class="line">-o 结果文件，结果输出保存的目录(文件夹)名称</span><br><span class="line">-F 数据库，设定要组装的基因组类型</span><br><span class="line">-s 参考序列</span><br><span class="line">-t 线程数</span><br><span class="line">-R 最大的一个扩充循环的数，一般默认15，提取基因 reads 的轮次(轮次越多,耗时越长)</span><br><span class="line">-k kmer的一个参数，调用SPAdes进行denovo组装的k-mer,数值必须是奇数, 最大值是127</span><br><span class="line">-w 提取叶绿体基因reads 时使用的长度比例或实际长度</span><br><span class="line"><span class="comment">#word-size：提取叶绿体基因reads 时，可以使用reads 长度的比例(ratio)，也可以设置实际长度的word-size。例如：如果使用ratio=0.6, 即 reads长度是150bp时，设置的word-size = 90bp，等同于设置 “-w 90”。</span></span><br></pre></td></tr></table></figure>

<h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p><strong>Starting from reads</strong></p>
<p>The <font color="green"><strong>green workflow</strong></font> in the flowchart  shows the processes of <code>get_organelle_from_reads.py</code>.</p>
<ul>
<li><p><strong>Input data</strong></p>
<p>Currently, <code>get_organelle_from_reads.py</code> was written for <strong>illumina pair-end/single-end data</strong> (fastq or fastq.gz). We recommend using <strong>adapter-trimmed</strong> raw reads without quality control. Usually, <strong>&gt;1G</strong> per end is enough for <strong>plastome</strong> for most normal angiosperm samples, and <strong>&gt;5G</strong> per end is enough for <strong>mitochondria</strong> genome assembly. Since v1.6.2, <code>get_organelle_from_reads.py</code> will <strong>automatically estimate the read data it needs</strong>, without user assignment nor data reducing (see flags <code>--reduce-reads-for-coverage</code> and <code>--max-reads</code>).</p>
</li>
<li><p><strong>Main Options</strong></p>
<ul>
<li><code>-w</code> The value word size, like the kmer in assembly, is crucial to the <strong>feasibility and efficiency</strong> of this process. The <strong>best word size changes upon data and will be affected</strong> by read length, read quality, base coverage, organ DNA percent and other factors. By default, GetOrganelle would <strong>automatically estimate a proper word siz</strong>e based on the data characters. Although the automatically-estimated word size value does not ensure the best performance nor the best result, <font color="green">you do not need to adjust this value</font> (<code>-w</code>) if a complete/circular organelle genome assembly is produced, because the circular result generated by GetOrganelle is highly consistent under different options and seeds. The automatically estimated word size may be screwy in some animal mitogenome data due to inaccurate coverage estimation, for which you fine-tune it instead.</li>
<li><code>-k</code> The best kmer(s) depend on a wide variety of factors too. Although more kmer values add the time consuming, you are recommended to use a wide range of kmers to benefit from the power of SPAdes. Empirically, you should include <strong>at least</strong> including <strong>one small</strong> kmer (e.g. <code>21</code>) and <strong>one large</strong> kmer (<code>105</code>) for a successful organelle genome assembly.</li>
<li><code>-s</code> GetOrganelle takes the seed (fasta format; if this was not provided, the default is <code>GetOrganelleLib/SeedDatabase/*.fasta</code>) as probe, the script would recruit target reads in successive rounds (extending process). <strong>The default seed works for most samples</strong>, but using a complete organelle genome sequence of a <strong>related species as the seed would help the assembly</strong> in many cases (e.g. degraded DNA samples, fastly-evolving in animal/fungal samples; see more <a href="https://github.com/Kinggerm/GetOrganelle/wiki/FAQ#how-to-assemble-a-target-organelle-genome-using-my-own-reference">here</a>).</li>
</ul>
</li>
<li><p><strong>Key Results</strong></p>
<p>The key output files include</p>
<ul>
<li><code>*.path_sequence.fasta</code>, each fasta file represents one type of genome structure</li>
<li><code>*.selected_graph.gfa</code>, the <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Terminology">organelle-only assembly graph</a></li>
<li><code>get_org.log.txt</code>, the log file</li>
<li><code>extended_K*.assembly_graph.fastg</code>, the raw assembly graph</li>
<li><code>extended_K*.assembly_graph.fastg.extend_embplant_pt-embplant_mt.fastg</code>, a simplified assembly graph</li>
<li><code>extended_K*.assembly_graph.fastg.extend_embplant_pt-embplant_mt.csv</code>, a tab-format contig label file for bandage visualization</li>
</ul>
<p>You may delete the files other than above if the resulting genome is complete (indicated in the log file and the name of the <code>*.fasta</code>). You are expected to obtain the complete organelle genome assembly for most animal/fungal mitogenomes and plant chloroplast genomes (see <a href="https://github.com/Kinggerm/GetOrganelle/wiki/FAQ#why-does-getorganelle-generate-a-circular-genome-for-embplant_nrfungus_nr">here for nuclear ribosomal DNAs</a>) with the recommended recipes.</p>
<p>If GetOrganelle <strong>failed</strong> to <strong>generate the complete circular genome</strong> (produce <code>*scaffolds*path_sequence.fasta</code>), please follow <a href="https://github.com/Kinggerm/GetOrganelle/wiki/FAQ#what-should-i-do-with-incomplete-resultbroken-assembly-graph">here</a> to <strong>adjust your parameters for a second run</strong>. You could also use the incomplete sequence to conduct downstream analysis.</p>
</li>
</ul>
<p>#植物2G左右数据，<strong>组装叶绿体基因组</strong>用</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -o plastome_output -R 15 -k 21,45,65,85,105 -F embplant_pt</span><br></pre></td></tr></table></figure>

<p>#更快的方法</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -o plastome_output --fast -k 21,65,105 -w 0.68 -F embplant_pt</span><br></pre></td></tr></table></figure>

<p>#组装<strong>植物线粒体基因组</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -o mitochondria_output -R 50 -k 21,45,65,85,105 -P 1000000 -F embplant_mt</span><br><span class="line"><span class="comment"># -P pre grouping value. default 20 0000</span></span><br><span class="line"><span class="comment"># 1. please use the 【FASTG file as the final output】 for downstream manual processing. until further updates, the FASTA output of plant mitochondria genome of numerous repeats may be error-prone</span></span><br><span class="line"><span class="comment"># 2. embplant_mt mode was not tested in the GetOrganelle paper due to the complexity of plant mitogenomes and the defects of short reads</span></span><br></pre></td></tr></table></figure>

<p>#组装<strong>植物核核糖体DNA</strong>片段</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -o nr_output -R 10 -k 35,85,115 -F embplant_nr</span><br></pre></td></tr></table></figure>

<p>#组装真菌线粒体</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -R 10 -k 21,45,65,85,105 -F fungus_mt -o fungus_mt_out</span><br></pre></td></tr></table></figure>

<p>#组装动物线粒体</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -R 10 -k 21,45,65,85,105 -F animal_mt -o animal_mt_out</span><br></pre></td></tr></table></figure>

<p>得到的文件有complete代表拼接成环。</p>
<p><strong>GetOrganelle –assembly 开始</strong></p>
<p>The <font color="blue"><strong>blue workflow</strong></font> in the chat shows the processes of <code>get_organelle_from_assembly.py</code>.</p>
<ul>
<li><p><strong>Input data &amp; Main Options</strong></p>
<ul>
<li><code>-g</code> The input must be a FASTG or GFA formatted assembly graph file.</li>
<li>If you input an assembly graph assembled from total DNA sequencing using third-party a de novo assembler (e.g. Velvet), the assembly graph may includes a great amount of non-target contigs. You may want to use <code>--min-depth</code> and <code>--max-depth</code> to greatly reduce the computational burden for target extraction.</li>
<li>If you input an <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Terminology">organelle-equivalent assembly graph</a> (e.g. manually curated and exported using Bandage), you may use <code>--no-slim</code>.</li>
</ul>
</li>
<li><p><strong>Key Results</strong></p>
<p>The key output files include</p>
<ul>
<li><code>*.path_sequence.fasta</code>, one fasta file represents one type of genome structure</li>
<li><code>*.selected_graph.gfa</code>, the <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Terminology">organelle-only assembly graph</a></li>
<li><code>get_org.log.txt</code>, the log file</li>
</ul>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">get_organelle_from_assembly.py -g assembly_graph.fastg -F embplant_pt -o output-plastome</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-g      SPAdes组装得到的FASTG的assembly graph</span><br><span class="line">-F      设定要组装的基因组类型</span><br><span class="line">-o      结果输出保存的目录(文件夹)名称</span><br><span class="line">--min-depth  剔除graph中depth低于阈值的contigs</span><br><span class="line">--max-depth    剔除graph中depth高于阈值的contigs</span><br><span class="line">--min-depth 10 和“--max-depth10000”这两条命令是备选的，具体的depth需要可以自行设定。</span><br></pre></td></tr></table></figure>

<p><strong>GetOrganelle –graph.gfa开始</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">gfa_to_fastg.py graph.gfa</span><br><span class="line">get_organelle_from_assembly.py -g graph.gfa.fastg -F embplant_pt -o output-plastome --no-slim</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-g     Bandage梳理后转换为fastg的graph*</span><br><span class="line">-F     设定要组装的基因组类群:embplant_pt(叶绿体),embplant_mt(线粒体)和embplant_nr(核糖体 RNA)</span><br><span class="line">-o     结果输出保存的目录(文件夹)名称</span><br></pre></td></tr></table></figure>

<blockquote>
<p>*，使用Bandage编辑后，可以“merge all possible nodes”，然后再输出的文件格式gfa图形文件，gfa文件可以用gfa_to_fastg.py做一下转换。虽然gfa也是图形文件，但是图形内容与fastg有差异些复杂图形会输出失败。</p>
</blockquote>
<h1 id="Chloroplast-Genome-Assembly"><a href="#Chloroplast-Genome-Assembly" class="headerlink" title="Chloroplast Genome Assembly**"></a>Chloroplast Genome Assembly**</h1>]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>【hifi mapping】【purge_dups】</title>
    <url>/blog/2022/03/18/2022-03-18-purgedups/</url>
    <content><![CDATA[<p>purge haplotigs and overlaps in an assembly based on read depth</p>
<span id="more"></span>

<p><a href="https://github.com/dfguan/purge_dups">https://github.com/dfguan/purge_dups</a></p>
<h1 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h1><p>purge_dups is designed to remove haplotigs and contig overlaps in a <em>de novo</em> assembly based on read depth.</p>
<p><img src="/blog/2022/03/18/2022-03-18-purgedups/1.png" alt="img"></p>
<p><code>purge_dups</code>根据read深度分析组装中haplotigs和overlaps。相对于<code>purge_haplotigs</code>，运行速度更快，而且<strong>自动确定阈值</strong>。</p>
<p><code>purge_dups</code>分为三个部分，<strong>第一部分</strong>是将序列<strong>回贴</strong>到基因组并分析<strong>覆盖度确定阈值</strong>，<strong>第二部分</strong>是将<strong>组装自我比对</strong>，<strong>第三部分</strong>是利用前两部分得到的信息<strong>鉴定</strong>原来序列中的<strong>haplotigs和overlaps</strong>.</p>
<h1 id="Directory-Structure"><a href="#Directory-Structure" class="headerlink" title="Directory Structure"></a>Directory Structure</h1><ul>
<li>scripts/pd_config.py: script to generate a configuration file used by run_purge_dups.py.</li>
<li>scripts/run_purge_dups.py: script to run the <strong>purge_dups pipeline</strong>.</li>
<li>scripts/run_busco: script to run busco, dependency: busco.</li>
<li>scripts/run_kcm: script to make k-mer comparison plot.</li>
<li>scripts/sub.sh: shell script to submit a <strong>farm</strong> job.</li>
<li>src: purge_dups source files.</li>
<li><font color="blue"><strong>src/split_fa</strong></font>: split fasta file by ‘N’s.</li>
<li><font color="blue"><strong>src/pbcstat</strong></font>: create <strong>read depth histogram and base-level read depth</strong> for an assembly based on <strong>pacbio</strong> data.</li>
<li><font color="blue"><strong>src/ngstat</strong></font>: create read depth histogram and base-level read detph for an assembly based on <strong>illumina</strong> data.</li>
<li><font color="blue"><strong>src/calcuts</strong></font>: <strong>calculate coverage cutoffs</strong>.</li>
<li><font color="blue"><strong>src/purge_dups</strong></font>: <strong>purge haplotigs and overlaps</strong> for an <strong>assembly</strong>.</li>
<li><font color="blue"><strong>src/get_seqs</strong></font>: <strong>obtain seqeuences after purging</strong>.</li>
<li>bin/* : all purge_dups excutables.</li>
</ul>
<h1 id="installation"><a href="#installation" class="headerlink" title="installation"></a>installation</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/dfguan/purge_dups.git</span><br><span class="line"><span class="built_in">cd</span> purge_dups/src &amp;&amp; make</span><br><span class="line"><span class="comment">#脚本在scripts目录，编译程序在bin目录</span></span><br></pre></td></tr></table></figure>

<h1 id="Pipeline-Guide"><a href="#Pipeline-Guide" class="headerlink" title="Pipeline Guide"></a>Pipeline Guide</h1><p>Given a primary assembly <em><strong>pri_asm</strong></em> and an alternative assembly <em><strong>hap_asm</strong></em> (<strong>optional</strong>, if you have one), follow the steps shown below to build your own purge_dups pipeline, steps with same number can be run simultaneously. Among all the steps, although <strong>step 5 is optional</strong>, we <strong>highly recommend</strong> our users to do so, because <strong>assemblers may produce overrepresented seqeuences</strong>. In such a case, The final <strong>step 5</strong> can be applied to <strong>remove those seqeuences</strong>.</p>
<h2 id="Step-1-Run-minimap2-to-align-pacbio-data-and-generate-paf-files-then-calculate-read-depth-histogram-and-base-level-read-depth-根据覆盖度计算分界点-cutoff"><a href="#Step-1-Run-minimap2-to-align-pacbio-data-and-generate-paf-files-then-calculate-read-depth-histogram-and-base-level-read-depth-根据覆盖度计算分界点-cutoff" class="headerlink" title="Step 1. Run minimap2 to align pacbio data and generate paf files, then calculate read depth histogram and base-level read depth. 根据覆盖度计算分界点(cutoff)"></a>Step 1. Run minimap2 to align pacbio data and generate paf files, then calculate read depth histogram and base-level read depth. 根据覆盖度计算分界点(cutoff)</h2><p>For PacBio CLR reads</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$pb_list</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	minimap2 -xmap-pb <span class="variable">$pri_asm</span> <span class="variable">$i</span> | gzip -c - &gt; <span class="variable">$i</span>.paf.gz</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">bin/pbcstat *.paf.gz (produces PB.base.cov and PB.stat files)</span><br><span class="line">bin/calcuts PB.stat &gt; cutoffs 2&gt;calcults.log</span><br></pre></td></tr></table></figure>

<p><strong>For PacBio CCS reads</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># gzip可以替换成pigz, 进行多线程压缩</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$pb_list</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	minimap2 -xasm20 <span class="variable">$pri_asm</span> <span class="variable">$i</span> | gzip -c - &gt; <span class="variable">$i</span>.paf.gz</span><br><span class="line"><span class="keyword">done</span><span class="comment"># 统计paf, 输出PB.base.cov和PB.stat文件</span></span><br><span class="line">bin/pbcstat *.paf.gz (produces PB.base.cov and PB.stat files)</span><br><span class="line">bin/calcuts PB.stat &gt; cutoffs 2&gt;calcults.log</span><br></pre></td></tr></table></figure>

<p><strong>Notice</strong> If you have a large genome, please set minimap2 <code>-I</code> option to ensure the genome can be indexed once, otherwise read depth can be wrong.</p>
<p>二代测序，用<code>bwa mem</code>进行比对，然后用<code>bin/ngscstat</code>统计bam覆盖度，然后用<code>bin/calcuts</code>计算分界点。</p>
<h2 id="Step-2-Split-an-assembly-and-do-a-self-self-alignment-Commands-are-following"><a href="#Step-2-Split-an-assembly-and-do-a-self-self-alignment-Commands-are-following" class="headerlink" title="Step 2. Split an assembly and do a self-self alignment. Commands are following:"></a>Step 2. Split an assembly and do a self-self alignment. Commands are following:</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#将assembly【从N处打断】，如果assembly中没有N就不打断，然后用minimap2进行contig自我比对。</span></span><br><span class="line"><span class="comment"># Split an assembly</span></span><br><span class="line">bin/split_fa <span class="variable">$pri_asm</span> &gt; <span class="variable">$pri_asm</span>.split</span><br><span class="line"><span class="comment"># do a self-self alignment</span></span><br><span class="line">minimap2 -xasm5 -DP <span class="variable">$pri_asm</span>.split <span class="variable">$pri_asm</span>.split | gzip -c - &gt; <span class="variable">$pri_asm</span>.split.self.paf.gz</span><br></pre></td></tr></table></figure>

<p>run step1&amp;step2 simultaneously</p>
<h2 id="Step-3-Purge-haplotigs-and-overlaps-with-the-following-command"><a href="#Step-3-Purge-haplotigs-and-overlaps-with-the-following-command" class="headerlink" title="Step 3. Purge haplotigs and overlaps with the following command."></a>Step 3. Purge haplotigs and overlaps with the following command.</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">根据每个碱基覆盖度以及组装自我比对结果对contig分类</span><br><span class="line"><span class="comment"># purge haplotigs and overlap</span></span><br><span class="line">bin/purge_dups -2 -T cutoffs -c PB.base.cov <span class="variable">$pri_asm</span>.split.self.paf.gz &gt; dups.bed 2&gt; purge_dups.log</span><br></pre></td></tr></table></figure>

<p>dups.bed<strong>第四列</strong>是每个<strong>contig的分类信息</strong>，分为**”JUNK”, “HIGHCOV”, “HAPLOTIG”, “PRIMARY”, “REPEAT”, “OVLP”** 6类，<code>purge_dups</code>可以先以默认参数运行，如果结果不理想，可以调整如下参数</p>
<ul>
<li><code>-f</code>默认是.8, 根据80%区域的覆盖度来对contig进行分类。例如80%的区域都低于5x，将该序列定义为JUNK。对应源码中的<code>classify_seq</code>函数的<code>min_frac</code>参数</li>
<li><code>-a</code>和<code>-b</code>过滤alignment, 对于源码中的<code>flt_by_bm_mm</code>的<code>min_bmf</code>和<code>min_mmf</code>参数</li>
<li><code>-m</code>表示将两个联配衔接时，最低的匹配碱基数</li>
<li><code>-M</code>和<code>-G</code>:分别表示第一轮和第二轮将前后两个联配衔接时最大空缺大小</li>
<li><code>-E</code>表示 如果合并之后的alignment在contig末尾的前15k内，那么就把alignment延伸至contig末尾</li>
<li><code>-l</code>: 用于控制overlap的大小，该值越小，overlap越多</li>
</ul>
<h2 id="Step-4-Get-purged-primary-and-haplotig-sequences-from-draft-assembly"><a href="#Step-4-Get-purged-primary-and-haplotig-sequences-from-draft-assembly" class="headerlink" title="Step 4. Get purged primary and haplotig sequences from draft assembly."></a>Step 4. Get purged primary and haplotig sequences from draft assembly.</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">bin/get_seqs -e dups.bed <span class="variable">$pri_asm</span> </span><br><span class="line"><span class="comment"># If you also want to remove the duplications in the middle, please remove 【`-e`】 option at your own risk, it may delete false positive duplications. For more options, please refer to `get_seqs -h`.</span></span><br></pre></td></tr></table></figure>

<p>这里的purged.fa就是最终结果，junk, haplotig和duplication都会在hap.fa中。</p>
<p>可选步骤: 将<strong>alternative assembly和输出hap.fa进行合并</strong>，然后运行上面四步，得到的<strong>purge.fa就是新的alternative assembly</strong>，而<strong>再次输出的hap.fa则是junk或overrepresented序列</strong>。</p>
<p>PS: 能不能用来过滤纯合基因组组装的垃圾序列呢？根据物种测试，过滤前后的BUSCO值，几乎没有变化，missing rate只提高了0.1%，</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 运行前</span></span><br><span class="line">C:98.8%[S:96.3%,D:2.5%],F:0.5%,M:0.7%,n:1375</span><br><span class="line"><span class="comment"># 运行后</span></span><br><span class="line">C:98.7%[S:96.3%,D:2.4%],F:0.5%,M:0.8%,n:1375</span><br></pre></td></tr></table></figure>

<p>用法可行，且Canu的作者建议用<code>purge_dups</code>处理，参考<a href="https://links.jianshu.com/go?to=https://github.com/marbl/canu/issues/1717%23issuecomment-629644894">canu-issues-1717</a>。</p>
<p>作者尚未在ONT和Illumina数据中测试软件，但是作者认为只需要修改<code>minimap2</code>的<code>-x map-pb</code>为<code>-x map-ont</code>就可以用在ONT数据上。</p>
<p><strong>Notice</strong> this command will only remove haplotypic duplications at the ends of the contigs. If you also want to remove the duplications in the middle, please remove <code>-e</code> option at your own risk, it may delete false positive duplications. For more options, please refer to <code>get_seqs -h</code>.</p>
<h2 id="Step-5-Merge-hap-fa-and-hap-asm-and-redo-the-above-steps-to-get-a-decent-haplotig-set"><a href="#Step-5-Merge-hap-fa-and-hap-asm-and-redo-the-above-steps-to-get-a-decent-haplotig-set" class="headerlink" title="Step 5. Merge hap.fa and $hap_asm and redo the above steps to get a decent haplotig set."></a>Step 5. Merge hap.fa and $hap_asm and redo the above steps to get a decent haplotig set.</h2><h1 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h1><ul>
<li>Read depth cutoffs calculation: the coverage cutoffs can be larger for a low heterozygosity species, which causes the purged assembly size smaller than expected. In such a case, please use script/hist_plot.py to make the histogram plot and set coverage cutoffs manually.</li>
<li>Repeats: purge_dups has a limited ability to process repeats.</li>
</ul>
<h1 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h1><p><strong>Q:</strong> Can I use purge_dups with <strong>short reads</strong>?</p>
<p><strong>A:</strong> Yes, purge_dups does have a program to process Illumina reads, it’s called <strong>ngscstat</strong> under the bin directory. But I have not got time to test it. If you want to play with it, please follow this workflow:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bwa mem $pri_asm $sr_1.fq $sr_2.fq | samtools view -b -o - &gt; $sr.bam </span><br><span class="line">ngscstat $sr.bam... # The program will generate two/three outputs, TX.stat and TX.base.cov which functions the same way as PB.stat and PB.base.cov respectively.  </span><br></pre></td></tr></table></figure>

<p>After you get the TX.stat and TX.base.cov file, you can following the normal purge_dups routine to clean your assembly.</p>
<p><strong>Q1:</strong> Can I validate the cutoffs used by purge_dups?</p>
<p><strong>A1:</strong> Yes, we also recommend this step. A script “hist_plot.py” under the scripts directory is available, you can also use it to manually select the cutoffs.</p>
<p><strong>Q2:</strong> How can I <strong>validate the purged assembly?</strong> Is it clean enough or overpurged?</p>
<p><strong>A2:</strong> There are many ways to validate the purged assembly. One way is to make a coverage plot for it which can also be <strong>hist_plot.py</strong>, the 2nd way is to run <strong>BUSCO</strong> and another way is to make a KAT plot with KAT (<a href="https://github.com/TGAC/KAT">https://github.com/TGAC/KAT</a>) or KMC (<a href="https://github.com/dfguan/KMC">https://github.com/dfguan/KMC</a>, use this if you only have a small memory machine) if short reads or some accurate reads are available.</p>
<p><strong>Q3:</strong> Why do I get <strong>much fewer haplotypic duplications</strong> than expected?</p>
<p><strong>A3:</strong> First check the original contig names, they should not contain any colons. Then check the cutoffs, if purge_dups automatically use <strong>a fairly low read depth for haplotypic duplications</strong>, it may <strong>remove nothing</strong>. In this case, you <strong>need to set the cutoffs manually.</strong></p>
<p><strong>Q4:</strong> why does purge_dups remove <strong>middle sequence in a contig?</strong></p>
<p><strong>A4:</strong> <strong>Some of them are real, while others may not</strong>. We are currently investigating them. Please use <code>-e</code> for <code>get_seqs</code> command if you <strong>only want to remove the duplications at the ends of the contigs.</strong></p>
<hr>
<p>Ref:<a href="https://www.jianshu.com/p/e218a1192d12">https://www.jianshu.com/p/e218a1192d12</a></p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>【Hi-C】【Juicebox】</title>
    <url>/blog/2022/03/17/2022-03-17-juicebox/</url>
    <content><![CDATA[<p>Juicerbox guidline</p>
<span id="more"></span>

<ul>
<li><p>通过<code>File</code>-&gt;<code>open</code>导入后缀为<code>hic</code>的文件查看，可导入本地的文件，也可输入url。软件内置ENCODE的数据集</p>
</li>
<li><p>自动展示所有染色体的HI-C图谱，通过工具栏<font color="blue"><strong>选择染色质</strong></font>，<font color="blue"><strong>调整分辨率</strong></font>，对交互矩阵<font color="blue"><strong>归一化</strong></font>，调整显示的染色质区域。以17号染色质体为例，在<code>Chromosomes</code>一栏中，两列都选择17号染色体，代表交互矩阵的行和列都是17号染色体，然后点击刷新，结果如下</p>
</li>
</ul>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/1.png" alt="img"></p>
<ul>
<li>通过<font color="blue"><strong>Normalization</strong></font>工具调整归一化方法(推荐banlanced？)；通过<font color="blue"><strong>Resolution</strong></font>工具调整分辨率；通过<font color="blue"><strong>Goto</strong></font>工具调整显示的染色体区域。</li>
<li>通过简单操作就可查看和展示Hi-C图谱，除基本功能外，还支持导入<font color="blue">注释文件</font>，通过<code>View</code>-&gt;<font color="blue">Show Annotation Panel</font>可打开注释文件面板，注释信息分<strong>1D和2D</strong>两种，1D主要指chip_seq,RNA_seq等信息，2D指TAD,染色质环等信息，通过<code>Load ENCODE</code>以导入ENCODE<a href="https://cloud.tencent.com/solution/database?from=10680">数据库</a>中的一维注释，示意如下</li>
</ul>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/2.png" alt="img"></p>
<ul>
<li>勾选需要导入的注释信息，通过Load导入</li>
</ul>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/3.png" alt="img"></p>
<ul>
<li>每个导入的track的颜色等配置可在面板中调整</li>
</ul>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/4.png" alt="img"></p>
<ul>
<li>通过<code>Load Loops/Domain</code>可导入2D的注释信息</li>
</ul>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/5.png" alt="img"></p>
<ul>
<li>导入后在Hi-C图谱中看到对应的标记</li>
</ul>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/6.png" alt="img"></p>
<p>黄色区域标记的是TAD, 浅蓝色区域标记的是染色质环，调整好之后的图片也可以导出成PDF或者SVG格式。</p>
<ul>
<li>导入asm后蓝色区分假染色体，绿色区分scaffold</li>
<li>按住shift选中contig</li>
<li>绿色不能太碎</li>
</ul>
<p><strong>操作：</strong></p>
<ul>
<li><p>所有纠错操作都基于shift键</p>
</li>
<li><p>操作不熟练，你可能需要反复undo和redo（右键）</p>
</li>
<li><p>选框时，你只要在本框范围内拖动（按shift不要松），都会选中这个框（选中后为带黑黄色的线），并不要很精确地选在框边缘（因为你把握不好，有可能这个边缘是另一个框的范围，这时就会选错）</p>
</li>
<li><p>选择框时，尽可能放大（双击，或菜单栏BP，一般25kb-50kb）</p>
</li>
<li><p>如果你的染色体数目不对。拆分染色体：先选中要拆分区域，右击add染色体，再选中，右击remove染色体</p>
</li>
</ul>
<ul>
<li>从某一个地方剪掉框：选中，出现剪刀符号，单击</li>
<li>旋转框：选中，出现旋转符号，单击</li>
<li>从一个地方移动：选中，鼠标移到要插入的contig框顶点，单击</li>
</ul>
<p>Juice_box调图是个细致的体力活。一想到我的基因组是这么人为调出来的，我自己对结果都产生了怀疑。如果是3D-DNA，再简单的基因组也还是会有很多碎的，因为它手贱重新打碎了。所以说如果你原始组装的contig数目比3d-dna跑出的FINAL.fasta中的contig数目少，甚至比手工纠错后再跑3D-DNA的数目少，也不要感到惊讶。反正我是越纠越差，基因组越来越小。可能是我不会调细节吧，再次吐槽，这个软件我是真的讨厌。</p>
<hr>
<p>ref <a href="https://www.jianshu.com/p/4483eece598d">https://www.jianshu.com/p/4483eece598d</a></p>
<p>注意事项：</p>
<ol>
<li>Juicebox的编辑功能在导入了assembly文件后放大scaffold块，放大到足够大的时候才能出现编辑的剪刀，进行分割染色体区域</li>
<li>如果要去掉某些散在区块中的空白区域则需要放大到足够大后，用shift+左键选中空白的区域进行剪切去掉</li>
<li>这些需要剪切的空白区域其实是表明这些contig和谁都没有关联，会在1-3.hic的步骤中被去除，相应的最终的.hic文件得到的hic组装结果能挂载到的基因会减少</li>
</ol>
<ul>
<li><strong>但是如果0.hic的结果太差，可以试用3.hic的结果，也许会更好，有提升功能，如果挂载的基因不太少的话，会很好</strong></li>
</ul>
<ol start="4">
<li>hic的最终assembly是（rawchrom.assembly）</li>
</ol>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="number">00</span><span class="selector-class">.nextpolish</span><span class="selector-class">.final</span><span class="selector-class">.assembly</span> -&gt; <span class="number">00</span><span class="selector-class">.nextpolish</span><span class="selector-class">.rawchrom</span><span class="selector-class">.assembly</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>通常来讲，用0.hic对应的结果去进行染色体区块编辑后再进行染色体水平的基因组组装<code>run-asm-pipeline-post-review.sh</code>，得到fasta的文件，然后再通过已经注释的contig版本的基因组基因的坐标信息，对应上染色体水平的基因组基因信息</li>
</ol>
<p>？关于ALLHiC组装，可以用3d-dna得到的最终基因组fasta结果再用ALLHiC进行组装，相当于基因组已经经过了3d-dna的纠错，得到的可能是更加准确的包含N的基因组序列，再经过ALLHiC进行打断去除N，得到更好的结果</p>
<hr>
<p><a href="https://www.bilibili.com/video/BV1ph411X7wj">https://www.bilibili.com/video/BV1ph411X7wj</a></p>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/7.png" alt="img"></p>
<p><strong>1. 挂载率</strong></p>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/8.png" alt="img"></p>
<p><strong>2. 基因组草图中组装错误太多</strong></p>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/9.png" alt="img"></p>
<p><strong>3. 样本杂质污染</strong></p>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/10.png" alt="img"></p>
<p><strong>4. 高杂合基因组</strong></p>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/11.png" alt="img"></p>
<p>HiC组装后续</p>
<p><img src="/blog/2022/03/17/2022-03-17-juicebox/12.png" alt="img"></p>
<p>两个contig之间可能是由500个N连接，hic关系决定</p>
<blockquote>
<p>Q: 3D-DNA 后的结果文件可继续用于ALLHiC</p>
</blockquote>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>【Hi-C】【Lachesis原理】</title>
    <url>/blog/2022/03/17/2022-03-17-LACHESIS/</url>
    <content><![CDATA[<p>Lachesis</p>
<span id="more"></span>

<p><a href="https://www.plob.org/article/24852.html">https://www.plob.org/article/24852.html</a></p>
<p><strong>染色体疆域</strong></p>
<p>染色质在细胞核内分布的并不是随机分布的，而是不同染色体占据不同的空间。</p>
<p><img src="/blog/2022/03/17/2022-03-17-LACHESIS/1.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p>
<p><strong>Hi-C实验原理</strong></p>
<p><img src="/blog/2022/03/17/2022-03-17-LACHESIS/2.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p>
<p><strong>基因组互作衰减</strong></p>
<p>染色体内互作强度较强，但也随着空间距离的增大互作强度在衰减。互作三定律</p>
<ul>
<li>1.<strong>染色体内互作富集</strong>（Intrachromosomal interaction enrichment）</li>
<li>2.<strong>互作随距离衰减</strong>（distance-dependent interaction decay）</li>
<li>3.<strong>局部互作平滑</strong>（local interaction smoothness）</li>
</ul>
<p><strong>Hic 优势</strong></p>
<ul>
<li>通过Scaffold间的交互频率大小，可以对已组装的基因组序列进行纠错。</li>
<li>基因信息不再仅仅是contig片段，而是被划分至染色体上，成为染色体水平。</li>
<li>无需辛苦的构建群体，单一一个体就能实现染色体定位。</li>
<li>相比遗传图谱，标记密度更大，序列定位更完整。</li>
<li>可以开展染色体重排等结构变异研究。</li>
<li>QTL、GWAS可以定位区间到某个染色体。</li>
<li>可以解析该物种的三维基因结构、染色体互作及动态变化。</li>
</ul>
<p><strong>HiC辅助组装</strong></p>
<p>将contigs组装到<strong>假染色体</strong>层面，实现基因组组装到染色体层面</p>
<p><strong>Lachesis辅助组装步骤</strong></p>
<ul>
<li>**Cluster(聚类)**。因为染色质内的互 作强度要高于染色质间的互作强度，所 以先对contig/scaffold进行聚类成染色体群。</li>
<li>**Order(排序)**。确定每个染色体群中contig/scaffold的顺序</li>
<li>**Orient(定向)**。确定每个 contig/scaffold的方向三个步骤按照互作强度依次</li>
</ul>
<p><img src="/blog/2022/03/17/2022-03-17-LACHESIS/3.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p>
<p><strong>cluster聚类原理</strong></p>
<p><img src="/blog/2022/03/17/2022-03-17-LACHESIS/4.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p>
<p><strong>order排序原理</strong></p>
<p><img src="/blog/2022/03/17/2022-03-17-LACHESIS/5.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p>
<p><strong>orient定向原理</strong></p>
<p><img src="/blog/2022/03/17/2022-03-17-LACHESIS/6.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>【Hi-C】【3D-DNA】</title>
    <url>/blog/2022/03/17/2022-03-17-3D-DNA/</url>
    <content><![CDATA[<p>二倍体物种目前3D-DNA应该是组装效果比较好的软件。ALL-HiC对多倍体效果很好</p>
<span id="more"></span>

<h1 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h1><p>组装，Juicer分析Hi-C数据，3D-DNA scaffolding，JBAT 对组装结果手工纠正，最终得到准染色体水平基因组。</p>
<p><img src="/blog/2022/03/17/2022-03-17-3D-DNA/1.png" alt="img"></p>
<p><strong>CPU-version juicer installation</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir ~/soft</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/theaidenlab/juicer.git</span><br><span class="line"><span class="built_in">cd</span> juicer</span><br><span class="line">ln -s CPU scripts</span><br><span class="line"><span class="built_in">cd</span> scripts/common</span><br><span class="line">wget https://hicfiles.tc4ga.com/public/juicer/juicer_tools.1.9.9_jcuda.0.8.jar</span><br><span class="line">ln -s juicer_tools.1.9.9_jcuda.0.8.jar  juicer_tools.jar</span><br></pre></td></tr></table></figure>

<p>aligned目录，其中”merged_nodups.txt”是下一步3D-DNA的输入文件之一。</p>
<p><strong>3D-DNA installation</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/soft</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/theaidenlab/3d-dna.git</span><br></pre></td></tr></table></figure>

<hr>
<p>如果基因组<strong>不是复杂基因组</strong>，比如说高杂合，高重复序列，或者Hi-C数据测太少，那么3d-dna的流程更加简单, run-asm-pipeline.sh -h只有<font color="blue"><strong>四个参数需要改</strong></font>:</p>
<ul>
<li>-i|–input: 过滤长度低于给定阈值的contig/scaffold, <strong>默认是15000</strong></li>
<li>-r|–round: 基因组中misjoin的<strong>纠错轮数</strong>，<strong>默认是2</strong>，当基因组<strong>比较准确</strong>，设置为<strong>0</strong>，然后在JABT中调整会更好</li>
<li>-m|–mode: 是否调用merge模块，<strong>当且仅当在杂合度比较高的情况下使用</strong>，也就是组装结果的单倍型基因组明显偏大（和预期estimated 比较）</li>
<li>-s|–stage: 从polish, split, seal, merge 或finalize 的某一个阶段开始</li>
</ul>
<hr>
<p><strong>基因组复杂</strong>，需要调整参数非常多, run-asm-pipeline.sh –help会输出更多的信息，你需要根据当前结果去确定每个阶段的参数应该如何调整。<br>最终的输出文件最关键的是下面三类:</p>
<ul>
<li>.fasta: 以<strong>FINAL标记的是最终结果</strong></li>
<li>.hic: <strong>各个阶段</strong>都会有输出结果，用于在JABT中展示</li>
<li>.assembly: <strong>各个阶段</strong>都会有输出，一共两列，存放contig的组装顺序</li>
</ul>
<hr>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>Juicer的输出结果到3D-DNA，分析流程见下图。3D-DNA先根据Hi-C数据分析contig中的<strong>misjoin</strong>，对其进行纠错。之后通过四步,分别是Polish, Split, Seal和Merge, 得到最终的基因组序列</p>
<p><img src="/blog/2022/03/17/2022-03-17-3D-DNA/2.png" alt="3d-dna流程"></p>
<h1 id="使用juicerbox手工纠错"><a href="#使用juicerbox手工纠错" class="headerlink" title="使用juicerbox手工纠错"></a>使用juicerbox手工纠错</h1><p>关于juicerbox的用法，可以看hoptop的<a href="https://links.jianshu.com/go?to=https://www.bilibili.com/video/av65134634">https://www.bilibili.com/video/av65134634</a><br>最常见的几种组装错误:</p>
<ul>
<li>misjoin: 切割</li>
<li>translocations: 移动</li>
<li>inversions: 翻转</li>
<li>chromosome boundaries: 确定染色体的边界</li>
</ul>
<p>这些错误的判断依赖于经验，所以只能靠自己多试试了。<br>最后输出genome.review.assembly用于下一步的分析</p>
<h1 id="再次运行3d-dna"><a href="#再次运行3d-dna" class="headerlink" title="再次运行3d-dna"></a>再次运行3d-dna</h1><p>根据JABT手工纠正的结果, genome.review.assembly, 使用run-asm-pipeline-post-review.sh重新组装基因组。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">~/soft/<span class="number">3</span>d-dna/run-<span class="keyword">asm</span>-pipeline-post-review.sh \</span><br><span class="line">    -r genome.review.assembly genome.fa aligned/merged_nodups.txt &amp;&gt; <span class="number">3</span>d.log &amp;</span><br></pre></td></tr></table></figure>

<h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>juicer代码至少以下几个地方都需要改：</p>
<p>临时文件不及时删除<br>bwa得到的SAM文件处理方式有待优化，使用BAM能更快的并行计算<br>参数命令判断很差，用-z判断字符串是否为0，而不是用-f或-d去判断文件是否存在<br>Linux的sort支持多线程，但是没看到用<br>脚本中有些限速步骤的awk代码，不算高效<br>前两条导致了运行过程占用大量硬盘，所以<strong>不准备2T左右的硬盘，很容易出错</strong>。第三条是一些报错不会及时停止运算，也不容易排查。估计公司从效率角度出发，应该是写了很多脚本来替换原来的awk脚本</p>
<p>另外，juicer在多倍体物种表现很差，建议使用ALLHiC</p>
<hr>
<p>ref：<a href="https://blog.csdn.net/u012110870/article/details/115511969">https://blog.csdn.net/u012110870/article/details/115511969</a></p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>【Hi-C】【Juicer】</title>
    <url>/blog/2022/03/16/2022-03-16-juicer/</url>
    <content><![CDATA[<p>Juicer is a platform for analyzing kilobase resolution Hi-C data. In this distribution, we include the pipeline for <strong>generating Hi-C maps from fastq raw data</strong> files and <strong>command line tools for feature annotation on the Hi-C maps</strong>.</p>
<span id="more"></span>


<p><a href="https://github.com/aidenlab/juicer">https://github.com/aidenlab/juicer</a></p>
<h1 id="Read-this-first"><a href="#Read-this-first" class="headerlink" title="Read this first!!"></a>Read this first!!</h1><p>To access Juicer 1.6 (last <strong>stable</strong> release), please see <a href="https://github.com/aidenlab/juicer/releases/tag/1.6">the Github Release</a>. If you clone the Juicer repo directly from Github, it will clone Juicer 2, which is under active development. If you encounter any bugs, please let us know.</p>
<h1 id="About-Juicer"><a href="#About-Juicer" class="headerlink" title="About Juicer"></a>About Juicer</h1><p>Juicer is a platform for analyzing kilobase resolution Hi-C data. In this distribution, we include the pipeline for <strong>generating Hi-C maps from fastq raw data files</strong> and <strong>command line tools for feature annotation on the Hi-C maps</strong>.</p>
<p><strong>If you use Juicer in your research, please cite: Neva C. Durand, Muhammad S. Shamim, Ido Machol, Suhas S. P. Rao, Miriam H. Huntley, Eric S. Lander, and Erez Lieberman Aiden. “Juicer provides a one-click system for analyzing loop-resolution Hi-C experiments.” Cell Systems 3(1), 2016.</strong></p>
<h1 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h1><p>Please see <a href="https://github.com/aidenlab/juicer/wiki">the wiki</a> for extensive documentation.</p>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions?"></a>Questions?</h1><p>For FAQs, or for asking new questions, please see our forum: <a href="http://aidenlab.org/forum.html">aidenlab.org/forum.html</a>.</p>
<hr>
<h2 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h2><p>In this repository, we include the scripts for running Juicer on AWS, LSF, Univa Grid Engine, SLURM, and a single CPU</p>
<p>/AWS - scripts for running pipeline and postprocessing on AWS</p>
<p>/UGER - scripts for running pipeline and postprocessing on UGER (Univa)</p>
<p>/SLURM - scripts for running pipeline and postprocessing on SLURM</p>
<p>/LSF - scripts for running pipeline and postprocessing on LSF <strong>BETA</strong></p>
<p>/CPU - scripts for running pipeline and postprocessing on a single CPU <strong>BETA</strong></p>
<p>/misc - miscellaneous helpful scripts</p>
<hr>
<h2 id="Hardware-and-Software-Requirements"><a href="#Hardware-and-Software-Requirements" class="headerlink" title="Hardware and Software Requirements"></a>Hardware and Software Requirements</h2><p>Juicer is a pipeline optimized for parallel computation on a cluster. Juicer consists of two parts: <strong>the pipeline that creates Hi-C files from raw data</strong>, and <strong>the post-processing command line tools</strong>.</p>
<h3 id="Cluster-requirements"><a href="#Cluster-requirements" class="headerlink" title="Cluster requirements:"></a>Cluster requirements:</h3><p>Juicer requires the use of a cluster, with <strong>ideally &gt;= 4 cores</strong> (min 1 core) and <strong>&gt;= 64 GB RAM</strong> (min 16 GB RAM)</p>
<p>Juicer currently works with the following resource management software:</p>
<ul>
<li><a href="http://www.openlava.org/">OpenLava</a></li>
<li><a href="https://www.ibm.com/systems/spectrum-computing/products/lsf">LSF</a></li>
<li><a href="https://slurm.schedmd.com/download.html">SLURM</a></li>
<li>GridEngine (Univa, etc. any flavor)</li>
</ul>
<h3 id="Juicer-tools-requirements"><a href="#Juicer-tools-requirements" class="headerlink" title="Juicer tools requirements"></a>Juicer tools requirements</h3><p>The minimum software requirement to run Juicer is a working Java installation (version &gt;= 1.8) on Windows, Linux, and Mac OSX. We recommend using the latest Java version available, but please do not use the Java Beta Version. Minimum system requirements for running Java can be found at<a href="https://java.com/en/download/help/sysreq.xml">https://java.com/en/download/help/sysreq.xml</a></p>
<p>To download and install the latest Java Runtime Environment (JRE), please go to <a href="https://www.java.com/download">https://www.java.com/download</a></p>
<h3 id="GNU-CoreUtils"><a href="#GNU-CoreUtils" class="headerlink" title="GNU CoreUtils"></a>GNU CoreUtils</h3><p>The latest version of GNU coreutils can be downloaded from <a href="https://www.gnu.org/software/coreutils/manual/">https://www.gnu.org/software/coreutils/manual/</a></p>
<h3 id="Burrows-Wheeler-Aligner-BWA"><a href="#Burrows-Wheeler-Aligner-BWA" class="headerlink" title="Burrows-Wheeler Aligner (BWA)"></a>Burrows-Wheeler Aligner (BWA)</h3><p>The <strong>latest version of BWA</strong> should be installed from <a href="http://bio-bwa.sourceforge.net/">http://bio-bwa.sourceforge.net/</a></p>
<h3 id="CUDA-for-HiCCUPS-peak-calling"><a href="#CUDA-for-HiCCUPS-peak-calling" class="headerlink" title="CUDA (for HiCCUPS peak calling)"></a>CUDA (for HiCCUPS peak calling)</h3><p>You must have an NVIDIA GPU to install CUDA.</p>
<p>Instructions for installing the latest version of CUDA can be found on the <a href="https://developer.nvidia.com/cuda-downloads">NVIDIA Developer site</a>.</p>
<p>The native libraries included with Juicer are compiled for CUDA 7 or CUDA 7.5. See the <a href="https://github.com/theaidenlab/juicer/wiki/Download">download page for Juicer Tools</a>.</p>
<p>Other versions of CUDA can be used, but you will need to download the respective native libraries from <a href="http://www.jcuda.org/downloads/downloads.html">JCuda</a>.</p>
<p>For best performance, use a dedicated GPU. You may also be able to obtain access to GPU clusters through Amazon Web Services or a local research institution.</p>
<p>If you cannot access a GPU, you can run the <a href="https://github.com/aidenlab/juicer/wiki/CPU-HiCCUPS">CPU version of HiCCUPS</a> directly using the <code>.hic</code> file and Juicer Tools.</p>
<h3 id="Building-new-jars"><a href="#Building-new-jars" class="headerlink" title="Building new jars"></a>Building new jars</h3><p>See the Juicebox documentation at <a href="https://github.com/theaidenlab/Juicebox">https://github.com/theaidenlab/Juicebox</a> for details on building new jars of the juicer_tools.</p>
<hr>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a><font color="red">Quick Start</font></h2><p>Run the Juicer pipeline on your cluster of choice with “juicer.sh [options]”</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Usage: juicer.sh [-g genomeID] [-d topDir] [-q queue] [-l long queue] [-s site]</span><br><span class="line">                 [-a about] [-R end] [-S stage] [-p chrom.sizes path]</span><br><span class="line">                 [-y restriction site file] [-z reference genome file]</span><br><span class="line">                 [-C chunk size] [-D Juicer scripts directory]</span><br><span class="line">                 [-Q queue time <span class="built_in">limit</span>] [-L long queue time <span class="built_in">limit</span>] [-e] [-h] [-x]</span><br><span class="line">* [-g genomeID] must be defined <span class="keyword">in</span> the script, e.g. <span class="string">&quot;hg19&quot;</span> or <span class="string">&quot;mm10&quot;</span> (default</span><br><span class="line">  <span class="string">&quot;hg19&quot;</span>); alternatively, it can be defined using the -z <span class="built_in">command</span></span><br><span class="line">* [<span class="string">&#x27;-d topDir&#x27;</span>] is the top level directory (default</span><br><span class="line">  <span class="string">&quot;/Users/nchernia/Downloads/neva-muck/UGER&quot;</span>)</span><br><span class="line">     [topDir]/fastq must contain the fastq files</span><br><span class="line">     [topDir]/splits will be created to contain the temporary split files</span><br><span class="line">     [topDir]/aligned will be created <span class="keyword">for</span> the final alignment</span><br><span class="line">* [-q queue] is the queue <span class="keyword">for</span> running alignments (default <span class="string">&quot;short&quot;</span>)</span><br><span class="line">* [-l long queue] is the queue <span class="keyword">for</span> running longer <span class="built_in">jobs</span> such as the hic file</span><br><span class="line">  creation (default <span class="string">&quot;long&quot;</span>)</span><br><span class="line">* [site] must be defined <span class="keyword">in</span> the script, e.g.  <span class="string">&quot;HindIII&quot;</span> or <span class="string">&quot;MboI&quot;</span></span><br><span class="line">  (default <span class="string">&quot;none&quot;</span>)</span><br><span class="line">* [about]: enter description of experiment, enclosed <span class="keyword">in</span> single quotes</span><br><span class="line">* [stage]: must be one of <span class="string">&quot;chimeric&quot;</span>, <span class="string">&quot;merge&quot;</span>, <span class="string">&quot;dedup&quot;</span>, <span class="string">&quot;final&quot;</span>, <span class="string">&quot;postproc&quot;</span>, or <span class="string">&quot;early&quot;</span>.</span><br><span class="line">    -Use <span class="string">&quot;chimeric&quot;</span> when alignments are <span class="keyword">done</span> but chimeric handling has not finished</span><br><span class="line">    -Use <span class="string">&quot;merge&quot;</span> when alignment has finished but the merged_sort file has not</span><br><span class="line">     yet been created.</span><br><span class="line">    -Use <span class="string">&quot;dedup&quot;</span> when the files have been merged into merged_sort but</span><br><span class="line">     merged_nodups has not yet been created.</span><br><span class="line">    -Use <span class="string">&quot;final&quot;</span> when the reads have been deduped into merged_nodups but the</span><br><span class="line">     final stats and hic files have not yet been created.</span><br><span class="line">    -Use <span class="string">&quot;postproc&quot;</span> when the hic files have been created and only</span><br><span class="line">     postprocessing feature annotation remains to be completed.</span><br><span class="line">    -Use <span class="string">&quot;early&quot;</span> <span class="keyword">for</span> an early <span class="built_in">exit</span>, before the final creation of the stats and</span><br><span class="line">     hic files</span><br><span class="line">* [<span class="string">&#x27;chrom.sizes path&#x27;</span>]: enter path <span class="keyword">for</span> chrom.sizes file</span><br><span class="line">* [<span class="string">&#x27;restriction site file&#x27;</span>]: enter path <span class="keyword">for</span> restriction site file (locations of</span><br><span class="line">  restriction sites <span class="keyword">in</span> genome; can be generated with the script</span><br><span class="line">  (misc/generate_site_positions.py) )</span><br><span class="line">* [<span class="string">&#x27;reference genome file&#x27;</span>]: enter path <span class="keyword">for</span> reference sequence file, BWA index</span><br><span class="line">  files must be <span class="keyword">in</span> same directory</span><br><span class="line">* [chunk size]: number of lines <span class="keyword">in</span> split files, must be multiple of 4</span><br><span class="line">  (default 90000000, <span class="built_in">which</span> equals 22.5 million reads)</span><br><span class="line">* [<span class="string">&#x27;Juicer scripts directory&#x27;</span>]: <span class="built_in">set</span> the Juicer directory,</span><br><span class="line">  <span class="built_in">which</span> should have scripts/ references/ and restriction_sites/ underneath it</span><br><span class="line">  (default /broad/aidenlab)</span><br><span class="line">* [queue time <span class="built_in">limit</span>]: time <span class="built_in">limit</span> <span class="keyword">for</span> queue, i.e. -W 12:00 is 12 hours</span><br><span class="line">  (default 1200)</span><br><span class="line">* [long queue time <span class="built_in">limit</span>]: time <span class="built_in">limit</span> <span class="keyword">for</span> long queue, i.e. -W 168:00 is one week</span><br><span class="line">  (default 3600)</span><br><span class="line">* -f: include fragment-delimited maps from hic file creation</span><br><span class="line">* -e: early <span class="built_in">exit</span></span><br><span class="line">* -h: <span class="built_in">print</span> this <span class="built_in">help</span> and <span class="built_in">exit</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Juicer-Usage"><a href="#Juicer-Usage" class="headerlink" title="Juicer Usage"></a>Juicer Usage</h2><ul>
<li><strong>Running Juicer with no arguments</strong> will run it with genomeID hg19 and site MboI</li>
<li><strong>Providing a genome ID</strong>: if not defined in the script, you can either directly modify the script or provide the script with the files needed. You would provide the script with the files needed via “-z reference_sequence_path” (needs to have the BWA index files in same directory), “-p chrom_sizes_path” (these are the chromosomes you want included in .hic file), and “-s site_file” (this is the listing of all the restriction site locations, one line per chromosome). Note that ligation junction won’t be defined in this case. The script (misc/generate_site_positions.py) can help you generate the file</li>
<li><strong>Providing a restriction enzyme</strong>: if not defined in the script, you can either directly modify the script or provide the files needed via the “-s site_file” flag, as above. Alternatively, if you don’t want to do any fragment-level analysis (as with a DNAse experiment), you should assign the site “none”, as in <code>juicer.sh -s none</code></li>
<li><strong>Directory structure</strong>: Juicer expects the fastq files to be stored in a directory underneath the top-level directory. E.g. HIC001/fastq. By default, the top-level directory is the directory where you are when you launch Juicer; you can change this via the -d flag. Fastqs can be zipped. [topDir]/splits will be created to contain the temporary split files and should be deleted once your run is completed. [topDir]/aligned will be created for the final files, including the hic files, the statistics, the valid pairs (merged_nodups), the collisions, and the feature annotations.</li>
<li><strong>Queues</strong> are complicated and it’s likely that you’ll have to modify the script for your system, though we did our best to avoid this. By default there’s a short queue and a long queue. We also allow you to pass in wait times for those queues; this is currently ignored by the UGER and SLURM versions. The short queue should be able to complete alignment of one split file. The long queue is for jobs that we expect to take a while, like writing out the merged_sort file</li>
<li><strong>Chunk size</strong> is intimitely associated with your queues; a smaller chunk size means more alignment jobs that complete in a faster time. If you have a hard limit on the number of jobs, you don’t want too small of a chunk size. If your short queue has a very limited runtime ceiling, you don’t want too big of a chunk size. Run time for alignment will also depend on the particulars of your cluster. We launch ~5 jobs per chunk. Chunk size must be a multiple of 4.</li>
<li><strong>Relaunch</strong> via the same script. Type <code>juicer.sh [options] -S stage</code> where “stage” is one of merge, dedup, final, postproc, or early. “merge” is for when alignment has finished but merged_sort hasn’t been created; “dedup” is for when merged_sort is there but not merged_nodups (this will relaunch all dedup jobs); “final” is for when merged_nodups is there and you want the stats and hic files; “postproc” is for when you have the hic files and just want feature annotations; and “early” is for early exit, before hic file creation. If your jobs failed at the alignment stage, run <code>relaunch_prep.sh</code> and then run juicer.sh.</li>
<li><strong>Miscelleaneous options</strong> include -a ‘experiment description’, which will add the experiment description to the statistics file and the meta data in the hic file; -r, which allows you to use bwa aln instead of bwa mem, useful for shorter reads; -R [end], in case you have one read end that’s short and one that’s long and you want to align the short end with bwa aln and the long end with bwa mem; and -D [Juicer scripts directory], to set an alternative Juicer directory; must have scripts/, references/, and restriction_sites/ underneath it</li>
</ul>
<hr>
<h2 id="Command-Line-Tools-Usage"><a href="#Command-Line-Tools-Usage" class="headerlink" title="Command Line Tools Usage"></a>Command Line Tools Usage</h2><p>Detailed documentation about the command line tools can be found on the wiki:</p>
<ul>
<li><a href="https://github.com/aidenlab/juicer/wiki/Feature-Annotation">Annotating features with Arrowhead, HiCCUPS, MotifFinder, APA, Eigenvector, and Pearsons</a></li>
<li><a href="https://github.com/aidenlab/juicer/wiki/Pre">Creating .hic with Pre</a></li>
<li><a href="https://github.com/aidenlab/straw">Extracting data from .hic files with straw</a></li>
</ul>
<p>To launch the command line tools, use the shell script “juicer_tools” on Unix/MacOS or type</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -jar juicer_tools.jar (command...) [flags...] &lt;parameters...&gt;`</span><br></pre></td></tr></table></figure>

<p>In the command line tools, there are several analysis functions:</p>
<ol>
<li><code>apa</code> for conducting aggregate peak analysis</li>
<li><code>hiccups</code> for annotating loops</li>
<li><code>motifs</code> for finding CTCF motifs</li>
<li><code>arrowhead</code> for annotating contact domains</li>
<li><code>eigenvector</code> for calculating the eigenvector (first PC) of the Pearson’s</li>
<li><code>pearsons</code> for calculating the Pearson’s</li>
</ol>
<p>The <code>juicer_tools</code> (Unix/MacOS) script can be used in place of the unwieldy <code>java -Djava.library.path=path/to/natives/ -jar juicer_tools.jar</code></p>
<hr>
<h1 id="juicer的工作目录结构"><a href="#juicer的工作目录结构" class="headerlink" title="juicer的工作目录结构"></a>juicer的工作目录结构</h1><p>要求固定目录结构，新建<code>juicer</code>目录，该目录为软件安装目录，目录下必须有4个子目录</p>
<p><code>references</code>目录存放参考基因组文件，<code>work</code>存放样本序列文件和分析结果，<code>scripts</code>存放软件运行脚本，<code>restriction_sites</code>存放参考基因组酶切图谱。</p>
<h1 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h1><p>从github上下载juicer和jcuda的源代码，放置到<code>scripts</code>目录。</p>
<p>其中的<code>CPU</code>目录就是单机服务器，而<code>AWS</code>, <code>LSF</code>, <code>PBS</code>等对应公有云和不同的集群系统。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd scripts/common</span><br><span class="line">wget https://hicfiles.tc4ga.com/public/juicer/juicer_tools.1.9.9_jcuda.0.8.jar</span><br><span class="line">ln -s juicer_tools.1.9.9_jcuda.0.8.jar  juicer_tools.jar</span><br></pre></td></tr></table></figure>

<h1 id="参考基因组，酶切图谱"><a href="#参考基因组，酶切图谱" class="headerlink" title="参考基因组，酶切图谱"></a>参考基因组，酶切图谱</h1><p>fasta序列文件和bwa 索引</p>
<p>juicer/misc/generate_site_positions.py可以输出4种内切酶的酶切图谱。HindIII；DpnII；MboI；Sau3AI</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">generate_site_positions.py HindIII hg19 hg19.fasta</span><br><span class="line">python ../juicer/misc/generate_site_positions.py  MboI  hg38_MboI ../references/Homo_sapiens_assembly38.fasta # 生成了 hg38_MboI.txt 文件</span><br><span class="line">awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125;&#123;print $1, $NF&#125;&#x27; hg38_MboI.txt &gt; hg38.chrom.sizes</span><br></pre></td></tr></table></figure>

<p>第一个参数内切酶名称，第二个参数自定义基因组版本，第三个参数基因组fasta文件路径，输出文件名称为第二个参数和第一个参数用下划线链接，后缀为<code>txt</code></p>
<h1 id="序列"><a href="#序列" class="headerlink" title="序列"></a>序列</h1><p>软件运行时对样本文件的存放位置也有要求，必须位于<code>work</code>目录下，以样本名作为一个子目录，序列文件存放于<code>fastq</code>目录下，示意如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/opt/juicer/work/MBR19/fastq</span><br><span class="line">/opt/juicer/work/MBR19/fastq/chr19_R1.fastq.gz</span><br><span class="line">/opt/juicer/work/MBR19/fastq/chr19_R2.fastq.gz</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="软件比较"><a href="#软件比较" class="headerlink" title="软件比较"></a>软件比较</h1><p><img src="/blog/2022/03/16/2022-03-16-juicer/1.png" alt="img"></p>
<h1 id="脚本原理（juicer-sh）"><a href="#脚本原理（juicer-sh）" class="headerlink" title="脚本原理（juicer.sh）"></a>脚本原理（juicer.sh）</h1><p>fastq等文件输入 —》bwa比对 —》排序 —》合并 —》去PCR重复 —》生成 hic文件</p>
<p>Juicer的工作流程见下图，输入<strong>原始</strong>fastq文件，处理得到<strong>中间</strong>文件.hic, 之后对.hic文件用于<strong>下游</strong>分析，包括</p>
<p>Arrowhead: 寻找存在关联的区域<br>HiCCUPS: 分析局部富集peaks<br>MotifFinder: 用于锚定peaks<br>Persons: 计算观测/期望的皮尔森相关系数矩阵<br>Eigenvector: 确定分隔</p>
<p><img src="/blog/2022/03/16/2022-03-16-juicer/2.png" alt="juicer工作流程"></p>
<h1 id="结果文件"><a href="#结果文件" class="headerlink" title="结果文件"></a>结果文件</h1><p>结果文件都在 aligned 中，主要文件是 .hic 文件，其中inter_30.hic 是设置了 mapq threshold &gt;30 的结果。如果 GPU （cudd）可用，软件会自动使用自带 <strong>HiCCUPS</strong> 算法计算 contact domains 并保存在 inter_30_contact_domains 文件夹。如果GPU不可用，可手动用自带的 <strong>CPU HiCCUPS</strong> 算法来计算，后面章节有介绍。</p>
<p>hic文件格式请看 <a href="https://links.jianshu.com/go?to=https://github.com/theaidenlab/juicebox/blob/master/HiC_format_v8.docx">https://github.com/theaidenlab/juicebox/blob/master/HiC_format_v8.docx</a></p>
<h1 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">juicer.sh \</span><br><span class="line">-z references/hg19.fa \</span><br><span class="line">-p restriction_sites/hg19.chrom.sizes \</span><br><span class="line">-y restriction_sites/hg19_HindIII.txt \</span><br><span class="line">-d /home/pub/software/juicer/work/HIC003/ \</span><br><span class="line">-D /home/pub/software/juicer \</span><br><span class="line">-t 5</span><br><span class="line"></span><br><span class="line">-d: juicer的目录 安装在/soft/，设置为/soft/juicer</span><br><span class="line">-D: juicer scripts的目录，安装在/soft/，设置为/soft/juicer/CPU</span><br></pre></td></tr></table></figure>

<p>需要注意, 指定文件路径时，最好指定绝对路径，特别是fastq文件路径。因为软件运行过程中会使用软链接，相对路径会出错。</p>
<p><code>splits</code>目录下存放中间结果，由于hi-C数据量很大，所以会将原始序列<strong>拆分成多份</strong>，<strong>并行运算加快速度</strong>。默认每份包含22.5M的reads, 可以通过<code>-C</code>参数调整，该参数指定拆分文件的行数，默认是90000000?， 注意fastq文件4行代表一条序列，所以这个参数的值必须是4的倍数。拆分后序列的R1和R2端分别通过bwa比对基因组，然后合并，筛选嵌合体序列，去重复，生成预处理后的结果文件。</p>
<p><code>aligned</code>目录下存放的是最终结果，包含了可以导入juicebox的后缀为<code>hic</code>的图谱文件, <code>inter.hic</code>和<code>inter_30.hic</code>， 30表示通过<code>MAPQ &gt; 30</code>过滤之后的结果。完整流程还会进行后续处理，包括识别TAD, 染色质环等结构。其中识别染色质环的HICCUPs算法必须通过<a href="https://cloud.tencent.com/product/gpu?from=10680">GPU</a>加速运行才可以，所以没有安装GPU卡的普通服务器无法运行这个步骤。</p>
<p>上述过程可看到，juicer使用简单。由于Hi-C数据测序量非常大，以及后续分析算法的复杂度，对服务器计算资源的要求相当高，必须高性能服务器才能满足要求，而该软件所需的GPU卡成本也非常高，一块的成本在2万元左右，这些因素一定程度制约了Hi-C的普及和发展。</p>
<h1 id="juicer下游分析"><a href="#juicer下游分析" class="headerlink" title="juicer下游分析"></a>juicer下游分析</h1><p><a href="https://zhuanlan.zhihu.com/p/341206245">https://zhuanlan.zhihu.com/p/341206245</a></p>
<p>目前针对Hi-C数据的研究主要是三个方面，分别是<code>A/B comparment</code> ，<code>TADS</code>，<code>Loops</code>。</p>
<p><code>juicer_tools.jar</code> 功能介绍</p>
<p><code>arrowhead</code> 注释TAD</p>
<p><code>hiccups</code> 注释loop</p>
<p><code>motigs</code> 定位CTCF元件</p>
<p><code>hiccupsdiff</code> 从多个loos文件中找到不同的loop</p>
<p><code>apa</code> 聚合峰的分析</p>
<p><code>pearsons</code> 计算O/E的皮尔森相关系数</p>
<p><code>eigenvector</code> 计算特征向量的皮尔森相关系数</p>
<p><code>dump</code> .hic文件互作矩阵提取</p>
<p><code>pre</code> 非juicer数据转.hic文件</p>
<h1 id="hic数据可视化"><a href="#hic数据可视化" class="headerlink" title="hic数据可视化"></a>hic数据可视化</h1><ul>
<li><p><strong>加载.hic文件</strong></p>
</li>
<li><p><strong>加载一维注释</strong></p>
</li>
<li><p><strong>加载二维注释，黄的的是TAD，天蓝色的是loop</strong></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>【long reads mapping】【minimap2】</title>
    <url>/blog/2022/03/16/2022-03-06-Linux-grid/2022-03-16-minimap2/</url>
    <content><![CDATA[<p>Minimap2 is a versatile sequence alignment program that aligns DNA or mRNA sequences against a large reference database. </p>
<span id="more"></span>

<p><a href="https://github.com/lh3/minimap2">https://github.com/lh3/minimap2</a></p>
<ul>
<li>将PacBio或OXford Nanopore的read和已有参考基因组（如人类）进行比对(<strong>long reads mapping</strong>)</li>
<li>寻找高错误率read(15%)之间的overlap</li>
<li>将PacBio Iso-Seq 或Nanopore cDNA或RNA序列比对到参考基因组(splicing aware)</li>
<li>将<strong>illumina</strong> 单端或者双端序列比对到参考基因组</li>
<li><strong>组装之间</strong>的比对</li>
<li><strong>临近物种</strong>的全基因组比对</li>
</ul>
<h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/lh3/minimap2</span><br><span class="line"><span class="built_in">cd</span> minimap2 &amp;&amp; make</span><br><span class="line"><span class="comment"># long sequences against a reference genome</span></span><br><span class="line">./minimap2 -a <span class="built_in">test</span>/MT-human.fa <span class="built_in">test</span>/MT-orang.fa &gt; test.sam</span><br><span class="line"><span class="comment"># create an index first and then map</span></span><br><span class="line">./minimap2 -x map-ont -d MT-human-ont.mmi <span class="built_in">test</span>/MT-human.fa</span><br><span class="line">./minimap2 -a MT-human-ont.mmi <span class="built_in">test</span>/MT-orang.fa &gt; test.sam</span><br><span class="line"><span class="comment"># use presets (no test data)</span></span><br><span class="line">./minimap2 -ax map-pb ref.fa pacbio.fq.gz &gt; aln.sam       <span class="comment"># PacBio CLR genomic reads</span></span><br><span class="line">./minimap2 -ax map-ont ref.fa ont.fq.gz &gt; aln.sam         <span class="comment"># Oxford Nanopore genomic reads</span></span><br><span class="line">./minimap2 -ax map-hifi ref.fa pacbio-ccs.fq.gz &gt; aln.sam <span class="string">&#x27;PacBio HiFi/CCS genomic reads (v2.19 or later)&#x27;</span></span><br><span class="line">./minimap2 -ax asm20 ref.fa pacbio-ccs.fq.gz &gt; aln.sam    <span class="string">&#x27;PacBio HiFi/CCS genomic reads (v2.18 or earlier)&#x27;</span></span><br><span class="line">./minimap2 -ax sr ref.fa read1.fa read2.fa &gt; aln.sam      <span class="comment"># short genomic paired-end reads</span></span><br><span class="line">./minimap2 -ax splice ref.fa rna-reads.fa &gt; aln.sam       <span class="comment"># spliced long reads (strand unknown)</span></span><br><span class="line">./minimap2 -ax splice -uf -k14 ref.fa reads.fa &gt; aln.sam  <span class="comment"># noisy Nanopore Direct RNA-seq</span></span><br><span class="line">./minimap2 -ax splice:hq -uf ref.fa query.fa &gt; aln.sam    <span class="comment"># Final PacBio Iso-seq or traditional cDNA</span></span><br><span class="line">./minimap2 -ax splice --junc-bed anno.bed12 ref.fa query.fa &gt; aln.sam  <span class="comment"># prioritize on annotated junctions</span></span><br><span class="line">./minimap2 -cx asm5 asm1.fa asm2.fa &gt; aln.paf             <span class="string">&#x27;intra-species asm-to-asm alignment&#x27;</span></span><br><span class="line">./minimap2 -x ava-pb reads.fa reads.fa &gt; overlaps.paf     <span class="comment"># PacBio read overlap</span></span><br><span class="line">./minimap2 -x ava-ont reads.fa reads.fa &gt; overlaps.paf    <span class="comment"># Nanopore read overlap</span></span><br><span class="line"><span class="comment"># man page for detailed command line options</span></span><br><span class="line">man ./minimap2.1</span><br></pre></td></tr></table></figure>

<h2 id><a href="#" class="headerlink" title></a></h2><h2 id="Users’-Guide"><a href="#Users’-Guide" class="headerlink" title="Users’ Guide"></a>Users’ Guide</h2><p>Minimap2 is a versatile sequence alignment program that aligns <strong>DNA or mRNA</strong> sequences <strong>against</strong> a large <strong>reference</strong> database. </p>
<p>Typical use cases include: </p>
<p>(1) <strong>mapping PacBio</strong> or Oxford <strong>Nanopore</strong> genomic <strong>reads</strong> to the human genome;</p>
<p>(2) <strong>finding overlaps between long read</strong>s with <strong>error rate</strong> up to ~15%;</p>
<p>(3) <strong>splice-aware alignment</strong> of PacBio Iso-Seq or Nanopore cDNA or Direct RNA reads <strong>against</strong> a <strong>reference</strong> genome;</p>
<p>(4) aligning <strong>Illumina</strong> single- or paired-end reads; </p>
<p>(5) <strong>assembly-to-assembly alignment</strong>; </p>
<p>(6) <strong>full-genome alignment</strong> between <strong>two closely related species</strong> with <strong>divergence below ~15%</strong>.</p>
<p>For ~10kb noisy reads sequences, minimap2 is <strong>tens of times faster</strong> than mainstream long-read mappers such as BLASR, BWA-MEM, NGMLR and GMAP. It is <strong>more accurate</strong> on simulated long reads and produces biologically meaningful alignment ready for downstream analyses. For &gt;100bp <strong>Illumina short reads</strong>, minimap2 is <strong>three times</strong> as fast as <strong>BWA-MEM</strong> and <strong>Bowtie2</strong>, and as accurate on simulated data. Detailed evaluations are available from the <a href="https://doi.org/10.1093/bioinformatics/bty191">minimap2 paper</a> or the <a href="https://arxiv.org/abs/1708.01492">preprint</a>.</p>
<h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd minimap2 &amp;&amp; make</span><br></pre></td></tr></table></figure>

<h3 id="PAF-a-Pairwise-mApping-Format"><a href="#PAF-a-Pairwise-mApping-Format" class="headerlink" title="PAF: a Pairwise mApping Format"></a>PAF: a Pairwise mApping Format</h3><p>PAF is a text format describing the <strong>approximate mapping positions</strong> between two set of sequences. PAF is TAB-delimited with each line consisting of the following predefined fields:</p>
<table>
<thead>
<tr>
<th>Col</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>string</td>
<td>Query sequence name</td>
</tr>
<tr>
<td>2</td>
<td>int</td>
<td>Query sequence length</td>
</tr>
<tr>
<td>3</td>
<td>int</td>
<td>Query start (0-based; BED-like; closed)</td>
</tr>
<tr>
<td>4</td>
<td>int</td>
<td>Query end (0-based; BED-like; open)</td>
</tr>
<tr>
<td>5</td>
<td>char</td>
<td>Relative strand: “+” or “-“</td>
</tr>
<tr>
<td>6</td>
<td>string</td>
<td>Target sequence name</td>
</tr>
<tr>
<td>7</td>
<td>int</td>
<td>Target sequence length</td>
</tr>
<tr>
<td>8</td>
<td>int</td>
<td>Target start on original strand (0-based)</td>
</tr>
<tr>
<td>9</td>
<td>int</td>
<td>Target end on original strand (0-based)</td>
</tr>
<tr>
<td>10</td>
<td>int</td>
<td>Number of residue matches</td>
</tr>
<tr>
<td>11</td>
<td>int</td>
<td>Alignment block length</td>
</tr>
<tr>
<td>12</td>
<td>int</td>
<td>Mapping quality (0-255; 255 for missing)</td>
</tr>
</tbody></table>
<p>If PAF is generated from an alignment, <strong>column 10 equals the number of sequence matches</strong>, and <strong>column 11 equals the total number of sequence matches, mismatches, insertions and deletions in the alignment</strong>. If alignment is not available, column 10 and 11 are still required but may be highly inaccurate.</p>
<p>A PAF file may optionally contain SAM-like typed key-value pairs at the end of each line.</p>
<h3 id="General-usage"><a href="#General-usage" class="headerlink" title="General usage"></a>General usage</h3><p>Without any options, minimap2 takes a <strong>reference</strong> database and a <strong>query sequence</strong> file as input and produce approximate mapping, without base-level alignment (i.e. coordinates are only approximate and no CIGAR in output), in the PAF format:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">minimap2 ref.fa query.fq &gt; approx-mapping.paf</span><br></pre></td></tr></table></figure>

<p>You can ask minimap2 to generate CIGAR at the <code>cg</code> tag of PAF with:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">minimap2 -c ref.fa query.fq &gt; alignment.paf</span><br></pre></td></tr></table></figure>

<p>or to output alignments in the <a href="https://samtools.github.io/hts-specs/SAMv1.pdf">SAM format</a>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">minimap2 -a ref.fa query.fq &gt; alignment.sam</span><br></pre></td></tr></table></figure>

<p>Minimap2 seamlessly works with <strong>gzip’d FASTA</strong> and <strong>FASTQ</strong> formats as input. You <strong>don’t need to convert</strong> between FASTA and FASTQ or decompress gzip’d files first.</p>
<p>For the human reference genome, minimap2 takes a few minutes to generate a minimizer index for the reference before mapping. To <strong>reduce indexing time</strong>, you can optionally save the index with option <strong>-d</strong> and <strong>replace the reference sequence file with the index file</strong> on the minimap2 command line:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">minimap2 -d ref.mmi ref.fa                     # indexing</span><br><span class="line">minimap2 -a ref.mmi reads.fq &gt; alignment.sam   # alignment</span><br></pre></td></tr></table></figure>

<p><em><strong>Importantly</strong></em>, it should be noted that once you build the index, indexing parameters such as <strong>-k</strong>, <strong>-w</strong>, <strong>-H</strong> and <strong>-I</strong> can’t be changed during mapping. If you are running minimap2 for <strong>different data types</strong>, you will probably need to keep <strong>multiple indexes generated</strong> with different parameters. This makes minimap2 different from BWA which always uses the same index regardless of query data types.</p>
<h3 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h3><p>Minimap2 uses the same base algorithm for all applications. However, due to the different data types it supports (e.g. short vs long reads; DNA vs mRNA reads), minimap2 needs to be tuned for optimal performance and accuracy. It is usually recommended to choose a preset with option <strong>-x</strong>, which <strong>sets multiple parameters</strong> at the same time. The default setting is the same as <code>map-ont</code>.</p>
<h4 id="Map-long-noisy-genomic-reads"><a href="#Map-long-noisy-genomic-reads" class="headerlink" title="Map long noisy genomic reads"></a>Map long noisy genomic reads</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">minimap2 -ax map-pb  ref.fa pacbio-reads.fq &gt; aln.sam   <span class="comment"># for 【PacBio CLR】 reads</span></span><br><span class="line">minimap2 -ax map-ont ref.fa ont-reads.fq &gt; aln.sam      <span class="comment"># for 【Oxford Nanopore】 reads</span></span><br></pre></td></tr></table></figure>

<p>The difference between <code>map-pb</code> and <code>map-ont</code> is that <code>map-pb</code> uses homopolymer-compressed (HPC) minimizers as <strong>seeds</strong>, while <code>map-ont</code> uses ordinary minimizers as seeds. Emperical evaluation suggests HPC minimizers improve performance and sensitivity when aligning PacBio CLR reads, but hurt when aligning Nanopore reads.</p>
<h4 id="Map-long-mRNA-cDNA-reads"><a href="#Map-long-mRNA-cDNA-reads" class="headerlink" title="Map long mRNA/cDNA reads"></a>Map long mRNA/cDNA reads</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">minimap2 -ax splice:hq -uf ref.fa iso-seq.fq &gt; aln.sam       # PacBio Iso-seq/traditional cDNA</span><br><span class="line">minimap2 -ax splice ref.fa nanopore-cdna.fa &gt; aln.sam        # Nanopore 2D cDNA-seq</span><br><span class="line">minimap2 -ax splice -uf -k14 ref.fa direct-rna.fq &gt; aln.sam  # Nanopore Direct RNA-seq</span><br><span class="line">minimap2 -ax splice --splice-flank=no SIRV.fa SIRV-seq.fa    # mapping against SIRV control</span><br></pre></td></tr></table></figure>

<p>There are different long-read RNA-seq technologies, including tranditional full-length cDNA, EST, PacBio Iso-seq, Nanopore 2D cDNA-seq and Direct RNA-seq. They produce data of varying quality and properties. By default, <code>-x splice</code> <strong>assumes the read orientation relative to the transcript strand is unknown</strong>. It tries two rounds of alignment to infer the orientation and write the strand to the <code>ts</code> SAM/PAF tag if possible. For <strong>Iso-seq, Direct RNA-seq</strong> and tranditional full-length <strong>cDNAs</strong>, it would be desired to apply <code>-u f</code> to force minimap2 to <strong>consider the forward transcript strand only</strong>. This speeds up alignment with slight improvement to accuracy. For <strong>noisy Nanopore Direct RNA-seq reads</strong>, it is recommended to use a smaller k-mer size for increased sensitivity to the first or the last exons.</p>
<p>Minimap2 rates an alignment by the score of the max-scoring sub-segment, <em>excluding</em> introns, and marks the best alignment as primary in SAM. When a <strong>spliced gene also has unspliced pseudogenes</strong>, minimap2 does not intentionally prefer spliced alignment, though in practice it more often marks the spliced alignment as the primary. By default, minimap2 outputs up to five secondary alignments (i.e. likely pseudogenes in the context of RNA-seq mapping). This can be tuned with option <strong>-N</strong>.</p>
<p>For <strong>long RNA-seq reads</strong>, minimap2 may produce chimeric alignments potentially caused by gene fusions/structural variations or by an intron longer than the max intron length <strong>-G</strong> (200k by default). For now, it is not recommended to apply an excessively large <strong>-G</strong> as this slows down minimap2 and sometimes leads to false alignments.</p>
<p>It is worth noting that by default <code>-x splice</code> prefers GT[A/G]..[C/T]AG over GT[C/T]..[A/G]AG, and then over other splicing signals. Considering one additional base improves the junction accuracy for noisy reads, but reduces the accuracy when aligning against the widely used SIRV control data. This is because SIRV does not honor the evolutionarily conservative splicing signal. If you are studying <strong>SIRV</strong>, you may apply <code>--splice-flank=no</code> to let minimap2 only model GT..AG, ignoring the additional base.</p>
<p>Since v2.17, minimap2 can optionally <strong>take annotated genes as input</strong> and prioritize on annotated splice junctions. To use this feature, you can</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">paftools.js gff2bed anno.gff &gt; anno.bed</span><br><span class="line">minimap2 -ax splice --junc-bed anno.bed ref.fa query.fa &gt; aln.sam</span><br></pre></td></tr></table></figure>

<p>Here, <code>anno.gff</code> is the gene annotation in the GTF or GFF3 format (<code>gff2bed</code> automatically tests the format). The output of <code>gff2bed</code> is in the 12-column BED format, or the BED12 format. With the <code>--junc-bed</code> option, minimap2 adds a bonus score (tuned by <code>--junc-bonus</code>) if an aligned junction matches a junction in the annotation. Option <code>--junc-bed</code> also takes 5-column BED, including the strand field. In this case, each line indicates an oriented junction.</p>
<h4 id="Find-overlaps-between-long-reads"><a href="#Find-overlaps-between-long-reads" class="headerlink" title="Find overlaps between long reads"></a>Find overlaps between long reads</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">minimap2 -x ava-pb  reads.fq reads.fq &gt; ovlp.paf    # PacBio 【CLR read】 overlap</span><br><span class="line">minimap2 -x ava-ont reads.fq reads.fq &gt; ovlp.paf    # Oxford 【Nanopore read】 overlap</span><br></pre></td></tr></table></figure>

<p>Similarly, <code>ava-pb</code> uses HPC minimizers while <code>ava-ont</code> uses ordinary minimizers. It is usually not recommended to perform base-level alignment in the overlapping mode because it is slow and may produce false positive overlaps. However, if performance is not a concern, you may try to add <code>-a</code> or <code>-c</code> anyway.</p>
<h4 id="Map-short-accurate-genomic-reads"><a href="#Map-short-accurate-genomic-reads" class="headerlink" title="Map short accurate genomic reads"></a>Map short accurate genomic reads</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">minimap2 -ax sr ref.fa reads-se.fq &gt; aln.sam           # single-end alignment</span><br><span class="line">minimap2 -ax sr ref.fa read1.fq read2.fq &gt; aln.sam     # paired-end alignment</span><br><span class="line">minimap2 -ax sr ref.fa reads-interleaved.fq &gt; aln.sam  # paired-end alignment</span><br></pre></td></tr></table></figure>

<p>When two read files are specified, minimap2 reads from each file in turn and merge them into an interleaved stream internally. Two reads are considered to be paired if they are adjacent in the input stream and have the same name (with the <code>/[0-9]</code> suffix trimmed if present). Single- and paired-end reads can be mixed.</p>
<p>Minimap2 <strong>does not work well with short spliced reads</strong>. There are many capable RNA-seq mappers for short reads.</p>
<h4 id="Full-genome-assembly-alignment"><a href="#Full-genome-assembly-alignment" class="headerlink" title="Full genome/assembly alignment"></a><font color="blue">Full genome/assembly alignment</font></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">minimap2 -ax asm5 ref.fa asm.fa &gt; aln.sam       # assembly to assembly/ref alignment</span><br></pre></td></tr></table></figure>

<p>For <strong>cross-species</strong> full-genome alignment, the scoring system needs to be tuned according to the sequence divergence.</p>
<h3 id="Advanced-features"><a href="#Advanced-features" class="headerlink" title="Advanced features"></a>Advanced features</h3><h4 id="Working-with-gt-65535-CIGAR-operations"><a href="#Working-with-gt-65535-CIGAR-operations" class="headerlink" title="Working with &gt;65535 CIGAR operations"></a>Working with &gt;65535 CIGAR operations</h4><p>Due to a design flaw, BAM does not work with CIGAR strings with &gt;65535 operations (SAM and CRAM work). However, for <strong>ultra-long nanopore reads</strong> minimap2 may align ~1% of read bases with long CIGARs beyond the capability of BAM. If you convert such SAM/CRAM to BAM, Picard and recent samtools will throw an error and abort. Older samtools and other tools may create corrupted BAM.</p>
<p>To avoid this issue, you can add option <code>-L</code> at the minimap2 command line. This option moves a long CIGAR to the <code>CG</code> tag and leaves a fully clipped CIGAR at the SAM CIGAR column. Current tools that don’t read CIGAR (e.g. merging and sorting) still work with such BAM records; tools that read CIGAR will effectively ignore these records. It has been decided that future tools will seamlessly recognize long-cigar records generated by option <code>-L</code>.</p>
<p><strong>TL;DR</strong>: if you work with ultra-long reads and use tools that only process BAM files, please add option <code>-L</code>.</p>
<h4 id="The-cs-optional-tag"><a href="#The-cs-optional-tag" class="headerlink" title="The cs optional tag"></a>The cs optional tag</h4><p>The <code>cs</code> SAM/PAF tag encodes bases at mismatches and INDELs. It matches regular expression <code>/(:[0-9]+|\*[a-z][a-z]|[=\+\-][A-Za-z]+)+/</code>. Like CIGAR, <code>cs</code> consists of series of operations. Each leading character specifies the operation; the following sequence is the one involved in the operation.</p>
<p>The <code>cs</code> tag is enabled by command line option <code>--cs</code>. The following alignment, for example:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CGATCGATAAATAGAGTAG---GAATAGCA</span><br><span class="line">||||||   ||||||||||   |||| |||</span><br><span class="line">CGATCG---AATAGAGTAGGTCGAATtGCA</span><br></pre></td></tr></table></figure>

<p>is represented as <code>:6-ata:10+gtc:4*at:3</code>, where <code>:[0-9]+</code> represents an identical block, <code>-ata</code> represents a deletion, <code>+gtc</code> an insertion and <code>*at</code> indicates reference base <code>a</code> is substituted with a query base <code>t</code>. It is similar to the <code>MD</code> SAM tag but is standalone and easier to parse.</p>
<p>If <code>--cs=long</code> is used, the <code>cs</code> string also contains identical sequences in the alignment. The above example will become <code>=CGATCG-ata=AATAGAGTAG+gtc=GAAT*at=GCA</code>. The long form of <code>cs</code> <strong>encodes both reference and query sequences in one string</strong>. The <code>cs</code> tag also encodes <strong>intron positions</strong> and <strong>splicing signals</strong> (see the <a href="https://lh3.github.io/minimap2/minimap2.html#10">minimap2 manpage</a> for details).</p>
<h4 id="Working-with-the-PAF-format"><a href="#Working-with-the-PAF-format" class="headerlink" title="Working with the PAF format"></a><font color="red">Working with the PAF format</font></h4><p>Minimap2 also comes with a (java)script <a href="https://github.com/lh3/minimap2/blob/master/misc/paftools.js">paftools.js</a> that processes alignments in the PAF format. It calls variants from assembly-to-reference alignment, lifts over BED files based on alignment, converts between formats and provides utilities for various evaluations. For details, please see <a href="https://github.com/lh3/minimap2/blob/master/misc/README.md">misc/README.md</a>.</p>
<h3 id="Algorithm-overview"><a href="#Algorithm-overview" class="headerlink" title="Algorithm overview"></a>Algorithm overview</h3><p>In the following, minimap2 command line options have a dash ahead and are highlighted in bold. The description may help to tune minimap2 parameters.</p>
<ol>
<li>Read <strong>-I</strong> [=<em>4G</em>] reference bases, extract (<strong>-k</strong>,<strong>-w</strong>)-minimizers and index them in a hash table.</li>
<li>Read <strong>-K</strong> [=<em>200M</em>] query bases. For each query sequence, do step 3 through 7:</li>
<li>For each (<strong>-k</strong>,<strong>-w</strong>)-minimizer on the query, check against the reference index. If a reference minimizer is not among the top <strong>-f</strong> [=<em>2e-4</em>] most frequent, collect its the occurrences in the reference, which are called <em>seeds</em>.</li>
<li>Sort seeds by position in the reference. Chain them with dynamic programming. Each chain represents a potential mapping. For read overlapping, report all chains and then go to step 8. For reference mapping, do step 5 through 7:</li>
<li>Let <em>P</em> be the set of primary mappings, which is an empty set initially. For each chain from the best to the worst according to their chaining scores: if on the query, the chain overlaps with a chain in <em>P</em> by <strong>–mask-level</strong> [=<em>0.5</em>] or higher fraction of the shorter chain, mark the chain as <em>secondary</em> to the chain in <em>P</em>; otherwise, add the chain to <em>P</em>.</li>
<li>Retain all primary mappings. Also retain up to <strong>-N</strong> [=<em>5</em>] top secondary mappings if their chaining scores are higher than <strong>-p</strong> [=<em>0.8</em>] of their corresponding primary mappings.</li>
<li>If alignment is requested, filter out an internal seed if it potentially leads to both a long insertion and a long deletion. Extend from the left-most seed. Perform global alignments between internal seeds. Split the chain if the accumulative score along the global alignment drops by <strong>-z</strong> [=<em>400</em>], disregarding long gaps. Extend from the right-most seed. Output chains and their alignments.</li>
<li>If there are more query sequences in the input, go to step 2 until no more queries are left.</li>
<li>If there are more reference sequences, reopen the query file from the start and go to step 1; otherwise stop.</li>
</ol>
<h3 id="Getting-help"><a href="#Getting-help" class="headerlink" title="Getting help"></a>Getting help</h3><p>Manpage <a href="https://lh3.github.io/minimap2/minimap2.html">minimap2.1</a> provides detailed description of minimap2 command line options and optional tags. The <a href="https://github.com/lh3/minimap2/blob/master/FAQ.md">FAQ</a>page answers several frequently asked questions. If you encounter bugs or have further questions or requests, you can raise an issue at the <a href="https://github.com/lh3/minimap2/issues">issue page</a>. There is not a specific mailing list for the time being.</p>
<h2 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h2><ul>
<li>Minimap2 may produce <strong>suboptimal alignments</strong> through <strong>long low-complexity regions</strong> where seed positions may be suboptimal. This should not be a big concern because even the optimal alignment may be wrong in such regions.</li>
<li>Minimap2 requires SSE2 instructions on x86 CPUs or NEON on ARM CPUs. It is possible to add non-SIMD support, but it would make minimap2 slower by several times.</li>
<li>Minimap2 <strong>does not work</strong> with a single query or database sequence ~<strong>2 billion bases or longer</strong> (2,147,483,647 to be exact). The total length of all sequences can well exceed this threshold.</li>
<li>Minimap2 often <strong>misses small exons</strong>.</li>
</ul>
<h2 id="methods"><a href="#methods" class="headerlink" title="methods"></a>methods</h2><p>Minimap2 follows a typical <strong>seed-chain-align procedure</strong> as is used by most full-genome aligners. It <strong>collects minimizers</strong> (Roberts <em>et al</em>., 2004) of the <strong>reference sequences</strong> and <strong>indexes them in a hash table</strong>, with the <strong>key</strong> being the hash of a minimizer and the <strong>value</strong> being a list of locations of the minimizer copies. Then for <strong>each query sequence</strong>, minimap2 takes query minimizers as <em>seeds</em>, finds exact matches (i.e. <em>anchors</em>) to the reference, and identifies sets of colinear anchors as <em>chains</em>. If base-level alignment is requested, minimap2 applies <strong>dynamic programming</strong> (DP) to extend from the ends of chains and to close regions between adjacent anchors in chains.</p>
<p>Minimap2 uses indexing and seeding algorithms similar to minimap (Li, 2016), and furthers the predecessor with more accurate chaining, the ability to produce base-level alignment and the support of spliced alignment.</p>
<h1 id="asm-vs-asm"><a href="#asm-vs-asm" class="headerlink" title="asm vs asm"></a>asm vs asm</h1><h2 id="Difference-of-SNP-amp-indel-between-asm-vs-asm"><a href="#Difference-of-SNP-amp-indel-between-asm-vs-asm" class="headerlink" title="Difference of SNP&amp;indel between asm vs asm"></a>Difference of SNP&amp;indel between asm vs asm</h2><p><a href="https://bleepcoder.com/cn/minimap2/296555096/a-best-practices-document-for-assembly-to-assembly">ref</a></p>
<p><code>paftools.js call</code>现在支持 VCF 输出。 要使用它，请将<code>-f ref.fa</code>加到命令行中：</p>
<p>对同一物种的asm使用<code>asm5</code> 。 如果略有不同，请使用<code>asm10</code> 。 如果序列差异很大，请使用<code>-a</code> 。</p>
<p>variant calling</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/lh3/minimap2   <span class="comment"># you need the latest version; not from conda</span></span><br><span class="line"><span class="built_in">cd</span> minimap2 &amp;&amp; make</span><br><span class="line"></span><br><span class="line">curl -L https://github.com/attractivechaos/k8/releases/download/v0.2.4/k8-0.2.4.tar.bz2 | tar -jxf -</span><br><span class="line">cp k8-0.2.4/k8-`uname -s` k8   <span class="comment"># or copy it to a directory on you $PATH</span></span><br><span class="line"></span><br><span class="line">./minimap2 -c --cs ref.fa query.fa \</span><br><span class="line">  | sort -k6,6 -k8,8n \</span><br><span class="line">  | ./k8 misc/paftools.js call -f ref.fa -L20000 - &gt; var.vcf</span><br></pre></td></tr></table></figure>

<p>两asm差异太大。 可以先尝试：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./minimap2 -c --cs ref.fa query.fa | sort -k6,6 -k8,8n | ./k8 misc/paftools.js call -L20000 - &gt; var.txt</span><br></pre></td></tr></table></figure>

<p>生成vcf方法</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/lh3/htsbox</span><br><span class="line">(<span class="built_in">cd</span> htsbox &amp;&amp; make)</span><br><span class="line">minimap2 -axasm5 wt_minion.fasta wt_pacbio.fasta | samtool sort - &gt; sorted.bam</span><br><span class="line">htsbox/htsbox pileup -q5 -S10000 -vcf wt_minion.fasta sorted.bam &gt; diff.vcf</span><br></pre></td></tr></table></figure>

<h2 id="convert-sam-asm-vs-asm-to-paf"><a href="#convert-sam-asm-vs-asm-to-paf" class="headerlink" title="convert sam(asm vs asm) to paf"></a>convert sam(asm vs asm) to paf</h2><p><a href="https://www.biostars.org/p/479287/">ref</a></p>
<p>Looks like no one has actually read the question correctly. <font color="blue"><strong>PAF is missing lots of information compared to SAM</strong></font>, because it is <font color="blue"><strong>a summary of alignment</strong></font>, but it also has <font color="blue">easy access to the <strong>alignment start</strong> and <strong>stop coordinates</strong>, <strong>sequences length</strong></font>, etc. Since <font color="blue">PAF is less information-dense you <strong>cannot convert in both directions</strong></font>.</p>
<p>There are several options:</p>
<ol>
<li>Use Heng Li’s experimental toolkit, <font color="blue">htsbox samview -p in.bam</font>: <a href="https://github.com/lh3/htsbox">https://github.com/lh3/htsbox</a></li>
<li>Use <font color="green"><strong>paftools.js sam2paf</strong></font>: <a href="https://github.com/lh3/minimap2/blob/master/misc/README.md#introduction">https://github.com/lh3/minimap2/blob/master/misc/README.md#introduction</a></li>
<li>Use this <font color="blue">python</font> library: <a href="https://bioconvert.readthedocs.io/en/master/_modules/bioconvert/sam2paf.html">https://bioconvert.readthedocs.io/en/master/_modules/bioconvert/sam2paf.html</a></li>
</ol>
<h2 id="visualization-of-PAF-file-obtained-from-asm-vs-asm-in-minimap2"><a href="#visualization-of-PAF-file-obtained-from-asm-vs-asm-in-minimap2" class="headerlink" title="visualization of PAF file obtained from asm_vs_asm in minimap2"></a>visualization of PAF file obtained from asm_vs_asm in minimap2</h2><p><a href="https://www.jianshu.com/p/befb3a440aed">Ref</a></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">source(<span class="string">&quot;.paf.R&quot;</span>)</span><br><span class="line">df &lt;- read.paf(<span class="string">&quot;./asm_vs_ref.paf&quot;</span>)</span><br><span class="line">plot_synteny(df)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>grid系统里面的视图(viewport)可以继续分为多个图层，每个图层可有不同的坐标系统。</p>
</blockquote>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">read.paf &lt;- <span class="keyword">function</span>(file, sep = <span class="string">&quot;\t&quot;</span>,</span><br><span class="line">                     header = <span class="literal">FALSE</span>,</span><br><span class="line">                     MQ = <span class="number">10</span>,</span><br><span class="line">                     ...)&#123;</span><br><span class="line">  data &lt;- readLines(file)</span><br><span class="line">  </span><br><span class="line">  dataSize &lt;- <span class="built_in">length</span>(data)</span><br><span class="line">  <span class="comment"># initialize </span></span><br><span class="line">  qName   &lt;- vector(<span class="string">&quot;character&quot;</span>, dataSize)</span><br><span class="line">  qLength &lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line">  qStart  &lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line">  qEnd    &lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line">  strand  &lt;- vector(<span class="string">&quot;character&quot;</span>, dataSize)</span><br><span class="line">  tName   &lt;- vector(<span class="string">&quot;character&quot;</span>, dataSize)</span><br><span class="line">  tLength &lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line">  tStart  &lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line">  tEnd    &lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line">  reMatch &lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line">  bLength &lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line">  mQuality&lt;- vector(<span class="string">&quot;integer&quot;</span>, dataSize)</span><br><span class="line"></span><br><span class="line">  i &lt;- 1</span><br><span class="line">  j &lt;- 0</span><br><span class="line">  <span class="keyword">for</span> (i <span class="keyword">in</span> seq(dataSize))&#123;</span><br><span class="line">    items   &lt;- strsplit(data[i], split = sep)[[<span class="number">1</span>]]</span><br><span class="line">    </span><br><span class="line">    quality &lt;- <span class="built_in">as.numeric</span>(items[<span class="number">12</span>]) <span class="comment">#Mapping Quality 0-255</span></span><br><span class="line">    <span class="keyword">if</span> (quality &lt; MQ)</span><br><span class="line">      <span class="keyword">next</span></span><br><span class="line">    j &lt;- j + <span class="number">1</span></span><br><span class="line">    qName[j]   &lt;- items[<span class="number">1</span>] <span class="comment"># Query sequence name</span></span><br><span class="line">    qLength[j] &lt;- <span class="built_in">as.integer</span>(items[<span class="number">2</span>])</span><br><span class="line">    qStart[j]  &lt;- <span class="built_in">as.integer</span>(items[<span class="number">3</span>]) + <span class="number">1L</span></span><br><span class="line">    qEnd[j]    &lt;- <span class="built_in">as.integer</span>(items[<span class="number">4</span>]) + <span class="number">1L</span> <span class="comment"># convert 0-based to 1-based</span></span><br><span class="line">    strand[j]  &lt;- items[<span class="number">5</span>] <span class="comment"># Relative strand: &quot;+&quot; or &quot;-&quot;</span></span><br><span class="line">    tName[j]   &lt;- items[<span class="number">6</span>] <span class="comment"># Target sequence name</span></span><br><span class="line">    tLength[j] &lt;- <span class="built_in">as.integer</span>(items[<span class="number">7</span>])</span><br><span class="line">    tStart[j]  &lt;- <span class="built_in">as.integer</span>(items[<span class="number">8</span>]) + <span class="number">1L</span></span><br><span class="line">    tEnd[j]    &lt;- <span class="built_in">as.integer</span>(items[<span class="number">9</span>]) + <span class="number">1L</span></span><br><span class="line">    reMatch[j] &lt;- <span class="built_in">as.integer</span>(items[<span class="number">10</span>])  <span class="comment">#Number of residue matches</span></span><br><span class="line">    bLength[j] &lt;- <span class="built_in">as.integer</span>(items[<span class="number">11</span>]) <span class="comment">#Alignment block length</span></span><br><span class="line">    mQuality[j]&lt;- <span class="built_in">as.integer</span>(items[<span class="number">12</span>]) <span class="comment">#Alignment block length</span></span><br><span class="line">  &#125; </span><br><span class="line">    pafDataframe &lt;- data.frame(qName = qName[<span class="number">1</span>:j], qStart = qStart[<span class="number">1</span>:j], qEnd = qEnd[<span class="number">1</span>:j],</span><br><span class="line">                               tName = tName[<span class="number">1</span>:j], tStart = tStart[<span class="number">1</span>:j], tEnd = tEnd[<span class="number">1</span>:j],</span><br><span class="line">                               qLength = qLength[<span class="number">1</span>:j], tLength = tLength[<span class="number">1</span>:j], </span><br><span class="line">                               strand  = strand[<span class="number">1</span>:j],</span><br><span class="line">                               reMatch = reMatch[<span class="number">1</span>:j], bLength = bLength[<span class="number">1</span>:j],</span><br><span class="line">                               mQuality = mQuality[<span class="number">1</span>:j],</span><br><span class="line">                               stringsAsFactors = <span class="literal">FALSE</span>)</span><br><span class="line">  <span class="built_in">return</span>(pafDataframe) </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot_synteny &lt;- <span class="keyword">function</span>(df, contigs = <span class="number">20</span>,</span><br><span class="line">                         lineSize = <span class="number">3</span>,</span><br><span class="line">                         borderCol = <span class="string">&quot;#5496ff&quot;</span>,... )&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># select the top N contig</span></span><br><span class="line">  x &lt;- df[,<span class="built_in">c</span>(<span class="string">&quot;qName&quot;</span>,<span class="string">&quot;qLength&quot;</span>)]</span><br><span class="line">  x &lt;- x[!duplicated(x$qName),]</span><br><span class="line">  x &lt;- x[order(x$qLength, decreasing = <span class="literal">TRUE</span>),][<span class="number">1</span>:contigs,]</span><br><span class="line"></span><br><span class="line">  y &lt;- df[,<span class="built_in">c</span>(<span class="string">&quot;tName&quot;</span>,<span class="string">&quot;tLength&quot;</span>)]</span><br><span class="line">  y &lt;- y[!duplicated(y$tName),]</span><br><span class="line">  y &lt;- y[order(y$tLength, decreasing = <span class="literal">TRUE</span>),][<span class="number">1</span>:contigs,]</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># make new page for ploting</span></span><br><span class="line">  grid::grid.newpage()</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># allot the ratio of each contig</span></span><br><span class="line">  x_frac &lt;- x$qLength / <span class="built_in">sum</span>(x$qLength)</span><br><span class="line">  y_frac &lt;- y$tLength / <span class="built_in">sum</span>(y$tLength)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># draw the contig name</span></span><br><span class="line">  grid::pushViewport(grid::viewport(height = <span class="number">0.7</span>,</span><br><span class="line">                        width =  <span class="number">0.7</span>,</span><br><span class="line">                        gp = grid::gpar(cex = <span class="number">0.75</span>),</span><br><span class="line">                        name = <span class="string">&quot;contigName&quot;</span>))</span><br><span class="line">  x_pos &lt;- <span class="built_in">c</span>(<span class="number">0</span>, <span class="built_in">cumsum</span>(x_frac)[<span class="number">1</span>:(contigs-<span class="number">1</span>)])</span><br><span class="line">  y_pos &lt;- 1- <span class="built_in">c</span>(<span class="number">0</span>, <span class="built_in">cumsum</span>(y_frac)[<span class="number">1</span>:(contigs-<span class="number">1</span>)])</span><br><span class="line">  <span class="keyword">for</span> (i <span class="keyword">in</span> <span class="built_in">seq.int</span>(<span class="number">1</span>,contigs))&#123;</span><br><span class="line">    grid::grid.text(label = x[i,<span class="number">1</span>], </span><br><span class="line">              x = grid::unit(x_pos[i], <span class="string">&quot;npc&quot;</span>),</span><br><span class="line">              y = grid::unit(<span class="number">1</span>, <span class="string">&quot;npc&quot;</span>),</span><br><span class="line">              just = <span class="built_in">c</span>(<span class="string">&quot;left&quot;</span>,<span class="string">&quot;bottom&quot;</span>),</span><br><span class="line">              rot = <span class="number">35</span></span><br><span class="line">              )</span><br><span class="line">    grid::grid.text(label = y[i, <span class="number">1</span>],</span><br><span class="line">              x = grid::unit(<span class="number">1</span>, <span class="string">&quot;npc&quot;</span>),</span><br><span class="line">              y = grid::unit(y_pos[i], <span class="string">&quot;npc&quot;</span>),</span><br><span class="line">              just = <span class="built_in">c</span>(<span class="string">&quot;left&quot;</span>)</span><br><span class="line">              )</span><br><span class="line">    </span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  vplay &lt;- grid::grid.layout(contigs, contigs, </span><br><span class="line">                       widths  = x_frac,</span><br><span class="line">                       heights = y_frac)</span><br><span class="line">  grid::pushViewport(grid::viewport(layout = vplay,</span><br><span class="line">                        name = <span class="string">&quot;vplay&quot;</span>))</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  <span class="comment"># line represent the synteny</span></span><br><span class="line">  <span class="keyword">for</span> ( i <span class="keyword">in</span> seq(<span class="number">1</span>, contigs))&#123;</span><br><span class="line">    <span class="keyword">for</span> (j <span class="keyword">in</span> seq(<span class="number">1</span>, contigs))&#123;</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># get the name and length for subsetting</span></span><br><span class="line">      xName   &lt;- x[i,<span class="number">1</span>]</span><br><span class="line">      xLength &lt;- x[i,<span class="number">2</span>]</span><br><span class="line">      yName   &lt;- y[j,<span class="number">1</span>] </span><br><span class="line">      yLength &lt;- y[j,<span class="number">2</span>]</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># push view port for plot Collinearity</span></span><br><span class="line">      grid::pushViewport(grid::viewport(layout.pos.col = i,</span><br><span class="line">                            layout.pos.row = j,</span><br><span class="line">                            xscale = <span class="built_in">c</span>(<span class="number">1</span>, xLength),</span><br><span class="line">                            yscale = <span class="built_in">c</span>(<span class="number">1</span>, yLength),</span><br><span class="line">                            name = paste0(<span class="string">&quot;pos&quot;</span>,i,j)))</span><br><span class="line">  </span><br><span class="line">      grid::grid.rect(gp=grid::gpar(col=borderCol))</span><br><span class="line">      <span class="comment"># select the data</span></span><br><span class="line">      plot_df &lt;- df[df$qName == xName &amp; df$tName == yName,] </span><br><span class="line">      blocks &lt;- nrow(plot_df)</span><br><span class="line">      <span class="comment">#cat(sprintf(&quot;block size is %d\n&quot;, blocks))</span></span><br><span class="line">      </span><br><span class="line">      <span class="keyword">if</span> (blocks == <span class="number">0</span>) &#123;</span><br><span class="line">        grid::upViewport() </span><br><span class="line">        <span class="keyword">next</span></span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># plot the line</span></span><br><span class="line">      <span class="keyword">for</span> (k <span class="keyword">in</span> seq(<span class="number">1</span>, blocks))&#123;</span><br><span class="line">        <span class="keyword">if</span> (plot_df$strand[k] == <span class="string">&quot;+&quot;</span>)&#123;</span><br><span class="line">          grid::grid.lines(x = <span class="built_in">c</span>(plot_df$qStart[k], plot_df$qEnd[k]),</span><br><span class="line">                     y = <span class="built_in">c</span>(plot_df$tStart[k], plot_df$tEnd[k]),</span><br><span class="line">                     gp=grid::gpar(lwd = lineSize),</span><br><span class="line">                     default.units = <span class="string">&quot;native&quot;</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          grid::grid.lines(x = <span class="built_in">c</span>(plot_df$qStart[k], plot_df$qEnd[k]),</span><br><span class="line">                     y = <span class="built_in">c</span>(plot_df$tEnd[k], plot_df$tStart[k]),</span><br><span class="line">                     gp=grid::gpar(lwd = lineSize),</span><br><span class="line">                     default.units = <span class="string">&quot;native&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      grid::upViewport() </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>HiFi-7-[HiFi+HiC-assembly-method]</title>
    <url>/blog/2022/03/16/2022-03-16-HiFi-7-HiC-assembly2/</url>
    <content><![CDATA[<p>辅助组装案例2</p>
<span id="more"></span>

<p>search：HiFi Hi-C  <a href="https://pubmed.ncbi.nlm.nih.gov/?term=HiFi%20Hi-C&amp;page=2">https://pubmed.ncbi.nlm.nih.gov/?term=HiFi%20Hi-C&amp;page=2</a></p>
<h1 id="1-2021-09-亚麻纤维"><a href="#1-2021-09-亚麻纤维" class="headerlink" title="1. 2021.09 亚麻纤维"></a>1. 2021.09 亚麻纤维</h1><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#">Front Genet.</a> 2021; 12: 735690.  cite1</p>
<p>Published online 2021 Sep 13. doi: <a href="https://dx.doi.org/10.3389%2Ffgene.2021.735690">10.3389/fgene.2021.735690</a></p>
<blockquote>
<p>Chromosome-Level Genome Assembly and Annotation of the Fiber Flax (<em>Linum usitatissimum</em>) Genome</p>
</blockquote>
<p><strong>Genome Assembly</strong></p>
<p>The HiFi long reads were assembled by <strong>Hifiasm</strong> v0.13-r308 with the <strong>default parameters</strong>. Then the <strong>HiFi reads were mapped back to the assembly</strong> to generate a <strong>coverage distribution plot</strong> using <strong>minimap2</strong> 2.17-r941. According to the <strong>covering depth</strong>, <strong>purge_dups</strong> v1.2.5 (Guan et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B22">2020</a>) was applied to <strong>remove redundant haplotigs</strong>. The <strong>Juicer v1.6</strong> (Durand et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B15">2016</a>) and <strong>3D-DNA</strong> v180922 (Dudchenko et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B13">2017</a>) pipelines were used to process the <strong>Hi-C data and scaffold the assembly</strong>. The results were polished using the <strong>Juicebox Assembly Tools</strong> v1.11.08 (Dudchenko et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B14">2018</a>). The CDC Bethune v2 assembly has made most use of the long continuity of optical maps. To further improve the accuracy of order and orient in our assembly, we integrated information from the <strong>Hi-C scaffolding</strong> and the CDC Bethune v2 assembly using the ALLMAPS pipeline (Tang et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B55">2015b</a>) implemented in jcvi utility libraries (Tang et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B54">2015a</a>).</p>
<h1 id="2-2021-06-玫瑰🌹"><a href="#2-2021-06-玫瑰🌹" class="headerlink" title="2. 2021.06 玫瑰🌹"></a>2. 2021.06 玫瑰🌹</h1><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#">Hortic Res.</a> 2021; 8: 141.  cite4</p>
<p>Published online 2021 Jun 18. doi: <a href="https://dx.doi.org/10.1038%2Fs41438-021-00594-z">10.1038/s41438-021-00594-z</a></p>
<blockquote>
<p>A chromosome-level genome assembly of rugged rose (<em>Rosa rugosa</em>) provides insights into its evolution, ecology, and floral characteristics</p>
</blockquote>
<p><strong>Genome assembly and quality evaluation</strong></p>
<p>Approximately 59.2 Gb of raw HiFi sequencing reads was obtained from the rosa DNA library. We first used <strong>HiCanu</strong> v2.2.1 for preliminary assembly of the rosa genome. Then, <strong>Redundans</strong> v 0.14a<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#CR27">27</a> was performed to <strong>remove the redundant sequences</strong>. A total of 150.6 Gb of <strong>Hi-C data</strong> were obtained to <strong>anchor</strong> the contig onto the chromosome. We <strong>aligned Hi-C</strong> reads to assembly by <strong>BWA</strong> v 0.7.17-r1188<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#CR28">28</a>. Next, the <strong>draft assembly genome</strong> was <strong>scaffolded with Hi-C reads by 3D-DNA</strong> v180114<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#CR29">29</a>. Then, <strong>Juicer</strong> was used to <strong>filter the sequence and cluster it</strong>, and the <strong>Juicerbox tool</strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#CR30">30</a> was applied to <strong>manually adjust chromosome construction</strong>. We finally <strong>anchored the scaffolds on seven chromosomes</strong>. In addition, the <strong>BUSCO</strong> v3.0.2pipeline was used to assess the completeness and accuracy of the <em>R. rugosa</em> genome with the embryophyte_odb10 dataset, which contains 1614 BUSCO gene sets.</p>
<h1 id="3-2022-02-香菇"><a href="#3-2022-02-香菇" class="headerlink" title="3. 2022.02 香菇"></a>3. 2022.02 香菇</h1><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877449/#">J Fungi (Basel).</a> 2022 Feb; 8(2): 167. </p>
<p>Published online 2022 Feb 9. doi: <a href="https://dx.doi.org/10.3390%2Fjof8020167">10.3390/jof8020167</a></p>
<blockquote>
<p>Haplotype-Resolved Genome Analyses Reveal Genetically Distinct Nuclei within a Commercial Cultivar of <em>Lentinula edodes</em></p>
</blockquote>
<p><strong>Genome Sequencing and Assembly</strong></p>
<p>SMRTbell libraries were sequenced on a PacBio Sequel II system, and consensus reads (HiFi reads) were generated using ccs software (<a href="https://github.com/pacificbiosci-ences/unanimity">https://github.com/pacificbiosci-ences/unanimity</a>, accessed on 22 December 2021) with the parameter “–inPasses 3”. We generated 8.65 Gb and 5.35 Gb PacBio HiFi reads of SP3 and SP30, respectively. These long (~15 kb) and highly accurate (&gt;99%) HiFi reads were assembled using <strong>HiCanu</strong> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877449/#B18-jof-08-00167">18</a>] for both strains with <strong>default parameters</strong>.</p>
<p>The vegetative mycelia of SP3 and SP30 were also used to generate Hi-C DNA libraries at the Frasergen Enterprise (Wuhan, China). The Hi-C libraries were quantified and sequenced on the Illumina Nova-seq platform (San Diego, CA, USA). The chimeric fragments from the original cross-linked long-distance physical interactions were then isolated and processed into libraries. For anchored contigs, 34,909,404 and 31,267,524 clean <strong>reads</strong> were generated from the Hi-C library and were <strong>mapped</strong> to the SP3 and SP30 <strong>preliminary assembly</strong> using <strong>Juicer</strong> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877449/#B20-jof-08-00167">20</a>] with default parameters. Paired reads mapped to different contigs were used for the Hi-C associated scaffolding. Self-ligated, non-ligated, and other invalid reads were filtered out. We applied <strong>3D-DNA</strong> to <strong>order</strong> and <strong>orient</strong> the clustered contigs. Then, <strong>Juicer</strong> was used to filter the sequences and cluster them, and the <strong>Juicebox</strong> was applied to <strong>adjust chromosome construction manually</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877449/#app1-jof-08-00167">Figure S2</a>). We finally <strong>anchored the scaffolds on ten chromosomes</strong>. In addition, the BUSCO v3.0.231 pipeline was used to assess the completeness and accuracy of the SP3 and SP30 genomes.</p>
<p><img src="/blog/2022/03/16/2022-03-16-HiFi-7-HiC-assembly2/1.png" alt="截屏2022-03-16上午10.03.37"></p>
<h1 id="4-2021-04-benchmark"><a href="#4-2021-04-benchmark" class="headerlink" title="4 2021.04 benchmark"></a>4 2021.04 benchmark</h1><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#">Mol Med Rep.</a> 2021 Apr; 23(4): 251. </p>
<p>Published online 2021 Feb 2. doi: <a href="https://dx.doi.org/10.3892%2Fmmr.2021.11890">10.3892/mmr.2021.11890</a></p>
<blockquote>
<p>Benchmarking of next and third generation sequencing technologies and their associated algorithms for <em>de novo</em> genome assembly</p>
</blockquote>
<p><strong>Genome assembly</strong> </p>
<p>In order to assess the hybrid assembly strategy, the present study chose to evaluate two pipelines, MaSuRCA (version 3.3.5) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b27-mmr-0-0-11890">27</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b28-mmr-0-0-11890">28</a>) and Wengan (version 0.1) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b29-mmr-0-0-11890">29</a>). MaSuRCA workflow offers three different assemblers, CABOG (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b30-mmr-0-0-11890">30</a>), SOAPdenovo (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b31-mmr-0-0-11890">31</a>) and Flye (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b32-mmr-0-0-11890">32</a>). The pipeline was tested using CABOG and Flye assemblers, which are designed for long-read assembly. Wengan pipeline is based on DiscovarDenovo assembler (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b33-mmr-0-0-11890">33</a>).</p>
<p>Canu (version 2.0) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b34-mmr-0-0-11890">34</a>) is a long-read assembler, designed to use long high-noise single-molecule sequencing data, such as Nanopore and PacBio reads. Its workflow is based on the Celera assembler (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b35-mmr-0-0-11890">35</a>) which was used in the Human Genome Project to produce the first draft of the human genome. <strong>Hifiasm</strong> (version 0.13) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b36-mmr-0-0-11890">36</a>) and <strong>HiCanu</strong> (Canu version 2.1.1) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b37-mmr-0-0-11890">37</a>) are long-read assemblers exclusively <strong>for HiFi reads.</strong> The <strong>main difference</strong> between HiFi assemblers and the ones mentioned previously, is that <strong>Hifiasm and HiCanu produce phased assemblies</strong>. A phased assembly is a <strong>haplotype-resolved assembly</strong>, where <strong>high complexity regions</strong>, such as <strong>genes</strong>, will be <strong>separated into two different alleles</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b36-mmr-0-0-11890">36</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b38-mmr-0-0-11890">38</a>). HiCanu is a modified version of Canu, adapted to take advantage of the characteristics of HiFi reads. <strong>Hifiasm</strong> produces <strong>two different files</strong> for the <strong>primary</strong> and <strong>alternative</strong> assembly, whereas <strong>HiCanu</strong> <strong>combines</strong> the <strong>primary and the alternative</strong> assembly in the <strong>same FASTA file</strong>.</p>
<p><strong>Scaffolding</strong> </p>
<p>In order to test the necessity of scaffolding, a scaffolder was used to improve the assembly <strong>continuity</strong> and <strong>completeness</strong>, as follows: <strong>Hi-C data are mapped</strong> to the <strong>primary assembly</strong> by <strong>Arima</strong> mapping pipeline (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b39-mmr-0-0-11890">39</a>), to produce a BAM file which is consequently converted to a BED file. <strong>SALSA</strong> (version 2.2) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b40-mmr-0-0-11890">40</a>) uses this BED file which contains the mapping information of Hi-C reads on the assembly, <strong>to scaffold</strong> the primary assembly.</p>
<p><strong>Quality control metrics</strong></p>
<p>QUAST (version 5.0.2)</p>
<p><strong>Genome consistency plots</strong></p>
<p>JupiterPlot (version 1.0) </p>
<h1 id="5-2022-02-PJ-番茄🍅"><a href="#5-2022-02-PJ-番茄🍅" class="headerlink" title="5. 2022.02-PJ 番茄🍅"></a>5. 2022.02-PJ 番茄🍅</h1><blockquote>
<p>A chromosome scale tomato genome built from complementary PacBio and Nanopore sequences alone reveals extensive linkage drag during breeding</p>
</blockquote>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/35106855/">https://pubmed.ncbi.nlm.nih.gov/35106855/</a></p>
<p>PacBio HiFi reads were independently assembled using Hifiasm and Canu, with respective N50 values of 31.3 and 17 Mbp (Table <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-tbl-0002">2</a>). Both HiFi assemblies <strong>contained single contigs that spanned the full length of the SL4.0 reference chromosome 5</strong> (Figure <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#support-information-section">S1</a>). We checked for the completeness of the assembly of gene sequences by Benchmarking Universal Single Copy Orthologs (BUSCO) analysis which showed both assemblies were almost gene complete (both 98.4%), slightly improving upon the SL4.0 genome and comparable to the <em>S. pimpinellifolium</em> ‘LA2093’ genome.</p>
<p><strong>Hifiasm</strong> v0.14.2 (Cheng et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0013">2021</a>) was used to assemble the HiFi reads with default settings. Canu v2.1.1 was used to assemble the HiFi reads in ‘HiCanu’ mode (Nurk et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0050">2020</a>) with an estimated genome size of 916 Mbp based on kmer counting of the raw HiFi data using Jellyfish v2.2.6 (Marçais &amp; Kingsford, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0044">2011</a>).</p>
<p><strong>Quast</strong> v5.0.2 (Mikheenko et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0047">2018</a>) and GAAS v1.1.0 (<a href="https://github.com/NBISweden/GAAS">https://github.com/NBISweden/GAAS</a>) were used to <strong>calculate statistics on fasta files</strong>. BUSCO was calculated using BUSCO v5.2.1 (Seppey et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0068">2019</a>) depending on hmmsearch v3.1, and metaeuk v4.a0f584d was used with lineage datasets solanales (<a href="https://busco-data.ezlab.org/v5/data/lineages/solanales_odb10.2020-08-05.tar.gz">https://busco-data.ezlab.org/v5/data/lineages/solanales_odb10.2020-08-05.tar.gz</a>) and eudicots (<a href="https://busco-data.ezlab.org/v5/data/lineages/eudicots_odb10.2020-09-10.tar.gz">https://busco-data.ezlab.org/v5/data/lineages/eudicots_odb10.2020-09-10.tar.gz</a>) to obtain evolutionarily informed expectations of gene content. To assess the LAI, LTR retriever v2.9.0 (Ou et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0051">2018</a>) was run with default settings on the respective genome assemblies.</p>
<p>We ran one single round of <strong>Salsa</strong> v2.2 (Ghurye et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0026">2019</a>) with optional settings: <strong>-e DNASE -m yes -p yes</strong>.</p>
<p>A modified version of the <strong>convert.sh</strong> script was used to convert the Salsa2 output to a Hi-C file, which was used within a local installation of <strong>Juicebox</strong> (<a href="https://github.com/aidenlab/Juicebox">https://github.com/aidenlab/Juicebox</a>) v1.11.08 to generate a <strong>Hi-C contact plot.</strong></p>
<p>The MbTMV genome assembly was aligned to SL4.0 (Hosmani et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0030">2019</a>) using <strong>Minimap2</strong> v2.17 (Li, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0039">2018</a>) with default settings, followed by running RaGOO v1.11 (Alonge et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0003">2019</a>) with default options.</p>
<h1 id="6-2021-09-gpb-拟南芥"><a href="#6-2021-09-gpb-拟南芥" class="headerlink" title="6. 2021.09-gpb 拟南芥"></a>6. 2021.09-gpb 拟南芥</h1><blockquote>
<p>High-quality Arabidopsis thaliana Genome Assembly with Nanopore and HiFi Long Reads</p>
</blockquote>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/34487862/">https://pubmed.ncbi.nlm.nih.gov/34487862/</a></p>
<p><strong>HiFi sequencing and assembly</strong></p>
<p>Sequencing was performed on a PacBio Sequel II instrument with Sequencing Primer V2 and Sequel II Binding Kit 2.0 at the Genome Center of Grandomics. A total of 22.90 Gb of HiFi reads with ∼157 × coverage were generated, and N50 of the reads was 15,424 bp. HiFi reads were assembled using <strong>hifiasm</strong> v. 0.14-r312 [<a href="https://www.sciencedirect.com/science/article/pii/S1672022921001741?via=ihub#b0085">17]</a>with <strong>default parameters</strong>, and the <strong>gfatools</strong> (<a href="https://github.com/lh3/gfatools">https://github.com/lh3/gfatools</a>) was used to convert sequence graphs in the <strong>GFA to FASTA</strong> format.</p>
<p><strong>Hi-C sequencing and scaffolding</strong></p>
<p>Hi-C library was prepared from cross-linked chromatins of plant cells using a standard Hi-C protocol; the library was then sequenced using Illumina NovaSeq 6000. A total of 21.14 Gb of Hi-C reads with ∼158 × coverage were generated. The Hi-C sequencing data were used to <strong>anchor</strong> all contigs using <strong>Juicer</strong> v. 1.5 [<a href="https://www.sciencedirect.com/science/article/pii/S1672022921001741?via=ihub#b0220">44]</a>, <strong>followed by a 3D-DNA scaffolding pipeline</strong> [<a href="https://www.sciencedirect.com/science/article/pii/S1672022921001741?via=ihub#b0225">45]</a>. Scaffolds were then <strong>manually checked and refined</strong> with <strong>Juicebox</strong> v. 1.11.08 [<a href="https://www.sciencedirect.com/science/article/pii/S1672022921001741?via=ihub#b0230">46]</a>.</p>
<h1 id="7-2021-11-J-Hered-茱萸"><a href="#7-2021-11-J-Hered-茱萸" class="headerlink" title="7. 2021.11-J Hered 茱萸"></a>7. 2021.11-J Hered 茱萸</h1><p><strong>Nuclear Genome Assembly</strong></p>
<p>We assembled the genome of the big berry manzanita following a <strong>protocol</strong> adapted from <strong>Rhie et al</strong>. (2021) as part of the CCGP assembly efforts. The CCGP assembly protocol version 1.0 uses PacBio <strong>HiFi</strong> reads and <strong>Hi-C</strong> chromatin capture data for the generation of high-quality and highly contiguous nuclear genome assemblies. The output corresponding to a diploid assembly consists of <strong>two pseudo haplotypes</strong> (<strong>primary</strong> and <strong>alternate</strong>). The <strong>primary</strong> assembly is <strong>more complete</strong> and consists of <strong>longer phased blocks</strong>. The <strong>alternate</strong> consists of <strong>haplotigs</strong> (contigs of clones with the same haplotype) in <strong>heterozygous regions</strong> and is not as complete and more fragmented. Given the characteristics of the latter, it <strong>cannot be considered on its own</strong> but as <strong>a complement of the primary assembly</strong> (<a href="https://lh3.github.io/2021/04/17/concepts-in-phased-assemblies">https://lh3.github.io/2021/04/17/concepts-in-phased-assemblies</a>, <a href="https://www.ncbi.nlm.nih.gov/grc/help/definitions/">https://www.ncbi.nlm.nih.gov/grc/help/definitions/</a>).</p>
<p>To generate this assembly, we <strong>removed remnant adapter</strong> sequences from the PacBio HiFi dataset using <strong>HiFiAdapterFilt</strong> and assembled the initial set of contigs with the filtered PacBio reads using <strong>HiFiasm</strong> (see Table 1 for assembly pipeline and relevant software). Next, we <strong>identified sequences corresponding to haplotypic duplications and contig overlaps</strong> on the <strong>primary assembly</strong> with <strong>purge_dups</strong> [Version 1.0.1] (Guan et al. 2020) and transferred them to the alternate assembly. We a<strong>ligned the Hi-C data</strong> to both <strong>primary and alternate assemblies</strong> using the <strong>Arima Genomics Mapping Pipeline</strong> (<a href="https://github.com/ArimaGenomics/mapping_pipeline">https://github.com/ArimaGenomics/mapping_pipeline</a>) and <strong>scaffolded</strong> the genomes using <strong>SALSA</strong> [Version 2, options –e GATCGATC] (Ghurye et al. 2017; Ghurye et al. 2019). We <strong>closed the generated gaps</strong> in both <strong>assemblies</strong> using the PacBio <strong>HiFi</strong> reads and <strong>YAGCloser</strong> (<a href="https://github.com/merlyescalona/yagcloser">https://github.com/merlyescalona/yagcloser</a>). The <strong>primary assembly</strong> was <strong>manually curated</strong> by <strong>iteratively generating and analyzing</strong> Hi-C <strong>contact maps</strong>. To generate the contact maps, we <strong>aligned</strong> the <strong>Hi-C</strong> data against the corresponding reference with <strong>bwa</strong> mem, identified ligation junctions, and generated <strong>Hi-C pairs</strong> using <strong>pairtools</strong> [Version 0.3.0] (Goloborodko et al. 2018). We generated a multi-resolution <strong>Hi-C matrix</strong> in binary form with <strong>cooler</strong> [Version 0.8.10] (Abdennur and Mirny 2020) and balanced it with <strong>hicExplorer</strong> [Version 3.6] (Ramírez et al. 2018). We used <strong>HiGlass</strong> [Version 2.1.11] (Kerpedjiev et al. 2018) and the <strong>PretextSuite</strong> (<a href="https://github.com/wtsi-hpag/PretextView">https://github.com/wtsi-hpag/PretextView</a>; <a href="https://github.com/wtsihpag/PretextMap">https://github.com/wtsihpag/PretextMap</a>; <a href="https://github.com/wtsi-hpag/PretextSnapshot">https://github.com/wtsi-hpag/PretextSnapshot</a>) to <strong>visualize the contact maps</strong>. Assemblies were then checked for contamination using the <strong>BlobToolKit Framework</strong> [Version 2.3.3] (Challis et al. 2020), and <strong>trimmed</strong> for remnants of sequence adaptors and <strong>mitochondrial</strong> contamination.</p>
<p>Table1 Assembly pipeline and software usage. Software citations are listed in the text</p>
<table>
<thead>
<tr>
<th>Assembly</th>
<th align="left">Software</th>
<th align="left">Version</th>
</tr>
</thead>
<tbody><tr>
<td>Filtering PacBio HiFi adapters</td>
<td align="left">HiFiAdapterFilt   <a href="https://github.com/sheinasim/HiFiAdapterFilt">https://github.com/sheinasim/HiFiAdapterFilt</a></td>
<td align="left">Commit 64d1c7b</td>
</tr>
<tr>
<td>K-mer counting</td>
<td align="left">Meryl</td>
<td align="left">1</td>
</tr>
<tr>
<td>Estimation of genome size and heterozygosity</td>
<td align="left"><font color="green"><strong>GenomeScope</strong> </font></td>
<td align="left">2</td>
</tr>
<tr>
<td><em>De novo</em> assembly (contiging)</td>
<td align="left"><font color="green"><strong>HiFiasm</strong> </font></td>
<td align="left">0.13-r308</td>
</tr>
<tr>
<td>Long read, genome-genome alignment</td>
<td align="left"><font color="green"><strong>minimap2</strong> </font></td>
<td align="left">2.16</td>
</tr>
<tr>
<td>Remove low-coverage, duplicated contigs</td>
<td align="left"><font color="green"><strong>purge_dups</strong></font></td>
<td align="left">1.0.1</td>
</tr>
<tr>
<td><strong>Scaffolding</strong></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td>Hi-C mapping for SALSA</td>
<td align="left"><font color="green"><strong>Arima</strong></font> Genomics mapping pipeline   <a href="https://github.com/ArimaGenomics/mapping_pipeline">https://github.com/ArimaGenomics/mapping_pipeline</a></td>
<td align="left">2e74ea4</td>
</tr>
<tr>
<td>Hi-C Scaffolding</td>
<td align="left"><font color="green"><strong>SALSA</strong> </font></td>
<td align="left">2</td>
</tr>
<tr>
<td>Gap closing</td>
<td align="left">YAGCloser?   <a href="https://github.com/merlyescalona/yagcloser">https://github.com/merlyescalona/yagcloser</a></td>
<td align="left">20e2769</td>
</tr>
<tr>
<td><strong>Hi-C contact map generation</strong></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td>Short-read alignment</td>
<td align="left">bwa</td>
<td align="left">0.7.17-r1188</td>
</tr>
<tr>
<td>SAM/BAM processing</td>
<td align="left">samtools</td>
<td align="left">1.11</td>
</tr>
<tr>
<td>SAM/BAM filtering</td>
<td align="left">pairtools</td>
<td align="left">0.3.0</td>
</tr>
<tr>
<td>Pairs indexing</td>
<td align="left">pairix</td>
<td align="left">0.3.7</td>
</tr>
<tr>
<td>Matrix generation</td>
<td align="left">Cooler</td>
<td align="left">0.8.10</td>
</tr>
<tr>
<td>Matrix balancing</td>
<td align="left">hicExplorer</td>
<td align="left">3.6</td>
</tr>
<tr>
<td>Contact map visualization</td>
<td align="left">HiGlass</td>
<td align="left">2.1.11</td>
</tr>
<tr>
<td></td>
<td align="left">PretextMap</td>
<td align="left">0.1.4</td>
</tr>
<tr>
<td></td>
<td align="left">PretextView</td>
<td align="left">0.1.5</td>
</tr>
<tr>
<td></td>
<td align="left">PretextSnapshot</td>
<td align="left">0.0.3</td>
</tr>
<tr>
<td><strong>Organelle assembly</strong></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td>Sequence similarity search</td>
<td align="left"><font color="green">BLAST+ </font></td>
<td align="left">2.10</td>
</tr>
<tr>
<td>Long read alignment</td>
<td align="left"><font color="green">Pbmm2</font> (<a href="https://github.com/PacificBiosciences/pbmm2">https://github.com/PacificBiosciences/pbmm2</a>)</td>
<td align="left">1.4.0</td>
</tr>
<tr>
<td>Variant calling and consensus</td>
<td align="left">bcftools</td>
<td align="left">1.11-5</td>
</tr>
<tr>
<td>Extraction of sequences</td>
<td align="left">seqtk</td>
<td align="left">1.3-r115</td>
</tr>
<tr>
<td>Circular-aware long-read alignment</td>
<td align="left"><font color="green">racon </font></td>
<td align="left">1.4.19</td>
</tr>
<tr>
<td>Sequence polishing</td>
<td align="left">raptor</td>
<td align="left">0.20.3</td>
</tr>
<tr>
<td>Sequence alignment</td>
<td align="left">lastz</td>
<td align="left">1.04.08</td>
</tr>
<tr>
<td>Gene annotation</td>
<td align="left">MitoFinder</td>
<td align="left">1.4</td>
</tr>
<tr>
<td><strong>Genome quality assessment</strong></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td>Basic assembly metrics</td>
<td align="left"><font color="green"><strong>QUAST</strong> </font></td>
<td align="left">5.0.2</td>
</tr>
<tr>
<td>Assembly completeness</td>
<td align="left"><font color="green"><strong>BUSCO</strong> </font></td>
<td align="left">5.0.0</td>
</tr>
<tr>
<td></td>
<td align="left">Merqury</td>
<td align="left">1</td>
</tr>
<tr>
<td><strong>Contamination screening</strong></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td>General contamination screening</td>
<td align="left">BlobToolKit</td>
<td align="left">2.3.3</td>
</tr>
</tbody></table>
<p><strong>Mitochondrial Genome Assembly</strong></p>
<p>We identified <strong>a subset of mitochondrial reads from the PacBio HiFi</strong> dataset using <strong>BLAST+</strong>  by identifying regions of similarity between the reads and the mitochondrial <strong>(mito) database</strong> (NCBI). These mitochondrial reads were used as input in <strong>HiFiasm</strong> [Version 0.13-r308] to generate the <strong>mitochondrial</strong> <strong>assembly</strong>. Given the circularity of the mitochondrial genome, we carried out self-alignment of the sequence using <strong>lastz</strong> [Version 1.04.08] (Harris 2007) to <strong>manually identify and remove duplicated regions</strong>. We aligned the subset of mitochondrial reads to the assembly using <strong>raptor</strong> [Version 0.20.3-171e0f1] (<a href="https://github.com/isovic/raptor">https://github.com/isovic/raptor</a>) and <strong>polished</strong> it with <strong>racon</strong> [Version 1.14.] (<a href="https://github.com/isovic/racon">https://github.com/isovic/racon</a>). We searched for <strong>matches</strong> of the resulting <strong>mitochondrial assembly</strong> sequence in the nuclear genome assembly using <strong>BLAST+</strong> and <strong>filtered out scaffolds from the nuclear genome</strong> with a percentage of <strong>sequence identity &gt;99%</strong> and <strong>size smaller than the mitochondrial assembly sequence</strong>. From the <strong>subset of mitochondrial reads</strong> used for the assembly, we analyzed the <strong>BLAST</strong> output and <strong>the species of the closest mitochondrial sequence</strong> available in the NCBI GenBank database, <em>Vaccinium macrocarpon</em> (Accession number: <a href="https://www.ncbi.nlm.nih.gov/nuccore/NC_023338.1">NC_023338.1</a>). We used the mitochondrial assembly of <em>V. macrocarpon</em> as a <strong>guide</strong> for the <strong>mitochondrial gene annotation</strong> generated with <strong>MitoFinder</strong> [Version 1.4] (Allio et al. 2020).</p>
<p><strong>Chloroplast Genome Assembly</strong></p>
<p>We identified chloroplast reads from the PacBio HiFi dataset with BLAST+ using the plastids RefSeq genomes [v4.1] (O’Leary et al. 2016). From this subset, we analyzed the matches and identified the species of the closest chloroplast sequence available in the NCBI database as <em>Camellia taliensis</em> (NC_022264.1). Next, we found matches of the <em>C. taliensis</em> chloroplast genome sequence in the nuclear genome assembly with BLAST+ and filtered out scaffolds from the nuclear genome assembly with length smaller than the <em>C. taliensis</em> length, sequence identity &gt;90%, and <em>e</em>-value &lt;0.00001. We aligned the filtered scaffolds to the <em>C. taliensis</em> chloroplast genome with minimap2 (Li 2018) and generated a consensus sequence with bcftools (Li 2011). We manually curated the sequence using lastz. Finally, we polished the last assembly version using raptor and racon and annotated it using the web platform GeSeq (Tillich et al. 2017).</p>
<h1 id="8-2022-02-pj-澳洲坚果-value"><a href="#8-2022-02-pj-澳洲坚果-value" class="headerlink" title="8. 2022.02-pj 澳洲坚果 value"></a>8. 2022.02-pj 澳洲坚果 value</h1><blockquote>
<p> De novo chromosome level assembly of a plant genome from long read sequence data</p>
</blockquote>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/34784084/">https://pubmed.ncbi.nlm.nih.gov/34784084/</a></p>
<p>We now report the use of <strong>HiFiasm</strong> to assemble the genome of Macadamia jansenii, a genome that has been used as a model to test sequencing and assembly. This achieved <strong>almost complete chromosome level assembly</strong> from the sequence data alone <strong>without</strong> the need for <strong>higher level chromosome map information</strong>. <strong>Eight of the 14 chromosomes were represented by a single large contig</strong> (six with telomere repeats at both ends) and the <strong>other six assembled from two to four main contigs</strong>. The small number of chromosome breaks appears to be the result of <strong>highly repetitive regions</strong> including ribosomal genes that cannot be assembled by these approaches. </p>
<p>Table 1. HiFiasm contigs in different size categories and comparison of primary and haploid assemblies generated from HiFiasm genome assembler tool</p>
<table>
<thead>
<tr>
<th align="left">Number of contigs</th>
<th align="left">Assembly length (Mb)</th>
<th align="left">N50 (Mb)</th>
<th align="left">N75 (Mb)</th>
<th align="left">busco(%)</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td align="left">HiFiasm assembly</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td></td>
</tr>
<tr>
<td align="left">Total contigs</td>
<td align="left">779</td>
<td align="left">826</td>
<td align="left">46</td>
<td align="left">25</td>
<td>99.6</td>
</tr>
<tr>
<td align="left">Contigs &gt;40 Mb</td>
<td align="left">10</td>
<td align="left">524</td>
<td align="left">50</td>
<td align="left">46</td>
<td>68.7</td>
</tr>
<tr>
<td align="left">Contigs &gt;10 Mb</td>
<td align="left">19</td>
<td align="left">746</td>
<td align="left">48</td>
<td align="left">39</td>
<td>93.9</td>
</tr>
<tr>
<td align="left">Contigs &gt;1 Mb</td>
<td align="left">30</td>
<td align="left">784</td>
<td align="left">46</td>
<td align="left">30</td>
<td>99.1</td>
</tr>
<tr>
<td align="left">Contigs &gt;100 kb</td>
<td align="left">94</td>
<td align="left">805</td>
<td align="left">46</td>
<td align="left">27</td>
<td>99.0</td>
</tr>
<tr>
<td align="left">Between 100 kb and 1 Mb</td>
<td align="left">64</td>
<td align="left">20</td>
<td align="left">0.49</td>
<td align="left">0.22</td>
<td>0.20</td>
</tr>
<tr>
<td align="left">Between 10 kb and 100 kb</td>
<td align="left">685</td>
<td align="left">22</td>
<td align="left">0.032</td>
<td align="left">0.028</td>
<td>0.00</td>
</tr>
<tr>
<td align="left">Comparison of HiFiasm primary and haploid assemblies</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td></td>
</tr>
<tr>
<td align="left">Primary assembly</td>
<td align="left">779</td>
<td align="left">827</td>
<td align="left">46.1</td>
<td align="left">25</td>
<td>99.60</td>
</tr>
<tr>
<td align="left">Hap 1_assembly</td>
<td align="left">879</td>
<td align="left">816</td>
<td align="left">24.4</td>
<td align="left">8.9</td>
<td>98.80</td>
</tr>
<tr>
<td align="left">Hap 2_assembly</td>
<td align="left">363</td>
<td align="left">776</td>
<td align="left">14.3</td>
<td align="left">5.4</td>
<td>97.90</td>
</tr>
<tr>
<td align="left">Hap 1 &gt;1 Mb</td>
<td align="left">96</td>
<td align="left">736</td>
<td align="left">16.4</td>
<td align="left">6.8</td>
<td>96.70</td>
</tr>
<tr>
<td align="left">Hap 2 &gt;1 Mb</td>
<td align="left">72</td>
<td align="left">766</td>
<td align="left">24.5</td>
<td align="left">12.3</td>
<td>98.10</td>
</tr>
</tbody></table>
<p><strong>HiFiasm assembly</strong></p>
<p>For assembly, <strong>24 core</strong> processing units and <strong>120 Gb of memory</strong> was employed. Default settings of the HiFiasm assembler were used to assemble heterozygous genomes with <strong>built-in duplication purging parameters</strong>. The HiFiasm output directory consists of two haploid (1 and 2), one primary contig and one alternate haplotig GFA graph files. Each halplotig and one primary contig GFA file was converted to FASTA format using the <strong>awk</strong> command.</p>
<p><strong>Analysis of assembly</strong></p>
<p>The primary HiFiasm assembly of <em>M. jansenii</em> included 779 contigs that were categorised into three subsets: (i) contigs &lt;1 Mb size; (ii) contigs &lt;1 Mb and more than 100 kb size; and (iii) contigs &lt;100 kb size. Along with the <strong>main primary and two haploid assemblies</strong>, all <strong>three</strong> sets of primary contig subsets were <strong>passed</strong> through analysis using <strong>quast</strong> (Gurevich et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0010">2013</a>), <strong>busco</strong> (Simão et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0028">2015</a>) and <strong>repeatmodeler</strong> (Humann et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0012">2019</a>). The <strong>telomere sequences</strong> in the HiFiasm <strong>contigs</strong> were identified using the <strong>bioserf platform</strong> (<a href="https://bioserf.org/">https://bioserf.org</a>) (Somanathan and Baysdorfer, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0029">2018</a>). <strong>Ribosomal RNA</strong> and <strong>other protein coding genes</strong> at the <strong>terminal</strong> end of the HiFiasm contigs were identified using an <strong>ncbi blast search</strong> (<a href="https://blast.ncbi.nlm.nih.gov/">https://blast.ncbi.nlm.nih.gov</a>). Ribosomal RNA in the contigs was identified using <strong>Barrnap</strong> (<a href="https://github.com/tseemann/barrnap">https://github.com/tseemann/barrnap</a>) (Seemann, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0023">2013</a>) with default settings for eukaryotes.</p>
<p><strong>Comparison with Hi-C assembly</strong></p>
<p>The HiFiasm contigs were compared with the <em>M. jansenii</em> 14 pseudo-molecules from the Hi-C assembly (Sharma et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0026">2021b</a>) using the online interactive D-Genies dotplot tool (Cabanettes and Klopp, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0003">2018</a>) to <strong>compare two genomes using Minimap2</strong> and, for <strong>alignments</strong>, dotplot images were created after selecting the ‘sort contigs’ option, selecting the ‘minimum identity’ parameter at 0.75 and checking the ‘strong precision’ tick box.</p>
<p><strong>Characterisation of organelle genomes content of HiFiasm contigs</strong></p>
<p>A reference <font color="red"><strong>mitochondrial</strong> genome, <strong>chloroplast</strong> genome and <strong>nuclear ribosomal RNA</strong> sequence</font> from this sample were assembled from <strong>Illumina raw reads</strong> (Murigneux et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0020">2020</a>) using the <strong>GetOrganelle toolkit</strong> (Jin et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0013">2020</a>) with default parameters. The <strong>HiFiasm contigs</strong> (779) were <strong>compared with</strong> the <strong>organellar and ribosomal sequences</strong> in dotplots.</p>
<h1 id="9-2021-04-Mol-Ecol-Resour-百香果"><a href="#9-2021-04-Mol-Ecol-Resour-百香果" class="headerlink" title="9. 2021.04-Mol Ecol Resour 百香果"></a>9. 2021.04-Mol Ecol Resour 百香果</h1><p><a href="https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13310">https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13310</a></p>
<blockquote>
<p>Chromosome-level reference genome assembly provides insights into aroma biosynthesis in passion fruit (Passiflora edulis)</p>
</blockquote>
<p>The assembled reference genome is 1.28 Gb size with a scaffold N50 of 126.4 Mb and 99.22% sequences anchored onto nine pseudochromosomes. 以往的核型分析表明百香果是一种二倍体，9对染色体</p>
<p><strong>Genome survey and assembly</strong><br>A total of 89.12 Gb of high-quality paired-end reads were obtained by <strong>Illumina</strong> genomic sequencing (~70.35X coverage, Table S1). The genome size, heterozygosity and repeat content were estimated based on k-mer distribution using <strong>21-mers</strong> extracted from the Illumina short reads. The estimated genome size was further validated using <strong>flow cytometr</strong>y. A total of 223.91 Gb raw PacBio subreads were filtered and corrected using pbccs pipeline with default parameters (<a href="https://github.com/PacificBiosciences/ccs">https://github.com/PacificBiosciences/ccs</a>). The resulted CCS reads were subjected to hifiasm for de novo assembly. We <font color="red"><strong>corrected</strong> the <strong>primary contigs</strong> by the <strong>Pilon</strong></font> (version1.18) (Utturkar, Klingeman, Hurt, &amp; Brown, 2017) program <strong>using 89.12 Gb (70.35×) of Illumina paired-end reads</strong>. BWA (version0.7.10-r789) (Li, 2013) and SAMtools (version1.9) (Li et al., 2009) were used for reads alignment and SAM/BAM format conversion. <strong>BUSCO</strong> (version3.0) (Simao, Waterhouse, Ioannidis, Kriventseva, &amp; Zdobnov, 2015) program with embryophyta_odb10 database were used to assess the completeness of genome and gene annotation .</p>
<p><strong>Chromosome assembly using Hi-C</strong></p>
<p>Approximately 96.4 Gb of Hi-C data were generated. The raw data were filtered using perl script as implemented in the software <strong>LACHESIS</strong> (Burton et al., 2013). BWA software was used to <strong>map the Hi-C reads to the draft assembly</strong> and <strong>uniquely mapped reads were selected for furtheranalysis</strong>. We further applied our newly developed <strong>ALLHiC pipeline</strong> to link the contigs into <strong>nine pseudo-chromosomes</strong>. <strong>HiC-pro</strong> (version2.10.0) (Servant et al., 2015) program was used to <strong>calculate Hi-C mapping rate and evaluate the quality of Hi-C scaffolding</strong>.</p>
<h1 id="10-2021-10-MolEcolResour-牡蛎🦪"><a href="#10-2021-10-MolEcolResour-牡蛎🦪" class="headerlink" title="10. 2021-10-MolEcolResour 牡蛎🦪"></a>10. 2021-10-MolEcolResour 牡蛎🦪</h1><blockquote>
<p>Chromosome-level genome and population genomic analysis provide insights into the evolution and environmental adaptation of Jinjiang oyster Crassostrea ariakensis</p>
</blockquote>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/34800349/">https://pubmed.ncbi.nlm.nih.gov/34800349/</a></p>
<p>The C. ariakensis genome was 662.9 Mb with contig N50 length of 5.9 Mb using PacBio HiFi-CCS long reads, and 99.83% sequences were anchored onto 10 pseudochromosomes using Hi-C data.</p>
<h1 id="11-2021-10-Front-Genet-思茅松毛虫"><a href="#11-2021-10-Front-Genet-思茅松毛虫" class="headerlink" title="11. 2021.10-Front Genet 思茅松毛虫"></a>11. 2021.10-Front Genet 思茅松毛虫</h1><blockquote>
<p>Chromosome-Level Genome Assembly Reveals Significant Gene Expansion in the Toll and IMD Signaling Pathways of <em>Dendrolimus kikuchii</em></p>
</blockquote>
<p>forest pests</p>
<p>Overall, a final genome assembly of 705.51 Mb with contig and scaffold N50 values of 20.89 and 24.73 Mb, respectively, was obtained. Of these contigs, 95.89% had unique locations on 29 chromosomes.</p>
<p><strong>Genome Assembly and Polish</strong></p>
<p>After quality control of raw reads, the pass reads were used for <em>de novo</em> genome assembly of using an <strong>OLC (overlap layout-consensus)/string graph method</strong> with NextDenovo (v2.3.0) with reads_cutoff:1 k and seed_cutoff:30 k. Firstly, self-correction of the original subreads was finished by NextCorrect to obtain consistent sequences (CNS reads). Then, CNS reads were used to obtain preliminary assembly through NextGraph (default parameter). The ONT, CCS and Hi-C data were used to correct the preliminary assembly using Racon (v1.3.1, default, CCS data) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B66">Vaser et al., 2017</a>)and Nextpolish (v1.2.4, default, ONT and Hi-C data) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B24">Hu et al., 2020</a>). <strong>BlastN was used to check the genome contamination</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#s10">Supplementary information S2</a>).</p>
<p>Completeness of the genome assembly was assessed using <strong>BUSCO</strong> v4.0.5 (Benchmarking universal Single-Copy Orthologs) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B58">Simao et al., 2015</a>) and CEGMA (Core Eukaryotic Gene Mapping Approach) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B55">Parra et al., 2007</a>). <strong>To evaluate the accuracy of the assembly</strong>, all <strong>paired-end reads were mapped to the assembled</strong> genome using <strong>BWA</strong>  (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B39">Li and Durbin, 2010</a>) and the <strong>mapping rate</strong> and the genome coverage of sequencing reads were both assessed using SAMtools v0.1.1855 (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B40">Li et al., 2009</a>). In addition, the base accuracy of the assembly was calculated using bcftools (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B13">Danecek and Mccarthy, 2017</a>). Coverage of the expressed genes of the assembly was examined by aligning all the RNA-seq reads against the assembly using HISAT with default parameters. <strong>To ensure that mitochondrial sequences were not included in the assembly,</strong> the draft genome assembly was submitted to the <strong>NT library</strong> and matching sequences were eliminated.</p>
<p><strong>Genome Anchoring to Chromosome</strong></p>
<p>The read quality (370 million paired-end reads) was controlled using Hi-C-Pro. Firstly low-quality sequences (quality scores &lt;20), adaptor sequences, and sequences shorter than 30 bp were filtered out using <strong>fastp</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B10">Chen et al., 2018</a>). Next, clean reads were mapped to the draft assembled sequence using <strong>bowtie2</strong> (v2.3.2) (-end-to-end –very-sensitive -L 30) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B37">Langmead and Salzberg, 2012</a>) to obtain the unique mapped paired-end reads. Invalid read pairs were filtered using <strong>HiC-Pro</strong> (v2.8.1) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B57">Servant et al., 2015</a>). The scaffolds were further <strong>clustered, ordered, and oriented onto chromosomes</strong> by <strong>LACHESIS</strong> (<a href="https://github.com/shendurelab/LACHESIS">https://github.com/shendurelab/LACHESIS</a>), with parameters <strong>CLUSTER_MIN_RE_SITES = 100, CLUSTER_MAX_LINK_DENSITY = 2.5, CLUSTER NONINFORMATIVE RATIO = 1.4, ORDER MIN N RES IN TRUNK = 60, ORDER MIN N RES IN SHREDS = 60.</strong> Lastly, placement and orientation errors exhibiting obvious discrete chromatin interaction patterns were <strong>manually adjusted</strong>.</p>
<p><strong>Synteny</strong> of the <em>D. kikuchii</em> <strong>genome</strong> with the <em>D. punctatus</em> <strong>genomes</strong> was analyzed using <strong>Minimap2</strong> and <strong>dotPlotly</strong> to identify chromosome structural changes among the two species.</p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>HiFi-6-[HiFi-HiC-assembly-method]</title>
    <url>/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/</url>
    <content><![CDATA[<p>辅助组装案例</p>
<span id="more"></span>

<h1 id="1-2016-05-np-碧冬茄"><a href="#1-2016-05-np-碧冬茄" class="headerlink" title="1. 2016.05-np 碧冬茄"></a>1. 2016.05-np 碧冬茄</h1><p><strong>Insight into the evolution of the Solanaceae from the parental genomes of Petunia hybrida</strong></p>
<h2 id="Genome-sequencing-assembly-and-annotation"><a href="#Genome-sequencing-assembly-and-annotation" class="headerlink" title="Genome sequencing, assembly and annotation."></a>Genome sequencing, assembly and annotation.</h2><p>Plants were grown and DNA was extracted following the methods described at Supplementary Note 1.</p>
<p>Illumina libraries with 0.17-, 0.35-, 0.5-, 0.8-, 1-, 2-, 5-, 8- and 15-kb inserts were sequenced at BGI-Shenzghen and University of Illinois, Roy J. Carver Biotechnology. PacBio P. axillaris DNA library was sequenced with P4/C2 chemistry.</p>
<p>Illumina reads were processed using <strong>Fastq-mcf</strong> (<strong>quality filtering</strong>; <a href="https://code.google.com/p/eautils/wiki/FastqMcf">https://code.google.com/p/eautils/wiki/FastqMcf</a>), <strong>PRINSEQ</strong> (<strong>duplication filtering</strong>; http:// prinseq.sourceforge.net/) and <strong>Musket</strong> (<strong>error correction</strong>; <a href="http://musket.sourceforge/">http://musket.sourceforge</a>. net/). <strong>Pacbio reads</strong> were processed using the <strong>SMRT Analysis pipeline</strong> (v.2.0.1; <a href="https://github.com/PacificBiosciences/SMRT-Analysis">https://github.com/PacificBiosciences/SMRT-Analysis</a>).</p>
<p>Both genomes were assembled with <strong>SOAPdenovo</strong> with different k-mer sizes. For both genomes, <strong>k-mer = 79</strong> showed the best statistics. Gaps between contigs were completed using <strong>GapCloser</strong> . Additionally for P. axillaris, <strong>PacBio reads</strong> were integrated in <strong>four different steps</strong>: (1) <strong>Rescaffolding</strong> of the <strong>Illumina contigs</strong> using the <strong>PacBio reads</strong> and the <strong>AHA assembler</strong>; (2) <strong>Gap filling</strong> using <strong>PBJelly</strong>; (3) <strong>Rescaffolding</strong> using the Illumina <strong>pair data</strong> and <strong>SSPACE</strong>; (4) Last round of <strong>gap filling</strong> using <strong>PBJelly</strong> . </p>
<p><strong>Genome size estimation</strong> was performed through the k-mers abundance distribution (<strong>k-mer = 31</strong>). <strong>Heterozygosity</strong> was <strong>estimated</strong> mapping the Illumina reads to the assemblies using <strong>Bowtie2</strong>, calling SNPs using <strong>FreeBayes</strong> and  annotating the SNPs using <strong>SnpEff</strong> .</p>
<p>The genome structural annotation was performed using <strong>Maker-P</strong>: (1) <strong>SNAP</strong> and <strong>Augustus</strong> as ab initio gene predictors; (2) Exonerate as experimental based predictor with 454 and Illumina RNASeq reads and protein sequences from different protein datasets. RNAseq Illumina data was mapped using <strong>Tophat2</strong> . tRNAs were annotated using <strong>tRNAscan</strong> (<a href="http://lowelab.ucsc.edu/tRNAscan-SE/">http://lowelab.ucsc.edu/tRNAscan-SE/</a>).</p>
<p>The <strong>gene functional annotation</strong> was performed by <strong>sequence homology search</strong> with different protein datasets using <strong>BlastP</strong> and protein domains search using <strong>InterProScan</strong> . Functional annotations were integrated using <strong>AHRD</strong> (<a href="https://github.com/groupschoof/AHRD">https://github.com/groupschoof/AHRD</a>). See Supplementary Note 1.</p>
<h2 id="Repetitive-elements-analysis"><a href="#Repetitive-elements-analysis" class="headerlink" title="Repetitive elements analysis"></a>Repetitive elements analysis</h2><p>Repeat annotation was performed using RepeatModeler (v1.0.8; <a href="http://www.repeatmasker.org/RepeatModeler.html">http://www.repeatmasker.org/RepeatModeler.html</a>), RepeatMasker (v4.0.5; <a href="http://www.repeatmasker.org/">http://www.repeatmasker.org</a>) with the repeat database Repbase (release 20140131; <a href="http://www.girinst.org/repbase/">http://www.girinst.org/repbase/</a>) and Geneious (v7.1.4; <a href="http://www.geneious.com/">http://www.geneious.com</a>). Identification of PVCV-like and EPRV elements was performed using BlastN and TBlastN . The identified sequences were aligned with ClustalW (MEGA5 package;<a href="http://www.megasoftware.net/">http://www.megasoftware.net/</a>) and then manually curated. RepeatExplorer (<a href="http://www.repeatexplorer.org/">http://www.repeatexplorer.org/</a>) and other methods were used to extend the analysis to unassembled repeats. Fluorescent in situ hybridization was performed in root tips from young P. axillaris and P. inflata plants for 5S rDNA and three PVCV viral probes following the procedure described in Supplementary Note 2.</p>
<p>The detection of dTph1 loci in P. hybrida W138 was performed through a BLAST40 search of the P. axillaris and P. inflata dTph1 elements including the 500 bp of flanking sequence against the TFS W138 collection. Polymorphisms found in the genomic flanking regions were used to identify the species of origin. dTph1 elements were identified in a P. axillaris population using a modification of the methodology described in Supplementary Note 3.</p>
<p>##Whole-genome duplication, tandem duplications and gene family analysis</p>
<p>Whole-genome collinear analysis was performed using SynMap and microsynteny analysis were performed using GEvo in the comparative genomics platform, CoGe .See Supplementary Note 5.</p>
<p>The gene family analysis included Solanum lycopersicum, S. tuberosum, Nicotiana benthamiana and Arabidopsis thaliana protein sets using BlastP (v2.2.27) on an all-versus-all comparison and grouping the genes into families with OrthoMCL, v2.0.8. See Supplementary Note 4.</p>
<h2 id="Gene-data-mining"><a href="#Gene-data-mining" class="headerlink" title="Gene data mining"></a>Gene data mining</h2><p>The specific identification of genes for P. axillaris and P. inflata genomes for colour and scent, root-specific pathways, self-incompatibility and circadian clock was performed through a BlastN/BlastP sequence homology search. Blast GUI, JBrowser (<a href="http://jbrowse.org/">http://jbrowse.org/</a>) and WebApollo (<a href="http://genomearchitect/">http://genomearchitect</a>. org/) were installed in a server to search and manually curate the gene structures of the identified genes. See Supplementary Notes 7, 8 and 10–12.</p>
<h1 id="2-2017-04-ng-山羊🐐"><a href="#2-2017-04-ng-山羊🐐" class="headerlink" title="2. 2017.04-ng 山羊🐐"></a>2. 2017.04-ng 山羊🐐</h1><p>Published in final edited form as:Nat Genet. 2017 April ; 49(4): 643–650. doi:10.1038/ng.3802.</p>
<p><strong>Single-molecule sequencing and chromatin conformation capture enable</strong> <strong>de novo</strong> <strong>reference assembly of the domestic goat genome</strong></p>
<p>​        首次在人之外的物种中直接de novo组装出染色体水平的基因组。利用<font color="blue"><strong>Pacbio+BioNano+Hi-C+Illumina</strong> 多层级</font>的策略，组装了一只山羊(Capra hircus)的基因组，获得<font color="blue"><strong>31</strong>个<strong>scaffold</strong>，<strong>663</strong>个<strong>gap</strong>区，scaffold <strong>N50</strong> 惊人地达到<strong>87M</strong>，几乎<strong>one scaffold one chromosome</strong></font>，并且成功地组装出<font color="blue"><strong>免疫基因区</strong>和<strong>大部分重复序列家族</strong></font>。</p>
<p>​        <font color="red">人的GRCh38版本有<strong>24</strong>个<strong>scaffold</strong>，<strong>169</strong>个<strong>unplacedscaffold</strong>，<strong>832个gap</strong>区</font>。</p>
<p>​        从<strong>96头</strong>山羊(<strong>6个品种</strong>)中，利用Illumina的 Caprine53K <font color="blue"><strong>SNP 芯片筛选</strong></font>出<font color="blue"><strong>基因型纯和度最高</strong></font>的个体用来<font color="blue"><strong>组装</strong></font>(San Clemente breed)。</p>
<h2 id="data"><a href="#data" class="headerlink" title="data"></a>data</h2><ol>
<li><p>Pacbio数据</p>
<p>一共产生465个SMRT cell的数据。其中使用P5-C3试剂的311个cell;使用P4-C2试剂的142个cell，XL-C2试剂的12个cell。数据量194G，覆盖深度达<strong>69X</strong>，<strong>subread</strong>的<strong>平均</strong>长度为<strong>5,110bp</strong>。</p>
</li>
<li><p>BioNano 数据</p>
<p>由于采样所用山羊意外死亡，其DNA不能满足Irsy optical mapping 测序需求，只好用其<strong>雄性后代</strong>采样。Optical map一共产生256Gb数据，覆盖<strong>98 X</strong>。</p>
</li>
<li><p>Hi-C数据</p>
<p>采样动物是最初那只山羊。Hi-C建库，序列用物理方法打断成300-500bp长度，PE101测序，产生<strong>115M reads</strong>的数据量。</p>
</li>
<li><p>Illumina 数据</p>
<p>采样最初那只山羊，PE251建库测序，获得<strong>23X</strong>的数据覆盖，用来做最后的<font color="red"><strong>错误校正</strong></font></p>
</li>
</ol>
<h2 id="组装策略及组装结果"><a href="#组装策略及组装结果" class="headerlink" title="组装策略及组装结果"></a><strong>组装策略及组装结果</strong></h2><ul>
<li><p>先用Pacbio的 long-read 数据构建contig， 使用<font color="blue"><strong>Celera Assembler</strong> PacBio corrected Reads 流程</font>组装。获得<font color="blue"><strong>3,074</strong>个contig(2.63G)，<strong>N50 4.159M</strong>b</font>。</p>
</li>
<li><p>接下来采用<font color="blue"><strong>Irys optical mapping</strong>数据构建<strong>scaffold</strong></font>，使用软件为<font color="blue"><strong>IrysView</strong></font>. 产生<font color="blue"><strong>842</strong>个scaffold，scaffold N50为<strong>13.4M</strong>b，contig N50为10.858M，最长scaffold为66.728Mb</font>。 利用<font color="red"><strong>radiation hybrid(RH) map比较</strong>发现</font>，<font color="blue">PacBio-Irys 联合</font>的方法已经<font color="blue">完整组装出<strong>20号染色体</strong></font>。</p>
</li>
<li><p>接下来用Hi-C数据，调用用<font color="red"><strong>Lachesis软件包</strong></font>，结合PacBio-Irys的结果，即整合的PacBio-Irys-PGA (PBIP)方法，获得较完美的组装结果。<font color="blue">Scaffold N50</font> 达到惊人的<font color="blue"><strong>87.347Mb</strong></font>(远超今年尖吻鲈，大猩猩N50 20Mb的高起点)，总共获得<font color="blue"><strong>31条</strong>scaffold</font>，(<font color="red">31,261条&lt;50kbp的**degenerate scaffold**不计入</font> )。</p>
</li>
<li><p>最后利用Illumina数据做<font color="red"><strong>一致性校正</strong>和最后的<strong>补洞</strong></font>，最后使得contig的数目下降到680条，产生的gap数目为663个。</p>
</li>
<li><p>利用Kraken v0.10.5 <font color="red">去除有<strong>病毒和细菌污染</strong>的序列</font>，去掉有NCBI vector污染的序列。获得最终的基因组 版本<strong>ARS1</strong>。</p>
</li>
</ul>
<h2 id="组装评估及比较分析"><a href="#组装评估及比较分析" class="headerlink" title="组装评估及比较分析"></a><strong>组装评估及比较分析</strong></h2><p>由于山羊之前已经产生过两个基因组版本<strong>CHIR_1.0、CHIR_2.0</strong>，可以用来做比较 分析，并且有RH mapping数据用来评估、校正ARS1的组装版本。 <strong>通过各种参数比较发现，ARS1均优于CHIR_2.0版本。</strong></p>
<p>1、通过比对发现，CHIR_2.0 比CHIR_1.0有更少的putative deletion(2,735 vs 1 0,256)和duplication(115 vs 290)。而2.0版本相较1.0有更多的inversion(215 v s 4)。通过比较，发现ARS1版本有大幅度地提升，较2.0版本少4倍的deletion， 少50倍inversion。</p>
<p>2、CHIR_2.0能填补CHIR_1.0 94.6%的gap，而剩下的那些gap通过分析ARS1得知，是CHIR_1.0的组装错误，而RH数据也支持了这一论断。 3、BUSCO是利用单拷贝ortholog来评估组装的可靠性，和CHIR_2.0相比，ARS1有更高的BUSCO score。</p>
<p>4、山羊52k SNP 芯片中，有1,723个SNP探针目前只能定位在CHIR_2.0组装版本 中的unplaced contigs上。而ARS1版本能把其中的90%(1,552/1,723)以上的S NP探针定位在染色体上。另外发现有26个low call-rate 的SNPmarker在ARS1组装版本上定位比较模棱两可。这也就解释了为什么这些maker在芯片上有较差的call -rate. </p>
<p>5、通过比较发现，CHIR_2.0版本中的3,495个内含子或外显子有gap的基因，在ARS1中都得到补全。同时也确认1,926个预测的外显子在CHIR_1.0或者2.0中有gap， 但在ARS1中得到修复。 </p>
<p>6、由于免疫基因区高度多态性和重复性，用二代测序数据很难组装起来，但是通过 分析发现，ARS1版本就很好地把LRC和NKC基因(免疫功能相关基因)定位在一个独立的常染色体scaffold上。 </p>
<p>7、通过和一代、二代组装策略相比，ARS1版本在重复序列的组装上获得了极大进步。对某些异染色体或异染色质的区域也获得了较好的组装覆盖。比如，在6条常 染色体上组装出&gt;5kbp的端粒序列。通过分析发现， 15条染色体scaffold，在着丝粒区域组装出大于2kbp长度的重复区，而其中的7条，更是装出来8kbp以上的重复区。更令人惊讶的是，19号和23号染色体都组装出高度重复的着丝粒和端粒区域， 贯通了有结构性异染色质区的染色体。 </p>
<p>8、在ARS1版本中鉴定出大于12kbp的重复模式序列多达105条。对于重复序列家 族的鉴定，在ARS1中获得的接近全长的BovB LINE 序列比CHIR_2.0多60%以上。 在CHIR_2.0版本里，被ARS1成功补全的gap中的43.6%与BovB重复序列一致(长 度大于3.5kbp)，即意味着二代测序的gap区大多都是重复序列，用三代就能较容易测通。 </p>
<p>9、关于性染色体的分析。通过比对发现，两个不同的scaffold比对到X染色体的不同但连续的区域，占预期X染色体大小(150Mb)的86%左右。通过和自己的、跨物种牛的Y染色体比对，最终确定出10Mb区域的序列，占Y染色体预估大小的50% 左右。通过比对牛和羊的Y染色体上的基因，发现在目前的scaffold中能找到16%， 而在先前过滤掉的degenerate contig中能找到84%的基因。考虑到Y染色体的异染 色质属性及X,Y染色体的拟常染色区域经常发现交换，实在太过复杂，超出目前的组装和认知水平，表示实在无能为力。</p>
<p>10、利用之前RH mapping data，对组装的大部分环节进行了校正及评估。比如多次辅助解决scaffold conflict的问题。</p>
<h2 id="基因组注释"><a href="#基因组注释" class="headerlink" title="基因组注释"></a><strong>基因组注释</strong></h2><p>多种方法结合注释基因集。<br>1.<strong>RNA-seq的方法:</strong> 6个组织(大多和脑组织相关)RNA-seq测序、13个SRA下载 数据，利用stringtie、cufflinks和Trinity(基于无参组装)。最后用PASA软件整合在一起;</p>
<p>2.<strong>用exonerate和tblastn 软件</strong>比对到几个近缘物种的Ensembl基因集上，获得同 源预测基因集;</p>
<p>3.<strong>用Braker1做Ab initio 预测</strong>;</p>
<p>4.<strong>CHIR_1.0 版本的注释基因集</strong>; 最后用<strong>EVM+PASA</strong>把以上4种数据整合成一个最终的基因集(设置的权重为RNAseq &gt; cDNA/protein &gt; ab initio gene predictions)。</p>
<h2 id="启示录"><a href="#启示录" class="headerlink" title="启示录"></a><strong>启示录</strong></h2><p>1、Pacbio RSII是一个较为理想组装平台，产生平均14Kbp左右的读长，最高到60 Kbp，可以组装出较为理想的基因组版本。由于三代的长读长优势，同时可以较好地组装出基因组中大部分高度重复区(主要集中在着丝粒和端粒区域);</p>
<p>2、BioNano 的Irys optical mapping 是一种非常有效的，成本比较适中的构建scaffold的平台。和Hi-C比优势在于定位错误较少，缺点是对N50的提高并不是特别显著，一般在2倍左右。如果正反链的Nt.BsqI酶切位点离得比较近，常常导致双链 断裂，限制了Optical Map scaffold的大小。所以，BioNano对较长的scaffold效果比较好。由于Optical map和pacbio产生的错误特征并不一样，两者结合，可以 相互校正，获得较好的组装指标;</p>
<p>3、Hi-C是目前非常火爆的一个技术，在多个领域都有很好的应用。在组装方面， 它能获得染色体级别的scaffold，但是也容易获得较高的contig定向错误。这也是 为什么文章中，先用optical mapping，后用Hi-C做scaffolding的重要原因之一。 作者建议在以后的实验中，可以选择较短的识别位点的限制内切酶(或者DNase Hi -C)来提高Hi-C交联的密度，降低定向错误。</p>
<p>4、利用同样的方法和平台，做类似的基因组项目，用Pacbio平台和scaffolding平 台，目前大约花费在$100,000上下,而一般的短reads平台测序加scaffolding 平台，只需要其三分之一的价格。但是用Pacbio平台却获得了高质量的、连续性好的基因组序列。目前Pacbio 新一代的sequel平台已经推出，单个cell的产量比RSII提 高7倍以上，测序成本将会得到大幅度降低，相信会成为未来基因组研究的主流工具之一。</p>
<p>5、本文的研究策略确实会启迪后来的研究者，为de novo组装树立新标杆。Pacbio 测序技术联合多种scaffolding 平台(比如BioNano、Hi-C，mating-pairedlibr ary，10X genomics)的使用， 会引领de novo 组装进入 near finished genome 或者finished genome的新时代。</p>
<p>6、但是，尽管做了很多努力，ARS1仍然是一个单体型混合型的组装版本。在未来，可以利用single molecule和Hi-C技术获得单体型分期(haplotype phasing) 的参考基因组。对于组成型异染色质区，尤其是着丝粒和端粒部分，仍然是组装的盲区，即使在人的基因组中这些区域也没有被完整组装出来。</p>
<h1 id="3-2020-09-cell-大豆泛基因组"><a href="#3-2020-09-cell-大豆泛基因组" class="headerlink" title="3. 2020.09-cell 大豆泛基因组"></a>3. 2020.09-cell 大豆泛基因组</h1><p>Pan-Genome of Wild and Cultivated Soybeans</p>
<p>Soybean is one of the most important vegetable oil and protein feed crops. To capture the entire genomic diversity, it is needed to construct a complete high-quality pan-genome from diverse soybean accessions. In this study, we performed individual de novo genome assemblies for <strong>26 representative soybeans</strong> that were selected from <strong>2,898 deeply sequenced accessions</strong>. Using these assembled genomes together with <strong>three previously reported genomes</strong>, we constructed a <strong>graph-based genome</strong> and performed pan-genome analysis, which identified <strong>numerous genetic variations that cannot be detected by direct mapping of short sequence reads onto a single reference genome</strong>. The <strong>structural variations</strong> from the 2,898 accessions that were <strong>genotyped</strong> based on the graph-based genome and the <strong>RNA-seq data</strong> from the representative 26 accessions helped to <strong>link genetic variations to candidate genes</strong> that are responsible for important traits. This pan-genome resource will promote evolutionary and functional genomics studies in soybean.</p>
<h2 id="SNP-Calling-and-Phylogenetic-Analyses"><a href="#SNP-Calling-and-Phylogenetic-Analyses" class="headerlink" title="SNP Calling and Phylogenetic Analyses"></a>SNP Calling and Phylogenetic Analyses</h2><h2 id="Genome-Assembly"><a href="#Genome-Assembly" class="headerlink" title="Genome Assembly"></a>Genome Assembly</h2><p><em>De novo</em> assembly was conducted referring to a <font color="blue"><strong>reported pipeline</strong></font> (Du and Liang, 2019; Shen et al., 2019). In brief, <font color="red"><strong>Canu</strong></font> (Koren et al., 2017) v1.7.1 was used to assemble PacBio subreads to PacBio contigs, after which <font color="red"><strong>HiSeq</strong></font> reads were used for <font color="red"><strong>error correction</strong></font>. <strong>Bio-nano optical maps</strong> were assembled into consensus physical maps by <strong>BioNano Solve</strong> v3.0.1 (<a href="https://bionanogenomics.com/">https://bionanogenomics.com/</a>, Solve_06082017Rel). Then <font color="red"><strong>HERA</strong></font> (Du and Liang, 2019) was used to combine PacBio contigs and Bionano based physical maps to <font color="blue"><strong>PacBio-BioNano hybrid scaffolds</strong></font>. To <font color="red"><strong>anchor</strong></font> hybrid scaffolds <font color="blue">into <strong>chromosomes</strong></font>, the <font color="blue"><strong>Hi-C</strong></font> sequencing data were <font color="red"><strong>aligned into scaffolds</strong></font> by <font color="red"><strong>Juicer</strong></font> (Durand et al., 2016) v1.5 and <font color="red"><strong>3D-DNA</strong></font> (Dudchenko et al., 2017).</p>
<h2 id="Repeat-Analysis-and-Gene-Annotation"><a href="#Repeat-Analysis-and-Gene-Annotation" class="headerlink" title="Repeat Analysis and Gene Annotation"></a>Repeat Analysis and Gene Annotation</h2><h2 id="Synteny-Analysis"><a href="#Synteny-Analysis" class="headerlink" title="Synteny Analysis"></a>Synteny Analysis</h2><p>Structural Variation Identification</p>
<p>Genetic Variation Analysis</p>
<p>Gene and miRNA Expression</p>
<p>Core and Dispensable Gene Family Clustering</p>
<p>CHS gene unit identification</p>
<p>Gene Fusion Event Identification</p>
<p>QUANTIFICATION AND STATISTICAL ANALYSIS</p>
<h1 id="4-2019-nc-大豆泛基因组-组装参考1"><a href="#4-2019-nc-大豆泛基因组-组装参考1" class="headerlink" title="4. 2019-nc 大豆泛基因组-组装参考1"></a>4. 2019-nc 大豆泛基因组-组装参考1</h1><p>HERA</p>
<h1 id="5-2019-09-scienceChina-大豆泛基因组-组装参考2"><a href="#5-2019-09-scienceChina-大豆泛基因组-组装参考2" class="headerlink" title="5. 2019.09-scienceChina 大豆泛基因组-组装参考2"></a>5. 2019.09-scienceChina 大豆泛基因组-组装参考2</h1><p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/1.png" alt="1"></p>
<p>For genome assembly, we sequenced additional 40 Gb SMRT reads from 5 cells for this update. Therefore, a total of <strong>120× PacBio reads</strong>, <strong>365× Bionano optical maps</strong> marked by BssSI, <strong>275× Bionano optical maps</strong> marked by BspQI, <strong>45× HiSeq</strong> reads and <strong>125×</strong> chromosome conformation capture sequencing (<strong>Hi-C</strong>) reads were used for the new genome assembly (Figure 1A). To make best of the sequencing data, we also <font color="red"><strong>adopted a new genome assembly pipeline</strong> by <strong>adding HERA</strong></font> (Du and Liang, 2018) to improve the sequence contiguity and reduce errors by accurately assembling the repetitive genome regions (Figure 1A). Briefly, <font color="blue">the whole assembly process <strong>differed from</strong> previous pipeline</font> at </p>
<p>(1) using <font color="red"><strong>CANU</strong></font> (v1.7.1) to replace Smrtmake for assembling PacBio subreads to PacBio contigs; </p>
<p>(2) using <font color="red"><strong>HERA</strong></font> to generate longer contigs; </p>
<p>(3) using <font color="red"><strong>Juicer and 3D-DNA to replace HiC-Pro and LACHESIS</strong></font> to anchor the hybrid scaffolds into chromosomes with Hi-C reads.</p>
<h1 id="6-2020-05-nc-同源四倍体紫花苜蓿"><a href="#6-2020-05-nc-同源四倍体紫花苜蓿" class="headerlink" title="6. 2020.05-nc 同源四倍体紫花苜蓿"></a>6. 2020.05-nc 同源四倍体紫花苜蓿</h1><p>HiFi助力同源四倍体紫花苜蓿基因组组装，NC</p>
<blockquote>
<p>Allele-aware chromosome-level genome assembly and efficient transgene-free genome editing for the autotetraploid cultivated alfalfa</p>
</blockquote>
<p>（1）使用Canu默认参数，利用CCS clean reads组装contigs。组装得到的Contig N50值为459kb，总长度为3.15GB。</p>
<blockquote>
<p>We assembled contigs from CCS clean reads using Canu, with default parameters. The N50 values of the contig sets were 459 kb, with total lengths 3154 Mb.</p>
</blockquote>
<p>（2）使用HiC-Pro将Hi-C reads与contigs 进行比对，产生比对BAM文件。</p>
<blockquote>
<p>Hi-C reads were aligned to contigs using <a href="https://pubmed.ncbi.nlm.nih.gov/26619908/">HiC-Pro(2015)</a>, yielding an alignment BAM file.</p>
</blockquote>
<p>（3）使用注释的蒺藜苜蓿蛋白作为参考，完全基于同源的策略注释contigs。对138,729个同源基因进行了结构注释。用MCscan用于鉴定contigs和参考基因组之间的共线性。显示紫花苜蓿和蒺藜苜蓿之间的高共线性。【下载父母本petunia ref】</p>
<blockquote>
<p>Contigs were annotated with a <font color="red"><strong>solely homology-based strategy</strong></font>, using annotated Medicago truncatula proteins as references. 138,729 homologous genes were structurally annotated. <font color="red"><strong>MCscan</strong> in <strong>Jcvi</strong></font> (<a href="https://zenodo.org/record/31631#.XpkUyTOeask">https://zenodo.org/record/31631#.XpkUyTOeask</a>) was used to identify <font color="red"><strong>synteny blocks</strong></font> between <strong>contigs and the reference</strong> genome. <font color="red"><strong>Contigs syntenic</strong> to M. truncatula were <strong>stacked and aligned</strong> to M. truncatula chromosomes</font>. The syntenic contigs are summarized in Supplementary Table 4.</p>
</blockquote>
<p>（4）使用内部脚本处理BAM文件，去除等位基因contigs之间的links。使用ALLHiC软件，<font color="red">提取、聚类和重排Contigs</font> (Contigs syntenic与蒺藜苜蓿染色体一致)，得到原始的scaffolds。</p>
<blockquote>
<p>An <strong>in-house script</strong> was used to <font color="red">prune the BAM</font> file and <font color="red">discard links between allelic contigs</font>. Contigs syntenic to one chromosome of M. truncatula, e.g., chr1, were extracted, sub-clustered and reordered using <font color="red">ALLHiC</font>, yielding a raw scaffold set.</p>
</blockquote>
<p>（5）<a href="https://pubmed.ncbi.nlm.nih.gov/27467250/">Juicebox</a>用于以图形和交互方式微调组装的scaffolds。剪裁了40个总长度达1800Mb的scaffolds 。</p>
<blockquote>
<p>Juicebox45 was used for fine-tuning assembled scaffolds in a graphic and inter-active fashion. Forty scaffolds with a total length of 1800 Mb were cropped (Supplementary Table 5).</p>
</blockquote>
<p>（6） 基于组装的scaffold，通过Hi-C数据，每个unplaced contig被分配到互作最强的那些contig cluster里。</p>
<blockquote>
<p>Based on this scaffold assembly, each unplaced contig was assigned to the contig cluster, to which the contig was most connected by Hi-C data.</p>
</blockquote>
<p>（7）使用ALLHiC对那些contig clusters再次进行重排和构建scaffold。</p>
<blockquote>
<p>Those contig clusters were reordered and scaffolded using ALLHiC. </p>
</blockquote>
<p>（8）使用Juicebox对scaffolds进行微调，并从scaffolds上去除不一致的contigs，产生最终的染色体基因组，其包含32条染色体(8个同源组，每个组中有4个等位基因染色体)，总长度为2738Mb，和419Mb未挂载到染色体水平的序列。</p>
<blockquote>
<p>Using Juicebox, scaffolds were fine-tuned and discordant contigs were removed from scaffolds, and the final chromosome assembly was generated, containing 32 chromosomes with a total length of 2738 Mb (Supplementary Table 6).</p>
</blockquote>
<h1 id="7-2021-11-gb-椰子🥥"><a href="#7-2021-11-gb-椰子🥥" class="headerlink" title="7. 2021.11-gb 椰子🥥"></a>7. 2021.11-gb 椰子🥥</h1><p>High-quality reference genome sequences of two coconut cultivars provide insights into evolution of monocot chromosomes and differentiation of fiber content and plant height</p>
<p>该研究绘制两个参考级别椰子基因组。揭示单子叶植物染色体的进化过程和椰子染色体的形成过程，分析高矮两种椰子耐盐，株高，纤维和脂质含量等关键性状的遗传差异，同时发现椰子进化过程中约在400万年前自然发生的绿色革命。高椰子2.39G矮椰子2.40G。基于椰子，紫萍，菠萝等基因组的共线性关系，重新构建了含有10条染色体的古单子叶植物基因组核型，并对基因组核型的进化路线进行推断。进一步利用叶间距表型进行全基因组关联分析，鉴定出12号染色体上GA20ox基因与椰子株高显著相关，并存在拷贝数变异；整合多种手段验证HA20ox以及赤霉素代谢途径在高矮种的差异并导致株高差异。400万年前，绿色革命。</p>
<h2 id="Hi-C-based-genome-assembly"><a href="#Hi-C-based-genome-assembly" class="headerlink" title="Hi-C-based genome assembly"></a>Hi-C-based genome assembly</h2><p>Both Cn. tall and Cn. dwarf genomes were assembled de novo using SMARTdenovo (<a href="https://github.com/ruanjue/smartdenovo">https://github.com/ruanjue/smartdenovo</a>) [-k 19 -J 3000] based on <font color="red"><strong>Nanopore long reads</strong></font> <strong>corrected</strong> with <font color="red"><strong>NextDenovo</strong></font> (<a href="https://github.com/Nextomics/NextDenovo">https://github.com/Nextomics/NextDenovo</a>). Raw contigs were <font color="blue"><strong>polished</strong></font> using <font color="blue"><strong>Nanopore long reads</strong></font> and <font color="blue"><strong>Illumina short reads</strong></font> with <font color="red"><strong>Next-Polish</strong></font> (v1.2.2) [49]. Then polished contigs were <font color="blue"><strong>anchored</strong></font> into chromosomes by using <font color="red"><strong>HiC-Pro (v2.11.1)</strong></font> [50] and <font color="red"><strong>LACHESIS</strong></font>[51]. Finally, the assembled genomes were <font color="blue"><strong>manual correction</strong></font> with <font color="red"><strong>Juicebox</strong></font> (v1.11.08).</p>
<p>To assess the quality of assembled genomes, raw Illumina <font color="blue"><strong>paired-end</strong> reads and <strong>RNA-seq</strong></font> reads from multiple tissues were <font color="blue"><strong>mapping</strong></font> to the genomes using <font color="red"><strong>BWA (v0.7.17-r1188)</strong></font> [52] and <font color="red"><strong>HISAT2 (v2.1.0)</strong></font> [53], respectively. In addition, Benchmarking Universal Single-Copy Orthologs (<font color="red"><strong>BUSCO</strong></font>) was also used to assess the genome completeness base on Embryophyta Plant database (odb10) [54].</p>
<h1 id="8-2021-11-nc-金粟兰基因组"><a href="#8-2021-11-nc-金粟兰基因组" class="headerlink" title="8. 2021.11-nc 金粟兰基因组"></a>8. 2021.11-nc 金粟兰基因组</h1><p>填补核心被子植物最后主要分支-金粟兰目的基因组信息，提供被子植物早期演化证据。刘建全团队致力于解析类群演化，探究不同物种间分化适应遗传机制。</p>
<p>被子植物（Angiosperms or flowering plants）是地球上分布范围最广、多样化最高、适应性最强的陆生植物类群，极大地影响了其他生物类群的演化进程，然而，由于被子植物在早期经历了快速的辐射进化，其内部演化关系迟迟未被解决，这一问题也被称为达尔文的“恼人之谜”。经过前人长时期的努力，目前被子植物被划分为：无油樟目、睡莲目、木兰藤目和核心被子植物（Mesangiospermae）。无油樟目、睡莲目、木兰藤目共同被称为ANA grade，是被子植物的基部类群，系统发育关系相对稳定，而核心被子植物包含了~99.95%的被子植物，又可被划分为5大类群：双子叶、单子叶、木兰类、金鱼藻目和金粟兰目，它们之间的演化关系一直存在争议。近年来，随着各类群代表物种全基因组测序相继完成，其各自的进化历程均有了坚实而可靠的证据，刘建全团队在2020年首次报道了金鱼藻和芡实的基因组，证明了核心被子植物内部存在广泛的不完全谱系分选和杂交事件是导致树形冲突的主要原因。但是金粟兰目一直未有基因组报道，其演化历程以及整个核心被子植物的演化过程还有待深入分析。为此该团队再次利用Nanopore、Illumina和Hi-C技术，构建了第一个金粟兰目植物（四川金粟兰，<em>Chloranthus sessilifolius</em>）的高质量染色体级别基因组，Contig N50高达53.74 Mb（图1），使用多种分析方法对上述问题进行了深入的阐述。</p>
<p>通过使用多种系统发育基因组学分析，包括单拷贝基因、低拷贝基因和共线性基因数据集，进行了串联树和溯祖树的构建，同时评估了长枝吸引、物种选择和同源聚类方法等的影响，使用多套数据集合和多种分析方法，获得了高可信度的拓扑结构，即金粟兰目和木兰类具有最近的亲缘关系，且他们一起与金鱼藻目+双子叶植物构成姊妹关系，而单子叶植物是其它所有核心被子植物的姊妹枝（图2）。</p>
<p>同时，作者也发现了大量的基因树或叶绿体树与物种树不一致的情况，因此着重评估了不完全谱系分选（ILS）和杂交事件对此冲突的贡献。通过PhyloNetworks分析鉴定到了三次可能的杂交事件，可以解析部分的树形冲突。然而值得注意的是五大类群之间的分化时间仅有23个百万年（158~135 Mya），如此短的分化时间，ILS可能发挥了更为主要的作用。使用theta参数对每个内部分支发生ILS的概率进行评估发现，除了木兰类和金粟兰目的姊妹关系较为稳定外，其他类群间都具有较高的theta值，而金鱼藻目+双子叶的祖先分枝具有较高的tehta值，均表明了ILS在核心被子植物内部的演化中发挥了重要作用（图3 a和b）。基于Phyabse和DendroPy进行树形模拟表明，当存在ILS时模拟的树形和真实树形具有高度一致性（R2＞0.99），而不存在ILS的模拟树形与真实树形则具有较低的相关性，进一步表明了ILS在核心被子植物的快速辐射中发挥了重要作用（图3 c-f）。进一步对树形异质性进行区分表明，ILS可基本解释金鱼藻目+双子叶的祖先枝上的树形冲突，也就是金鱼藻目+双子叶、木兰类+金粟兰和单子叶之间的冲突，而其他核心被子植物类群间的冲突还有其他因素（例如杂交）的参与。</p>
<p>此外，本研究还鉴定了四川金粟兰独有的一次WGD事件，同时5大核心被子植物分枝的加倍事件都不共享；鉴定了花发育相关的基因家族，解析了其特有花器官的可能形成原因；鉴定了萜类合成和木质部形成相关的基因家族，为今后研究其简单木质部形成和萜类物种合成通路演化提供了基础。</p>
<p>综上所述，该研究报道了高质量的四川金粟兰基因组，填补了核心被子植物金粟兰目的基因组信息，并通过多种分析策略和方法，深入的揭示了核心被子植物间的复杂演化历程，该成果对于早期被子植物的起源、辐射进化以及适应性演化提供数据支撑和理论基础。</p>
<h2 id="Genome-size-estimate-and-assembly"><a href="#Genome-size-estimate-and-assembly" class="headerlink" title="Genome size estimate and assembly."></a>Genome size estimate and assembly.</h2><p>To estimate the genome size of C. sessilifolius, we surveyed 150 bp paired-end reads, computed 21 bp K-mer frequencies using <font color="red"><strong>Jellyfish</strong></font>, and exported the resulting histogram into <font color="red">findGSE</font>. <font color="red"><strong>Nextdenovo</strong></font> (https:// github.com/Nextomics/Nextdenovo) was selected for <font color="blue"><strong>correcting reads</strong></font> with para- meters “read_cutoff=2k, seed_cutoff=30k, blocksize=1.5g” and then <font color="red"><strong>Smartdenovo</strong></font> (<a href="https://github.com/ruanjue/smartdenovo">https://github.com/ruanjue/smartdenovo</a>) for <font color="blue"><strong>de novo assembly</strong></font> with parameters “wtpre -J 3,000; wtzmo-k 21 -z 10 -Z 16 -U -1 -m 0.1 -A 1000; wtclp -d 3 -k 300 -m 0.1 -FT; wtlay -w 300 -s 200 -m 0.1 -r 0.95 -c 1”. <font color="blue">The preliminary contigs were further <strong>polished</strong> by aligning the Illumina <strong>short</strong> <strong>reads</strong> to the contigs</font> using <font color="red"><strong>Nextpolish</strong></font>. After four rounds of successive iterative correction, the final genome sequence was obtained. The GC content and sequencing coverage analyses were applied to evaluate the presence of contamination. The quality of the genome assembly was also assessed using <font color="red"><strong>BUSCO</strong></font> (Benchmarking Universal Single-Copy Orthologs) with the embry- ophyta_odb10 database. The clean <font color="blue">Hi-C</font> data were mapped to contig sequences by <font color="red"><strong>Bowtie2</strong></font> and 354 Mb valid interaction pairs were extracted. Based on those chromatin interactions, <font color="red"><strong>LACHESIS</strong></font> was employed to <font color="blue"><strong>cluster</strong>, <strong>order</strong>, and <strong>orient</strong> the <strong>contigs</strong> into <strong>pseudo-chromosomes</strong></font>.</p>
<h1 id="9-2022-01-gb-油茶"><a href="#9-2022-01-gb-油茶" class="headerlink" title="9. 2022.01-gb 油茶"></a>9. 2022.01-gb 油茶</h1><blockquote>
<p>The genome of oil-Camellia and population genomics analysis provide insights into seed oil domestication</p>
</blockquote>
<p>油茶是我国传统木本油料树种，具有2300余年栽培食用历史。自上世纪起，经过四代科技工作者艰苦努力，我国油茶主栽良种衍生出数百个品种。但受制于<font color="blue">多倍性、长时效</font>特性，油茶育种工作效率不高。</p>
<p>2022年1月10日，中国林业科学研究院亚热带林业研究所（亚林所）研究员<strong>姚小华团队</strong>和<strong>殷恒福团队</strong>在<strong>《基因组生物学》（Genome Biology）</strong>发表最新论文。</p>
<p>该研究成功组装全球首个染色体级别高质量油茶基因组，揭示<font color="red">油茶物种<strong>进化历史</strong>及其<strong>种子含高油脂</strong>、<strong>高不饱和脂肪酸</strong>的<strong>驯化机制</strong></font>，建立了油脂性状早期选择技术体系，为加快良种选育效率、保障我国粮油安全奠定了基础。</p>
<h2 id="抱子怀胎的油茶良种育种缓慢"><a href="#抱子怀胎的油茶良种育种缓慢" class="headerlink" title="抱子怀胎的油茶良种育种缓慢"></a>抱子怀胎的油茶良种育种缓慢</h2><p>良种是农业生产的“芯片”。作为我国四大油料作物之一，油茶是农民增收、粮油安全、生态建设的“重要法宝”。我国油茶育种历经了选择育种和定向杂交育种阶段，主栽良种由家系品种、农家品种走向无性系良种，衍生出数百个品种，构成了我国油茶产业的发展基础。</p>
<p>但由于油茶结实之前要经历漫长的童期，而且从<font color="blue">开花到果实成熟需要整整1年时间</font>，俗称‘抱子怀胎’，导致油茶育种年限长，新品种选育缓慢，良种选育速度无法满足产业发展的需求，已成为阻碍油茶产业发展的重要因素。</p>
<p>我国长期面临食用油供需压力，对外依存度高达60%。油茶能够利用我国亚热带区域的宜林山地种植，不与粮争地，是保障我国粮油安全、实现乡村振兴的重要抓手。</p>
<p>油茶泛指山茶科山茶属植物中油脂含量高，具有一定栽培面积的，有经济栽培价值的物种的总称，是我国主推的重要木本油料树种。我国现有油茶种植面积7000万亩，以普通油茶（Camellia oleifera）为主，年总产值1200亿元左右。</p>
<p>油茶籽油中不饱和脂肪酸达90%以上，其中以单不饱和脂肪酸油酸为主，富含角鲨烯、维生素E、甾醇、多酚等功能成分，具有极高的保健价值，被誉为“液体黄金”。</p>
<p>然而研究发现, 油茶基因组具有<font color="red"><strong>杂合率高、重复序列占比大</strong>的特点，其杂合率达到了<strong>2.52%</strong></font>，远高于大部分已测序的物种，这为基因组组装带来了巨大挑战。</p>
<h2 id="染色体级别组装"><a href="#染色体级别组装" class="headerlink" title="染色体级别组装"></a>染色体级别组装</h2><p>经过四年多的努力，该团队获得大小为<font color="red">2.95 GB，Contig N50为<strong>1.002 MB</strong></font>的二倍体油茶（CON）的基因组图谱，并将基因组<font color="red">锚定到15条染色体</font>，锚定率达到<font color="red">91.33%</font>，获得了质量优良的油茶基因组图谱。</p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/2.png" alt="油茶基因组图谱及其进化"></p>
<p>同时，利用控制杂交的群体建立<font color="red"><strong>高密度的遗传标记连锁图谱</strong></font>，对<font color="red">基因组<strong>图谱组装</strong>进行进一步<strong>校正</strong></font>，为未来重要性状的基因定位提供支撑。</p>
<p>油茶物种起源与分布主要集中在我国南方亚热带地区。通过对油茶基因组的比较分析，发现油茶基因组共发生<font color="red"><strong>两次全基因组复制</strong>事件</font>：第一次为古老的<font color="red">γ复制</font>，第二次发生在<font color="red"><strong>山茶属与猕猴桃属</strong>分化前不久</font>。</p>
<p>而山茶属形成之后并没有发生特殊的全基因组复制事件。通过山茶—猕猴桃、山茶—柿、柿—猕猴桃<font color="red"><strong>属间同源突变率的比较</strong></font>印证这一观点。</p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/3.png" alt="油茶基因组重复序列分析"></p>
<p>山茶属包括200多个物种，包括以<strong>普通油茶</strong>为代表的油茶组、以<strong>茶</strong>为代表的茶组和以<strong>山茶花</strong>为代表的山茶组等。系统发育和分子钟标定分析发现，<strong>油茶和茶的分化</strong>发生在大约17.3百万年前。</p>
<p>在长期栽培驯化中，区别于以叶用为目的的茶和以观赏为目的的山茶，油茶在人工选择作用下进化成以种子油脂为主要栽培目的的木本油料树种，使得油茶成为研究植物种子<font color="red"><strong>油脂性状驯化</strong></font>的绝佳材料。</p>
<p>为进一步揭示油茶油脂性状驯化的分子机制，该团队利用全国分布区内的<font color="red">221个代表品种</font>开展<font color="red"><strong>群体转录组测序和关联分析</strong></font>。结果发现在长期<strong>驯化</strong>过程中，油茶果实逐渐<strong>增大</strong>，种仁油脂含量显著<strong>提高</strong>，油脂品质不断<strong>优化</strong>，形成了目前主栽的果大、含油率高、油脂品质优良的栽培类型。</p>
<p>进一步分析发现驯化过程中，油茶基因组中<font color="red"><strong>油脂代谢通路</strong>中的多个<strong>基因</strong>受到了<strong>显著的人工选择</strong></font>。此外，<font color="red">胁迫应答、激素生物合成</font>等通路也受到显著选择。</p>
<p>为了挖掘高度可信的油脂代谢关键基因，联合采用<font color="red"><strong>基因组遗传变异、基因表达水平和表型性状变异关联分析</strong></font>。令人惊讶的是，在<font color="red">筛选出的<strong>21个候选</strong>基因</font>中，有<font color="red"><strong>14个</strong></font>属于油脂合成和分解代谢通路基因。</p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/4.png" alt="油茶品种群体关联分析发掘油脂产量与品质的调控基因"></p>
<p>其中，油脂代谢通路中的8个基因和植物激素相关转录因子IAA26在长期<strong>栽培驯化</strong>过程中<strong>形成</strong><font color="red"><strong>显著</strong>的<strong>单核苷酸多态性</strong>和<strong>表达水平差异</strong></font>。“这8个基因既包括<font color="red">油脂合成</font>基因，也有<font color="red">油脂分解代谢</font>基因，这表明油茶<font color="red"><strong>油脂性状</strong></font>是由参与合成和分解的<font color="red"><strong>两类基因协同调控</strong></font>的结果。</p>
<h2 id="Genome-sequencing-de-novo-assembly-and-annotation"><a href="#Genome-sequencing-de-novo-assembly-and-annotation" class="headerlink" title="Genome sequencing, de novo assembly, and annotation"></a>Genome sequencing, de novo assembly, and annotation</h2><p>The genomic DNA of CON was prepared by using the young <strong>leaves</strong>. Ten 20 kb de novo SMRTbell libraries were constructed according to the standard manufacturer’s protocol and used for <font color="red">SMRT PacBio</font> genome sequencing. A total of 27,876,348 reads (total size of <strong>320 G</strong>) were generated and used for initial assembly by the <font color="red"><strong>Falcon</strong></font> (v0.3.0) pipeline. The <font color="red"><strong>HaploMerger2</strong></font> (v20180603) program (default parameters) was used to <strong>reduce the redundancy</strong>, and <font color="red"><strong>Arrow program</strong></font> with default parameters was used to <strong>correct</strong> the sequencing <strong>errors</strong>. Further, a total of <font color="red">210 G</font> clean data generated by the <strong>Illumina</strong> Nova- Seq6000 platform was used to <font color="red">correct</font> the PacBio reads.</p>
<p>To circumvent the high heterozygosity of the CON genome, a <font color="red"><strong>hybrid assembly of strategy</strong></font> was used to construct the high-quality reference genome. The details of the <font color="red"><strong>BioNano, 10X Genomics, and Hi-C</strong></font> sequencing procedures were described in the Additional File 3: Method S1; and the hybrid assembly approach was described in <strong>Additional File 2</strong>: Fig. S3. Finally, to construct a chromosome-scale reference genome, the Hi-C chromosomal interaction was created using HiC-pro [38] software (v2.5.0) (<strong>Additional File 2</strong>: Fig. S4). </p>
<p>The <font color="red">repetitive elements</font> in the CON genome, including tandem repeats and interspersed repeats, were identified. Tandem repeats were discovered by <font color="red"><strong>Tandem Repeats Finder</strong></font> v4.07b. Interspersed repeats in the genome were identified using an integration of <strong>independent homology searching and de novo predictions</strong> (See details in Additional File 3: Method S2). Non-coding RNA genes (ncRNA) were annotated in this study (see details in Additional File 3: Method S2) and the results were shown in Additional File 1: Table S4.</p>
<p>We <font color="red">annotated</font> the assembled genome through combining three different approaches: <font color="red"><strong>ab initio prediction, homology-based prediction,</strong> and <strong>transcriptome alignment</strong></font>. To ob- tain the transcriptome data, the total RNA of seven different tissues from CON was se- quenced using the Illumina NovaSeq platform. The transcripts homolog prediction was performed initially by MAKER (v2.31.10); Augustus (v3.3.1) and SNAP (v2006-07-28) were used for de novo prediction. Finally, both homolog and de novo prediction results were integrated using MAKER and resulted in the final gene models (Additional File 1: Table S5; see details in Additional File 3: Method S2)</p>
<p><font color="red"><strong>Functional annotation</strong></font> was achieved by comparing predicted proteins against public databases, including NCBI non-redundant protein sequences database (Nr), SwissProt (201709) [39], eggNOG [39], KEGG (v84) [40], Interpro (v5.16-55.0) [41], and GO [42] using Blast (v2.2.3) [43].</p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/5.png" alt="5"></p>
<p>PacBio+illumina : Falcon+Arrow+BWA+Pilon+HaploMerger-&gt;contigs</p>
<p>scaffold+HiC : <font color="red"><strong>JUICER+3D-DNA</strong></font></p>
<h1 id="10-2022-01-HorticRes-甘菊"><a href="#10-2022-01-HorticRes-甘菊" class="headerlink" title="10. 2022.01-HorticRes 甘菊"></a>10. 2022.01-HorticRes 甘菊</h1><p><strong>The</strong> <em><strong>chrysanthemum lavandulifolium</strong></em> <strong>genome and the molecular mechanism underlying diverse capitulum types</strong></p>
<p><strong>菊花</strong>(<em>Chrysanthemum ×morifolium</em> Ramat.)是世界著名的观赏植物，具有千姿百态的花型。实际菊花的花是指由<font color="red"><strong>外围的舌状花</strong></font>和<font color="red"><strong>盘心的管状花</strong></font>共同构成的<font color="red"><strong>头状花序</strong></font>。其花型由头状花序上舌状花和管状花的形态和相对数量决定。解析同一头状花序上舌状花和管状花分化的分子调控机制不仅可以为阐明菊花复杂的头状花序形态奠定基础，也将为菊科植物头状花序发育提供新见解。但目前关于菊花花型的研究受到其复杂遗传背景的限制，导致无法充分利用菊花丰富的基因资源进行花型定向育种。因此，获得高质量的菊花及其近缘种的基因组信息并在此基础上<font color="red">研究<strong>头状花序发育</strong>的<strong>分子调控机制</strong></font>显得尤为必要。</p>
<p>近日，<em><strong>Horticulture Research</strong></em>在线发表了<strong>北京林业大学戴思兰团队</strong>题为<em><strong>The Chrysanthemum lavandulifolium genome and the molecular mechanism underlying diverse capitulum types</strong></em> 的研究论文。该论文完成<font color="red"><strong>菊花近缘野生种</strong>之一<strong>甘菊</strong></font>(C. lavandulifolium)的全基因测序工作，获得了染色体水平上的高质量甘菊参考基因组，结合<font color="red"><strong>3种不同类型菊科植物头状花序</strong>的<strong>转录组数据</strong></font>初步解析了头状花序发育的<strong>分子调控机制</strong>，为实现人工调控菊花花型奠定了坚实的分子理论基础。</p>
<p>甘菊为菊属植物中的<strong>二倍体物种</strong>，采用<strong>Illumina + Pacbio + Hi-C</strong>测序技术对其进行全基因测序，获得了2.60 Gb的染色体水平的参考基因组。其中<font color="red">94.46%的序列锚定到<strong>9条染色体</strong>上</font>。甘菊基因组中重复序列占基因组的67.69%，<em>Cypsy</em>和<em>Copia</em>的占比分别为37.92%和29.06%，插入时间在1.25百万年前。<font color="red"><strong>比较基因组分析</strong></font>结果表明，甘菊经历了<font color="red"><strong>两次全基因组复制(WGD)事件</strong></font>，其中<font color="red"><strong>最近一次</strong>是所有<strong>菊科植物共有</strong></font>，而<font color="red"><strong>较早一次</strong>是核心双子叶植物共有的<strong>γ事件</strong></font>，**甘菊自身没有发生WGD，其基因组演化的动力来源主要是<font color="red">串联重复事件</font>**。</p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/6.png" alt="overview and genome evolution"></p>
<p>基于<font color="blue">甘菊头状花序发育的6个重要时期</font>和<font color="blue">其他菊科植物不同类型头状花序发育关键时期</font>的<font color="red">转录组</font>有参分析发现，MADS-box、TCP、NAC和LOB基因家族<font color="red">可能参与<strong>管状花和舌状花的分化</strong></font>。值得注意的是，<em>NAM</em>和<em>LOB30</em>高表达于舌管兼备型的头状花序中，而在全舌型和全管型的头状花序中表达量相对较低，这表明其可能是参与两类小花分化的关键基因。结合关键基因在全舌型、全管型以及舌管兼备型的头状花序中的表达模式和蛋白互作模式，初步推测并构建了不同类型头状花序发育可能的调控机制。在全管型头状花序中，<em>CUC2</em>与<em>LFY</em>和<em>AG</em><font color="red"><strong>共同调控</strong>管状花原基的起始</font>。而CUC2和CUC3的<font color="red"><strong>互作及协同表达</strong>则会<strong>促进</strong>全舌型头状花序中舌状花原基的起始</font>。在舌管兼备型的头状花序中，<em>NAM</em>和<em>LOB30</em>的表达则参与<font color="red"><strong>调控</strong>舌状花和管状花原基的分化</font>。LOB30可以与LFY, TFL1, CUC2, CUC3和NAM互作，表明其在基因调控网络中的核心位置。总之，<em>NAM</em>和<em>LOB</em>不仅可以与花序分生组织相关基因如<em>LFY</em> 等互作，也可以与两类小花身份决定基因如<em>CYC2</em>-<em>LIKE</em>等基因互作，这表明<em><strong>NAM</strong></em><strong>和LOB30在头状花序上舌状花和管状花原基分化调控中的关键角色</strong>。</p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/7.png" alt="The expression patterns of NAM/CUC and LOB30 homologous genes in ten asteraceae species"></p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/8.png" alt="the probable gene regulation mechanism in the development of different capitula types"></p>
<p><strong>高质量甘菊参考基因组的获得不仅可以为栽培菊花基因组的破译提供有效的参考，更为解析菊花乃至菊科植物多样的生物学性状提供丰富的基因资源。</strong></p>
<p>北京林业大学戴思兰课题组一直致力于菊花研究，基于<font color="blue">植物系统学研究方法</font>对<font color="blue">菊属植物种间<strong>亲缘关系</strong>和菊花<strong>品种起源</strong></font>进行探索，在<font color="red"><strong>种质资源评价，花色、花型、开花期</strong>和<strong>抗逆性</strong>等观赏性状形成的<strong>分子机理</strong></font>，菊花<font color="blue">优异种质创制</font>以及<font color="blue">产业化栽培技术</font>等开展全面研究，取得了一系列重要突破性进展和研究成果。</p>
<p>2.6G：scaffold Num 178；scaN50 300M；N90 212M；Longest 322M</p>
<h2 id="Genome-assembly-and-quality-assessment"><a href="#Genome-assembly-and-quality-assessment" class="headerlink" title="Genome assembly and quality assessment"></a><strong>Genome assembly and quality assessment</strong></h2><p>For the <font color="blue">PacBio RSII</font> platform data, <font color="blue">longer subreads were <strong>selected</strong></font> by the <font color="blue">error correction module</font> of <font color="red"><strong>canu v1.5</strong></font> [35]. <font color="blue">Raw overlapping subreads were <strong>detected</strong></font> through the highly sensitive overlap detection program <font color="red"><strong>MHAP v2.1</strong></font> [36], and the <font color="blue">error correction of these data was <strong>carried</strong></font> out by the <font color="red"><strong>Falcon</strong></font> sense method v0.40 (“correct- edErrorRate = 0.025”) [37]. The error-corrected subreads were used to <font color="blue">generate a <strong>draft assembly</strong></font> in <font color="red"><strong>WTDBG v2.5</strong></font> (<a href="https://github.com/ruanjue/wtdbg">https://github.com/ruanjue/wtdbg</a>). <font color="blue"><strong>Iterative polishing</strong></font> by <font color="red"><strong>Pilon v1.22</strong></font> [38] was achieved by <font color="blue"><strong>aligning</strong></font> adapter-trimmed and paired-end <font color="blue">Illumina <strong>reads</strong> to the <strong>PacBio draft genome</strong></font>. <font color="red"><strong>Clean nanopore data</strong></font> were acquired via sequencing on the PromethION platform, and these data were <font color="blue">corrected with the same method</font> described above. The draft genome assembled by <font color="red"><strong>WTDBG v2.5</strong></font> (https:// github.com/ruanjue/wtdbg) was <font color="blue"><strong>corrected</strong> three times</font> by <font color="red"><strong>Racon v1.3.3</strong></font> [39] by aligning adapter-trimmed and paired-end Illumina reads to the <font color="blue"><strong>Nanopore draft genome</strong></font>. Then, the <font color="blue">PacBio draft genome as a <strong>query input</strong></font> was <font color="blue"><strong>aligned against</strong> the <strong>Nanopore draft genome</strong></font> using <font color="red"><strong>MUMmer v4.0.0</strong></font> [40]. The PacBio draft genome and Nanopore <font color="blue"><strong>draft genome</strong></font> were then <font color="blue"><strong>merged</strong></font> using <font color="red"><strong>quickmerge v0.3.0</strong></font> [21]. This <font color="blue"><strong>merged draft genome</strong></font> was <font color="blue"><strong>polished</strong></font> by <font color="red"><strong>Racon v1.3.3</strong></font> [39] and <font color="red"><strong>Pilon v1.22</strong></font> [38]. The <font color="blue">mapping depth</font> was obtained by <font color="blue"><strong>aligning</strong> corrected Nanopore sequencing data</font> to the merged assembly by <font color="red"><strong>minimap2 v2.17</strong></font> [41] with default parameters. Then, <font color="red"><strong>purge haplotigs v1.0.4</strong></font> [22] was used to <font color="blue"><strong>eliminate</strong> redundancy according to the <strong>coverage depth</strong></font> and obtain the <font color="blue"><strong>purged haplotig genome</strong></font>. Ultimately, a <em>C. lavandulifolium</em> genome with a total length of <strong>3.10 G</strong>b was obtained. The second-generation sequencing data, core gene completeness and BUSCOs were evaluated to verify the accuracy of the genome assembly.</p>
<h2 id="Hi-C-sequencing-and-assistant-assembly"><a href="#Hi-C-sequencing-and-assistant-assembly" class="headerlink" title="Hi-C sequencing and assistant assembly"></a><strong>Hi-C sequencing and assistant assembly</strong></h2><p>Hi-C is a technology derived from chromosome conformation capture technology that utilizes high- throughput sequencing data and is mainly used to assist in genome assembly. We constructed Hi-C fragment libraries with insert sizes of 300–700 bp, as illustrated in Rao et al. [42], and sequenced them using the Illumina platform [42]. <font color="blue"><strong>Before</strong> <strong>chromosome assembly</strong>, we first performed a <strong>preassembly</strong> for the <strong>error correction of scaffolds</strong>, which required <strong>splitting the scaffolds into segments of 50 kb</strong>, on average</font>. Then, the Hi-C data were <font color="blue">mapped</font> to these segments using <font color="red"><strong>BWA</strong></font> aligner v0.7.10-r789 [43]. We <font color="red"><strong>retained</strong> the <strong>uniquely mapped</strong> data</font> to assemble the genome using <font color="red"><strong>LACHESIS</strong></font> [44] with the following <font color="green"><strong>parameters</strong>: CLUSTER_MIN_RE_SITES = 80; CLUSTER_MAX_LINK_DENSITY = 2; CLUSTER_NONINFORMATIVE_RATIO = 2; ORDER_MIN_N_RES_IN_TRUN = 16; ORDER_MIN_N_RES_IN_SHREDS = 16</font>. To further address the redundant sequences, we manually checked any two segments that showed inconsistent connections with the raw scaffold. The detailed workflow schema for the assembly pipeline of the chromosome-scale <em>C. lavandulifolium</em> genome is shown in Supplementary Figure 24.</p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/9.png" alt="9"></p>
<h1 id="11-2022-01-HorticRes-粉葛"><a href="#11-2022-01-HorticRes-粉葛" class="headerlink" title="11. 2022.01-HorticRes 粉葛"></a>11. 2022.01-HorticRes 粉葛</h1><p><em><strong>Chromosomal-level genome and multi-omics dataset of Pueraria lobata var. thomsonii provide new insights into legume family and the isoflavone and puerarin biosynthesis pathways</strong></em> </p>
<p>粉葛基因组及多组学分析为<font color="red">葛根素</font>等功效成分的生物合成研究提供新见解</p>
<p>广西壮族自治区农业科学院经济作物研究所严华兵团队。该研究利用<strong>PacBio</strong>、<strong>Illumina</strong>测序以及<strong>Hi-C</strong>技术测序组装，<strong>获得了首个<font color="red">豆科葛属药食同源植物粉葛</font>染色体级别的基因组</strong>，标志着粉葛研究迈入基因组时代，开启了<font color="blue">葛属<strong>进化</strong>、野葛<strong>驯化</strong>、粉葛<strong>品种改良</strong></font>之旅，助力广西特色优势粉葛产业高质量发展。</p>
<p>鉴于粉葛<font color="blue">杂合度较高</font>，研究者选用了PacBio和Hi-C测序，构建的粉葛基因组大小为<strong>1.38Gb</strong>，<font color="blue">Contig N50=598kb</font>，并将<font color="blue">99.3%的序列<strong>锚定</strong>到11条染色体上</font>，BUSCO评估<font color="blue">92.9%</font>。通过注释，共获得45270个蛋白编码基因，其中<font color="blue"><strong>94.4%的基因</strong>可以得到<strong>功能注释</strong></font>，基因组中<font color="blue">重复序列</font>占比为62.7%。将粉葛<font color="red">与<strong>16个近缘物种</strong>(包含5个豆科植物)进行<strong>比较基因组</strong>分析</font>，结果表明6个豆科植物共有基因家族为11204个，粉葛基因组中<font color="blue"><strong>显著扩张的4743个基因家族</strong>主要富集在与<strong>类黄酮、生物碱、甾醇和萜类</strong>等生物合成相关的通路</font>；粉葛<font color="red"><strong>特有</strong>基因家族</font>为2373个，主要<font color="blue">富集在与<strong>萜类</strong>生物合成相关的通路</font>；粉葛基因组中受到<font color="blue"><strong>显著正选择</strong>的基因</font>共有34个，富集在<font color="blue"><strong>昼夜节律、同源重组、淀粉代谢和蔗糖代谢</strong></font>等途径。</p>
<p><font color="red"><strong>系统进化分析</strong></font>表明，粉葛<strong>与大豆亲缘关系最近</strong>，两者在20.1个百万年前产生分化。通过<font color="red"><strong>Ks</strong>和<strong>4DTV分析</strong></font>，<strong>粉葛共经历两次WGD事件</strong>，一次WGD事件是<font color="blue">大豆与粉葛<strong>共有</strong></font>，发生在44.5个百万年前；另一次WGD事件是在粉葛与大豆分化后，<font color="blue">粉葛<strong>独自</strong>经历</font>，发生时间大致在4.8个百万年前。</p>
<p>通过对高葛根素ZG-19和低葛根素ZG-39进行<font color="red"><strong>转录组</strong>和<strong>代谢组</strong>分析</font>，研究者检测到了614种225种差异代谢物(DMs)，1814个差异表达基因(DEG)，DMs和DEG的丰富功能类别<strong>重叠</strong>，这说明它们都是与<font color="blue">类黄酮、异黄酮和ABC转运相关的基因或代谢物</font>。进一步分析代谢物与基因表达的相关系数，结果表明代谢物和基因对在样本中高度相关，60%的显著相关性涉及上调的代谢物和下调或不变的基因，在15%的显著相关性中，代谢物和基因表达的变化方向相同。此外，研究者在异黄酮生物合成途径中发现了大量的DMs和DEG。<strong>这充分解析了粉葛中异黄酮的生物合成途径。</strong></p>
<p>通过<font color="red"><strong>同源基因搜索</strong></font>，研究者发现<font color="blue">编码<strong>葛根素合成途径</strong>中关键酶的9个基因家族</font>在粉葛中都有所<font color="blue">扩张</font>；通过分析糖基转移酶家族中催化糖基化修饰的基因，共鉴定出104个GT基因，有13个基因与8-C-葡萄糖基转移酶(8-C-GT)同源，其中6个与先前研究的催化大豆苷元C-糖基化为葛根素的PIUGT43基因同源；编码大豆异黄酮合酶(IFS)的基因(CHR11G3854.1)催化着葛根素合成的中间代谢物大豆苷元的合成，被鉴定为与葛根素的合成途径高度相关。总之，上述分析<strong>初步解析了粉葛中葛根素的生物合成途径。</strong></p>
<p><strong>综上，该研究通过构建高质量的粉葛基因组解析了粉葛基因组的<font color="red">进化特征</font>；通过多组学分析深入解析了粉葛中<font color="red">重要次生代谢物异黄酮、葛根素等生物合成途径</font>，从而为粉葛的资源利用、遗传育种等研究提供了新见解。</strong></p>
<p><strong>严华兵研究员团队在葛根上的研究进展：</strong></p>
<p><strong>严华兵</strong>团队近年<strong>在全球葛根资源收集与鉴定评价、葛属资源分类、葛根<font color="red">基因组与分子生物学</font>、粉葛和野葛品种选育、健康种苗生产、高产高效栽培等方面取得了一系列的成果</strong>。团队目前广泛收集全球葛属种质资源419份，包括野葛、粉葛、葛麻姆、大花葛、泰葛、苦葛、红葛、须弥葛、食用葛等；通过开发<strong>葛SSR分子标记</strong>，构建了广西葛核心种质库；通过<strong>广泛靶向代谢组</strong>解析葛属葛种野葛、粉葛和葛麻姆等3个变种块根中影响<strong>食用品质和药用品质</strong>的<strong>代谢差异</strong>；结合表型鉴定通过叶绿体基因组研究，揭示了葛及其<strong>近缘种之间的系统发育关系</strong>；挖掘了调控<strong>葛根素合成代谢相关的结构基因和转录因子</strong>，并正在开展相关基因功能验证工作；选育出适合开发葛花茶、高葛根素粉葛、无渣粉葛、药用野葛等系列葛根新品种，并逐步建立配套种苗繁育和高效栽培技术。</p>
<p>1.37G：contig Num 5145；conN50 593kb；</p>
<h2 id="Genome-survey"><a href="#Genome-survey" class="headerlink" title="Genome survey"></a>Genome survey</h2><p>Short reads produced by the Illumina 6000 platform were <font color="blue">quality-filtered</font> by <font color="red"><strong>HTQC</strong></font> [23] (version v1.92.310) using the following method. Adaptors were firstly removed from the sequencing reads, and read pairs with any one end having an average quality &lt;20 were discarded. Ends of reads were trimmed if average quality was &lt;20 in the sliding window size of 5 bp, and read pairs with <font color="red">any end <strong>shorter than 75 bp</strong> were removed</font>. The quality-filtered reads were used for estimation of genome size. The <strong>17-mer</strong> occurrence distribution of sequencing reads was generated from short libraries with <font color="red"><strong>Jellyfish</strong></font> [24] (v2).</p>
<h2 id="Genome-assembly"><a href="#Genome-assembly" class="headerlink" title="Genome assembly"></a>Genome assembly</h2><p>Subreads generated with the above long-read third-generation sequencing were used for genome assembly of <em>P. lobata</em>. The draft assembly of the genome was made using <font color="red"><strong>Falcon (v0.3.0)</strong></font> [25]. To <font color="blue"><strong>correct</strong> errors</font> in the primary assembly, <font color="red"><strong>Racon</strong></font> (v1.44) tools were used to <font color="blue"><strong>polish</strong></font> the genome [26]. <font color="blue">Illumina-derived <strong>short reads</strong></font> were used to <font color="blue"><strong>correct</strong></font> any <font color="blue"><strong>remaining errors</strong></font> by <font color="red"><strong>NextPolish (v1.1.0)</strong></font> [27].</p>
<p><font color="blue">To scaffold the contigs</font>, 425 011 698 clean-read pairs were sequenced from the Hi-C library. <font color="red"><strong>Fastp</strong></font> (0.19.5) [28] was used to filter Hi-C data, including <font color="blue"><strong>removing adaptors</strong> and l<strong>ow-quality</strong> reads</font>. <font color="red"><strong>HiC-Pro</strong></font> Proto was used to obtain effective reads [29]. After filtering, <font color="blue">6%【?】 of high-quality and effective Hi-C data was retained</font>. The <font color="blue">resulting <strong>effective reads</strong></font> were <strong>mapped</strong> to the <strong>assembled and polished</strong> <em>P. thomsonii</em> <strong>genome</strong> using <font color="red"><strong>BWA</strong></font> (bwa-0.7.17) [30] with default parameters. <font color="red"><strong>ALL-HiC</strong></font> software was used to <font color="blue"><strong>anchor</strong> scaffolds to chromosomes</font> to obtain the chromosome-level <em>P. thomsonii</em> assembly.</p>
<h1 id="12-2022-03-ng-四倍体土豆"><a href="#12-2022-03-ng-四倍体土豆" class="headerlink" title="12. 2022.03-ng 四倍体土豆"></a>12. 2022.03-ng 四倍体土豆</h1><blockquote>
<p>Chromosome-scale and haplotype-resolved genome assembly of a tetraploid potato cultivar</p>
</blockquote>
<p>##<strong>Genome size estimation.</strong> </p>
<p>After <strong>trimming</strong> off 10× genomics <font color="blue"><strong>barcodes and hexamers</strong></font> from the 370.3-Gb reads combined from the 10× single-cell CNV libraries and single-molecule libraries, <em>k</em>-mer counting (<em>k</em> = 21) was performed with <font color="red"><strong>Jellyfish</strong></font> (v.2.2.10). The <em>k</em>-mer histogram was provided to <font color="red"><strong>findGSE</strong></font> (v.1.0)39 to estimate the haploid/tetraploid genome size of ‘Otava’ under the <font color="blue">heterozygous mode</font> (with ‘exp_hom = 200’; Extended Data Fig. 1).</p>
<p>##<strong>Initial tetraploid genome assembly, polishing and purging.</strong> </p>
<p>The initial assembly of the tetraploid genome was performed using <font color="red"><strong>hifiasm (v.0.7)</strong></font> with <strong>default settings</strong> with the 102 Gb raw PacBio HiFi reads of ‘Otava’, where the output consisting of <font color="red"><strong>unitigs</strong> (locally haplotype-resolved contigs)</font> was selected for <strong>further processing</strong>. </p>
<p>Then the <font color="blue">short reads</font> from the two 10× single-cell CNV libraries were <font color="blue"><strong>aligned</strong> to the assembly</font> using <font color="red"><strong>bowtie2 (v.2.2.8)</strong></font>. These <font color="blue">alignments were used to <strong>polish</strong> the <strong>assembly</strong></font> with <font color="red"><strong>pilon (v.1.22)</strong></font> with <font color="green"><strong>options</strong> of <strong>–fixbases –changes –diploid –mindepth 0.8</strong></font>. </p>
<p>Further, <font color="blue"><strong>short</strong> reads</font> of the two 10× single-cell CNV libraries, additional 10× single-molecule libraries <strong>and</strong> PacBio <font color="blue"><strong>HiFi</strong> reads</font> were <font color="blue"><strong>all aligned</strong> to the <strong>polished assembly</strong></font> (using <font color="red"><strong>bowtie2</strong></font> and <font color="red"><strong>minimap2</strong></font> (v.2.17-r491) respectively). Among <font color="blue">17,153 raw contigs, <strong>9,041 contigs</strong></font> which were <font color="blue">longer than <strong>50 kb</strong></font> and with an <font color="blue">average sequencing depth over <strong>80×</strong> were <strong>kept</strong></font>. </p>
<p><font color="blue">HiFi reads were <strong>re-aligned</strong> to the purged assembly and contigs covered less than 3× were <strong>removed</strong></font>. </p>
<p>The HiFi reads-based <font color="red"><strong>purging process</strong></font> was repeated for <font color="blue"><strong>five rounds</strong></font> to get an initial assembly of <font color="blue">6,366 contigs</font> for subsequent analysis (Supplementary Fig. 1).</p>
<p>##<strong>Haplotype-specific PacBio HiFi read separation and haplotype assembly.</strong></p>
<p>HiFi reads were <font color="blue">classified into 48 groups</font> on the basis of alignments to the 50-kb coverage markers using customized code. Specifically, to assign a read to a marker, at least 500 bp of the read had to be aligned to the marker (reads aligning two neighboring markers were assigned to the marker with a larger overlapping size). Reads overlapping non-haplotig marker were randomly assigned to one of the marker-associated groups.</p>
<p><font color="red"><strong>Each set</strong> of HiFi reads</font> was independently assembled using <font color="red"><strong>hifiasm</strong></font> (v.0.7) with default settings. The resulting contigs were first polished with <font color="red">short reads using <strong>pilon</strong></font> with <font color="green"><strong>–fix bases –changes –diploid –mindepth 0.8</strong></font> and then with <font color="red">HiFi reads using <strong>racon</strong></font> (v.1.4.10)46 with<font color="green"> <strong>-u –no-trimming</strong></font>.</p>
<p>##<strong>Evaluation of haplotyping accuracy.</strong> </p>
<p>For <font color="blue">each haplotype assembly</font> and the sequencing data of the parental genomes, <em>k</em>-mers (<em>k</em> = 21) were counted using <font color="red"><strong>KMC</strong></font>. Specifically, <em>k</em>-mers found in ‘Hera’ but not in ‘Stieglitz’ (with a coverage<br>of 6–12), as well as <em>k</em>-mers found in ‘Stieglitz’ but not in ‘Hera’ (with a coverage of 5–11) were selected using kmc_tools simple. For each haplotype, the sets of assembled <em>k</em>-mers were intersected with the two sets of parental-specific <em>k</em>-mers (using kmc_tools simple with subfunction intersect), which revealed <strong><em>k</em>-mers common with either of the parental genomes</strong>. </p>
<p>As a haplotype can only be inherited from one of the parents, it is expected to find parental-specific *k-*mers only of one parent. The overall haplotyping precision was determined as the total number of correctly phased <em>k</em>-mers divided by the total number of <em>k</em>-mers investigated in the <font color="red"><strong>48 haplotype assemblies</strong></font>. Note, this was done <font color="rblueed">before and after contig <strong>polishing</strong></font>, where we observed the same haplotyping accuracy.</p>
<p>##<strong>Haplotype-specific contig scaffolding using group-specific Hi-C reads.</strong> </p>
<p><font color="blue">Each haplotype-specific contig-level assembly</font> was indexed with <font color="red"><strong>bwa index</strong></font> (with -a bwtsw) (v.0.7.15-r1140) and <font color="red"><strong>samtools faidx</strong></font>. The haplotype-specific Hi-C read pairs were aligned using <font color="red"><strong>bwa aln</strong> and <strong>bwa sampe</strong></font>. Aligned reads (in pairs) were <strong>converted into BAM</strong> files using samtools view with options of <font color="green">-b -F12</font>. The BAM files were filtered with <font color="red"><strong>filterBAM_forHiC.pl</strong></font> (from ALLHiC package, v.0.9.13) to <font color="blue"><strong>remove nonuniquely mapped reads</strong></font>. Then BAM files were converted to bed files using <font color="red"><strong>bamToBed</strong></font> (from bedtools package) and <font color="blue"><strong>sorted</strong> by read name</font>. The <strong>bed files</strong> were provided to <font color="red"><em><strong>SALSA2</strong></em></font> (run with <font color="green">-s 100000000 -m yes -i 10 -e DNASE</font>). Potential chimeric contigs were broken at the chimeric sites given by SALSA2 output file of input_breaks, leading to a <font color="blue"><strong>new set</strong> of contigs for each of the 48 original groups</font>.</p>
<p>For <font color="blue">each new group of contigs</font>, the above process of <font color="red"><strong>contig indexing, Hi-C read alignment</strong> and <strong>BAM filtering</strong></font> was repeated. Then, for each haplotype, <font color="red"><strong>ALLHiC_ partition</strong></font> was run with <font color="green">-e GATC -k 1 -m 25</font>; <font color="red"><strong>allhic extract</strong></font> was run with <font color="green">–RE GATC</font>; allhic optimize and <font color="red"><strong>ALLHiC_build</strong></font> were run with <font color="green">default settings</font>; the chromosome contact map was visualized with <font color="red"><strong>ALLHiC_plot</strong></font> at <font color="green">1-Mb</font> resolution, where obvious mis-placement/orientation of large contigs were visually identified and manually corrected (Extended Data Fig. 3).</p>
<h1 id="13-2022-03-ng-六倍体小麦"><a href="#13-2022-03-ng-六倍体小麦" class="headerlink" title="13. 2022.03-ng 六倍体小麦"></a>13. 2022.03-ng 六倍体小麦</h1><blockquote>
<p>Long-read genome sequencing of bread wheat facilitates disease resistance gene cloning</p>
</blockquote>
<table>
<thead>
<tr>
<th>Genomic feature</th>
<th>Value</th>
</tr>
</thead>
<tbody><tr>
<td><em><strong>Length of HiFi assembly</strong></em></td>
<td>14.66 Gb</td>
</tr>
<tr>
<td>Number of contigs</td>
<td>5,055</td>
</tr>
<tr>
<td>Length of contig N50</td>
<td>30.22 Mb</td>
</tr>
<tr>
<td>Length of contig N90</td>
<td>5.5 Mb</td>
</tr>
<tr>
<td><strong><em>Length of hybrid assembly</em>a</strong></td>
<td>14.68 Gb</td>
</tr>
<tr>
<td><em><strong>Length of hybrid scaffolds</strong></em></td>
<td>14.46 Gb</td>
</tr>
<tr>
<td>Number of hybrid scaffolds</td>
<td>324</td>
</tr>
<tr>
<td>Length of hybrid scaffold N50</td>
<td>204.26 Mb</td>
</tr>
<tr>
<td>Gap size</td>
<td>18.8 Mb (0.13%)</td>
</tr>
<tr>
<td><em><strong>Length of pseudomolecule assembly</strong></em></td>
<td>14.68 Gb</td>
</tr>
<tr>
<td><em><strong>Total length of anchored pseudomolecules</strong></em></td>
<td>14.45 Gb</td>
</tr>
<tr>
<td>Number of anchored hybrid scaffolds or contigs</td>
<td>717</td>
</tr>
<tr>
<td>Gap size</td>
<td>11.6 Mb (0.08%)</td>
</tr>
<tr>
<td>Number of high-confidence genes</td>
<td>110,383</td>
</tr>
<tr>
<td><em><strong>Total length of unanchored chromosome</strong></em></td>
<td>224.01 Mb</td>
</tr>
<tr>
<td>Number of unanchored hybrid scaffolds or contigs</td>
<td>3,910</td>
</tr>
<tr>
<td>Gap size</td>
<td>8.1 Mb (3.6%)</td>
</tr>
<tr>
<td>Number of high-confidence genes</td>
<td>6,455</td>
</tr>
<tr>
<td><em><strong>BUSCO</strong></em></td>
<td></td>
</tr>
<tr>
<td>Complete</td>
<td>99.4%</td>
</tr>
<tr>
<td>Duplicated</td>
<td>96.3%</td>
</tr>
<tr>
<td>Fragmented</td>
<td>0.1%</td>
</tr>
<tr>
<td>Missing</td>
<td>0.5%</td>
</tr>
</tbody></table>
<h2 id="Genome-assembly-and-validation"><a href="#Genome-assembly-and-validation" class="headerlink" title="Genome assembly and validation."></a><strong>Genome assembly and validation.</strong></h2><p>The PacBio HiFi reads were assembled using <font color="red"><strong>hifiasm12 (v.0.11)</strong></font> with <font color="green">default parameters</font>. Hybrid scaffolding incorporating the PacBio contigs and the <font color="blue">optical map</font> was performed using the <font color="red"><strong>hybridScaffold pipeline</strong></font> (Bionano Solve 3.6) with default parameters. For the pseudomolecule construction, the Omni-C reads were incorporated using <font color="red"><strong>Juicer tools (v.1.6)</strong></font> and <font color="red"><strong>3D-DNA (v.180114)</strong></font>. </p>
<p>In brief, the preprocessing of the Omni-C reads was performed with juicer.sh (parameter: -s none). The ‘merged_nodups.txt’ output file corresponding to the Hi-C contacts with duplicates removed was subsequently used with run-asm-pipeline.sh (parameter: -r 0) as input to produce the ‘.hic’ and ‘.assembly’ files. These files were uploaded into Juicebox (v.1.11.08) to visualize the Hi-C map and for manual curation. </p>
<p>As a final step, the script <font color="red"><strong>run-asm-pipeline-post-review.sh</strong></font> (default parameters) was used to save the final Hi-C contact map and to output the final Kariega assembly (21 pseudomolecules and 1 unanchored pseudochromosome). To <font color="blue"><strong>validate</strong> the genome assembly</font>, we remapped the optical map onto the pseudomolecule using the <font color="red"><strong>hybridScaffold pipeline</strong></font> (Bionano Solve 3.6), and the final pseudomolecules were compared with the recent bread wheat assemblies of Chinese Spring (IWGSC RefSeq v.2.1) and the assemblies of the 10+ Wheat Genomes Project using <font color="red"><strong>MashMap</strong></font> (v.2.0; parameter: -s 300000–pi 98).</p>
<h1 id="14-2019-10-二倍体巴特利特梨-【四倍体土豆参考hic组装1】"><a href="#14-2019-10-二倍体巴特利特梨-【四倍体土豆参考hic组装1】" class="headerlink" title="14.  2019.10 二倍体巴特利特梨 【四倍体土豆参考hic组装1】"></a>14.  2019.10 二倍体巴特利特梨 【四倍体土豆参考hic组装1】</h1><blockquote>
<p>Pseudo-chromosome–length genome assembly of a double haploid “Bartlett” pear (<em>Pyrus communis</em> L.)</p>
</blockquote>
<p><strong>Genome assembly and scaffolding</strong></p>
<p>The genome assembly workflow began with <em>de novo</em> assembly of contigs from the PacBio long reads using 2 tools, <font color="red"><strong>Canu</strong></font> (version 1.5) and <font color="red"><strong>Falcon</strong></font> (version 0.5). For each assembler the most important assembly parameters were systematically varied (Supplementary Methods), as defined by the tool developers, and by consideration of assembly theory (e.g., overlap length, overlap identity for overlap layout consensus assembly). <font color="blue"><strong>Optimal settings</strong> were <strong>selected</strong></font> by <strong>comparison of assembly statistics</strong> (total size assembled and contig N50) and by <strong>alignment of Illumina PE</strong> data to the assembly with <font color="red"><strong>bowtie2</strong></font> (using the “very fast” pre-set). For <font color="blue">all PacBio assemblies</font> the consensus step was performed by running <font color="red"><strong>Quiver纠错</strong></font> (Genomic Consensus version 2.3.3) (with default parameters) on <font color="blue">raw PacBio contigs</font> and using the full 63× of PacBio data.</p>
<p>Assembled contigs were further joined into scaffolds using a combination of <strong>BioNano optical mapping</strong> data, <strong>Hi-C</strong> chromatin conformation capture data, and <strong>genetic maps.</strong> The best <font color="blue">assemblies from Canu and Falcon</font> were <font color="blue">independently combined with</font> BioNano optical mapping data using the <font color="red">IrysView</font> software to develop the Canu + BioNano (CB) and Falcon + BioNano (FB) assemblies, respectively. The BioNano scaffolding process identified conflicts between the assembled contigs and the optical map, indicating some degree of misassembly in both Canu and Falcon results.</p>
<p><strong>Assembly polishing</strong></p>
<p><font color="red"><strong>Pilon</strong></font> (version1.21) [31] was <font color="blue">run iteratively</font> on the assembly, with <font color="blue">Illumina sequence realigned to the polished assembly</font> at each iteration and then <font color="blue">alignments passed to Pilon to call the next consensus</font>. Alignments for Pilon were produced using <font color="red"><strong>BWA mem</strong></font> (v0.7.17) with default settings. <em>k</em>-mer spectrum comparisons were made using the <em>k</em>-mer analysis toolkit (<font color="red"><strong>KAT</strong></font>) (version 2.3.4) [13] (KAT comp) at a <em>k</em>-mer size of 32, and <font color="blue">the metric used to assess each iteration was the number of <strong>k-mers shared between</strong> the <strong>assembly</strong> and the <strong>Illumina</strong> reads</font>. </p>
<p>In a second consensus phase, <font color="blue">RNA-Seq</font> reads were aligned as single end (SE), to the genome using <font color="red"><strong>Hisat</strong></font> (version 2.1.0)  with default parameters. This time the effectiveness of consensus calling was <font color="blue">assessed by analysis of <strong>full-length alignments</strong> of assembled RNA-Seq transcripts</font>. All transcripts designated as “complete” by Evigene  were aligned to the genome with BLAT  (version 3.4, with [34] minimum match identity 90%). Alignments were filtered to <strong>retain only full-length alignments</strong> (i.e., from query start to query end). </p>
<p>Finally, the number of gaps in the alignments (query gaps + target gaps) was used as a metric with the rationale that this serves as a proxy for the number of indels in alignments of assembled messenger RNA sequence.</p>
<p><strong>Scaffold clustering and genome anchoring using Hi-C</strong></p>
<p>Hi-C reads were aligned to the polished scaffolds in CB with <font color="red"><strong>Bowtie2</strong></font> (version 2.3.3.1) . Each of the paired reads was aligned independently; then these SE alignments were subsequently merged as recommended by the LACHESIS developers. Based on the alignments, <font color="red">CB scaffolds were <strong>arranged</strong> into <strong>17 ordered</strong> and <strong>oriented</strong> <strong>clusters</strong> using the <strong>LACHESIS</strong> software</font>. As an <font color="blue">internal check</font>, the process was completed on <font color="blue">2 different random 95% sub-samplings of the Hi-C data</font>, as well as on the full data set. The clusters produced by <strong>all 3</strong> of these LACHESIS runs were <font color="blue">identical</font>. <font color="blue">LACHESIS produces groups of scaffolds</font> that are ordered and oriented relative to each other. These scaffold groupings were <font color="blue">compared with the genetic map</font> and the <strong>consistency</strong> of these sources of information was <strong>assessed</strong>. <font color="blue">The SNP probe mapping </font>at the scaffold <strong>validation step</strong> was compared with the clusters produced by LACHESIS.</p>
<p><strong>Illumina assembly</strong></p>
<p>The Illumina data were also assembled on their own, using the de Bruijn graph–based assembler <font color="red"><strong>SOAPdenovo2</strong></font> (version 2.04). <font color="blue"><strong>This assembly</strong></font> was <font color="blue"><strong>used in various ways</strong></font> during the course of the pear genome project (for further scaffold validation, for training the <em>ab initio</em> gene predictors, etc.). <font color="red"><strong>【借鉴】The Illumina data were assembled twice</strong></font>. The <font color="red">first pass</font> contigs were screened using the Kraken software and an index built from the entire RefSeq database. <font color="red">Reads aligning to contaminant contigs were <strong>removed</strong></font> and the remaining data were assembled again.</p>
<h1 id="15-2021-05-nbt-人-【四倍体土豆参考hic组装2】"><a href="#15-2021-05-nbt-人-【四倍体土豆参考hic组装2】" class="headerlink" title="15.  2021.05-nbt 人 【四倍体土豆参考hic组装2】"></a>15.  2021.05-nbt 人 【四倍体土豆参考hic组装2】</h1><blockquote>
<p>Chromosome-scale, haplotype-resolved assembly of human genomes</p>
</blockquote>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/10.png" alt="10"></p>
<p>outline of the phased assembly algorithm, <font color="red"><strong>DipAsm</strong></font></p>
<p>Assemble HiFi reads into unphased contigs using <font color="red"><strong>Peregrine</strong></font> (1);</p>
<p> <font color="blue"><strong>group</strong> and <strong>order</strong></font> contigs into scaffolds with <font color="blue"><strong>Hi-C</strong> data</font> using <font color="blue"><strong>Hirise/3D-DNA</strong></font> (3D de novo assembly) (2);</p>
<p> <font color="blue"><strong>map HiFi reads</strong> to scaffolds</font> and <font color="blue"><strong>call heterozygous SNPs</strong></font> using <font color="red"><strong>DeepVariant</strong></font> (3);</p>
<p> <font color="blue"><strong>phase</strong></font> heterozygous SNP calls with both HiFi and Hi-C data using <font color="red"><strong>WhatsHap plus HapCUT2</strong></font> (4);</p>
<p> partition reads based on their phase using <font color="red"><strong>WhatsHap</strong></font> (5);</p>
<p> assemble partitioned reads into <font color="blue"><strong>phased contigs</strong></font> using <font color="red"><strong>Peregrine</strong></font> (6).</p>
<p><strong>Phased sequence assembly.</strong> </p>
<p>We ran <font color="red"><strong>Peregrine v.0.1.5.2</strong></font> with the following command line: ‘peregrine asm reads.lst 24 24 24 24 24 24 24 24 24 –with-consensus –shimmer-r 3 –best_n_ovlp 8–output asm’, where file ‘reads. lst’ gives the list of input read files and directory ‘asm’ holds the output assembly. </p>
<p>We <font color="blue"><strong>mapped Hi-C reads to contigs</strong></font> with <font color="red"><strong>BWA-MEM</strong></font> v.0.7.17 and <font color="blue"><strong>scaffolded</strong></font> the Peregrine contigs with <font color="red"><strong>juicer v.1.5</strong></font> and <font color="red"><strong>3D-DNA v.180922</strong></font>. We preprocessed data with <font color="green"><strong>‘juicer.sh -d juicer -p chrom.sizes -y cut-sites.txt -z contigs.fa -D’</strong></font>, where file <strong>‘cut-sites.txt’</strong> was <strong>generated</strong> using the <strong>generate_site_positions_Arima. py</strong> script, which <strong>outputs merged_nodups.txt</strong>. The scaffolds were produced with <font color="green"><strong>‘run-asm-pipeline.sh -m haploid contigs.fa merged_nodups.txt’</strong></font>. </p>
<p>We then called small variants using DeepVariant v.0.8.0 with the pretrained PacBio model. </p>
<p>We mapped Hi-C reads to the scaffolds and ran HapCUT2 v.1.1 over heterozygous SNP sites to obtain sparse phasing at the chromosome scale. The resulting haplotypes were then combined with PacBio HiFi data using WhatsHap v.0.18, with default parameters, to generate fine-scale, chromosome-long phasing. </p>
<p>We partitioned HiFi reads based on the phases of SNPs residing on these reads, and ran Peregrine again for reads on the same haplotype from the same scaffold. This provided the final phased assembly.</p>
<h1 id="16-2018-11-ng-同源多倍体甘蔗-【四倍体土豆参考hic组装3】"><a href="#16-2018-11-ng-同源多倍体甘蔗-【四倍体土豆参考hic组装3】" class="headerlink" title="16.  2018.11-ng 同源多倍体甘蔗 【四倍体土豆参考hic组装3】"></a>16.  2018.11-ng 同源多倍体甘蔗 【四倍体土豆参考hic组装3】</h1><blockquote>
<p>Allele-defined genome of theautopolyploid sugarcane <em>Saccharum spontaneum</em> L.</p>
</blockquote>
<p><strong>材料</strong></p>
<p>栽培甘蔗的<font color="blue">单倍型个体</font><em>S.spontaneum</em>“AP85-441”(1n = 4x = 32) 进行基因组<em>denovo</em>测序研究。<br>64份甘蔗（<em>Saccharum spontaneum</em>）群体材料进行<font color="blue">遗传多样性研究</font>。</p>
<p><strong>方法</strong></p>
<p>二代280-bp和500-bp(PE) 小片段文库（Illumina HiSeq 2500）<br>BAC文库（Illumina HiSeq 2500，PE250）；三代大片段文库~20kb SMRTbellTM（<font color="blue">PacbioRSII</font>）<br>Hi-C文库（<font color="blue">HindIII酶切</font>），500-700bp小片段文库（HiSeqX ten，PE150）</p>
<p><strong>主要结果</strong>：</p>
<p><strong>甘蔗基因组denovo</strong><br>利用BAC文库进行二代测序，ALLPATH-LG,SPAdes 和SOAPdenovo2进行初步组装，进一步利用<font color="blue">87X 三代PacBio数据进行<strong>纠错</strong></font>，<font color="red"><strong>CANU</strong></font>组装，组装基因组3.13G，<font color="blue">contigN50=45 kb</font>（流式评估基因组大小：3.36G）；通过Hi-C染色体挂载技术，针对<font color="red"><strong>多倍体染色挂载最新算法ALLHIC</strong></font>，进一步将contig水平提升至染色体水平，<strong>挂载率达到93%<strong>；通过BUSCO和二代数据回比评估基因组完整性高达</strong>97.3%<strong>。再通过<font color="red"><strong>MAKER</strong></font>对同源多倍体甘蔗<font color="blue">特异等位基因进行</font></strong>手动注释</strong>，以获得高质量的甘蔗基因组</p>
<p>**基础染色体数目的减少 *<em>禾本科染色体数进化（高粱n= 10到甘蔗n= 8）<br>AP85-441基因组的组装显示了</em>S.spontaneum*的染色体数目从10降到8，而这与频繁复制的古复制染色体对相关，通过与高粱的聚类比对，发现高粱祖先5染色体和8号染色体同源物经历了染色体裂变（图2）。SbChr05（A12）的祖先染色体断裂分为两个主要部分，即C5S（A12S）和C5L（A12L），分别转移到SbChr06（A2）和SbChr07（A5）的祖先染色体；SbChr8（A11）的祖先染色体断裂为两个主要的部分，即C8S（A11S）和C8L（A11L），分别转移到SbChr09（A6）和SbChr02（A7+ A9）的祖先染色体中。SbChr8和SsChr5之间及SbChr5和SsChr7之间近乎同源的短片段是在高粱与甘蔗分化前，高粱SSA形成于13.4MYA同源基因的残留物，同时发现，S5中较小的SSA区域和S8中SSA的较大区域在重排的AP85-441基因组中也是保守的。</p>
<p><strong>S.spontaneum的多倍体化分析</strong><br>进一步研究发现了甘蔗（<em>Saccharum spontaneum</em> L.）染色体由高粱（<em>Sorghum</em>）演变进化过程中经历了染色体断裂与融合后，发生了两次WGD事件（图3）；对甘蔗的基因组的多倍化研究中发现，通过两次全基因组复制事件的发生，导致了甘蔗染色体的自发加倍过程；对同源多倍体甘蔗的特异等位基因的鉴定作为本研究的另一亮点，文章在鉴定等位基因的同时，进一步分析研究了等位基因的表达模式，结果发现不同单倍型表达模式相似，并无明显差异；对甘蔗C4光合作用的研究中鉴定了24个基因，7种关键酶参与NADP-MEC4途径；在甘蔗中蔗糖对的积累的研究中发现与高粱相比甘蔗中的液泡膜糖转运蛋白（TSTs，一种蔗糖转运蛋白）发生了基因家族的扩张，所以推测TSTs参与蔗糖在液泡中的积累；<em>S.spontaneum</em>为现代栽培甘蔗提供了抗病性基因，在对其研究中发现，甘蔗中的80％的NBS编码基因位于四个重排染色体（Ss02，Ss05，Ss06和Ss07）上，其中51％位于重排区域。</p>
<p><strong>S.spontaneum的起源与遗传多样性分析</strong><br>通过对64份甘蔗（<em>Saccharum spontaneum</em>）群体材料遗传多样性研究，发现其具有广泛的自然部分范围，遍及亚洲，印度次大陆，地中海和非洲，且自然种群具有广泛的表型，遗传和倍性水平多样性（图4）。研究发现，与高粱相比具有大规模染色体重排的<em>S. spontaneum</em>区域具有比非重排区域更高的遗传多样性，并且可能经历了更强的平衡选择。虽然几条单独的染色体没有显示出显著差异，但是比较所有染色体上的平均值显示重排区域中的核苷酸多样性（0.00025±0.00003）远高于非重排区域中的核苷酸多样性（0.00021±0.00001），染色体重排区域的Tajima’s D（-0.659±0.052）远远高于非重排区（-0.720±0.011），重排区的SNP密度(360.27±48.41) 高于非重排区域（297.46±12.65, P=0.001798）；此外，GO富集显示，染色体非重排区主要富集到与基本生命周期，光合作用，呼吸作用和ATP合成的通路上。重排区主要富集在GO生物合成和代谢，跨膜转运和离子结合通路上。</p>
<p><em>S. spontaneum</em>重排区具有高度的遗传多样性将更适应环境压力，例如对各种非生物胁迫（干旱，盐度，碱性，金属离子等）的反应，这些受到次生细胞生物合成和代谢，跨膜转运和离子结合的控制的基因在这些区域可以检测到。在多倍化事件后，重排区域经历了更强的平衡选择。</p>
<p><strong>讨论</strong></p>
<p>本研究利用复杂基因组Hi-C建库测序技术，并结合ALLHiC算法成功组装了高复杂同源多倍体甘蔗基因组AP85-441，高质量的甘蔗基因组的获得，为后续研究其蔗糖含量，抗性等性状及农业育种基础奠定了基础。</p>
<p><strong>Genome assembly overview.</strong> </p>
<p>The sugarcane AP85-441 contig-level assembly incorporated sequencing data from a mixture of sequencing technologies (Supplementary Fig. 1), including BAC pools sequenced with Illumina HiSeq 2500 and whole-genome shotgun sequencing with PacBio RS II as well as Hi-C reads, followed by Illumina short reads polishing. Each BAC pool was independently assembled using <font color="red">ALLPATHS-LG, SPAdes and SOAPdenovo2</font>, and best results were retained. For PacBio assembly, <font color="red"><strong>Canu v1.511</strong></font> was used, as it is capable<br>of avoiding collapsed repetitive regions and haplotypes. Self-correction was performed with parameter corOutCoverage = 100, which allowed us to correct all of the input PacBio reads. The corrected reads, along with BAC-assembled contigs, were imported to the assembly step. <font color="blue">Chromosomal assembly</font> was constructed based on proximity-guided assembly using our newly developed program, <font color="red"><strong>ALLHIC</strong>, which is designed for <strong>polyploid</strong> genome scaffolding</font> (see Supplementary Note for details).</p>
<p><img src="/blog/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/11.png" alt="11"></p>
<h1 id="17-2019-08-np-ALLHiC【四倍体土豆参考hic组装4】"><a href="#17-2019-08-np-ALLHiC【四倍体土豆参考hic组装4】" class="headerlink" title="17.  2019.08-np ALLHiC【四倍体土豆参考hic组装4】"></a>17.  2019.08-np ALLHiC【四倍体土豆参考hic组装4】</h1><blockquote>
<p>Assembly of allele-aware, chromosomal-scale autopolyploid genomes based on Hi-C data</p>
</blockquote>
<p><strong>existing approaches are mostly designed for diploid genomes and often with the aim of reconstructing a haploid representation, thereby having limited power to reconstruct chromosomes for autopolyploid genomes. We developed a novel algorithm (ALLHiC) that is capable of building allele-aware, chromosomal-scale assembly for <font color="red">auto-polyploid genomes</font> using Hi-C paired-end reads with innovative ‘prune’ and ‘optimize’ steps. Application on simulated data showed that ALLHiC can phase allelic contigs and substantially improve ordering and orientation when compared to other mainstream Hi-C assemblers</strong></p>
<h1 id="18-2020-05-nc-紫花苜蓿同源四倍体-06【四倍体土豆参考hic组装5】"><a href="#18-2020-05-nc-紫花苜蓿同源四倍体-06【四倍体土豆参考hic组装5】" class="headerlink" title="18. 2020.05-nc 紫花苜蓿同源四倍体-06【四倍体土豆参考hic组装5】"></a>18. 2020.05-nc 紫花苜蓿同源四倍体-06【四倍体土豆参考hic组装5】</h1><h1 id="19-2020-10-ng-二倍体土豆-【四倍体土豆参考hic组装6】"><a href="#19-2020-10-ng-二倍体土豆-【四倍体土豆参考hic组装6】" class="headerlink" title="19. 2020.10-ng 二倍体土豆 【四倍体土豆参考hic组装6】"></a>19. 2020.10-ng 二倍体土豆 【四倍体土豆参考hic组装6】</h1><blockquote>
<p>Haplotype-resolved genome analyses of a heterozygous diploid potato</p>
</blockquote>
<p>ref of 12: Hi-C-genetic-maps-for-<font color="red">correction</font></p>
<p>马铃薯(Solanum tuberosum L.)是全球重要的块茎作物。人们正在努力将这种作物从无性繁殖的四倍体转化为种子繁殖的、自交系为基础的杂交作物，但这一过程需要对马铃薯基因组有更好的了解。</p>
<p><strong>Genome assembly and phasing using PacBio CCS reads.</strong> </p>
<p>A total of 29 Gb CCS reads were assembled using <font color="red"><strong>Canu</strong></font> (v1.91) with the <font color="green"><strong>parameter</strong> –pacbio-hifi</font>.<br>Canu <font color="blue">generated <strong>two</strong> assemblies</font> composed of contigs and unitigs (Supplementary Table 4), and the <font color="blue"><strong>unitig</strong> assembly consisted of the <strong>contigs that split at any alternative paths</strong> in the assembly graph</font>. The contig assembly had longer continuity but more chimeric fragments嵌合体片段 as revealed in the genetic mapping analysis. To avoid the mis-joining of two haplotypes, <font color="red"><strong>the unitig assembly</strong></font> rather than the contig assembly was chosen for the <font color="red"><strong>subsequent analysis</strong></font>. The unitigs were then <font color="blue"><strong>polished</strong> iteratively using <strong>two rounds</strong></font> of <font color="red"><strong>Pilon</strong></font> with ~150 Gb of WGS <strong>Illumina</strong> data, generating the genome <strong>draft RHgv2</strong>.</p>
<p>Similarly, the sequenced reads of RH selfing progeny后代 were mapped to unitigs of RHgv2 to perform <font color="blue"><strong>genetic grouping</strong></font>. Because the unitigs were relatively long (N50 = 2 Mb), windows with a size of 200 kb rather than the whole unitig were used. If the adjacent windows of one unitig showed contrary read distribution, the unitig was defined as chimeric and broken between windows; 40 chimeric unitigs with a total length of 95 Mb were broken. In total, <font color="blue">1.31 Gb of 1.53 Gb sequences were assigned to 24 linkage groups</font>.</p>
<p>After merging, 141 Mb sequences and 5,252 annotated genes of RHgv1 were added to the RHgv2, yielding a 1.67 Gb genome draft with 1.54 Gb sequences assigned to 24 groups, termed RHgv3 (Supplementary Table 6). The sequences from the RHgv1 and RHgv2 assemblies were named as ontctg* and unitig* in the AGP file, respectively (Supplementary Data 3).</p>
<p><strong>Construction of pseudochromosomes.</strong> </p>
<p>As no approach generated satisfactory results on the RH genome, we introduced the group information derived from the genetic mapping to assist the Hi-C application on chromosome-level assembly. The process was performed on RHgv3 including three steps as follows:</p>
<ol>
<li><font color="blue"><strong>Align</strong></font>. The 24 previously determined groups were divided into <font color="blue"><strong>two haplotypes</strong> to <strong>generate</strong> <strong>two</strong> <strong>pseudohaploid genome drafts</strong></font>. The 132 Mb sequences that could not be assigned to any group were added to two pseudohaploid genomes. Total <font color="blue">Hi-C reads were <strong>aligned</strong> to <strong>each</strong> pseudohaploid genome using <strong>HiC-Pro</strong> to calculate the <strong>contact frequency</strong></font>. This step <font color="blue">yielded <strong>two bam files</strong> for the two pseudohaploid genomes</font>.</li>
<li><font color="blue"><strong>Rescue</strong></font>. Using the <font color="blue">bam file as input</font>, the <em>rescue</em> function in <font color="red"><strong>ALLHiC</strong></font> was applied to assign unplaced sequences to known groups. Because the 132 Mb <strong>unplaced sequences</strong> were <strong>added</strong> to two pseudohaploid genomes and <strong>processed twice</strong>, the rescued <strong>results were redundant</strong>. For every <strong>unplaced sequence</strong>, we <strong>considered its best Hi-C signal density</strong> to decide the group to which it belonged. After this step, the sequence content of 24 groups was updated with an <strong>extra 75.6 Mb</strong> sequences assigned to proper groups.</li>
<li><font color="blue"><strong>Optimize and build</strong></font>. For each pseudohaploid genome, using <font color="red">the bam file and the updated group file as input</font>, the <font color="red"><strong><em>optimize</em> function in ALLHiC</strong></font> decidedthe <strong>order</strong> and <strong>orientation</strong> of scaffolds for each group; thus, the <font color="red"><strong><em>build</em> function</strong></font> generated fasta sequences on that basis. By performing this step, we identified the pseudochromosomes for 24 groups. The order and orientation of scaffolds on chromosomes are provided in Supplementary Data 3.</li>
</ol>
<h1 id="20-2021-12-gb-杏树【四倍体土豆参考hic组装7】"><a href="#20-2021-12-gb-杏树【四倍体土豆参考hic组装7】" class="headerlink" title="20. 2021.12-gb 杏树【四倍体土豆参考hic组装7】"></a>20. 2021.12-gb 杏树【四倍体土豆参考hic组装7】</h1><blockquote>
<p>Gamete binning: chromosome-level and haplotype-resolved genome assembly enabled by high-throughput single-cell sequencing of gamete genomes</p>
</blockquote>
<p>ref of 12: Hi-C-genetic-maps-for-correction</p>
<p>一种基于单倍体配子单细胞测序的方法。基于445个个体花粉粒的全基因组测序，组装了一株二倍体杏树的两个基因组。</p>
<p><strong>Genome size estimation</strong></p>
<p>After trimming off 10x Genomics barcodes and hexamers from the 61.7 Gb reads of the two 10x sc-CNV libraries, k-mer counting (k=21) was performed with <font color="red"><strong>Jellyfish</strong></font>. The k-mer histogram was provided to<font color="red"> <strong>findGSE</strong></font> to estimate the size of the “Rojo Pasión” genome under the heterozygous mode (with “exp_hom=200”; Add- itional file 1: Fig. S3).</p>
<p><strong>Preliminary diploid-genome assembly and curation</strong></p>
<p>With the 19.9 G raw PacBio reads of “Rojo Pasión” (Additional file 1: Fig. S2), a pre-liminary diploid assembly was constructed using <font color="red"><strong>Canu</strong></font> (with options “genome- Size=242500000 corMhapSensitivity=high corMinCoverage=0 corOutCoverage=100 correctedErrorRate=0.105”).</p>
<p>All raw <strong>Illumina reads</strong> from the 10x libraries were <font color="red">firstly <strong>aligned</strong> to the <strong>initial assembly</strong></font> using <font color="red"><strong>bowtie2</strong></font>. Then, the purge haplotigs pipeline was used to remove haplotigs (i.e., haplotype-specific contigs inflating the true haploid genome) based on statistical analysis of sequencing depth and identify primary contigs to build up a curated haploid assembly. To reduce the false-positive rate in defining haplotigs, each haplotig was blasted to the curated assembly; if over 50% of the haplotig could not be covered by any primary contigs, it was re-collected as a primary contig.</p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>HiFi-5-[HiC-Pro]-[MCscan]-[ALLHiC]</title>
    <url>/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/</url>
    <content><![CDATA[<p>HiC-Pro将fq文件处理成互作allValidPairs，再转化成可视化hic文件(for juicer)</p>
<span id="more"></span>

<h1 id="HiC简介"><a href="#HiC简介" class="headerlink" title="HiC简介"></a>HiC简介</h1><ul>
<li><p><strong>1.1 Hi-C技术</strong>高通量染色体构象捕获技术(<code>High-throughput chromosome conformation capture</code>)研究全基因组三维构象及分析染色质片段相互作用的实验技术</p>
</li>
<li><p><strong>1.2 Hi-C目的</strong>了解核内染色质的三维构象、获得细胞核内空间位置非常接近或存在相互作用的染色质测序片段更好地研究染色质内或染色质间的互作、基因调控元件在全基因组范围内调控的情况</p>
</li>
<li><p><strong>1.3 Hi-C应用方向</strong>辅助基因组组装、揭示空间调控、揭示物种进化、疾病研究、三维结构差异分析、还原染色体三维结构、构建染色体跨度单体型</p>
</li>
<li><p><strong>1.4 互作本质</strong>统计学上基因组两点之间发生空间接触的概率</p>
</li>
<li><p><strong>1.5 Hi-C实验原理</strong></p>
</li>
<li><p><strong>1.6 二代文库构建及测序</strong></p>
</li>
<li><p><strong>1.7 Hi-C实际文库类型</strong>将HIC数据进行比对是会出现不同的比对情况，需要的是<font color="blue">双端唯一匹配</font>。对单端匹配、多处比对、未比对的reads进行过滤。</p>
<p><img src="/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/5.png" alt="HiC-Pro的使用"></p>
<p>Hi-C文库构建产生多种分子类型，包括 re-ligation、Dangling ends、self circle 、dump reads 及valid pairs reads等类型。 在 Hi-C 分析中，<font color="red">仅valid pair可以反映基因组上位点与位点间的互作</font>。因此，<font color="blue">非重复的valid pair</font>所占比例是评估Hi-C文库质量重要指标</p>
<p><img src="/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/6.png" alt="三维基因组技术（三）：Hi-C 数据比对及HiC-Pro的使用"></p>
</li>
<li><p><strong>互作矩阵的生成</strong>由于计算资源，数据量等因素，<font color="blue">需要确定一个互作单位：bin</font>。将基因组按照一定大小分成bin。<font color="red">将过滤后的有效序列分配到这些bin中</font></p>
<p><img src="/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/7.png" alt="三维基因组技术（三）：Hi-C 数据比对及HiC-Pro的使用"></p>
</li>
<li><p><strong>互作矩阵的矫正</strong>Hi-C数据中由于<font color="blue">内切酶偏好性、基因组本身质量、基因组序列特异性</font> 导致其在基因组不同位置间存在偏差。因此，<font color="red">对互作矩阵校正，使其数据在基因组上每个位点的覆盖度一致</font>。常用矫正方式有<font color="red"><strong>迭代矫正、归一化</strong></font>等</p>
<p><img src="/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/8.png" alt="三维基因组技术（三）：Hi-C 数据比对及HiC-Pro的使用"></p>
</li>
</ul>
<h2 id="HiC常规软件"><a href="#HiC常规软件" class="headerlink" title="HiC常规软件"></a>HiC常规软件</h2><table>
<thead>
<tr>
<th align="left">软件名</th>
<th align="left">hiclib</th>
<th align="left">HiC-Pro</th>
<th align="left">HICUP</th>
<th align="left">Juice</th>
</tr>
</thead>
<tbody><tr>
<td align="left">比对软件</td>
<td align="left">Bowtie2</td>
<td align="left">Bowtie2</td>
<td align="left">Bowtie2</td>
<td align="left">BWA-mem</td>
</tr>
<tr>
<td align="left">比对策略</td>
<td align="left">迭代比对</td>
<td align="left">全局、局部比对</td>
<td align="left">先截短后比对</td>
<td align="left">Pair-end，嵌合reads过滤</td>
</tr>
<tr>
<td align="left">嵌合reads处理</td>
<td align="left">√</td>
<td align="left">√</td>
<td align="left">√</td>
<td align="left">√</td>
</tr>
<tr>
<td align="left">构建矩阵</td>
<td align="left">√</td>
<td align="left">√</td>
<td align="left">×</td>
<td align="left">√</td>
</tr>
<tr>
<td align="left">标准化</td>
<td align="left">ICE</td>
<td align="left">ICE</td>
<td align="left">×</td>
<td align="left">KR</td>
</tr>
<tr>
<td align="left">结果文件</td>
<td align="left">hdf5、hm、bychr(HDF5)</td>
<td align="left">SAM、validpair</td>
<td align="left">SAM</td>
<td align="left">SAM、MND、.hic</td>
</tr>
<tr>
<td align="left">特点</td>
<td align="left">比对结果可靠，存储消耗小</td>
<td align="left">简单易用，输出结果可读</td>
<td align="left">过滤非常严格</td>
<td align="left">后续分析接口多，juicebox可视化</td>
</tr>
</tbody></table>
<h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><p>HiFi助力同源四倍体紫花苜蓿基因组组装，NC</p>
<blockquote>
<p>Allele-aware chromosome-level genome assembly and efficient transgene-free genome editing for the autotetraploid cultivated alfalfa</p>
</blockquote>
<p>（1）使用Canu默认参数，利用CCS clean reads组装contigs。组装得到的Contig N50值为459kb，总长度为3.15GB。</p>
<blockquote>
<p>We assembled contigs from CCS clean reads using Canu, with default parameters. The N50 values of the contig sets were 459 kb, with total lengths 3154 Mb.</p>
</blockquote>
<p>（2）使用HiC-Pro将Hi-C reads与contigs 进行比对，产生比对BAM文件。</p>
<blockquote>
<p>Hi-C reads were aligned to contigs using <a href="https://pubmed.ncbi.nlm.nih.gov/26619908/">HiC-Pro(2015)</a>, yielding an alignment BAM file.</p>
</blockquote>
<p>（3）使用注释的蒺藜苜蓿蛋白作为参考，完全基于同源的策略注释contigs。对138,729个同源基因进行了结构注释。用MCscan用于鉴定contigs和参考基因组之间的共线性。显示紫花苜蓿和蒺藜苜蓿之间的高共线性。【下载父母本petunia ref】</p>
<blockquote>
<p>Contigs were annotated with a <font color="red"><strong>solely homology-based strategy</strong></font>, using annotated Medicago truncatula proteins as references. 138,729 homologous genes were structurally annotated. <font color="red"><strong>MCscan</strong> in <strong>Jcvi</strong></font> (<a href="https://zenodo.org/record/31631#.XpkUyTOeask">https://zenodo.org/record/31631#.XpkUyTOeask</a>) was used to identify <font color="red"><strong>synteny blocks</strong></font> between <strong>contigs and the reference</strong> genome. <font color="red"><strong>Contigs syntenic</strong> to M. truncatula were <strong>stacked and aligned</strong> to M. truncatula chromosomes</font>. The syntenic contigs are summarized in Supplementary Table 4.</p>
</blockquote>
<p><img src="/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/1.png" alt="STable4"></p>
<p>（4）使用内部脚本处理BAM文件，去除等位基因contigs之间的links。使用ALLHiC软件，<font color="red">提取、聚类和重排Contigs</font> (Contigs syntenic与蒺藜苜蓿染色体一致)，得到原始的scaffolds。</p>
<blockquote>
<p>An <strong>in-house script</strong> was used to <font color="red">prune the BAM</font> file and <font color="red">discard links between allelic contigs</font>. Contigs syntenic to one chromosome of M. truncatula, e.g., chr1, were extracted, sub-clustered and reordered using <font color="red">ALLHiC</font>, yielding a raw scaffold set.</p>
</blockquote>
<p>（5）<a href="https://pubmed.ncbi.nlm.nih.gov/27467250/">Juicebox</a>用于以图形和交互方式微调组装的scaffolds。剪裁了40个总长度达1800Mb的scaffolds 。</p>
<blockquote>
<p>Juicebox45 was used for fine-tuning assembled scaffolds in a graphic and inter-active fashion. Forty scaffolds with a total length of 1800 Mb were cropped (Supplementary Table 5).</p>
</blockquote>
<p><img src="/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/2.png" alt="STable5"></p>
<p>（6） 基于组装的scaffold，通过Hi-C数据，每个unplaced contig被分配到互作最强的那些contig cluster里。</p>
<blockquote>
<p>Based on this scaffold assembly, each unplaced contig was assigned to the contig cluster, to which the contig was most connected by Hi-C data.</p>
</blockquote>
<p>（7）使用ALLHiC对那些contig clusters再次进行重排和构建scaffold。</p>
<blockquote>
<p>Those contig clusters were reordered and scaffolded using ALLHiC. </p>
</blockquote>
<p>（8）使用Juicebox对scaffolds进行微调，并从scaffolds上去除不一致的contigs，产生最终的染色体基因组，其包含32条染色体(8个同源组，每个组中有4个等位基因染色体)，总长度为2738Mb，和419Mb未挂载到染色体水平的序列。</p>
<blockquote>
<p>Using Juicebox, scaffolds were fine-tuned and discordant contigs were removed from scaffolds, and the final chromosome assembly was generated, containing 32 chromosomes with a total length of 2738 Mb (Supplementary Table 6).</p>
</blockquote>
<p><img src="/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/3.png" alt="STable6"></p>
<h1 id="HiC-Pro-install"><a href="#HiC-Pro-install" class="headerlink" title="HiC-Pro install"></a>HiC-Pro install</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">conda env create -f ./HiC-Pro/environment.yml -p ///software/HiC_Pro_ENV</span><br><span class="line"><span class="comment">#【install env in my software dir】</span></span><br><span class="line">conda activate env</span><br><span class="line"></span><br><span class="line">tar -zxvf HiC-Pro-master.tar.gz</span><br><span class="line"><span class="built_in">cd</span> HiC-Pro-master</span><br><span class="line"><span class="comment">## Edit config-install.txt file if necessary</span></span><br><span class="line">make configure</span><br><span class="line">make install<span class="comment"># failed </span></span><br><span class="line"><span class="comment">#(g++ -Wall -O2 -std=c++0x -o build_matrix /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0/scripts/src/build_matrix.cpp; mv build_matrix /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0/scripts)</span></span><br><span class="line"><span class="comment">#(g++ -Wall -O2 -std=c++0x -o cutsite_trimming /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0/scripts/src/cutsite_trimming.cpp; mv cutsite_trimming /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0/scripts)</span></span><br><span class="line"><span class="comment">#cp -Ri /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0 /usr/local/bin//HiC-Pro_3.1.0</span></span><br><span class="line"><span class="comment">#cp: cannot create directory ‘/usr/local/bin//HiC-Pro_3.1.0’: Permission denied</span></span><br><span class="line"><span class="comment">#make: *** [Makefile:78: cp] Error 1</span></span><br><span class="line"></span><br><span class="line">but <span class="keyword">in</span> the bin file,it can be use?</span><br></pre></td></tr></table></figure>

<p>Make configure and make install, whats the function of those two steps?</p>
<h1 id="HiC-Pro-GitHub"><a href="#HiC-Pro-GitHub" class="headerlink" title="HiC-Pro-GitHub"></a><a href="https://github.com/nservant/HiC-Pro">HiC-Pro-GitHub</a></h1><p><a href="https://doi.org/10.1186/s13059-015-0831-x">Genome Biology 2015</a></p>
<p>HiC-Pro was designed to process Hi-C data, from <font color="red"><strong>raw fastq files</strong></font> (paired-end Illumina data) to <font color="red"><strong>normalized contact maps</strong></font>. It supports the main Hi-C protocols, including digestion protocols as well as protocols that do not require restriction enzymes such as DNase Hi-C. In practice, HiC-Pro was successfully <font color="blue"><strong>applied to many data-sets</strong></font> including dilution Hi-C, in situ Hi-C, DNase Hi-C, Micro-C, capture-C, capture Hi-C or HiChip data.<br>The pipeline is flexible, scalable and optimized. It can operate either on a single laptop or on a computational cluster. HiC-Pro is sequential and each step of the workflow can be run independantly.<br>HiC-Pro includes a fast implementatation of the iterative correction method (see the <a href="https://github.com/hiclib/iced">iced python package</a> for more information). Finally, HiC-Pro can use phasing data to build <a href="https://github.com/nservant/HiC-Pro/blob/master/doc/AS.md">allele-specific contact maps</a>.</p>
<h2 id="HiC-Pro-annotation-files"><a href="#HiC-Pro-annotation-files" class="headerlink" title="HiC-Pro annotation files"></a>HiC-Pro annotation files</h2><p>In order to process the raw data, HiC-Pro requires three annotation files. Note that the pipeline is provided with some Human and Mouse annotation files.<br><strong>Please be sure that the chromosome names are the same than the ones used in your bowtie indexes !</strong></p>
<ul>
<li><strong>A BED file</strong> of the <font color="blue"><strong>restriction fragments after digestion</strong></font>. This file <font color="blue">depends</font> both of the <font color="blue"><strong>restriction enzyme</strong></font> and the <font color="blue"><strong>reference genome</strong></font>. See the <a href="https://github.com/nservant/HiC-Pro/blob/master/doc/FAQ.md">FAQ</a> and the <a href="https://github.com/nservant/HiC-Pro/blob/master/doc/UTILS.md">HiC-Pro utilities</a> for details about <font color="blue"><strong>how to generate</strong></font> this file. A few annotation files are provided with the HiC-Pro sources as examples. 根据限制性内切酶消化的参考基因组信息 .bed文件。酶切图谱</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#example：/PATH/TO/HiC-Pro_2.11.1/annotation</span></span><br><span class="line"> head HindIII_resfrag_hg19.bed</span><br><span class="line"> chr1   0       16007   HIC_chr1_1    0   +</span><br><span class="line"> chr1   16007   24571   HIC_chr1_2    0   +</span><br><span class="line"> chr1   24571   27981   HIC_chr1_3    0   +</span><br><span class="line"> (...)</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#GENOME_FRAGMENT = # 储存消化碎片位置信息的bed文件，一般在HiC-Pro的annotation文件夹下</span></span><br><span class="line"><span class="comment">#LIGATION_SITE = # 酶切位点重连接后的序列</span></span><br><span class="line"><span class="comment">#注：GENOME_FRAGMENT 和 LIGATION_SITE 完全取决于使用了什么酶，一般HiC建库的酶是Hind III，所以要仔细检查数据来源的说明。 </span></span><br><span class="line">digest_genome.py -r A^AGCTT -o HindIII_resfrag_hg19.bed hg19_rCRSchrm.fa  </span><br></pre></td></tr></table></figure>

<p>通过软件脚本产生基因组酶切图谱，输入内切酶名称或者酶切位点序列都可以，用法：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">digest_genome.py -r A^AGCTT -o mm9_hindiii.bed mm9.fasta</span><br><span class="line">digest_genome.py -r hindiii -o mm9_hindiii.bed mm9.fasta</span><br></pre></td></tr></table></figure>

<p>NcoI、BamHI、EcoRI、HindIII、NdeI、XhoI, 参考：<a href="https://www.biomart.cn/experiment/430/457/741/43956.htm"><font color="red"><strong>常见限制性内切酶识别序列(酶切位点)</strong></font></a></p>
<table>
<thead>
<tr>
<th align="left">限制性内切酶</th>
<th align="left">酶切位点，<code>^</code>为切割位点</th>
</tr>
</thead>
<tbody><tr>
<td align="left">MboI</td>
<td align="left">^GATC</td>
</tr>
<tr>
<td align="left">DpnII</td>
<td align="left">^GATC</td>
</tr>
<tr>
<td align="left">BglII</td>
<td align="left">A^GATCT</td>
</tr>
<tr>
<td align="left">HindIII</td>
<td align="left">A^AGCTT</td>
</tr>
</tbody></table>
<ul>
<li><strong>A table file</strong> of chromosomes’ size. This file can be easily find on the <font color="blue">UCSC genome browser</font>. Of note, pay attention to the contigs or scaffolds, and be aware that HiC-pro will generate a map per chromosomes pair. For model organisms such as Human or Mouse, which are well annotated, we usually recommand to remove all scaffolds. 染色体大小的表格文件。从UCSC下载染色体长度文件，或自己根据fasta序列统计长度</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example：/PATH/TO/HiC-Pro_2.11.1/annotation</span><br><span class="line">head chrom_hg19.sizes</span><br><span class="line">   chr1    249250621</span><br><span class="line">   chr2    243199373</span><br><span class="line">   chr3    198022430</span><br><span class="line">   chr4    191154276</span><br><span class="line">   chr5    180915260</span><br><span class="line">   chr6    171115067</span><br><span class="line">   chr7    159138663</span><br><span class="line">   ...</span><br></pre></td></tr></table></figure>

<p><font color="green"><strong>how?</strong></font> </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools faidx genome.fa</span><br><span class="line">awk ‘&#123;print $1 &quot;t&quot; $2&#125;‘ genome.fa.fai &gt; genome_sizes.bed</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>The bowtie2 indexes</strong>. See the <a href="http://bowtie-bio.sourceforge.net/bowtie2/index.shtml">bowtie2 manual page</a> for details about how to create such indexes.</p>
</li>
<li><p>```sh<br>bowtie2-build hg19.fasta hg19</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">## how to use</span><br><span class="line"></span><br><span class="line">```sh</span><br><span class="line">  HiC-Pro --help</span><br><span class="line">  usage : HiC-Pro -i INPUT -o OUTPUT -c CONFIG [-s ANALYSIS_STEP] [-p] [-h] [-v]</span><br><span class="line">  Use option -h|--help for more information</span><br><span class="line"></span><br><span class="line">  HiC-Pro 3.1.0</span><br><span class="line">  ---------------</span><br><span class="line">  OPTIONS</span><br><span class="line"></span><br><span class="line">   -i|--input INPUT : &#x27;input data folder&#x27;; contains a folder per sample with input files</span><br><span class="line">   -o|--output OUTPUT : &#x27;output folder&#x27;</span><br><span class="line">   -c|--conf CONFIG : &#x27;configuration file&#x27; for Hi-C processing</span><br><span class="line">   [-p|--parallel] : if specified run HiC-Pro on a cluster&#x27;?&#x27;</span><br><span class="line">   [-s|--step ANALYSIS_STEP] : run only a subset of the HiC-Pro workflow; &#x27;if not specified the complete workflow is run&#x27;</span><br><span class="line">      mapping: perform reads &#x27;alignment&#x27; - require fast files</span><br><span class="line">      proc_hic: perform Hi-C &#x27;filtering&#x27; - require BAM files</span><br><span class="line">      quality_checks: run Hi-C &#x27;quality control&#x27; plots</span><br><span class="line">      merge_persample: &#x27;merge&#x27; multiple inputs and remove duplicates if specified - require .validPairs files</span><br><span class="line">      build_contact_maps: &#x27;Build raw inter/intrachromosomal contact maps&#x27; - require .allValidPairs files</span><br><span class="line">      ice_norm : run ICE &#x27;normalization&#x27; on contact maps - require .matrix files</span><br><span class="line">   [-h|--help]: help</span><br><span class="line">   [-v|--version]: version</span><br></pre></td></tr></table></figure></li>
<li><p><font color="blue"><strong>Copy and edit</strong></font> the configuration file <font color="blue"><strong>‘config-hicpro.txt’</strong> </font> in your <font color="blue"><strong>local folder</strong></font>. See the <a href="https://github.com/nservant/HiC-Pro/blob/master/doc/MANUAL.md">manual</a> for details about the configuration file</p>
</li>
<li><p>Put <font color="blue"><strong>all input files in a rawdata folder</strong></font>. The input files have to be organized with <font color="blue"><strong>one folder per sample</strong></font>, such as;</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">+ PATH_TO_MY_DATA</span><br><span class="line">  + sample1</span><br><span class="line">    ++ file1_R1.fastq.gz</span><br><span class="line">    ++ file1_R2.fastq.gz</span><br><span class="line">    ++ ...</span><br><span class="line">  + sample2</span><br><span class="line">    ++ file1_R1.fastq.gz</span><br><span class="line">    ++ file1_R2.fastq.gz</span><br><span class="line">  *...</span><br></pre></td></tr></table></figure>

<ul>
<li>Run HiC-Pro on your <font color="blue"><strong>laptop</strong></font> in standalone model</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">MY_INSTALL_PATH/bin/HiC-Pro -i <span class="string">&#x27;FULL&#x27;</span>_PATH_TO_DATA_FOLDER -o FULL_PATH_TO_OUTPUTS -c MY_LOCAL_CONFIG_FILE</span><br></pre></td></tr></table></figure>

<ul>
<li>Run HiC-Pro on a <font color="blue"><strong>cluster</strong></font> (TORQUE/SGE/SLURM/LSF)</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">MY_INSTALL_PATH/bin/HiC-Pro -i FULL_PATH_TO_DATA_FOLDER -o FULL_PATH_TO_OUTPUTS -c MY_LOCAL_CONFIG_FILE -p</span><br></pre></td></tr></table></figure>

<ul>
<li>In the latter <font color="blue">case[cluster]</font>, you will have the following message :</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Please run HiC-Pro in two steps :</span><br><span class="line"> 1- The following command will launch the parallel workflow through 12 torque jobs:</span><br><span class="line"> qsub HiCPro_step1.sh</span><br><span class="line"> 2- The second command will merge all outputs to generate the contact maps:</span><br><span class="line"> qsub HiCPro_step2.sh</span><br></pre></td></tr></table></figure>

<p>Execute the displayed command from the <font color="blue"><strong>output folder</strong></font>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">qsub HiCPro_step1.sh</span><br></pre></td></tr></table></figure>

<p>Once executed succesfully (may take several hours), run the step using:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">qsub HiCPro_step2.sh</span><br></pre></td></tr></table></figure>

<h2 id="config-editing"><a href="#config-editing" class="headerlink" title="config editing"></a>config editing</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#######################################################################</span></span><br><span class="line"><span class="comment">## SYSTEM AND SCHEDULER - Start Editing Here !!</span></span><br><span class="line"><span class="comment">#######################################################################</span></span><br><span class="line">N_CPU = 2</span><br><span class="line">LOGFILE = hicpro.log</span><br><span class="line">JOB_NAME =</span><br><span class="line">JOB_MEM =</span><br><span class="line">JOB_WALLTIME =</span><br><span class="line">JOB_QUEUE =</span><br><span class="line">JOB_MAIL =</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BOWTIE2_IDX_PATH =</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#######################################################################</span></span><br><span class="line"><span class="comment">## Digestion Hi-C</span></span><br><span class="line"><span class="comment">#######################################################################</span></span><br><span class="line">GENOME_FRAGMENT = HindIII_resfrag_hg19.bed</span><br><span class="line">LIGATION_SITE = AAGCTAGCTT</span><br><span class="line">MIN_FRAG_SIZE =</span><br><span class="line">MAX_FRAG_SIZE =</span><br><span class="line">MIN_INSERT_SIZE =</span><br><span class="line">MAX_INSERT_SIZE =</span><br><span class="line">MIN_MAPQ: 最低的质量分数，用于筛选，表示低于该MAPQ值会被过滤</span><br><span class="line">BOWTIE2_IDX_PATH: 基因组bowtie2索引路径，eg:/path/hg19</span><br><span class="line">BOWTIE2_GLOBAL_OPTIONS: 默认GLOBAL比对设置</span><br><span class="line">BOWTIE2_LOCAL_OPTIONS: 默认LOCAL比对设置</span><br><span class="line">REFERENCE_GENOME： Bowtie2索引前缀</span><br><span class="line">GENOME_SIZE： 基因组sizes bed文件</span><br><span class="line">GENOME_FRAGMENT: 基因组酶切文件,eg. /path/hg19_HindIII.bed</span><br><span class="line">LIGATION_SITE: 酶切位点末端补平再次连接后形成的嵌合序列，eg. AAGCTAGCTT</span><br><span class="line">MIN_FRAG_SIZE: 最小的理论酶切片段大小,eg. 100</span><br><span class="line">MAX_FRAG_SIZE: 最大的理论酶切片段大小,eg. 100000</span><br><span class="line">MIN_INSERT_SIZE: 最小的文库片段大小,eg.100</span><br><span class="line">MAX_INSERT_SIZE: 最大的文库片段大小,eg.1000</span><br><span class="line"><span class="string">&#x27;BIN_SIZE:需要生成的矩阵分辨率（bp)&#x27;</span></span><br><span class="line">MATRIX_FORMAT：矩阵的形式，upper表示保留上半部分</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">BOWTIE2_IDX_PATH = <span class="comment"># bowtie2索引文件目录，索引文件提前下载或用bowtie2-build生成</span></span><br><span class="line">REFERENCE_GENOME = <span class="comment"># bowtie2索引的文件名</span></span><br><span class="line">GENOME_SIZE = <span class="comment"># 染色体大小文件，可从http://hgdownload.cse.ucsc.edu/goldenPath/ 下载</span></span><br><span class="line">GENOME_FRAGMENT = <span class="comment"># 储存消化碎片位置信息的bed文件，一般在HiC-Pro的annotation文件夹下</span></span><br><span class="line">LIGATION_SITE = AAGCTAGCTT<span class="comment"># 酶切位点重连接后的序列</span></span><br><span class="line"><span class="comment"># 注：GENOME_FRAGMENT 和 LIGATION_SITE 完全取决于使用了什么酶，一般来说是Hind III，所以要仔细检查数据来源的说明。 </span></span><br><span class="line">PAIR2_EXT = <span class="comment"># 根据文件名称，分别输入双端数据文件名称，不用输入后缀</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#???GENOME_SIZE = 在建立的索引目录下新建一个txt文件：</span></span><br><span class="line">cat &gt;chrom_bacteria.sizes  <span class="comment">#创建一个新的文件cat &gt; filename，文件名我是参考hicpro的配置示例 </span></span><br><span class="line">Chromosome 4016942  <span class="comment">#在文件中写入内容，表明这个参考基因的大小是4016942bp,1bp即为1个碱基对（base pair）</span></span><br></pre></td></tr></table></figure>

<h2 id="test"><a href="#test" class="headerlink" title="test"></a>test</h2><p>The test dataset and associated results are available <a href="https://zerkalo.curie.fr/partage/HiC-Pro/">here</a>. Small fastq files (2M reads) extracted from the Dixon et al. 2012 paper are available for test.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Get the data. Will download a test_data folder and a configuration file</span></span><br><span class="line"> wget https://zerkalo.curie.fr/partage/HiC-Pro/HiCPro_testdata.tar.gz &amp;&amp; tar -zxvf HiCPro_testdata.tar.gz</span><br><span class="line"></span><br><span class="line"> <span class="comment">## Edit the configuration file and set the path to Human bowtie2 indexes</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Run HiC-Pro</span></span><br><span class="line"> time HICPRO_INSTALL_DIR/bin/HiC-Pro -c config_test_latest.txt -i test_data -o hicpro_latest_test</span><br></pre></td></tr></table></figure>

<h1 id="HIC-PRO’S-DOC"><a href="#HIC-PRO’S-DOC" class="headerlink" title="HIC-PRO’S DOC"></a><a href="http://nservant.github.io/HiC-Pro/">HIC-PRO’S DOC</a></h1><h1 id="分步原理"><a href="#分步原理" class="headerlink" title="分步原理"></a>分步原理</h1><p>ref：<a href="https://www.jianshu.com/p/76533e6d6152">https://www.jianshu.com/p/76533e6d6152</a></p>
<p><img src="/blog/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/4.png" alt="img"></p>
<ul>
<li><p><font color="red"><strong>比对、过滤HiC比对结果、检测有效HiC序列、结果合并、构建HiC关联图谱、关联图谱标准化。</strong></font></p>
</li>
<li><p>HiC-Pro可输出各个尺度的HiC<font color="red">标准化互作图谱</font>，从每个<font color="red">窗口5Kb到1Mb</font>，窗口越大，生成互作关系越少，计算时间就越少，反之越多。同时HiC-Pro能与下游可视化软件<font color="red"><strong>HiCPlotter</strong></font>等兼容，输出文件可直接用于可视化分析。</p>
</li>
<li><p>HiC-Pro<font color="red">自动化比对，标准化和构建相互作用矩阵</font>，在处理多样化的测序数据时，HiC-Pro能够<strong>检测和自动过滤</strong>测序数量差的reads和无效片段。</p>
</li>
</ul>
<h2 id="1-Reads-Mapping"><a href="#1-Reads-Mapping" class="headerlink" title="1.Reads Mapping"></a>1.Reads Mapping</h2><p>将fastq文件用bowtie2 mapping一次，查看log：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat mapping_step1.log</span><br><span class="line"><span class="comment">###mapping fastq to reference genome , 将unmapping的read 另存为 unmap.fastq</span></span><br><span class="line">/PATH/TO/bowtie2/bowtie2-2.3.3.1/bowtie2 --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder --un bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap.fastq --rg-id BMG --rg SM:SRR400264_00_R2 -p 20 -x /PATH/TO/HiC-Pro_2.11.1/Bowtie2Index/hg19 -U rawdata/dixon_2M/SRR400264_00_R2.fastq.gz 2&gt;&gt; logs/dixon_2M/SRR400264_00_R2_bowtie2.log| /PATH/TO/samtools/samtools-1.6/bin/samtools view -F 4 -bS - &gt; bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.bam</span><br><span class="line"></span><br><span class="line">/PATH/TO/bowtie2/bowtie2-2.3.3.1/bowtie2 --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder --un bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap.fastq --rg-id BMG --rg SM:SRR400264_00_R1 -p 20 -x /PATH/TO/HiC-Pro_2.11.1/Bowtie2Index/hg19 -U rawdata/dixon_2M/SRR400264_00_R1.fastq.gz 2&gt;&gt; logs/dixon_2M/SRR400264_00_R1_bowtie2.log| /PATH/TO/samtools/samtools-1.6/bin/samtools view -F 4 -bS - &gt; bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.bam</span><br></pre></td></tr></table></figure>

<p>结果文件</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">|   |-- bwt2_global</span><br><span class="line">|   |   |-- dixon_2M</span><br><span class="line">|   |   |   |-- SRR400264_00_R1_hg19.bwt2glob.bam</span><br><span class="line">|   |   |   |-- SRR400264_00_R1_hg19.bwt2glob.unmap.fastq</span><br><span class="line">|   |   |   |-- SRR400264_00_R2_hg19.bwt2glob.bam</span><br><span class="line">|   |   |   |-- SRR400264_00_R2_hg19.bwt2glob.unmap.fastq</span><br><span class="line">|   |   `-- dixon_2M_2</span><br><span class="line">|   |       |-- SRR400264_01_R1_hg19.bwt2glob.bam</span><br><span class="line">|   |       |-- SRR400264_01_R1_hg19.bwt2glob.unmap.fastq</span><br><span class="line">|   |       |-- SRR400264_01_R2_hg19.bwt2glob.bam</span><br><span class="line">|   |       |-- SRR400264_01_R2_hg19.bwt2glob.unmap.fastq</span><br></pre></td></tr></table></figure>

<p>有mapping和unmapping。因为read是嵌合基因。mapping上的是背景基因组。<font color="blue">unmapping需要下一步处理</font>。</p>
<h2 id="2-片段分配和过滤"><a href="#2-片段分配和过滤" class="headerlink" title="2. 片段分配和过滤"></a>2. 片段分配和过滤</h2><p>查看log</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat mapping_step2.log</span><br><span class="line"><span class="comment">### 酶切</span></span><br><span class="line">/PATH/TO/HiC-Pro/HiC-Pro_2.11.1/scripts/cutsite_trimming --fastq bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap.fastq --cutsite AAGCTAGCTT --out bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_trimmed.fastq &gt; logs/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_readsTrimming.log 2&gt;&amp;1</span><br><span class="line">/PATH/TO/HiC-Pro/HiC-Pro_2.11.1/scripts/cutsite_trimming --fastq bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap.fastq --cutsite AAGCTAGCTT --out bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_trimmed.fastq &gt; logs/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_readsTrimming.log 2&gt;&amp;1</span><br><span class="line"><span class="comment">### 再用bowtie2 mapping一次</span></span><br><span class="line">/PATH/TO/bowtie2/bowtie2-2.3.3.1/bowtie2 --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder --rg-id BML --rg SM:SRR400264_00_R1_hg19.bwt2glob.unmap -p 20 -x /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/Bowtie2Index/hg19 -U bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_trimmed.fastq 2&gt;&gt; logs/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_bowtie2.log | /PATH/TO/samtools/samtools-1.6/bin/samtools view -bS - &gt; bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line">/PATH/TO/bowtie2/bowtie2-2.3.3.1/bowtie2 --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder --rg-id BML --rg SM:SRR400264_00_R2_hg19.bwt2glob.unmap -p 20 -x /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/Bowtie2Index/hg19 -U bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_trimmed.fastq 2&gt;&gt; logs/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_bowtie2.log | /PATH/TO/samtools/samtools-1.6/bin/samtools view -bS - &gt; bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_bwt2loc.bam</span><br></pre></td></tr></table></figure>

<p>这一步将unmapping结果，用酶切位点分割，然后将分割结果，再mapping一次。得到结果</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">|   |-- bwt2_local</span><br><span class="line">|       |-- dixon_2M</span><br><span class="line">|       |   |-- SRR400264_00_R1_hg19.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line">|       |   |-- SRR400264_00_R1_hg19.bwt2glob.unmap_trimmed.fastq</span><br><span class="line">|       |   |-- SRR400264_00_R2_hg19.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line">|       |   |-- SRR400264_00_R2_hg19.bwt2glob.unmap_trimmed.fastq</span><br><span class="line">|       |-- dixon_2M_2</span><br><span class="line">|           |-- SRR400264_01_R1_hg19.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line">|           |-- SRR400264_01_R1_hg19.bwt2glob.unmap_trimmed.fastq</span><br><span class="line">|           |-- SRR400264_01_R2_hg19.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line">|           |-- SRR400264_01_R2_hg19.bwt2glob.unmap_trimmed.fastq</span><br></pre></td></tr></table></figure>

<h2 id="3-mapping-combine-log"><a href="#3-mapping-combine-log" class="headerlink" title="3. mapping_combine.log"></a>3. mapping_combine.log</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat mapping_combine.log</span><br><span class="line"></span><br><span class="line"><span class="comment">### 将global的bam与local的bam用samtools merge</span></span><br><span class="line">/PATH/TO/samtools/samtools-1.6/bin/samtools merge -@ 20 -n -f bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.bam bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line">/PATH/TO/samtools/samtools-1.6/bin/samtools merge -@ 20 -n -f bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.bam bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line"></span><br><span class="line"><span class="comment">### sort</span></span><br><span class="line">/PATH/TO/samtools/samtools-1.6/bin/samtools sort -@ 20 -n -T tmp/SRR400264_00_R2_hg19 -o bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.sorted.bam bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam</span><br><span class="line">/PATH/TO/samtools/samtools-1.6/bin/samtools sort -@ 20 -n -T tmp/SRR400264_00_R1_hg19 -o bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.sorted.bam bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam</span><br><span class="line"></span><br><span class="line">[bam_sort_core] merging from 0 files and 20 in-memory blocks...</span><br><span class="line">[bam_sort_core] merging from 0 files and 20 in-memory blocks...</span><br><span class="line"></span><br><span class="line"><span class="comment">### 改名</span></span><br><span class="line">mv bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.sorted.bam bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam</span><br><span class="line">mv bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.sorted.bam bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam</span><br></pre></td></tr></table></figure>

<h2 id="4、merge"><a href="#4、merge" class="headerlink" title="4、merge"></a>4、merge</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">### 将R1与R2 merge为一个文件。</span></span><br><span class="line">cat mergeSAM.log</span><br><span class="line">/PATH/TO/python/python-2.7.10/bin/python /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/scripts/mergeSAM.py -q 0 -t -v -f bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam -r bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam -o bowtie_results/bwt2/dixon_2M/SRR400264_00_hg19.bwt2pairs.bam</span><br><span class="line"><span class="comment">## mergeBAM.py</span></span><br><span class="line"><span class="comment">## forward= bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam</span></span><br><span class="line"><span class="comment">## reverse= bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam</span></span><br><span class="line"><span class="comment">## output= bowtie_results/bwt2/dixon_2M/SRR400264_00_hg19.bwt2pairs.bam</span></span><br><span class="line"><span class="comment">## min mapq= 0</span></span><br><span class="line"><span class="comment">## report_single= False</span></span><br><span class="line"><span class="comment">## report_multi= False</span></span><br><span class="line"><span class="comment">## verbose= True</span></span><br><span class="line"><span class="comment">## Merging forward and reverse tags ...</span></span><br></pre></td></tr></table></figure>

<h2 id="5、利用HiCPro的mapped-2hic-fragments-py程序将比对结果转化为Hi-C片段信息"><a href="#5、利用HiCPro的mapped-2hic-fragments-py程序将比对结果转化为Hi-C片段信息" class="headerlink" title="5、利用HiCPro的mapped_2hic_fragments.py程序将比对结果转化为Hi-C片段信息"></a>5、利用HiCPro的mapped_2hic_fragments.py程序将比对结果转化为Hi-C片段信息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat mapped_2hic_fragments.log</span><br><span class="line">/PATH/TO/python /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/scripts/mapped_2hic_fragments.py -v -S -t 100 -m 100000 -s 100 -l 600 -a -f /PATH/TO/HiC-Pro_2.11.1/annotation/HindIII_resfrag_hg19.bed -r bowtie_results/bwt2/dixon_2M/SRR400264_00_hg19.bwt2pairs.bam -o hic_results/data/dixon_2M</span><br><span class="line"><span class="comment">## overlapMapped2HiCFragments.py</span></span><br><span class="line"><span class="comment">## mappedReadsFile= bowtie_results/bwt2/dixon_2M/SRR400264_00_hg19.bwt2pairs.bam</span></span><br><span class="line"><span class="comment">## fragmentFile= /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/annotation/HindIII_resfrag_hg19.bed</span></span><br><span class="line"><span class="comment">## minInsertSize= 100</span></span><br><span class="line"><span class="comment">## maxInsertSize= 600</span></span><br><span class="line"><span class="comment">## minFragSize= 100</span></span><br><span class="line"><span class="comment">## maxFragSize= 100000</span></span><br><span class="line"><span class="comment">## allOuput= True</span></span><br><span class="line"><span class="comment">## SAM ouput= True</span></span><br><span class="line"><span class="comment">## verbose= True</span></span><br></pre></td></tr></table></figure>

<p>再对输出的valid pairs文件排序：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">LANG=en; sort -T tmp -k2,2V -k3,3n -k5,5V -k6,6n -o hic_results/data/sample/sample_sample_genome_ref.bwt2pairs.validPairs hic_results/data/sample/sample_sample_genome_ref.bwt2pairs.validPairs</span><br></pre></td></tr></table></figure>

<h2 id="6-对所有的valid-pairs进行合并"><a href="#6-对所有的valid-pairs进行合并" class="headerlink" title="6 对所有的valid pairs进行合并"></a>6 对所有的valid pairs进行合并</h2><figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">LANG=en; sort -T tmp -S <span class="number">50</span>% -k2,<span class="number">2</span>V -k3,<span class="number">3</span>n -k5,<span class="number">5</span>V -k6,<span class="number">6</span>n -m hic_results/data/dixon_2M_2/SRR400264_01_hg19.bwt2pairs.validPairs | awk -F<span class="string">&quot;\t&quot;</span> <span class="string">&#x27;BEGIN&#123;c1=0;c2=0;s1=0;s2=0&#125;(c1!=<span class="subst">$2</span> || c2!=<span class="subst">$5</span> || s1!=<span class="subst">$3</span> || s2!=<span class="subst">$6</span>)&#123;print;c1=<span class="subst">$2</span>;c2=<span class="subst">$5</span>;s1=<span class="subst">$3</span>;s2=<span class="subst">$6</span>&#125;&#x27;</span> &gt; hic_results/data/dixon_2M_2/dixon_2M_2.allValidPairs</span><br></pre></td></tr></table></figure>

<p>生成最终文件dixon_2M_2.allValidPairs。</p>
<p>这个文件还不能可视化，如果要可视化，一般在jucebox里面查看。需要用配套的hicpro2juicebox.sh来转化：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## e.g.1</span></span><br><span class="line">HICPRO_PATH/bin/utils/hicpro2juicebox.sh -i hicpro_res/hic_results/data/dixon_2M/dixon_2M_allValidPairs -g hg19 -j /usr/<span class="built_in">local</span>/juicebox/juicebox_clt_1.4.jar</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-j jar</span><br><span class="line">/PATH/TO/juicer/juicer/UGER/scripts/juicer_tools.jar</span><br></pre></td></tr></table></figure>

<h1 id="HiC-Pro-输出"><a href="#HiC-Pro-输出" class="headerlink" title="HiC-Pro 输出"></a>HiC-Pro 输出</h1><p>共有<strong>bowtie_results</strong>和<strong>hic_results</strong>两个结果文件夹。</p>
<p>其中<strong>bowtie_results</strong>下三个文件夹：bwt2、bwt2_global和bwt2_local，分别是序列比对结果、<font color="blue">染色体间</font>关联比对结果和<font color="blue">染色体内</font>部关联比对结果。bwt2文件夹有数据统计结果输出文件，如mpairstat文件。</p>
<p><strong>hic_results</strong>文件夹下共有data、matrix以及pic三个文件夹。</p>
<ul>
<li><p>data文件夹下是比对上的有效序列对，文件末尾为_allValidPairs合并后的pairs数据</p>
<p><code>DEPairs</code>:Dangling end pairs数据</p>
<p><code>DumpPairs</code>:实际片段长度和理论片段长度不同的数据</p>
<p><code>REPairs</code>：酶切片段重新连接的pairs</p>
<p><code>FiltePairs</code>:MAPQ过低的pairs</p>
<p><code>SCPairs</code>：片段自连的pairs</p>
</li>
<li><p>pic文件夹下是各类结果数据统计；存放统计分析图片</p>
<p>HiC文库片段分布文件</p>
<p>双端比对过滤质控图</p>
<p>有效数据过滤质控图</p>
<p>配对数据不同类型数据比例展示图</p>
</li>
<li><p>matrix文件夹下分为 iced(标准化) 和 raw(原始) 两个文件夹，分别标准化后的关联矩阵和初始的关联矩阵。存放不同分辨率矩阵文件</p>
</li>
</ul>
<p>后续compartment，TAD和loop？</p>
<h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzUyMTk4ODM0OQ==&mid=2247483678&idx=1&sn=a1aa97892723f6fb51bd3b01a6441e6c&chksm=f9d3f08ccea4799af0a4401e938307a3f6e860239e905deb6963a82a8fc799a4af504e96bc10&scene=178&cur_album_id=1399424041152528385#rd">微信公众号</a></p>
<p><a href="https://weixin.sogou.com/weixin?type=2&query=%E6%9F%93%E8%89%B2%E8%B4%A8%E9%AB%98%E7%BA%A7%E7%BB%93%E6%9E%84%E7%A0%94%E7%A9%B6%E4%B9%8BHi-C%E6%8A%80%E6%9C%AF%EF%BC%88%E4%B8%8B%E7%AF%87%EF%BC%89%E2%80%94%E2%80%94%E5%8F%AF%E8%A7%86%E5%8C%96%E5%AE%9E%E6%88%98&ie=utf8&s_from=input&_sug_=n&_sug_type_=&w=01019900&sut=935&sst0=1646835948011&lkt=2,1646835946980,1646835947908">染色质高级结构研究之Hi-C技术（下篇）——可视化实战</a></p>
<h1 id="Error-debug"><a href="#Error-debug" class="headerlink" title="Error debug"></a>Error debug</h1><blockquote>
<p>HIC-PRO DOES NOT GENERATE ANY MAPS<br>HiC-Pro is using the chrom.sizes files to build the map.<br>Be sure that your chromosome names are the same in all annotations files (bowtie2 indexes, restriction fragments, chromosome sizes, etc.)</p>
</blockquote>
<blockquote>
<p>hiclib and mirnylib are not compatible with python 2.5 and 3.x, but work fine with py 2.6, 2.7</p>
<p>hiclib主要用于数据标准化，hicpro可以，为什么还要安装hiclib? 或者是想比较两者分析的结果？</p>
<p>HiC-Pro需要python版本&gt;=3.7, 安装3.9</p>
</blockquote>
<p><strong>Error1</strong>：directly use hicpro on the cluster,  —qual 多一个-无法解决，自己安装<br>/software/biosoft/software/bowtie2-2.2.9/bowtie2-align-s: <font color="red"><strong>unrecognized option ‘—quals’</strong></font><br>Bowtie 2 version 2.2.9 by Ben Langmead (<a href="mailto:&#108;&#97;&#110;&#103;&#109;&#101;&#97;&#x40;&#99;&#115;&#x2e;&#106;&#104;&#x75;&#46;&#x65;&#x64;&#117;">&#108;&#97;&#110;&#103;&#109;&#101;&#97;&#x40;&#99;&#115;&#x2e;&#106;&#104;&#x75;&#46;&#x65;&#x64;&#117;</a>, <a href="http://www.cs.jhu.edu/~langmea">www.cs.jhu.edu/~langmea</a>)<br>Usage:<br>  bowtie2 [options]* -x <bt2-idx> {-1 <m1> -2 <m2> | -U <r>} [-S <sam>]</sam></r></m2></m1></bt2-idx></p>
<p>Encountered internal Bowtie 2 exception (#1)<br>Command: /software/biosoft/software/bowtie2-2.2.9/bowtie2-align-s –wrapper basic-0 –very-sensitive -L 30 –score-min L,-0.6,-0.2 –end-to-end –reorder –rg-id BMG –rg SM:L3_R1 <font color="red"><strong>—quals</strong></font> -p 10 -x /xtdisk/xueyb_group/wangchenA/Petunia_denovo/HiFi/02.bwa_mapping/primary//HiFi.p_ctg –passthrough -U /tmp/34683.unp<br>(ERR): bowtie2-align exited with value 1</p>
<p>自己安装时，先创建conda环境，再tar xzvf，然后<font color="red"><strong>编辑config-install.txt的prefix 再make configure &amp;&amp; make install</strong></font><br><strong>Error2</strong>在错误产生output文件夹时再次运行直接报错stat: <font color="red"><strong>Bad file descriptor，先删除output_dir</strong></font><br>设置config-install.txt 的prefix时设置成///software/HiC-Pro<font color="red"><strong>/</strong></font><br>报错：<br><strong>Error3</strong>：install in another dir HiC-Pro， PREFIX = /xtdisk/xueyb_group/wangchenA/software/HiC-Pro/<br>/xtdisk/xueyb_group/wangchenA/software/HiC-Pro/HiC-Pro-3.1.0/bin/../scripts//Makefile:48: /xtdisk/xueyb_group/wangchenA/software/HiC-Pro<font color="red"><strong>//</strong></font>config-system.txt: No such file or directory<br>make:  No rule to make target ‘/xtdisk/xueyb_group/wangchenA/software/HiC-Pro<font color="red"><strong>//</strong></font>config-system.txt’.  Stop.<br>The config-system.txt file is a file which should be within the installation folder.<br>检查config-system.txt 发现多了//<br>设置config-install.txt 的prefix时设置成///software/HiC-Pro时会<font color="red"><strong>自动产生软件名文件夹</strong></font>，后面<font color="red">多加斜杠/直接报错</font></p>
<p><strong>successfully installed</strong>  </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">(HiC_Pro_ENV) [HiC-Pro-3.1.0]$ vi config-install.txt </span><br><span class="line">PREFIX = ////software</span><br><span class="line">(HiC_Pro_ENV) [HiC-Pro-3.1.0]$ make configure</span><br><span class="line">make -f ./scripts/install/Makefile CONFIG_SYS=./config-install.txt</span><br><span class="line">make[1]: Entering directory <span class="string">&#x27;/xtdisk/group/wangchenA/HiC-Pro-3.1.0&#x27;</span></span><br><span class="line">./scripts/install/install_dependencies.sh -c ./config-install.txt -p /xtdisk/group/wangchenA/software -o /xtdisk/group/wangchenA/software/HiC-Pro_3.1.0 -q</span><br><span class="line">Make sure internet connection works <span class="keyword">for</span> your shell prompt under current user<span class="string">&#x27;s privilege ...</span></span><br><span class="line"><span class="string">Starting HiC-Pro installation !</span></span><br><span class="line"><span class="string">Checking dependencies</span></span><br><span class="line"><span class="string">- Python libraries ...OK</span></span><br><span class="line"><span class="string">- R installation ...OK</span></span><br><span class="line"><span class="string">- Bowtie2 installation ...OK</span></span><br><span class="line"><span class="string">- Samtools installation ...OK</span></span><br><span class="line"><span class="string">Checking HiC-Pro configuration</span></span><br><span class="line"><span class="string">- Configuration for TORQUE/PBS system ...OK</span></span><br><span class="line"><span class="string">done !</span></span><br><span class="line"><span class="string">make[1]: Leaving directory &#x27;</span>/xtdisk/group/wangchenA/HiC-Pro-3.1.0<span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">(/HiC_Pro_ENV) [HiC-Pro-3.1.0]$ make install</span></span><br><span class="line"><span class="string">(g++ -Wall -O2 -std=c++0x -o build_matrix /xtdisk/group/wangchenA/HiC-Pro-3.1.0/scripts/src/build_matrix.cpp; mv build_matrix /xtdisk/group/wangchenA/HiC-Pro-3.1.0/scripts)</span></span><br><span class="line"><span class="string">(g++ -Wall -O2 -std=c++0x -o cutsite_trimming /xtdisk/group/wangchenA/HiC-Pro-3.1.0/scripts/src/cutsite_trimming.cpp; mv cutsite_trimming /xtdisk/group/wangchenA/HiC-Pro-3.1.0/scripts)</span></span><br><span class="line"><span class="string">cp -Ri /xtdisk/group/wangchenA/HiC-Pro-3.1.0 /xtdisk/group/wangchenA/software/HiC-Pro_3.1.0</span></span><br><span class="line"><span class="string">HiC-Pro installed in /xtdisk/group/wangchenA/software/HiC-Pro_3.1.0 !</span></span><br></pre></td></tr></table></figure>

<p>Issue from: <a href="https://github.com/nservant/HiC-Pro/issues/289">https://github.com/nservant/HiC-Pro/issues/289</a></p>
<blockquote>
<p>you <font color="green"><strong>do not have the rigths</strong></font> to install HiC-Pro in <font color="green"><strong>/usr/local/bin</strong></font><br>Update the <font color="green"><strong>PREFIX= in the config-install.txt</strong></font> file before running the installation</p>
<p>You <font color="green"><strong>cannot install it in the path where you have downloaded it</strong> </font>!Please <font color="green"><strong>set another prefix</strong></font>.Note that it will <font color="green"><strong>create the HiC-Pro_3.0.0 folder by itself</strong></font></p>
</blockquote>
<p><font color="red"><strong>NOTICE</strong></font></p>
<ul>
<li>./configure –prefix=  &amp;&amp;  make  &amp;&amp;  make install</li>
<li>Vim config-install.txt PREFIX  &amp;&amp;  make configure  &amp;&amp;  make install</li>
</ul>
<hr>
<p><strong>bowtie_pairing] Error 1</strong><br><a href="https://github.com/nservant/HiC-Pro/issues/482">https://github.com/nservant/HiC-Pro/issues/482</a></p>
<p>Thu Sep 23 04:23:58 CST 2021<br>Pairing of R1 and R2 tags …<br>Logs: logs/sample1/mergeSAM.log<br>make: *** [bowtie_pairing] Error 1</p>
<p>the mergeSAM.log<br>~/miniconda3/envs/hic-pro_env/bin/python ~/02_software/hic-pro/HiC-Pro-3.1.0/scripts/mergeSAM.py -q 10 -t -v -f bowtie_results/bwt2/sample1/XB_R1_merged_canu_asm.fasta.bwt2merged.bam -r bowtie_results/bwt2/sample1/XB_R2_merged_canu_asm.fasta.bwt2merged.bam -o bowtie_results/bwt2/sample1/XB_merged_canu_asm.fasta.bwt2pairs.bam<br>[E::idx_find_and_load] Could not retrieve index file for ‘bowtie_results/bwt2/sample1/XB_R1_merged_canu_asm.fasta.bwt2merged.bam’<br>[E::idx_find_and_load] Could not retrieve index file for ‘bowtie_results/bwt2/sample1/XB_R2_merged_canu_asm.fasta.bwt2merged.bam’</p>
<p>mapping_combine.log:<br>[bam_sort_core] merging from 6120 files and 36 in-memory blocks…<br>[E::hts_open_format] Failed to open file “tmp/XB_R1_merged_canu_asm.fasta.1018.bam” : Too many open files<br>samtools sort: fail to open “tmp/XB_R1_merged_canu_asm.fasta.1018.bam”: Too many open files</p>
<p>yes well done ! So the samtools sort failed.<br>If you look at your command, -@ 36 -m 21M, means that it only has 21Mo to sort the file which is too few.<br>So it has to swap a lot, and generate too many tmp files.<br>This memory parameter is in your configuration file SORT_RAM. By default, it is set to 768M</p>
<p>Actually, the SORT_RAM parameter is divided by the number of CPUs<br>For instance, using 1000M with 4 CPUs means that samtools sort is run with 250M of RAM.<br>So it makes sense … you have 1000M / 36 CPU = 27M of RAM.<br>I would suggest to decrease the number of CPU to 8 for instance … this is enough ! or to increase again the SORT_RAM parameter.</p>
<hr>
<p>ref</p>
<p><a href="https://www.plob.org/article/24873.html">https://www.plob.org/article/24873.html</a></p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>【Linux集群任务调度系统】【LSF/SGE/Slurm/PBS】【grid】</title>
    <url>/blog/2022/03/06/2022-03-06-Linux-grid/</url>
    <content><![CDATA[<p>调度器主要是基于<strong>HPC场景</strong>的<strong>集群任务调度系统</strong>，英文<strong>Cluster Scheduler</strong>、<strong>Job Scheduler</strong>等。</p>
<p>市面主流调度器有四大流派：<font color="red"><strong>LSF   SGE   Slurm   PBS</strong></font></p>
<span id="more"></span>

<h1 id="从Cluster-集群-、Grid-网格-到-Cloud-（云）"><a href="#从Cluster-集群-、Grid-网格-到-Cloud-（云）" class="headerlink" title="从Cluster (集群)、Grid (网格) 到 Cloud （云）"></a>从Cluster (集群)、Grid (网格) 到 Cloud （云）</h1><p>为解决复杂的<strong>计算密集型</strong>和<strong>数据密集型</strong>问题，需要<strong>高网络性能</strong>、<strong>快速存储</strong>、<strong>大量内存</strong>、<strong>超高计算能力</strong>。</p>
<h2 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a><strong>Cluster</strong></h2><p>一组松散集成的计算机<strong>软件</strong>或<strong>硬件</strong>连接起来<strong>高度紧密地协作</strong>完成计算工作。在某种意义上，可以被看作是一台计算机。集群系统中的<font color="blue"><strong>单个计算机</strong></font>通常称为<font color="blue"><strong>节点node</strong></font>，通常通过<strong>局域网(LAN)连接</strong>,性价比比<font color="blue"><strong>大型机（mainframe）</strong></font>等<strong>高</strong>。</p>
<h2 id="Grid"><a href="#Grid" class="headerlink" title="Grid"></a><strong>Grid</strong></h2><p>通过<strong>利用</strong>大量<strong>异构计算机</strong>的<strong>未用资源</strong>，如<strong>CPU</strong>、<strong>磁盘存储</strong>等，将其作为嵌入在分布式的一个<strong>虚拟的计算机集群</strong>，为解决<strong>大规模计算问题</strong>提供一个<strong>模型</strong>。目标是<font color="blue">解决</font>对单一超级计算机都<font color="blue">困难的大问题</font>，并同时保持解决多个<font color="blue">较小</font>问题的灵活性。网格天生就是在本地网、城域网或广域网上进行分布的。网格<font color="blue">可以分布在任何地方</font>。而<font color="blue">集群</font>物理上都在<font color="blue">一处</font>，通常是<font color="blue">局域网互连</font>。</p>
<h2 id="Cloud"><a href="#Cloud" class="headerlink" title="Cloud"></a><strong>Cloud</strong></h2><p>集群技术发展而来，区别在于<font color="blue">集群虽然把多台机器联起来</font>，但其<font color="blue">某项<strong>具体任务</strong>执行的时候还是会被转发到<strong>某台服务器</strong>上</font>，而<font color="blue">云</font>可以简单认为是<font color="blue">任务被<strong>分割成多个进程</strong>在<strong>多台服务器</strong>上<strong>并行计算</strong></font>，优势是大数据量的操作性能非常好。云可以使用廉价的PC服务器 ，可以<font color="blue"><strong>管理</strong>大数据量与大集群</font>，<font color="blue">关键技术在于能够对云内的基础设施进行动态按需分配与管理</font>。云计算与并行计算、分布式计算的区别，<font color="red">对于计算机用户，<strong>并行计算</strong>由<strong>单个用户完成</strong>，<strong>分布式计算</strong>由<strong>多个用户合作</strong>完成，<strong>云计算</strong>是<strong>没有用户参与</strong>，而是交给<strong>网络另一端的服务器完成</strong>。</font></p>
<p><img src="/blog/2022/03/06/2022-03-06-Linux-grid/1.png" alt="img"></p>
<p><img src="/blog/2022/03/06/2022-03-06-Linux-grid/2.png" alt="img"></p>
<p><strong>研究发现</strong>：<strong>商务计算机</strong>只用到其<strong>功能</strong>的 <strong>10％ —20％</strong>。24 小时内，一般的 <strong>UNIX 服务器</strong>只<strong>利用 10％</strong> 的时间，大型机大约 40％，<strong>台式机少于 5％</strong>。同样时间间隔内，利用<strong>网格计算</strong>，<strong>资源利用</strong>可以达到 <strong>90％</strong> 。</p>
<h2 id="从服务角度看网格分类"><a href="#从服务角度看网格分类" class="headerlink" title="从服务角度看网格分类"></a><strong>从服务角度看网格分类</strong></h2><ul>
<li><p><strong>专用网格</strong></p>
<p>由用于网格的<strong>专用硬件</strong>和<strong>计算资源</strong>组成, 提供了<strong>最大</strong>的<strong>控制</strong>和<strong>灵活性</strong></p>
</li>
<li><p><strong>非专用网格</strong></p>
<p>更多地<strong>依赖</strong>于<strong>现有网络</strong>和<strong>基础设施</strong>，对<strong>网络决策</strong>的<strong>控制很少</strong>甚至不能控制。</p>
</li>
<li><p><strong>分布式网格</strong></p>
<p>分布式网格 由在 WAN 或 <font color="blue"><strong>Internet 上分布的</strong>、<strong>位于任何位置</strong></font>（内部或外部）的<strong>计算机资源组成</strong>。</p>
</li>
</ul>
<h2 id="从应用角度网格分类"><a href="#从应用角度网格分类" class="headerlink" title="从应用角度网格分类"></a><strong>从应用角度网格分类</strong></h2><ul>
<li><p><strong>计算网格</strong></p>
<p>侧重于<font color="blue">计算密集型</font>操作的网格</p>
</li>
<li><p><strong>数据网格</strong></p>
<p>处理数据的数据计算系统——<font color="blue">控制大量的分布式数据的共享和管理</font></p>
</li>
<li><p><strong>设备网格</strong></p>
<p><font color="blue">用于<strong>远程控制</strong>设备和分析产生的数据</font></p>
</li>
</ul>
<h1 id="SGE-Sun-Grid-Engine"><a href="#SGE-Sun-Grid-Engine" class="headerlink" title="SGE [Sun Grid Engine]"></a>SGE [Sun Grid Engine]</h1><p><font color="red">从<strong>登陆节点</strong>上<strong>向计算节点</strong>进行<strong>任务投递</strong></font>。SGE或者其他集群管理工作做的事情就是<font color="blue">将用户投递的<strong>任务排队</strong></font>，然后将任务交给<font color="blue"><strong>能够运行</strong>的<strong>计算节点执行</strong></font>，工作流程分四步:</p>
<ol>
<li><strong>接受</strong>用户投放的<strong>任务</strong></li>
<li>在任务运行以前，将任务<strong>放到</strong>一个<strong>存储区域</strong></li>
<li><strong>发送任务</strong>到一个<strong>执行设备</strong>，并<strong>监控</strong>任务的运行</li>
<li>运行<strong>结束</strong>写回结果并记录运行<strong>日志</strong></li>
</ol>
<h2 id="SGE的常用命令"><a href="#SGE的常用命令" class="headerlink" title="SGE的常用命令"></a>SGE的常用命令</h2><h3 id="任务投递"><a href="#任务投递" class="headerlink" title="任务投递"></a>任务投递</h3><p>SGE中投递任务所用到的命令是<code>qsub</code>. 最简单的用法，即将要执行的命令通过标准输入的方式传递给<code>qsub</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ls -l &quot;</span> | qsub</span><br></pre></td></tr></table></figure>

<p>投递之后可以用<code>qstat</code>查看任务运行情况，如下图</p>
<p><img src="/blog/2022/03/06/2022-03-06-Linux-grid/3.png" alt="img"></p>
<p>任务投递情况</p>
<p>第一列是任务编号, 第二列是优先级，第三列是任务名字，在参数里没有特别说明的情况下，SGE会用任务的来源进行命令，STDIN表示来自于标准输入，第四列是用户名，第五列是运行状态(“r”表示运行中), 第六列表示任务投递和开始时间，第七列是任务投递的节点，第8列则是要申请的线程数。在执行完成后会在家目录下生成”STDIN.e7883”和”STDIN.o7883”, 其中7883是任务编号, 前者存放标准错误输出, 后者存放标准输出， 因此”cat STDIN.o7883”的内容就是<code>ls -l</code>的内容。</p>
<p>另一种方法是先写脚本后投递，比如先编辑文件”ls.sh”, 然后用”qsub ls.sh”投递任务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls -l</span><br></pre></td></tr></table></figure>

<p>跟之前一样，最后在home目录产生了”ls.sh.exxxx”和”ls.sh.exxxx”两个文件</p>
<p>实际肯定没有那么简单，需要增加各种参数来调整<code>qsub</code>的行为，用<code>qsub -help</code>可以看完整参数，但是常用的为如下几个 </p>
<ul>
<li>-q xxx : 指定要投递到的队列，如果不指定的话，SGE会在用户可使用的队列中选择一个满足要求的队列</li>
<li>-V： <font color="red">将当前的环境变量传递到执行命令的节点【在使用PBS时，直接运行可以执行，投递PBS则失败，是任务到了计算节点不识别环境变量？】</font></li>
<li>cwd: 在当前目录下执行任务, sge的日志会输出到当前路径。 不增加该指令，所有投递的任务都会在home目录下执行</li>
<li>-l resource=value: 请求资源数, 例如 <code>-l vf=25G -l h=node1</code> 任务的预估内存要25G(内存估计的值应稍微大于真实内存，内存预估偏小可能会导致节点跑挂), 申请在node1上运行</li>
<li>-S /bin/bash: 表示在bash环境下执行命令。默认tcsh.</li>
<li>-pe openmpi 4: 表示使用openmpi进行并行运算，且申请的线程是4，</li>
<li>-N 任务名: 手动执行任务的名字</li>
<li>-j y|n ：是否将标准输入和标准输入合并成一个文件</li>
<li>-sync y|n: 是否等待任务结束，返回退出码</li>
<li>-o path: 指定标准输出的文件夹</li>
</ul>
<p>接下来就可以添加这些参数运行一些命令，例如在命令行里投递一个比对任务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;bowtie2 -p 8 -x index/ref -1 data/A_1.fq -2 data/A_2.fq | samtools sort &gt; A.bam&quot;</span> | qsub -V -cwd -l vf=25G -S /bin/bash -pe openmpi 8 -N A.bt2</span><br></pre></td></tr></table></figure>

<p>这些参数除了在<strong>外部设置</strong>外，还可以在shell脚本<strong>内部设置</strong>，如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#$ -S /bin/bash</span></span><br><span class="line"><span class="comment">#$ -V</span></span><br><span class="line"><span class="comment">#$ -cwd</span></span><br><span class="line"><span class="comment">#$ -l vf=25G</span></span><br><span class="line"><span class="comment">#$ -pe openmpi 8</span></span><br><span class="line"><span class="comment">#$ -N a.bt2</span></span><br><span class="line">bowtie2 -p 8 -x index/ref -1 data/A_1.fq -2 data/A_2.fq | samtools sort &gt; A.bam</span><br></pre></td></tr></table></figure>

<h3 id="查询任务"><a href="#查询任务" class="headerlink" title="查询任务"></a>查询任务</h3><p>除任务投递外，查询任务也是常用命令，除直接用<code>qstat</code>查看，还有如下参数比较好用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">qstat -f        <span class="comment"># 查看用户任务</span></span><br><span class="line">qstat -j jobId  <span class="comment"># 按任务id查看</span></span><br><span class="line">qstat -explain a|c|A|E -j jobID <span class="comment"># 查看任务任务并给出解释</span></span><br><span class="line">qstat -u user   <span class="comment"># 按用户查看</span></span><br></pre></td></tr></table></figure>

<p>任务状态：</p>
<ul>
<li>qw: 表示等待状态</li>
<li>hqw: 任务挂起等待中，待依赖的任务完成后执行</li>
<li>Eqw: 投递任务出错</li>
<li>r: 表示任务正在运行</li>
<li>s: 暂时挂起</li>
<li>dr: 节点挂了之后，删除任务就会出现这个状态，只有节点重启后，任务才会消失</li>
</ul>
<h3 id="删除任务"><a href="#删除任务" class="headerlink" title="删除任务"></a>删除任务</h3><p>任务删除也比较重要，偶尔会出现任务投递出错的情况</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">qdel -j 1111   删除任务号为1111的任务</span><br></pre></td></tr></table></figure>

<h3 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h3><ul>
<li><p>qrsh：与qsub相比，是交互式的投递任务，注意参数:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-now yes|no</span><br></pre></td></tr></table></figure>

<p>默认设置为yes</p>
<ul>
<li>若设置为yes，<font color="blue">立即调度作业</font>，如果没有可用资源，则拒绝作业，任务投递失败，任务状态为Eqw。</li>
<li>若设置为no，调度时如果没有可用资源，则将作业<font color="blue">排入队列</font>，等待调度。</li>
<li>例子： qrsh -l vf=*G -q all.q -now no -w n *sh</li>
</ul>
</li>
<li><p>qacct 从集群日志中抽取任意账户信息</p>
</li>
<li><p>qalter 更改已提交但正处于暂挂状态的作业的属性</p>
</li>
<li><p>qconf 为集群和队列配置提供用户界面</p>
<ul>
<li><code>qconf -spl</code>查看可用并行环境</li>
</ul>
</li>
<li><p>qhold 阻止已提交作业的执行</p>
</li>
<li><p>qhost 显示<font color="blue">SGE执行主机</font>（即<font color="blue">各个计算节点</font>）的<font color="blue">状态信息</font></p>
<ul>
<li><code>qhost -j</code>按照节点显示任务</li>
<li><code>qhost -F</code>展示每个节点的资源</li>
</ul>
</li>
<li><p>qlogin 启动telnet或类似的登录会话。</p>
</li>
</ul>
<h2 id="案例：一个投递比对任务的简单脚本"><a href="#案例：一个投递比对任务的简单脚本" class="headerlink" title="案例：一个投递比对任务的简单脚本"></a>案例：一个投递比对任务的简单脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"><span class="built_in">set</span> -u</span><br><span class="line"><span class="built_in">set</span> -o pipefail</span><br><span class="line"></span><br><span class="line">threads=8</span><br><span class="line">index=index/hg19</span><br><span class="line"></span><br><span class="line">FQ_DIR=<span class="string">&quot;analysis/0-raw-data&quot;</span></span><br><span class="line">ALIGN_DIR=<span class="string">&quot;analysis/2-read-align&quot;</span></span><br><span class="line">LOG_DIR=<span class="string">&quot;analysis/log&quot;</span></span><br><span class="line">TMP_DIR=<span class="string">&quot;analysis/tmp&quot;</span></span><br><span class="line"></span><br><span class="line">mkdir -p <span class="variable">$&#123;ALIGN_DIR&#125;</span></span><br><span class="line">mkdir -p <span class="variable">$&#123;LOG_DIR&#125;</span></span><br><span class="line">mkdir -p <span class="variable">$&#123;TMP_DIR&#125;</span></span><br><span class="line"></span><br><span class="line">tail -n+2 download_table.txt | cut -f 6 | <span class="keyword">while</span> <span class="built_in">read</span> id;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;</span></span><br><span class="line"><span class="string">    bowtie2 --very-sensitive-local --mm -p <span class="variable">$threads</span> -x <span class="variable">$index</span> -U <span class="variable">$&#123;FQ_DIR&#125;</span>/<span class="variable">$id</span>.fastq.gz 2&gt; <span class="variable">$&#123;LOG_DIR&#125;</span>/<span class="variable">$id</span>.bt2.log | \</span></span><br><span class="line"><span class="string">    samtools sort -@ 2 -m 1G -T <span class="variable">$&#123;TMP_DIR&#125;</span>/<span class="variable">$&#123;id&#125;</span> -o <span class="variable">$&#123;ALIGN_DIR&#125;</span>/<span class="variable">$&#123;id&#125;</span>.sort.bam&quot;</span> | qsub -V -cwd -pe openmpi <span class="variable">$threads</span> -N <span class="variable">$&#123;id&#125;</span>_bt2 -q all.q -S /bin/bash</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h1 id="PBS-Protable-Batch-System"><a href="#PBS-Protable-Batch-System" class="headerlink" title="PBS [Protable Batch System]"></a>PBS [Protable Batch System]</h1><h2 id="1-服务器集群"><a href="#1-服务器集群" class="headerlink" title="1. 服务器集群"></a>1. 服务器集群</h2><ul>
<li>服务器集群指将很多服务器集中一起进行同种服务，在<font color="blue">客户端看来就像只有一个服务器</font>，集群可以利用多个计算机进行<font color="blue">并行计算</font>从而获得很高的计算速度，也可以用多个计算机做<font color="blue">备份</font>，从而使得任何一个机器坏了整个系统还是正常运行。</li>
<li>集群是一组独立的计算机（节点）的集合体，节点间通过高性能的互连网络连接；<strong>各节点</strong>除作为<strong>单一计算资源</strong>供交互式用户使用外，还可以<strong>协同工作</strong>并表现为一个单一的、集中的计算资源供并行计算任务使用。</li>
</ul>
<p><strong>1.1. 集群系统基本信息</strong></p>
<ul>
<li>集群配制的<a href="https://baike.baidu.com/item/%E5%88%80%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8/1375424">刀片计算节点</a>的CPU，GPU配制情况。<a href="https://www.dt-stor.com/yingpanbaike/407.html#:~:text=%E5%88%80%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%9C%BA%E6%9E%B6%E5%BC%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E6%AF%94%EF%BC%8C%E5%88%80%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9B%A0%E5%85%B1%E4%BA%AB%E5%86%B7%E5%8D%B4%E3%80%81%E7%94%B5%E6%BA%90%E7%B3%BB%E7%BB%9F%E8%80%8C%E6%88%90%E4%B8%BA%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%84%E8%8A%82%E8%83%BD%E7%8E%AF%E4%BF%9D%E4%BA%A7%E5%93%81%EF%BC%8C%E4%B8%8E%E5%90%8C%E7%AD%89%E7%9A%841U%E6%9C%BA%E6%9E%B6%E5%BC%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E6%AF%94%EF%BC%8C%E8%83%BD%E8%80%97%E9%99%8D%E4%BD%8E%E8%BE%BE,40%25%EF%BC%8C%E7%A9%BA%E9%97%B4%E5%8D%A0%E7%94%A8%E5%87%8F%E5%B0%9140%25%20%E3%80%82">刀片机优缺点</a>; <a href="https://www.intel.cn/content/www/cn/zh/products/docs/processors/cpu-vs-gpu.html">GPU与CPU</a>。</li>
<li>系统配备的<strong>并行文件系统</strong>，各组<strong>刀片机</strong>之间的<strong>网络连接</strong></li>
<li>系统配制的<font color="blue">登陆管理节点</font>，部署的集群管理系统。用户可根据<font color="blue">登录节点IP，登录集群，提交作业</font>，编译程序。</li>
</ul>
<p><strong>1.2. 集群计算资源列表</strong></p>
<p><img src="/blog/2022/03/06/2022-03-06-Linux-grid/4.png" alt="集群计算资源列表示例"></p>
<ul>
<li>一般搭建好集群后，都会给出集群计算资源列表，类似于上图的几个部分。<ul>
<li>首先，会将整个<font color="blue">集群划分为若干个队列（Queue）</font>，并根据<font color="blue">队列资源配置</font>情况进行<font color="blue">相应命名</font>；</li>
<li> 其次，<font color="blue">每个<strong>队列</strong>下若干个<strong>计算节点</strong>（<strong>nodes</strong>），每个计算节点配制<strong>若干个CPU</strong>（<strong>ppn</strong>）</font>；</li>
<li>最后，对集群的一些其他<strong>信息说明</strong>和<strong>限制情况说明</strong>，如CPU型号和核数，用户<strong>可提交的作业数</strong>，每个作业的<strong>最大运行时间</strong>等。</li>
</ul>
</li>
<li>在往集群上投递任务之前，首先要了解该<strong>任务所需的计算资源是否能被集群所满足</strong>。</li>
</ul>
<h2 id="2-PBS任务管理系统"><a href="#2-PBS任务管理系统" class="headerlink" title="2. PBS任务管理系统"></a>2. PBS任务管理系统</h2><h3 id="2-1-PBS-简介"><a href="#2-1-PBS-简介" class="headerlink" title="2.1 PBS 简介"></a><strong>2.1 PBS 简介</strong></h3><ul>
<li>PBS （Protable Batch System） 是一种常用作业管理系统，其他类似的还有 LSF 和 SLURM。</li>
</ul>
<ul>
<li><p>PBS会根据一个集群上的<strong>可用计算节点</strong>的<strong>计算资源</strong><font color="blue">管理和调度</font>所有计算作业（无论批处理作业还是交互式作业）。</p>
</li>
<li><p>目前有两个版本：<font color="blue">OpenPBS（开源）</font>和<font color="blue">PBSPro（商业）</font>。TORQUE：基于PBS项目的开源软件，是开源的OpenPBS改进版。主要包括：</p>
</li>
<li><p><strong>PBS Server</strong>：运行于集群的<font color="red"><strong>管理节点</strong></font>。<font color="red"><strong>创建并接受作业、修改作业、激活调度器（PBS Scheduler）以及通知PBS执行器（PBS Moms）执行作业</strong></font></p>
</li>
<li><p><strong>PBS Scheduler激活调度器</strong>：根据资源管理器获知<strong>各个节点的资源状况</strong>和<strong>系统的作业信息</strong>生成相应<font color="red">作业优先级列表</font></p>
</li>
<li><p><strong>PBS MomsPBS执行器</strong>：<font color="blue">每个节点均有一个<strong>后台进程</strong>，该进程真正<strong>启动</strong>和<strong>停止</strong>提交到该节点的作业</font></p>
</li>
</ul>
<h3 id="2-2-常用PBS命令"><a href="#2-2-常用PBS命令" class="headerlink" title="2.2 常用PBS命令"></a><strong>2.2 常用PBS命令</strong></h3><ul>
<li>查看节点状态<br><font color="red"><strong>pbsnodes （查看所有节点）</strong></font><br><font color="red"><strong>pbsnodes -l free （查看空闲节点）</strong></font><br>pbsnodes 某节点 （查看某节点状态）</li>
<li>节点切换<br><font color="red"><strong>ssh 某节点 （转到某节点）</strong></font></li>
<li>退出节点<br><strong>exit （离开节点）</strong></li>
<li>查看任务运行状态<br><font color="red"><strong>【qstat （列出所有作业运行状态）】</strong></font></li>
</ul>
<blockquote>
<p>【主要包括以下几个方面信息】</p>
<ul>
<li><p>Job ID 任务ID号</p>
</li>
<li><p>Name 任务脚本名称</p>
</li>
<li><p>User 用户名</p>
</li>
<li><p>Time Use 任务运行时间</p>
</li>
<li><p>S State 任务状态<br>* B 只用于任务向量，表示任务向量已经开始执行<br>* E 任务在运行后退出<br>* H 任务被服务器或用户或者管理员阻塞<br>* Q 任务正在排队中，等待被调度运行<br>* R 任务正在运行<br>* S 任务被服务器挂起，由于一个更高优先级的任务需要当前任务的资源<br>* T 任务被转移到其它执行节点了<br>* U 由于服务器繁忙，任务被挂起<br>* W 任务在等待它所请求的执行时间的到来(qsub -a)<br>* X 只用于子任务，表示子任务完成<br>* C 表示程序正在被关闭，一般是程序运行错误，报错</p>
</li>
<li><p>Queue 任务执行所在队列</p>
</li>
</ul>
<p><strong>qstat -q （列出队列使用信息）</strong><br><strong>qstat -n （列出队列中使用的节点）</strong><br><strong>qstat -f jobid （查看jobid任务的详细信息）</strong></p>
</blockquote>
<ul>
<li><strong>提交</strong>任务到集群<br>qsub 文件名.pbs/.sh （提交任务）<br>echo “script.py” | qsub -l q batch1 -l nodes=1:ppn=2 (直接在终端设置PBS资源命令，并在此资源下提交可执行脚本)</li>
<li><strong>任务挂起，释放，重新加载</strong><br>qhold：挂起作业<br>qrls：释放挂起的作业<br>qrerun：重新运行作业</li>
<li><strong>任务更改</strong><br>qmove：将作业移动到另一个队列<br>qalter： 更改作业资源属性</li>
<li>删除任务<br><strong>qdel jobid</strong> （取消任务）</li>
</ul>
<h3 id="2-3-qsub-提交任务"><a href="#2-3-qsub-提交任务" class="headerlink" title="2.3 qsub 提交任务"></a><strong>2.3 qsub 提交任务</strong></h3><p><strong>2.3.1 通过终端提交任务</strong></p>
<ul>
<li>通过命令行参数传递给 qsub 命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &quot;python script.py -i inputdir -o outdir &quot; | qsub -q Batch1 -l nodes=1:ppn=1 -l mem=40gb -N jobname</span><br></pre></td></tr></table></figure>

<p><strong>执行script.py 脚本， 通过pbs投递任务, 任务提交到Batch1队列，所需资源为，1个节点，节点使用1个cpu, 40GB物理内存，该任务命名jobname</strong></p>
<ul>
<li>-N 任务名称</li>
<li>-q 指定Queue</li>
<li><font color="red">-l</font> resource_list 指定<font color="red">任务所需资源</font><br>一般包括：<br>* cput=N， 请求N秒CPU时间，N也可以写成hh:mm::ss，单位分别是 时：分：秒<br>* mem=N[K|M|G|][B|W], 请求N大小的<font color="red">内存</font><br>* nodes=N, N个<font color="red">节点</font><br>* ppn=M, 每个节点需要M个<font color="red">cpu</font></li>
<li>-e path 将标准错误重定向到path</li>
<li>-o path 标准输出重定向到path</li>
<li>-j join 将标准输出信息与标准错误信息合并到同一个文件join中去</li>
<li>-p priority 任务优先级，整数，无定义默认0</li>
<li>-m mail_options mail_option =a：左右abort时给用户发信；=b：作业开始时发信；=e：作业结束时发信. 默认=a</li>
</ul>
<p><strong>2.3.2 <font color="red">PBS通过sh脚本执行命令</font></strong></p>
<ul>
<li><font color="red">在 PBS 脚本中以 #PBS 方式指定</font><br>在PBS系统中，用户使用qsub命令提交用户程序。用户运行程序的命令 以及 PBS环境变量设置 共同组成了PBS作业脚本。</li>
<li>注释为 “#” 开头</li>
<li>PBS指令为 “#PBS” 开头</li>
<li>shell命令 （运行脚本的命令）</li>
</ul>
<p>例如 run.sh</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">参数解析</span></span><br><span class="line"><span class="meta">#</span><span class="bash">指定节点数目 ppn指每个节点运行的cpu数量（4个小节点，每个48个CPU）</span></span><br><span class="line"><span class="meta">#</span><span class="bash">PBS -l nodes=1:ppn=16</span></span><br><span class="line"><span class="meta">#</span><span class="bash">指定合并到标准输出文件中</span></span><br><span class="line"><span class="meta">#</span><span class="bash">PBS -j oe</span></span><br><span class="line"><span class="meta">#</span><span class="bash">设置程序运行的最大时间192小时</span></span><br><span class="line"><span class="meta">#</span><span class="bash">PBS -l walltime=192:00:00</span></span><br><span class="line"><span class="meta">#</span><span class="bash">指定qsub的所有环境变量都传递到批处理作业中</span></span><br><span class="line"><span class="meta">#</span><span class="bash">PBS -V</span></span><br><span class="line"><span class="meta">#</span><span class="bash">输出文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash">PBS -o /public/home/tang/chaim/back_info/<span class="variable">$jobname</span>.out</span></span><br><span class="line"><span class="meta">#</span><span class="bash">错误输出文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash">PBS -e /public/home/tang/chaim/back_info/<span class="variable">$jobname</span>.err</span></span><br><span class="line">cd PBS_O_OUTDIR</span><br><span class="line"><span class="meta">#</span><span class="bash"> 程序执行命令</span></span><br><span class="line">python script.py -i inputdir -o outdir </span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行脚本</span></span><br><span class="line">qsub run.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 制定命令开始运行的时间</span>  </span><br><span class="line">qusb -a 070000 run.s  #7天后运行程序，此时是处于W状态(等待状态)</span><br><span class="line">qsub -a 2400 run.s #24h后运行程序</span><br></pre></td></tr></table></figure>

<p><strong>2.3.3 通过交互式的方式执行任务</strong></p>
<ul>
<li><strong>qsub -I</strong></li>
<li>qsub -I -q Batch1 -l nodes=1:ppn=1 -l mem=80gb -N jobname</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">[#</span><span class="bash">11<span class="comment">#Rd01@login ~]$</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash">qsub -I -q Batch1 -l nodes=1:ppn=1 -l mem=80gb -N jobname</span></span><br><span class="line">qsub: waiting for job 1230615.admin to start</span><br><span class="line">qsub: job 1230615.admin ready</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">[#</span><span class="bash">1<span class="comment">#Rd01@comput4 ~]$</span></span></span><br><span class="line"><span class="meta">$</span></span><br></pre></td></tr></table></figure>

<h3 id="2-4-PBS常用环境变量"><a href="#2-4-PBS常用环境变量" class="headerlink" title="2.4 PBS常用环境变量"></a><strong>2.4 PBS常用环境变量</strong></h3><ul>
<li>PBS_ENVIRONMENT：批处理作业为 PBS_BATCH，交互式作业为 PBS_INTERACTIVE</li>
<li>PBS_JOBID：PBS 系统给作业分配的标识号</li>
<li>PBS_JOBNAME：用户指定的作业名称</li>
<li>PBS_NODEFILE：包含作业所用计算节点的文件名</li>
<li>PBS_QUEUE：作业所执行的队列名称</li>
<li>PBS_O_HOME：执行 qsub 命令的 HOME 环境变量值</li>
<li>PBS_O_PATH：执行 qsub 命令的 PATH 环境变量值</li>
<li>PBS_O_SHELL：执行 qsub 命令的 SHELL 环境变量值</li>
<li>PBS_O_HOST：执行 qsub 命令节点名称</li>
<li>PBS_O_QUEUE：提交作业的最初队列名称</li>
<li>PBS_O_WORKDIR：执行 qsub 命令所在的绝对路径</li>
</ul>
<h1 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h1><p><strong>如果有一天，你有16万个CPU，你要怎么用？</strong> <strong>调度器</strong>最大程度压榨现有<strong>资源或时间的最大价值</strong>。</p>
<p>不同行业因使用习惯和不同调度器对应用的支持力度不同，往往有不同偏好：<strong>比如高校和超算经常用Slurm，半导体公司最常用的是LSF和SGE，工业制造业可能用PBS更多一些。</strong></p>
<p>1篇 <a href="https://fastonetech.com/blog/biotech-fastone-help-hms-on-molecules-selection-20200709/">15小时虚拟筛选10亿分子，《Nature》+HMS验证云端新药研发未来</a> 文章里哈佛大学医学院用<strong>云端16万个CPU来筛选10亿种化合物</strong>，只用了15小时。<br><strong>超大规模计算集群上的工作流程图</strong>：</p>
<p><img src="/blog/2022/03/06/2022-03-06-Linux-grid/5.png" alt="调度器-生信分析-高性能计算集群-化合物筛选"></p>
<p>蓝色框表示计算节点，其中包含CPU核数（蓝色框内的黑色正方形），紫色小圆圈代表待处理的配体。整张图代表整个计算集群，并行运行1.1到X.1个任务，任务1.1完成后会自动运行任务1.2，以此类推直到任务完成。<br>每个任务（包含多个子任务）使用3个计算节点，每个节点有8个CPU核。</p>
<p><strong>假设有10亿化合物需要筛选，面对16万CPU，把流程图里缺乏的时间维度考虑进来，我们可以多思考几个问题：</strong></p>
<ol>
<li><strong>16万CPU，怎么顺利一一配置，启动，关闭？</strong></li>
<li><strong>怎么能让集群整体资源利用率最高？跑更多任务？</strong></li>
<li><strong>能不能指定特定任务在某种类型计算节点上运行？</strong></li>
<li><strong>任务之间存在先后顺序，能否确保特定任务一定先运行？</strong></li>
<li><strong>怎么统计和限制不同用户的用量？</strong></li>
<li><strong>怎么监控每个节点的状态和使用情况？</strong></li>
<li><strong>怎么降低集群的整体运行成本？避免浪费？</strong></li>
<li><strong>计算节点间网络/数据传输怎么考虑？</strong></li>
<li><strong>如何应对云上集群资源高度动态的特性？空闲资源不足时怎么办？</strong></li>
</ol>
<p>如果还不是特别明白，再打个比方。认真想像一下你是老板，手里有且只有100个打工人，你想想要怎么管理才能让他们更好地为你工作？？</p>
<p><strong>基于这几家主流调度器：LSF/SGE/Slurm/PBS以及它们的不同演化版本进行了梳理和盘点，尤其是对云的支持方面划了重点。</strong></p>
<h2 id="LSF"><a href="#LSF" class="headerlink" title="LSF"></a>LSF</h2><p><strong>基于LSF（Load Sharing Facility）的调度器主要有Spectrum LSF、PlatformLSF、OpenLava三家。</strong></p>
<p>早期LSF由Toronto大学开发的Utopia系统发展而来。<br>2007年，<strong>Platform Computing</strong>基于早期老版本的LSF开源了一个简化版Platform Lava。</p>
<p>这个开源项目2011年中止了，被<strong>OpenLava</strong>接手。<br>2011年，Platform员工David Bigagli基于Platform Lava的派生代码创建了OpenLava 1.0。2014年，一些Platform的员工成立了Teraproc公司，为OpenLava提供开发和商业支持。<strong>2016年IBM就LSF版权对Teraproc公司发起诉讼，2018年IBM胜诉，OpenLava被禁用。</strong></p>
<p>2011年，Platform Lava开源项目中止后。<strong>2012年1月，IBM收购了Platform Computing。Spectrum LSF</strong>就是IBM收购后推出的商用版本，目前更新到10.1.0，同时支持Linux和Windows，<font color="red">最大节点数超过6000，在国内提供商业支持。</font><br><strong>Platform LSF</strong>是LSF的早期版本，与Spectrum LSF一样属于IBM，目前版本是9.1.3，目测已经停止更新以维护为主。</p>
<h2 id="SGE"><a href="#SGE" class="headerlink" title="SGE"></a>SGE</h2><p><strong>基于SGE（Sun Grid Engine）的调度器包括UGE（Univa Grid Engine）和SGE（Son of Grid Engine）。</strong></p>
<p>1993年，<strong>Grid Engine</strong>作为商业软件发布，先后使用了<strong>CODINE</strong>（Computing in Distributed Networked Environments）、<strong>GRD</strong>（Global Resource Director）作为名称。1999年，第一次由Genias Software推出市场，然后被Gridware公司收购。直到2000年被SUN收购之后正式改名<strong>Sun Grid Engine</strong>，2001年发布开源版。</p>
<p>2010年被Oracle收购后改名<strong>Oracle Grid Engine</strong>，改成闭源版，不提供源代码。原来开源项目的资料库禁止用户修改。<br>于是，Grid Engine社区开始开源版本的<strong>SGE</strong>（<strong>Son of Grid Engine</strong>）项目。该调度器最后一次更新为2016年的8.1.9，由于存在版权风险，SGE已长期无维护和更新。</p>
<p>2013年Univa收购了Oracle Grid Engine，成为唯一商业软件<strong>UGE（Univa Grid Engine）</strong>提供商。UGE最新版本为8.6.15，同时支持Linux和Windows，国内暂无商业支持的相关信息。<br>2020年9月，Altair收购了Univa。</p>
<h2 id="Slurm-四大流派里唯一纯开源派"><a href="#Slurm-四大流派里唯一纯开源派" class="headerlink" title="Slurm 四大流派里唯一纯开源派"></a>Slurm <strong>四大流派里唯一纯开源派</strong></h2><p><font color="red"><strong>Slurm全称为Simple Linux Utility for Resource Management</strong></font>，前期主要由劳伦斯利弗莫尔国家实验室、SchedMD、Linux NetworX、Hewlett-Packard 和 Groupe Bull 负责开发，受到闭源软件Quadrics RMS的启发。</p>
<p>Slurm最新版本为20.02，目前由社区和SchedMD公司共同维护，<strong>保持开源和免费</strong>，由SchedMD公司提供商业支持，仅支持Linux系统，<font color="red">最大节点数量超过12万</font>。<br>Slurm拥有<font color="red">容错率高、支持异构资源、高度可扩展等优点，每秒可提交超过1000个任务，且由于是开放框架，高度可配置，拥有超过100种插件，因此适用性相当强。</font></p>
<p><strong>全球60%的TOP500超算中心和超大规模集群（包括我国的天河二号等）都采用Slurm作为调度系统。我们的TOP500就是用Slurm调度云上资源跑的。</strong><a href="https://fastonetech.com/blog/top500/">上榜啦～花费4小时5500美元，速石科技跻身全球超算TOP500</a></p>
<p>支持在Slurm上的集群自动伸缩和云端费用监控，并支持AWS、阿里云、Azure、腾讯云、华为云、Google Cloud等云厂商。</p>
<p><strong><a href="https://fastonetech.com/blog/case-vina-20201021/">生信云实证Vol.3</a>：提速2920倍！用AutoDockVina对接2800万个分子  这篇主要基于用户不同的策略，跨区、跨类型自动为用户调度云资源，如何以最快速度or最低成本完成计算任务。</strong></p>
<h2 id="PBS"><a href="#PBS" class="headerlink" title="PBS"></a>PBS</h2><p><strong>基于PBS（Portable Batch System）的调度器包括OpenPBS、PBS PRO、Moab/TORQUE。</strong></p>
<p>PBS最初是由MRJ Technology Solutions于 1991 年 6 月开始为 <font color="red">NASA 所研发的作业调度系统</font>，MRJ于 20 世纪90 年代末被 Veridian 收购。2003年，Altair收购了Veridian，获得了PBS的技术和知识产权。<br><font color="red"><strong>PBS Pro</strong></font>是Altair旗下PBS WORKS提供的<font color="red">商业版本，支持可视化界面，节点数超过50000个。</font></p>
<p>2016年Altair基于<strong>PBS Pro</strong>提供了开源许可版本，其与MRJ于1998年发布的原始开源版本两者合二为一大致就是现在的<font color="red"><strong>OpenPBS</strong></font>。<font color="red">与Pro版本比，多了很多限制，但都支持Linux和Windows。</font></p>
<p><strong>Moab/TORQUE合在一起是一个完整调度器的功能，现在属于同一家公司Adaptive Computing。</strong>90年代中期由MHPCC的David Jackson开发的Maui，他后来创立了Adaptive Computing。</p>
<p><strong>Moab</strong>是Adaptive Computing 公司（前身为 Cluster Resources 公司开发的Maui Cluster Scheduler）维护的 OpenPBS 分支，2003年发布。该项目最初是开源免费的，后来变成了商用软件Moab后不再免费。</p>
<p><strong>TORQUE</strong>（Terascale Open-source Resource and QUEue Manager）早期的 Torque 也是开源免费软件，不过 2018 年 6 月开始 TORQUE 不再开源。<br><font color="red">两者均只支持Linux系统，提供可视化界面，拥有约数千个节点。</font></p>
<p>云服务方面，PBS Pro能通过<strong>Altair Control产品</strong>从本地溢出到多云和Auto-Scale集群自动伸缩，支持的云厂商包括AWS、Azure和Google Cloud。</p>
<p>Moab/TORQUE 则可通过 <strong>NODUSCloud OS 产品</strong>实现本地扩展到云，支持TORQUE 或 Slurm集群和自动伸缩，可支持的云厂商包括AWS、Azure、GoogleCloud 和华为云，并通过 Account Manager 产品实现云端费用监控。</p>
<hr>
<p>ref</p>
<p> <a href="https://fastonetech.com/blog/cluster-scheduler-20201105/">https://fastonetech.com/blog/cluster-scheduler-20201105/</a></p>
<p><a href="https://www.jianshu.com/p/45e3f88086f3">https://www.jianshu.com/p/45e3f88086f3</a></p>
<p><a href="https://www.jianshu.com/p/b7b540a3c015">https://www.jianshu.com/p/b7b540a3c015</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>technology</tag>
      </tags>
  </entry>
  <entry>
    <title>HiFi-4-QC-BUSCO</title>
    <url>/blog/2022/03/05/2022-03-02-HiFi-4-BUSCO/</url>
    <content><![CDATA[<p>BUSCO - <strong>B</strong>enchmarking <strong>U</strong>niversal <strong>S</strong>ingle-<strong>C</strong>opy <strong>O</strong>rthologs</p>
<p>普遍通用的单拷贝直系同源测试?</p>
<span id="more"></span>

<p>official：<a href="https://busco.ezlab.org/busco_userguide.html">https://busco.ezlab.org/busco_userguide.html</a></p>
<p>Ref:<a href="https://www.jianshu.com/p/5041460f7a5d">https://www.jianshu.com/p/5041460f7a5d</a></p>
<p>BUSCO是使用python语言编写的<font color="blue">对<strong>转录组</strong>和<strong>基因组组装质量</strong>进行<strong>评估</strong></font>的软件。相近物种间总有一些保守序列，BUSCO<font color="blue">使用这些<strong>保守序列</strong>与<strong>组装结果</strong>进行<strong>比对</strong></font>，鉴定组装结果是否包含这些序列，包含单条、多条还是部分或者不包含等情况给出结果</p>
<blockquote>
<p>BUSCO 软件根据<strong>OrthoDB 数据库</strong>，构建了<strong>几个大的进化分支</strong>的<strong>单拷贝基因集</strong>。将转录本拼接结果<strong>与该基因集比较</strong>，根据比对上的比例、完整性，来评价拼接结果的<strong>准确性和完整性</strong></p>
</blockquote>
<p>基于大量物种的<font color="blue">单拷贝基因构建数据集</font>，用于评估<font color="blue"><strong>基因组组装，转录组组装，基因注释，蛋白集的完整性</strong></font>。core-genes 构建方式，90%物种共享的基因即为核心基因。使用的是直系同源基因家族的概念，基于100个物种基因组，某一个基因家族存在于&gt;90个基因组中，即将该基因家族认定为核心基因</p>
<p>BUSCO使用其他工具搭建流程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">genoem assemble : tBLASTn --&gt; Augustus --&gt; HMMER3 √</span><br><span class="line">Transcriptome   :             Find ORF --&gt; HMMER3</span><br><span class="line">Gene set        :                          HMMER3</span><br></pre></td></tr></table></figure>

<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><h2 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 没有镜像的话，添加镜像</span><br><span class="line">conda config --show </span><br><span class="line">conda config --add channels conda-forge</span><br><span class="line"></span><br><span class="line"># 构建conda的python3环境</span><br><span class="line">【conda create --name python36 python=3.6】</span><br><span class="line">#  然后激活</span><br><span class="line">【conda activate python36】</span><br><span class="line"># 执行安装</span><br><span class="line">【conda install -c conda-forge -c bioconda busco=5.3.0】</span><br><span class="line"># 在使用完busco之后可以退出python36环境</span><br><span class="line">【conda deactivate】</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="独立安装？"><a href="#独立安装？" class="headerlink" title="独立安装？"></a>独立安装？</h2><p>busco，依赖Augustus，HMMER，Blast+</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  ============ 下载BUSCO  ============ </span></span><br><span class="line"><span class="built_in">cd</span> ~/Applications/download</span><br><span class="line">wget -c https://gitlab.com/ezlab/busco/-/archive/master/busco-master.zip -O busco.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># ============ 下载依赖的工具 ============</span></span><br><span class="line"><span class="comment"># 下载Augustus</span></span><br><span class="line">wget -c http://bioinf.uni-greifswald.de/augustus/binaries/augustus.current.tar.gz</span><br><span class="line"><span class="comment"># 下载HMMER</span></span><br><span class="line">wget -c http://eddylab.org/software/hmmer/hmmer.tar.gz -O hmmer.tar.gz</span><br><span class="line"><span class="comment"># 下载Blast+</span></span><br><span class="line">wget -c ftp://ftp.ncbi.nlm.nih.gov/blast/executables/LATEST/ncbi-blast-2.7.1+-x64-linux.tar.gz</span><br><span class="line"><span class="comment">#-------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="built_in">cd</span> ~/Applications/download</span><br><span class="line"></span><br><span class="line"><span class="comment"># === 安装busco ===</span></span><br><span class="line">unzip busco.zip</span><br><span class="line"><span class="comment"># 改名</span></span><br><span class="line">mv busco-master busco </span><br><span class="line"><span class="comment"># 移动到外部</span></span><br><span class="line">mv busco ../</span><br><span class="line"><span class="built_in">cd</span> ../busco</span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">python setup.py install</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ~/Applications/download</span><br><span class="line"><span class="comment"># === 安装Augustus ===</span></span><br><span class="line">tar -xzvf augustus.current.tar.gz</span><br><span class="line"><span class="built_in">cd</span> augustus-3.3.1</span><br><span class="line"><span class="built_in">cd</span> ../</span><br><span class="line">mv augustus-3.3.1 ../</span><br><span class="line"><span class="built_in">cd</span> ../augustus-3.3.1</span><br><span class="line"><span class="comment"># 打开common.mk文件，将ZIPINPUT = true注释掉（即在最前面加一#号）</span></span><br><span class="line">vim common.mk</span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ~/Applications/download</span><br><span class="line"><span class="comment"># === 安装HMMER ===</span></span><br><span class="line">tar -xzvf hmmer.tar.gz</span><br><span class="line"><span class="built_in">cd</span> hmmer-3.2.1</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"><span class="comment"># === 安装blast+ ===</span></span><br><span class="line">tar -xzvf ncbi-blast-2.7.1+-x64-linux.tar.gz</span><br><span class="line"><span class="comment"># 改名</span></span><br><span class="line">mv ncbi-blast-2.7.1+ ../blast+-2.7.1-linux</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除安装包</span></span><br><span class="line"><span class="built_in">cd</span> ~/Applications/download</span><br><span class="line">rm busco.zip</span><br><span class="line">rm augustus.current.tar.gz</span><br><span class="line">rm hmmer.tar.gz</span><br><span class="line">rm ncbi-blast-2.7.1+-x64-linux.tar.gz</span><br></pre></td></tr></table></figure>



<h2 id="下载数据库文件"><a href="#下载数据库文件" class="headerlink" title="下载数据库文件"></a>下载数据库文件</h2><p><a href="https://busco-data.ezlab.org/v5/data/lineages/">https://busco-data.ezlab.org/v5/data/lineages/</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">大类五类</span><br><span class="line">- Bacteria 细菌</span><br><span class="line">- Protists 原生生物</span><br><span class="line">- Metazoa 后生动物</span><br><span class="line">- Fungi 真菌</span><br><span class="line">- Plant 植物</span><br><span class="line">下载的是植物相关 embryophyta_odb10.2020-09-10.tar.gz</span><br><span class="line"># 解压文件</span><br><span class="line">tar -xzvf embryophyta_odb9.tar.gz</span><br></pre></td></tr></table></figure>

<p>执行时需要对应的数据库文件路径 ///embryophyta_odb9</p>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>配置是必须的，<strong>这一步需要仔细一些，路径出错的话是无法通过busco的检测的</strong>，在安装好软件之后 <code>~/Applications/busco/config/</code>之中并没有<code>config.ini</code>文件，只有一个<code>config.ini_default</code>文件，可以把里面的内容复制下来，</p>
<ul>
<li>方法1</li>
</ul>
<p>新建<code>config.ini</code>文件或者直接复制</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp config.ini_default config.ini</span><br></pre></td></tr></table></figure>

<ul>
<li>方法2</li>
</ul>
<p>也可新建</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 增加配置文件</span></span><br><span class="line">vim ~/Applications/busco/config/config.ini</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># BUSCO specific configuration</span></span><br><span class="line"><span class="comment">#It 【overrides default values】 in code and dataset cfg, and is 【overridden by arguments in command line】</span></span><br><span class="line"><span class="comment"># Uncomment lines when appropriate</span></span><br><span class="line">[busco]</span><br><span class="line"><span class="comment"># Input file</span></span><br><span class="line">;<span class="keyword">in</span> = ./sample_data/target.fa</span><br><span class="line"><span class="comment"># Run name, used in output files and folder</span></span><br><span class="line">;out = SAMPLE</span><br><span class="line"><span class="comment"># Where to store the output directory</span></span><br><span class="line"><span class="comment">#【？】 out_path = /workdir</span></span><br><span class="line"><span class="comment"># Path to the BUSCO dataset</span></span><br><span class="line">;lineage_path = ./sample_data/example</span><br><span class="line"><span class="comment"># Which mode to run (【genome / protein / transcriptome】)</span></span><br><span class="line">;mode = genome</span><br><span class="line"><span class="comment"># How many threads to use for 【multithreaded】 steps</span></span><br><span class="line">;cpu = 1</span><br><span class="line"><span class="comment"># Domain for augustus retraining, eukaryota or prokaryota</span></span><br><span class="line"><span class="comment"># 【Do not change】 this unless you know exactly why !!!</span></span><br><span class="line">;domain = eukaryota</span><br><span class="line"><span class="comment"># Force rewrite if files already exist (True/False)</span></span><br><span class="line">;force = False</span><br><span class="line"><span class="comment"># Restart mode (True/False)</span></span><br><span class="line">;restart = False</span><br><span class="line"><span class="comment"># Blast e-value</span></span><br><span class="line">;evalue = 1e-3</span><br><span class="line"><span class="comment"># Species to use with augustus, for old datasets only</span></span><br><span class="line">;species = fly</span><br><span class="line"><span class="comment"># Augustus extra parameters</span></span><br><span class="line"><span class="comment"># Use single quotes, like this: &#x27;--param1=1 --param2=2&#x27;</span></span><br><span class="line">;augustus_parameters = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># Tmp folder</span></span><br><span class="line">;tmp_path = ./tmp/</span><br><span class="line"><span class="comment"># How many candidate regions (contigs, scaffolds) to consider for each BUSCO</span></span><br><span class="line">;<span class="built_in">limit</span> = 3</span><br><span class="line"><span class="comment"># Augustus long mode for retraining (True/False)</span></span><br><span class="line">;long = False</span><br><span class="line"><span class="comment"># Quiet mode (True/False)</span></span><br><span class="line">;quiet = False</span><br><span class="line"><span class="comment"># Debug logs (True/False), it needs Quiet to be False</span></span><br><span class="line">debug = True</span><br><span class="line"><span class="comment"># tar gzip output files (True/False)</span></span><br><span class="line">;gzip = False</span><br><span class="line"><span class="comment"># Force single core for the tblastn step</span></span><br><span class="line">;blast_single_core = True</span><br><span class="line"></span><br><span class="line">【[tblastn]】</span><br><span class="line"><span class="comment"># path to tblastn</span></span><br><span class="line">path = ~/Applications/blast+-2.7.1-linux/bin</span><br><span class="line"></span><br><span class="line">【[makeblastdb]】</span><br><span class="line"><span class="comment"># path to makeblastdb</span></span><br><span class="line">path = ~/Applications/blast+-2.7.1-linux/bin</span><br><span class="line"></span><br><span class="line">【[augustus]】</span><br><span class="line"><span class="comment"># path to augustus</span></span><br><span class="line">path = ~/Applications/augustus-3.3.1/bin</span><br><span class="line"></span><br><span class="line">【[etraining]】</span><br><span class="line"><span class="comment"># path to augustus etraining</span></span><br><span class="line">path = ~/Applications/augustus-3.3.1/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># path to augustus perl scripts, redeclare it for each new script        </span></span><br><span class="line">【[gff2gbSmallDNA.pl]】                                                      </span><br><span class="line">path = ~/Applications/augustus-3.3.1/scripts                         </span><br><span class="line">【[new_species.pl]】                                                         </span><br><span class="line">path = ~/Applications/augustus-3.3.1/scripts                         </span><br><span class="line">【[optimize_augustus.pl]】                                                   </span><br><span class="line">path = ~/Applications/augustus-3.3.1/scripts                         </span><br><span class="line">                                                                         </span><br><span class="line">【[hmmsearch]】                                                              </span><br><span class="line"><span class="comment"># path to HMMsearch executable                                           </span></span><br><span class="line">path = ~/Applications/hmmer-3.2.1/src                                </span><br><span class="line">                                                                         </span><br><span class="line">【[Rscript]】                                                                </span><br><span class="line"><span class="comment"># path to Rscript, if you wish to use the plot tool                      </span></span><br><span class="line">path = /usr/bin/</span><br></pre></td></tr></table></figure>

<p>新建config.ini`文件之后，</p>
<ol>
<li>将<code>config.ini</code>文件中的<code>out_path = /workdir</code>前面加上<code>#</code><br>因为输出路径有时候会出错，所以注释掉，之后运行busco，<font color="blue">输出的路径就是cd的路径</font></li>
<li>之后需要改这几项对应的路径（<strong>里面的路径需要更改为自己的工具的路径</strong>）</li>
</ol>
<table>
<thead>
<tr>
<th>选项</th>
<th>相关</th>
</tr>
</thead>
<tbody><tr>
<td>[tblastn]</td>
<td>blast+</td>
</tr>
<tr>
<td>[makeblastdb]</td>
<td>blast+</td>
</tr>
<tr>
<td>[augustus]</td>
<td>Augustus</td>
</tr>
<tr>
<td>[hmmsearch]</td>
<td>HMMER</td>
</tr>
<tr>
<td>[gff2gbSmallDNA.pl]</td>
<td>Augustus</td>
</tr>
<tr>
<td>[new_species.pl]</td>
<td>Augustus</td>
</tr>
<tr>
<td>[optimize_augustus.pl]</td>
<td>Augustus</td>
</tr>
<tr>
<td>[hmmsearch]</td>
<td>HMMER</td>
</tr>
</tbody></table>
<h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># augustus工具的执行文件所在文件夹</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/ssd/Applications/augustus-3.3.1/bin:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="comment"># augustus工具附加脚本所在文件夹</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/ssd/Applications/augustus-3.3.1/scripts:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="comment"># augustus工具配置文件的所在位置 。AUGUSTUS_CONFIG_PATH 需要使用绝对路径</span></span><br><span class="line"><span class="built_in">export</span> AUGUSTUS_CONFIG_PATH=<span class="string">&quot;/home/ssd/Applications/augustus-3.3.1/config&quot;</span></span><br><span class="line"><span class="comment"># hmmer工具的执行文件所在文件夹</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/ssd/Applications/hmmer-3.2.1/src:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="comment"># blast+工具的执行文件所在文件夹</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/ssd/Applications/blast+-2.7.1-linux/bin:<span class="variable">$PATH</span>&quot;</span></span><br></pre></td></tr></table></figure>



<h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">run_BUSCO.py -i [组装的文件.fasta]  -l  [数据库文件夹] -o [输出文件名] -m [评估模式] [其他一些选项]</span><br></pre></td></tr></table></figure>

<p>实例，如果用<code>conda</code>安装BUSCO。执行只需写<code>busco</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先cd到对应的组装文件的文件夹</span></span><br><span class="line"><span class="comment"># 确保canu全路径，conda安装，which busco</span></span><br><span class="line"><span class="comment"># -i 输入文件</span></span><br><span class="line"><span class="comment"># -l BUSCO的数据库文件</span></span><br><span class="line"><span class="comment"># -o 输出的文件名的后缀以及文件夹的名称</span></span><br><span class="line"><span class="comment"># -m 分析类型（genome、transcriptome、proteins）</span></span><br><span class="line"><span class="comment"># --cpu 线程数</span></span><br><span class="line">busco \</span><br><span class="line">    -i contigs.fasta \</span><br><span class="line">    -l ~/database/BUSCO/embryophyta_odb9 \</span><br><span class="line">    -o suffix\</span><br><span class="line">    -m genome \</span><br><span class="line">    --cpu 8</span><br></pre></td></tr></table></figure>

<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a><font color="red">参数</font></h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">usage: busco -i [SEQUENCE_FILE] -l [LINEAGE] -o [OUTPUT_NAME] -m [MODE] [OTHER OPTIONS]</span><br><span class="line"></span><br><span class="line">Welcome to BUSCO 5.3.0: the Benchmarking Universal Single-Copy Ortholog assessment tool.</span><br><span class="line">For more detailed usage information, please review the README file provided with this distribution and the BUSCO user guide. Visit this page https://gitlab.com/ezlab/busco<span class="comment">#how-to-cite-busco to see how to cite BUSCO</span></span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  <span class="string">&#x27;-i&#x27;</span> SEQUENCE_FILE, --<span class="keyword">in</span> SEQUENCE_FILE</span><br><span class="line">                        Input sequence file <span class="keyword">in</span> <span class="string">&#x27;FASTA format&#x27;</span>. Can be an assembled genome or transcriptome (DNA), or protein sequences from an annotated gene <span class="built_in">set</span>. Also possible to use a path to a directory containing multiple input files.</span><br><span class="line">  <span class="string">&#x27;-o&#x27;</span> OUTPUT, --out OUTPUT</span><br><span class="line">                        Give your analysis run a recognisable short name. <span class="string">&#x27;Output folders and files will be labelled with this name&#x27;</span>. The path to the output folder is <span class="built_in">set</span> with --out_path.</span><br><span class="line">  <span class="string">&#x27;-m&#x27;</span> MODE, --mode MODE  Specify <span class="built_in">which</span> BUSCO analysis mode to run.</span><br><span class="line">                        There are three valid modes:</span><br><span class="line">                        - geno or <span class="string">&#x27;genome&#x27;</span>, <span class="keyword">for</span> genome assemblies (DNA)</span><br><span class="line">                        - tran or transcriptome, <span class="keyword">for</span> transcriptome assemblies (DNA)</span><br><span class="line">                        - prot or proteins, <span class="keyword">for</span> annotated gene sets (protein)</span><br><span class="line">  <span class="string">&#x27;-l&#x27;</span> LINEAGE, --lineage_dataset LINEAGE</span><br><span class="line">                        Specify the name of the BUSCO lineage to be used<span class="string">&#x27;database?&#x27;</span></span><br><span class="line">  --augustus            Use augustus gene predictor <span class="keyword">for</span> eukaryote runs</span><br><span class="line">  --augustus_parameters --PARAM1=VALUE1,--PARAM2=VALUE2</span><br><span class="line">                        Pass additional arguments to Augustus. All arguments should be contained within a single string with no white space, with each argument separated by a comma.</span><br><span class="line">  --augustus_species AUGUSTUS_SPECIES</span><br><span class="line">                        Specify a species <span class="keyword">for</span> Augustus training.</span><br><span class="line">  --auto-lineage        Run auto-lineage to find optimum lineage path</span><br><span class="line">  --auto-lineage-euk    Run auto-placement just on eukaryote tree to find optimum lineage path</span><br><span class="line">  --auto-lineage-prok   Run auto-lineage just on non-eukaryote trees to find optimum lineage path</span><br><span class="line">  <span class="string">&#x27;-c&#x27;</span> N, --cpu N         Specify the number (N=<span class="built_in">integer</span>) of threads/cores to use.</span><br><span class="line">  <span class="string">&#x27;--config&#x27;</span> CONFIG_FILE  Provide a config file</span><br><span class="line">  --datasets_version DATASETS_VERSION</span><br><span class="line">                        Specify the version of BUSCO datasets, e.g. odb10</span><br><span class="line">  <span class="string">&#x27;--download&#x27;</span> [dataset [dataset ...]]</span><br><span class="line">                        Download dataset. Possible values are a specific dataset name, <span class="string">&quot;all&quot;</span>, <span class="string">&quot;prokaryota&quot;</span>, <span class="string">&quot;eukaryota&quot;</span>, or <span class="string">&quot;virus&quot;</span>. If used together with other <span class="built_in">command</span> line arguments, make sure to place this last.</span><br><span class="line">  --download_base_url DOWNLOAD_BASE_URL</span><br><span class="line">                        Set the url to the remote BUSCO dataset location</span><br><span class="line">  --download_path DOWNLOAD_PATH</span><br><span class="line">                        Specify <span class="built_in">local</span> filepath <span class="keyword">for</span> storing BUSCO dataset downloads</span><br><span class="line">  <span class="string">&#x27;-e&#x27;</span> N, --evalue N      <span class="string">&#x27;E-value cutoff for BLAST searches&#x27;</span>. Allowed formats, 0.001 or 1e-03 (Default: 1e-03)</span><br><span class="line">  -f, --force           Force rewriting of existing files. Must be used when output files with the provided name already exist.</span><br><span class="line">  -h, --<span class="built_in">help</span>            Show this <span class="built_in">help</span> message and <span class="built_in">exit</span></span><br><span class="line">  --<span class="built_in">limit</span> N             How many candidate regions (contig or transcript) to consider per BUSCO (default: 3)</span><br><span class="line">  --list-datasets       Print the list of available BUSCO datasets</span><br><span class="line">  --long                Optimization Augustus self-training mode (Default: Off); adds considerably to the run time, but can improve results <span class="keyword">for</span> some non-model organisms</span><br><span class="line">  --metaeuk_parameters <span class="string">&quot;--PARAM1=VALUE1,--PARAM2=VALUE2&quot;</span></span><br><span class="line">                        Pass additional arguments to Metaeuk <span class="keyword">for</span> the first run. All arguments should be contained within a single string with no white space, with each argument separated by a comma.</span><br><span class="line">  --metaeuk_rerun_parameters <span class="string">&quot;--PARAM1=VALUE1,--PARAM2=VALUE2&quot;</span></span><br><span class="line">                        Pass additional arguments to Metaeuk <span class="keyword">for</span> the second run. All arguments should be contained within a single string with no white space, with each argument separated by a comma.</span><br><span class="line">  <span class="string">&#x27;--offline&#x27;</span>            <span class="string">&#x27;To indicate that BUSCO cannot attempt to download files&#x27;</span></span><br><span class="line">  --out_path OUTPUT_PATH</span><br><span class="line">                        Optional location <span class="keyword">for</span> results folder, excluding results folder name. <span class="string">&#x27;Default is current working directory&#x27;</span>.</span><br><span class="line">  -q, --quiet           Disable the info logs, <span class="string">&#x27;displays only errors&#x27;</span></span><br><span class="line">  -r, --restart         <span class="string">&#x27;Continue a run that had already partially completed&#x27;</span>.</span><br><span class="line">  --tar                 <span class="string">&#x27;Compress some subdirectories with many files to save space&#x27;</span></span><br><span class="line">  --update-data         Download and replace with last versions all lineages datasets and files necessary to their automated selection</span><br><span class="line">  -v, --version         Show this version and <span class="built_in">exit</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>fasta文件中，一些组装工具生成的<code>contig</code>的名字是形如<code>&gt;contig/1/12345</code>之类的，这种fasta文件运行时BUSCO会报错，解决办法是改名，perl单行。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cat contig.fasta | perl -p -e <span class="string">&#x27;s&#123;/&#125;&#123;&#125;g&#x27;</span> &gt; contig.new.fasta</span><br></pre></td></tr></table></figure>





<h1 id="结果解读"><a href="#结果解读" class="headerlink" title="结果解读"></a>结果解读</h1><p>在运行文件夹下会有</p>
<ul>
<li><code>run_suffix</code> 文件夹：因为上面<code>-o</code>选项设置了<code>suffix</code>，所以文件夹名称加了后缀。文件夹里，有一个文件最为重要。是<code>short_summary_suffix.txt</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Summarized benchmarking in BUSCO notation for file assembly/spades/contigs.fasta</span><br><span class="line"># BUSCO was run in mode: genome</span><br><span class="line">    C:98.6%[S:98.6%,D:0.0%],F:0.0%,M:1.4%,n:148</span><br><span class="line"></span><br><span class="line">    146 Complete BUSCOs (C)</span><br><span class="line">    146 Complete and single-copy BUSCOs (S)</span><br><span class="line">    0   Complete and duplicated BUSCOs (D)</span><br><span class="line">    0   Fragmented BUSCOs (F)</span><br><span class="line">    2   Missing BUSCOs (M)</span><br><span class="line">    148 Total BUSCO groups searched</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">缩写</th>
<th>全称</th>
<th>说明</th>
<th>关系</th>
</tr>
</thead>
<tbody><tr>
<td align="left">C</td>
<td>Complete</td>
<td>多少个BUSCO测试基因被覆盖。</td>
<td>C = S + D</td>
</tr>
<tr>
<td align="left">S</td>
<td>single-copy</td>
<td>多少个基因经过比对发现是单拷贝。</td>
<td>-</td>
</tr>
<tr>
<td align="left">D</td>
<td>duplicated</td>
<td>多少个基因经过比对发现包含多拷贝。</td>
<td>-</td>
</tr>
<tr>
<td align="left">F</td>
<td>Fragment</td>
<td>多少个基因经过比对覆盖不完全，只是部分比对上。</td>
<td>-</td>
</tr>
<tr>
<td align="left">M</td>
<td>Miss</td>
<td>没有得到比对结果的基因数</td>
<td>-</td>
</tr>
<tr>
<td align="left">Total</td>
<td>Total</td>
<td>总共测试的基因条目数</td>
<td>Total = C + F + M</td>
</tr>
</tbody></table>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">一般情况下对于完整度较好的基因组组装结果来讲，Complete and single-copy越多越好，而Complete and duplicated和Missing越少越好，对于Fragmented也尽可能地少一些。</span><br><span class="line">真实项目中，Complete BUSCOs (C) 的比例通常都能达到 <span class="number">80%</span> 以上。</span><br><span class="line">C值表示和BUSCO集相比的完整度，M值表示可能缺少的基因数，D则是重复数。</span><br></pre></td></tr></table></figure>



<p>三种比对</p>
<ul>
<li>情况1 - 完全覆盖</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">说明: +表示组装得到基因序列 -表示用于测试的基因序列</span><br><span class="line"></span><br><span class="line">组装 : ================+++++++==============</span><br><span class="line">测试                   -------</span><br><span class="line">                       或者</span><br><span class="line">组装 : ==============+++++++++++============</span><br><span class="line">测试                   -------               </span><br></pre></td></tr></table></figure>

<ul>
<li>情况2 - 部分覆盖</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">组装 : ================+++++++==============</span><br><span class="line">测试                   -----</span><br><span class="line">                     /      \</span><br><span class="line">                       或者</span><br><span class="line">组装 : ================+++++++==============</span><br><span class="line">测试                   -------</span><br><span class="line">                     /        \</span><br></pre></td></tr></table></figure>

<ul>
<li>情况3 - 没有比对</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">组装 : ================+++++++==============</span><br><span class="line">测试 </span><br></pre></td></tr></table></figure>

<p>一般<code>S</code> + <code>D</code>的数值也就是<code>C</code>的值越大越好，但是在文献中作者说如果<code>D</code>的数值太多的话可能意味着组装错误的可能性较大。因为一个基因（BUSCO数据库中该基因一般为单拷贝）被覆盖多次，那么可能就是说该基因所在的片段组装可能出现问题。<br>因为理论上</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">理论上：--------------------------------------------</span><br><span class="line">实际上：--------   ----------    ----------    -----</span><br><span class="line">错误的：--------                 -------------</span><br><span class="line">           \\\\                    ///</span><br><span class="line">          -----------     --------------</span><br></pre></td></tr></table></figure>

<p>理论上组装之后各个片段之间应该前后有序，之间除了重复区域或者其他特殊片段之外不应该有可以重叠的地方。<br>例如</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequence1 : ..TAGTCGTGA                         GTGCATGCTGTAGC..</span><br><span class="line">                       \                       /</span><br><span class="line">                        AAAATTGG......CGATGAAAA</span><br><span class="line">                       /                       \</span><br><span class="line">sequence2 : ..GGGTAGCGG                         TTGACTAGCTAGCT..</span><br></pre></td></tr></table></figure>

<p>也就是说中间一段序列是两个序列的共同部分，除非这个序列存在多个拷贝，否则就很可能是拼接错误。通常一般这种拼接错误的序列的两端会出现重复序列。另外如果是多倍体组装的话，<code>D</code>值也可能大。</p>
<p>一般来看，<code>S</code>似乎越大越好，<code>M</code>越小越好，说明组装的越完整，因为检测的单拷贝同源基因出现得多。但是<code>D</code>与<code>F</code>这两个数值越大不见得就是好的，因为组装的错误可能会带来这两个值的增大。不能仅仅只是通过这一个软件来判定。比如还可以借助<code>QUAST</code>和常规指标<code>N50</code>、<code>总的核酸量</code>、<code>点阵图</code>等等多个辅助标准来进行综合的评估。</p>
<h1 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h1><p>执行完毕后，可使用<code>generate_plot.py</code>画图，条形图。</p>
<ul>
<li>首先把所有经过BUSCO检测的结果聚集到一个文件夹之内</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir my_summaries</span><br><span class="line">cp run_SPEC1/short_summary_SPEC1.txt my_summaries/.</span><br><span class="line">cp run_SPEC2/short_summary_SPEC2.txt my_summaries/.</span><br><span class="line">cp run_SPEC3/short_summary_SPEC3.txt my_summaries/.</span><br><span class="line">cp run_SPEC4/short_summary_SPEC4.txt my_summaries/.</span><br><span class="line">cp run_SPEC5/short_summary_SPEC5.txt my_summaries/.</span><br></pre></td></tr></table></figure>

<ul>
<li>运行</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python scripts/generate_plot.py –wd my_summaries</span><br></pre></td></tr></table></figure>

<p>五个数值变成条形图显示，对比更加明显.</p>
]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>【paper】Insight into the evolution of the Solanaceae from the parental genomes of Petunia hybrida</title>
    <url>/blog/2022/03/02/2022-03-02-paper-Petunia/</url>
    <content><![CDATA[<p>Solanaceae 茄科</p>
<span id="more"></span>

<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>The assemblies include 91.3% and 90.2% coverage of their diploid genomes (1.4 Gb; 2n = 14) containing 32,928 and 36,697 protein-coding genes, respectively. The genomes reveal that the Petunia lineage has experienced at least two rounds of hexaploidization: the older gamma event, which is shared with most Eudicots, and a more recent Solanaceae event that is shared with tomato and other solanaceous species. Transcription factors involved in the shift from bee to moth pollination reside in particularly dynamic regions of the genome, which may have been key to the remarkable diversity of floral colour patterns and pollination systems. The high-quality genome sequences will enhance the value of Petunia as a model system for research on unique biological phenomena such as small RNAs, symbiosis, self-incompatibility and circadian rhythms.</p>
<p>矮牵牛是一种流行的花坛植物，作为一种遗传学模式系统有着悠久的历史。我们报道了其两个野生亲本腋毛假单胞菌(P. axillaris N)和膨胀假单胞菌(P. inflata S6)近交系衍生物的全基因组测序和组装。该组合的二倍体基因组覆盖率为91.3%和90.2% (1.4 Gb;2n = 14)，分别含有32,928个和36,697个蛋白编码基因。基因组显示矮矮花至少经历了两轮六倍化:更古老的伽玛事件，与大多数双子叶植物共享，以及更近的茄科事件，与番茄和其他茄科植物共享。转录因子参与了从蜜蜂到飞蛾的传粉过程，它们位于基因组中特别活跃的区域，这可能是花的颜色模式和传粉系统显著多样性的关键。高质量的基因组序列将提高矮种矮花作为研究小rna、共生、自交不亲和性和昼夜节律等独特生物现象的模型系统的价值。</p>
<p>矮牵牛（<em>Petunia hybrida</em>）属于茄科（Solanaceae），是一种流行的花坛植物，长期作为一个遗传模式系统。本论文报道了矮牵牛的两个野生亲本的基因组，<em>P. axillaris</em> N 和 <em>P. inflata</em> S6。The assemblies include 91.3% and 90.2% coverage of their diploid genomes (1.4 Gb; 2n = 14) containing 32,928 and 36,697 protein-coding genes, respectively. 组装的基因组矮牵牛的基因组大小大约是1.4Gb，14对染色体。报道的两个基因组分别注释到32928和36697个编码蛋白基因。</p>
<p><em>P. axillaris</em> N 基因组的组装利用了137 X的二代测序（Illumina）数据和 21 X三代测序（PacBio）技术数据，<em>P. inflata</em> S6 基因组的组装利用了 135 X 的二代测序数据，测序深度都不低。相信矮牵牛基因组的发布会推动自交不亲和、花色等方面的研究。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>petunia</tag>
      </tags>
  </entry>
  <entry>
    <title>HiFi-3-assemble-software</title>
    <url>/blog/2022/03/02/2022-03-02-HiFi-3-software/</url>
    <content><![CDATA[<p>Hifiasm is a <font color="blue"><strong>fast haplotype-resolved de novo assembler</strong></font> for <font color="blue"><strong>PacBio HiFi reads(High Fidelity,high accuracy consensus reads)</strong></font>. HiCanu, Hifiasm, BUSCO, Peregrine, minimap2</p>
<span id="more"></span>



<h1 id="HiFi-快-准-狠"><a href="#HiFi-快-准-狠" class="headerlink" title="HiFi 快 准 狠"></a><a href="https://zhuanlan.zhihu.com/p/138395531">HiFi 快 准 狠</a></h1><h2 id="组装快"><a href="#组装快" class="headerlink" title="组装快"></a>组装快</h2><p>CLR或Nanopore长Reads测序准确性较低，进行组装时需要利用高准确性Illumina短Reads纠错。而HiFi Reads本身即高准确性长Reads，可直接拼接，因此大大节省运算资源和时间。第一篇利用HiFi进行人基因组组装的报道表明，<font color="red"><strong>HiFi Reads组装速度比CLR Reads快10–100倍</strong></font> <a href="https://pubmed.ncbi.nlm.nih.gov/31406327/">[1]</a>。另一项同时利用HiFi 和CLR 对人基因组组装的比较中，HiFi 组装仅花费约2,800个CPU时，而CLR 组装花费超过50,000个CPU时，利用Nanopore Reads进行组装更是花费约151,000个CPU时 <a href="https://pubmed.ncbi.nlm.nih.gov/31711268/">[2]</a>。27 Gb六倍体加州红杉超大基因组，利用HiFi Reads两周就完成组装。</p>
<h2 id="组装准"><a href="#组装准" class="headerlink" title="组装准"></a>组装准</h2><h3 id="1-连续性与CLR和Nanopore相当"><a href="#1-连续性与CLR和Nanopore相当" class="headerlink" title="1 连续性与CLR和Nanopore相当"></a>1 连续性与CLR和Nanopore相当</h3><p>虽HiFi Reads在<font color="red"><strong>读长打折扣</strong></font>，但在<font color="red"><strong>连续性方面毫不逊色</strong></font>于PacBio CLR和Nanopore Reads。同时利用HiFi 和CLR 对人基因组组装的比较中，<font color="red"><strong>HiFi 和CLR 组装的Contigs N50相当</strong></font>（25.52 Mb和29.26 Mb）。一般认为<font color="red">Nanopore ultra-long</font>在基因组组装<font color="red"><strong>连续性更具优势</strong></font>，但同时利用HiFi 和Nanopore 进行水稻组装的报道中，三个组装软件中两个的组装结果都显示<font color="red"><strong>HiFi 组装Contigs N50高于Nanopore Reads</strong></font> <a href="https://pubmed.ncbi.nlm.nih.gov/33319909/">[3]</a>。</p>
<h3 id="2-组装质量显著提升"><a href="#2-组装质量显著提升" class="headerlink" title="2 组装质量显著提升"></a>2 组装质量显著提升</h3><p>由于HiFi 与Illunima短Reads具有相当的碱基准确性，因此在组装上具有CLR和Nanopore无法比拟的优势。利用HiFi 对人基因组组装结果表明，<font color="red"><strong>HiFi 组装质量比CLR高6倍，比经Illumina校正的Nanopore高77倍</strong></font> <a href="https://pubmed.ncbi.nlm.nih.gov/31406327/">[1]</a>。</p>
<p>值得一提，利用HiFi 和Nanopore 进行水稻组装文章表明，<font color="red"><strong>对于高重复区域利用高质量Illumina对Nanopore长Reads纠错效果一般</strong></font>。原因在于Illumina<font color="blue">短Reads在重复区域很难准确比对</font>，导致<strong>覆盖深度有限</strong>，因而<strong>无法起到准确纠错的作用</strong>。而HiFi 兼具长读长和高准确性双重优势，对<font color="red"><strong>重复区域</strong>仍然能够获得<strong>较高</strong>的组装<strong>质量</strong></font>。</p>
<h3 id="3-对重复区域和着丝粒区域具有较高的分辨率"><a href="#3-对重复区域和着丝粒区域具有较高的分辨率" class="headerlink" title="3 对重复区域和着丝粒区域具有较高的分辨率"></a>3 对重复区域和着丝粒区域具有较高的分辨率</h3><p>除了整个基因组的连续性和准确性，HiFi 在<font color="red"><strong>重复区域</strong>和<strong>着丝粒区域</strong></font>的组装也表现不俗。对人基因组的组装表现上，HiFi 组装对<font color="red"><strong>散在重复</strong>的<strong>分辨率为43%</strong></font>，<font color="red"><strong>高于</strong> CLR和已有的Nanopore版本</font>。对于<font color="red"><strong>数百拷贝的串联重复</strong></font>，HiFi 组装<font color="red">比CLR具有<strong>更高</strong>的<strong>分辨率</strong>和<strong>准确性</strong></font>。而专门针对HiFi Reads组装优化的<font color="blue"><strong>HiCanu</strong></font>在<font color="blue"><strong>重复序列和着丝粒组装</strong></font>方面更有良好表现。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/9.png" alt="img"></p>
<p>HiFi和CLR对<strong>串联重复区域组装</strong>结果的比较 <a href="https://pubmed.ncbi.nlm.nih.gov/31711268/">[2]</a></p>
<p><strong>variable number of tandem repeats (VNTRs)</strong></p>
<blockquote>
<p>b) Dot plot of a <strong>6.7 kbp VNTR</strong> in the <strong>intron</strong> of <em>RTEL1</em> (chr20:63693361–63693833) (top panel), <strong>which was resolved in the HiFi assembly only</strong>. The <strong>CLR assembly</strong> contained a <strong>gap</strong> over this region. The overall structure and length of this VNTR was <strong>supported by the ONT reads</strong> mapping to this location, which averaged 5,956 +/− 1799 bp (n = 5 ultra-long ONT reads), placing the HiFi sequence length at &lt;1 standard deviation away from the average ONT read. The motif homology plot (bottom panel) indicates that the content of the <em>RTEL1</em> VNTR is relatively pure, with an average sequence identity to the 15-mer repeat unit of 94.49% across the 439 copies.</p>
</blockquote>
<blockquote>
<p>c)Dot plot of the <strong>zinc finger protein gene <em>ZNF717</em></strong> (GRCh38 coordinates: chr3:75777127–75780446) (top panel), which was <strong>collapsed in the CLR</strong> assembly but <strong>fully represented in the HiFi assembly</strong>. The number of copies of this <strong>35 bp repeat unit</strong> increased from <strong>15 in the CLR</strong> assembly to <strong>89 in the HiFi</strong> assembly. The large amount of variation between individual copies of this VNTR is shown in the region between the <strong>red lines</strong> in the motif homology plots (bottom panels). The <strong>level of purity within the VNTR increased</strong> from 80.38% sequence identity in the CLR assembly to 90.75% sequence identity in the HiFi assembly. The red vertical lines indicate the start and end position of the VNTR.</p>
</blockquote>
<h2 id="狠"><a href="#狠" class="headerlink" title="狠"></a>狠</h2><h3 id="1-简单复杂基因组通吃"><a href="#1-简单复杂基因组通吃" class="headerlink" title="1 简单复杂基因组通吃"></a><strong>1 简单复杂基因组通吃</strong></h3><p>PacBio官方，除了已报道的<strong>人、水稻、果蝇和跗库蚊</strong>，目前HiFi 组装已经在<strong>人、大麻、燕麦、四倍体月季和六倍体加州红杉</strong>等物种中应用。即便是<strong>大麻、燕麦、月季、加州红杉</strong>这些<strong>复杂</strong>基因组，HiFi 组装不俗。11 Gb燕麦的Contig N50高达<strong>20 Mb</strong>！高重复高杂合的多倍体裸子植物的加州红杉超大基因组，HiFi 的Contig N50也达到1.92 Mb，远高于已报道其他裸子植物基因组。</p>
<h3 id="2-高质量单倍型基因组组装"><a href="#2-高质量单倍型基因组组装" class="headerlink" title="2 高质量单倍型基因组组装"></a><strong>2 高质量单倍型基因组组装</strong></h3><p>组装<strong>多倍体</strong>时，组装软件必须能<strong>区分不同的等位基因</strong>，并<strong>保存为不同的序列</strong>。用HiCanu对人基因组的HiFi Reads组装结果包含<strong>超过2 Gb的替代Contig</strong>，而<strong>其它软件</strong>只能产生<strong>不到400 Mb</strong>的<strong>替代Contig</strong>。说明HiCanu结合HiFi Reads具有更强的<strong>区分单倍型的能力</strong>。并且，HiCanu组装的<font color="blue">主要Contig</font>和<font color="blue">替代Contig</font>都具有较高的<font color="red">BUSCO完整性</font>（&gt; <strong>94％</strong>和&gt; 75％），远<strong>高</strong>于<strong>Nanopore ultra-long Reads</strong>组装的BUSCO完整性（分别只有**63%<strong>和</strong>0.3%**）。</p>
<h1 id="hifiasm-Official-doc"><a href="#hifiasm-Official-doc" class="headerlink" title="hifiasm Official doc"></a><a href="https://github.com/chhylp123/hifiasm">hifiasm Official doc</a></h1><p><strong>install</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install hifiasm (requiring g++ and zlib)</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/chhylp123/hifiasm</span><br><span class="line"><span class="comment">#download zipfile unzip</span></span><br><span class="line"><span class="built_in">cd</span> hifiasm &amp;&amp; make</span><br></pre></td></tr></table></figure>

<p><strong>simple use</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Run on test data (use -f0 for small datasets)?</span></span><br><span class="line">wget https://github.com/chhylp123/hifiasm/releases/download/v0.7/chr11-2M.fa.gz</span><br><span class="line">./hifiasm -o <span class="built_in">test</span> -t4 -f0 chr11-2M.fa.gz 2&gt; test.log</span><br><span class="line">【awk <span class="string">&#x27;/^S/&#123;print &quot;&gt;&quot;$2;print $3&#125;&#x27;</span> test.bp.p_ctg.gfa &gt; test.p_ctg.fa】  <span class="comment"># get primary contigs in FASTA</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Assemble inbred/homozygous genomes (-l0 disables duplication purging)</span></span><br><span class="line"><span class="comment">#?</span></span><br><span class="line">hifiasm -o CHM13.asm -t32 -l0 CHM13-HiFi.fa.gz 2&gt; CHM13.asm.log</span><br><span class="line"><span class="comment"># Assemble heterozygous genomes with built-in duplication purging</span></span><br><span class="line"><span class="comment">#?</span></span><br><span class="line">hifiasm -o HG002.asm -t32 HG002-file1.fq.gz HG002-file2.fq.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hi-C phasing with paired-end short reads in two FASTQ files</span></span><br><span class="line"><span class="comment">#add Hi-C data</span></span><br><span class="line">hifiasm -o HG002.asm --h1 read1.fq.gz --h2 read2.fq.gz HG002-HiFi.fq.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trio binning assembly (requiring https://github.com/lh3/yak)</span></span><br><span class="line"><span class="comment">#combine parent sequencing data</span></span><br><span class="line">yak count -b37 -t16 -o pat.yak &lt;(cat pat_1.fq.gz pat_2.fq.gz) &lt;(cat pat_1.fq.gz pat_2.fq.gz)</span><br><span class="line">yak count -b37 -t16 -o mat.yak &lt;(cat mat_1.fq.gz mat_2.fq.gz) &lt;(cat mat_1.fq.gz mat_2.fq.gz)</span><br><span class="line">hifiasm -o HG002.asm -t32 -1 pat.yak -2 mat.yak HG002-HiFi.fa.gz</span><br></pre></td></tr></table></figure>

<h2 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h2><p>Hifiasm is a <font color="blue"><strong>fast haplotype-resolved de novo assembler</strong></font> for <font color="blue"><strong>PacBio HiFi reads</strong></font>. It can <strong>assemble a human genome in several hours</strong> and assemble a <strong>~30Gb</strong> California redwood genome in <strong>a few days</strong>. Hifiasm emits <font color="red"><strong>partially phased assemblies</strong></font> of quality competitive with the best assemblers. Given <font color="green"><strong>parental short reads</strong></font> or <font color="green"><strong>Hi-C data</strong></font>, it produces arguably <font color="red"><strong>the best haplotype-resolved assemblies</strong></font> so far.</p>
<h2 id="Why-Hifiasm"><a href="#Why-Hifiasm" class="headerlink" title="Why Hifiasm?"></a>Why Hifiasm?</h2><ul>
<li>Hifiasm delivers high-quality assemblies. It tends to generate <font color="blue">longer contigs</font> and resolve <font color="blue">more segmental duplications</font> than other assemblers.</li>
<li>Given <font color="blue">Hi-C reads</font> or <font color="blue">short reads from the parents</font>, hifiasm can produce overall <font color="blue"><strong>the best haplotype-resolved assembly</strong></font> so far. It is the assembler of choice by the <a href="https://humanpangenome.org/">Human Pangenome Project</a> for the first batch of samples.</li>
<li>Hifiasm can <font color="blue">purge duplications?</font> between haplotigs without relying on third-party tools such as purge_dups. Hifiasm does <font color="blue">not need polishing tools?</font> like pilon or racon, either. This simplifies the assembly pipeline and saves running time.</li>
<li>Hifiasm is <font color="blue">fast</font>. It can assemble a human genome in half a day and assemble a ~30Gb redwood genome in three days. <font color="blue">No genome is too large for hifiasm</font>.</li>
<li>Hifiasm is trivial to install and easy to use. It does not required Python, R or C++11 compilers, and can be compiled into a single executable. The default setting works well with a variety of genomes.</li>
</ul>
<h1 id="hifiasm-paper"><a href="#hifiasm-paper" class="headerlink" title="hifiasm paper"></a>hifiasm paper</h1><p>ref：<a href="https://www.jianshu.com/p/6d79690dce5d">https://www.jianshu.com/p/6d79690dce5d</a></p>
<p><a href="https://hifiasm.readthedocs.io/en/latest/index.html">https://hifiasm.readthedocs.io/en/latest/index.html</a></p>
<p><a href="https://links.jianshu.com/go?to=https://github.com/chhylp123/hifiasm">https://github.com/chhylp123/hifiasm</a></p>
<p><a href="https://links.jianshu.com/go?to=https://www.nature.com/articles/s41592-020-01056-5">https://www.nature.com/articles/s41592-020-01056-5</a></p>
<h2 id="原理介绍1"><a href="#原理介绍1" class="headerlink" title="原理介绍1"></a>原理介绍1</h2><p>hifiasm有效利用PacBio HiFi测序技术，在<font color="red"><strong>分型组装图(pahsed assembly gprah)</strong></font>中可靠的表示单倍体信息。</p>
<p><strong>第一阶段</strong>：通过所有序列相互比对，对潜在测序错误纠正。如果<font color="red">一个位置只存在两种碱基类型</font>，且每个碱基类型<font color="red">至少有3条read支持</font>，那么这个位置会被当作<font color="red">杂合位点</font>，否则视作测序错误纠正。</p>
<p><strong>第二阶段</strong>：根据<font color="red">序列之间重叠关系</font>，构建<font color="red">分型的字符串图(phased string graph)</font>。其中调整朝向的序列作为<font color="red">顶点(vertex)</font>，一致重叠作为<font color="red">边(edge)</font>。字符串图中的<font color="red">气泡(bubble)</font>则是<font color="red">杂合位点</font>。</p>
<p><strong>第三阶段</strong>：如果没有额外的信息，hifiasm会<font color="red">随机选择气泡一边</font>构建primary assembly，另一边则是alternate assembly. 该策略和HiCanu，Falcon-Unzip一样。对于杂合基因组而言，由于存在一个以上的纯合haplotype，因此<font color="red">primary assembly可能还会包含haplotigs</font>。HiCanu依赖第三方的purge_dups, 而hifiasm内部实现purge_dups算法的变种，简化了流程。如果有<font color="red">额外信息</font>，hifiasm可正确的对<font color="red">haplotype进行分型</font>。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/1.png" alt="img"></p>
<h2 id="hifiasm-原理介绍2"><a href="#hifiasm-原理介绍2" class="headerlink" title="hifiasm 原理介绍2"></a>hifiasm 原理介绍2</h2><p><strong>可识别单倍型的纠错</strong></p>
<p>Hifiasm将所有hifi reads读取到内存中进行<font color="red"><strong>all-vs-all比对并纠错</strong></font>。基于reads间overlap信息，如果read上有一个碱基与其他碱基不同，并有<font color="red"><strong>至少3条reads支持</strong></font>，则认为它是<font color="red"><strong>SNP</strong></font>并保留，<strong>否则</strong>认为是错误并<strong>纠正</strong>。</p>
<p><strong>组装图的构建</strong></p>
<p>在校正之后，大多数错误被去除，同时<font color="red"><strong>杂合变异信息被保留</strong></font>。基于这些信息，Hifiasm构建了<font color="red"><strong>以reads为顶点、重叠区为边的定相string-graph</strong></font>。</p>
<p><strong>组装序列的生成</strong></p>
<ul>
<li><p>如果<font color="red">没有其他数据</font>，Hifiasm在输出序列时会<font color="red"><strong>任意选择</strong>每个气泡<strong>bubble</strong>的<strong>一侧输出</strong>类似<strong>Falcon unzip</strong>和<strong>HiCanu</strong>的主要组装结果</font>（primary contigs）。</p>
</li>
<li><p>如果同时有<font color="red">父母本的测序数据</font>，Hifiasm可以通过<font color="red">亲本特有的kmer</font>在图上<font color="red">识别来自父母本的序列</font>，得到<font color="red"><strong>两套单倍体</strong>基因组</font>。</p>
</li>
<li><p>当然HiFiasm文章中也提到：</p>
<p>与其他基于图形的汇编程序不同，HiFiasm致力于<strong>保持所有单倍型的连续性。</strong><br><font color="red"><strong>HiCanu</strong>只试图<strong>保持一个亲本单倍型</strong>的<strong>连续性</strong></font>，并且经常<font color="red">破坏另一个单倍型的连续性</font>，当分离亲本单倍型时，这些突变点将导致单倍型分解的碎片—HiCanu<font color="red">没有充分利用HiFi Reads</font><br>Hifiasm针对HiFi特点开发，在hifi数据的组装表现上较同类软件更为突出，在多个基因组上表现出了更高的<strong>准确性</strong>和组装的<strong>连续性</strong>。</p>
</li>
</ul>
<h2 id="仅HiFi数据模式"><a href="#仅HiFi数据模式" class="headerlink" title="仅HiFi数据模式"></a>仅HiFi数据模式</h2><p>最基本的用法，会得到两个部分分型的组装</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">wget https://github.com/chhylp123/hifiasm/releases/download/v0.7/chr11-2M.fa.gz</span><br><span class="line">hifiasm -o <span class="built_in">test</span> -t 32 chr11-2M.fa.gz 2&gt; test.log</span><br><span class="line"><span class="comment">#-o输出文件前缀 -t线程</span></span><br></pre></td></tr></table></figure>

<p>结果文件关注如下几项 (prefix为前缀）</p>
<ul>
<li><code>prefix.bp.r_utg.gfa</code>: haplotype-resolved raw unitig graph，记录所有的单倍型信息</li>
<li><code>prefix.bp.p_utg.gfa</code>: 在raw unitig graph基础上过滤小的bubble，</li>
<li><code>prefix.bp.p_ctg.gfa</code>: 主要contig的assembly graph</li>
<li><code>prefix.bp.hap1.p_ctg.gfa</code>: haplotype1的部分分型的contig graph</li>
<li><code>prefix.bp.hap2.p_ctg.gfa</code>: haplotype2的部分分型的contig graph</li>
</ul>
<p>如果并不需要部分分型的组装，只要primary和alternate的组装结果，可以在之前命令的基础上，加上 <code>--primary</code>参数。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hifiasm --primary -o <span class="built_in">test</span> -t 32 chr11-2M.fa.gz 2&gt; test.log2</span><br></pre></td></tr></table></figure>

<p>由于hifiasm运行时会将步骤中纠错和相互比对的结果保存成 bin 文件，因此rerun速度很快(前缀名差异)。</p>
<p>primay模式下输出的文件和之前的类似，唯一的不同在于没有 <strong>bp</strong></p>
<p>prefix<code>.r_utg.gfa</code>: haplotype-resolved raw unitig graph: 保留了组装生成的所有单体型信息，包括体细胞突变和重复的测序错误。</p>
<p>prefix<code>.p_utg.gfa</code>: haplotype-resolved processed unitig graph without small bubbles：无小气泡的单倍型解析；去掉由于体细胞突变和数据背景噪音引起的small bubbles（这个并不是真正的单体型信息），对于高度杂合基因组物种优先选择这个结果。</p>
<p>prefix<code>.p_ctg.gfa</code>: assembly graph of primary contigs：对于低杂合度物种来说，优先选择该文件；对于高杂合度物种，该结果代表其中一个单倍型。</p>
<p>prefix<code>.a_ctg.gfa</code>: assembly graph of alternate contigs：组装出来的另一套单体型基因组结果。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#contig，通过awk提取</span></span><br><span class="line">awk <span class="string">&#x27;/^S/&#123;print &quot;&gt;&quot;$2;print $3&#125;&#x27;</span> test.p_ctg.gfa &gt; test.p_ctg.fa</span><br></pre></td></tr></table></figure>

<h2 id="双亲二代测序Trio-binning模式"><a href="#双亲二代测序Trio-binning模式" class="headerlink" title="双亲二代测序Trio-binning模式"></a>双亲二代测序Trio-binning模式</h2><p>如果有双亲数据，则可使用trio-binning方法进行更可靠的分型。分为两步，<font color="red"><strong>先用yak统计k-mers， 然后用hifiasm进行组装</strong></font></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yak count -k31 -b37 -t16 -o pat.yak paternal.fq.gz</span><br><span class="line">yak count -k31 -b37 -t16 -o mat.yak maternal.fq.gz</span><br><span class="line">hifiasm -o NA12878.asm -t 32 -1 pat.yak -2 mat.yak NA12878.fq.gz</span><br></pre></td></tr></table></figure>

<p>输出和之前类似，主要关注文件名<font color="red">带 dip 的输出gfa文件</font></p>
<ul>
<li><strong>prefix.r_utg.gfa</strong>(Haplotype-resolved raw unitig graph in GFA format):保存了所有的单倍型信息。</li>
</ul>
<ul>
<li><code>prefix.dip.hap1.p_ctg.gfa</code>: 完成分型的<font color="red"><strong>父源单倍体 contig图</strong></font>。(Phased paternal/haplotype1 contig graph):保留了阶段性父系/单倍型1组装。</li>
<li><code>prefix.dip.hap2.p_ctg.gfa</code>: 完全分型的<font color="red"><strong>母源单倍体contig图</strong></font>。(Phased maternal/haplotype2 contig graph):保留了阶段性母系/单倍型2组装。</li>
</ul>
<h2 id="附加Hi-C模式"><a href="#附加Hi-C模式" class="headerlink" title="附加Hi-C模式"></a>附加Hi-C模式</h2><p>由于Hi-C数据能够提供<strong>远距信息</strong>，因此也能<strong>用于单倍体分型</strong>。需要加两个参数， h1为Hi-C的read1, h2 为Hi-C的read2</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hifiasm -o NA12878.asm -t 32 --h1 read1.fq.gz --h2 read2.fq.gz HiFi-reads.fq.gz</span><br></pre></td></tr></table></figure>

<p>在该模式下，每个contig要么是来自于父亲，要么是来自于母亲。hifiasm将<font color="red">同一来源的contig放在同一个组装中</font>。需要注意的是，hifiasm未必能够处理好<font color="red">着丝粒附近区域</font>，另外<font color="red">hifiasm中Hi-C也不会用于进行scaffold</font>。</p>
<p>输出结果重点关注带hic的文件</p>
<ul>
<li><code>prefix.hic.p_ctg.gfa</code>: 主要contig的组装图</li>
<li><code>prefix.hic.hap1.p_ctg.gfa</code>: 完全分型的haplotype1的contig图</li>
<li><code>prefix.hic.hap2.p_ctg.gfa</code>: 完全分型的haplotype2的contig图</li>
<li><code>prefix.hic.a_ctg.gfa</code> : 如果设置了 <code>--primary</code>参数，还会输出该次要contig的组装图</li>
</ul>
<h2 id="日志和参数调整"><a href="#日志和参数调整" class="headerlink" title="日志和参数调整"></a>日志和参数调整</h2><p>绝大部分的时候，只需要使用默认参数即可得到相对比较好的结果。但是当默认参数无法达到目的，就需要检查日志信息，阅读相关参数从而优化结果。</p>
<p>日志信息主要分三项</p>
<ul>
<li><font color="red">k-mer图</font>: 纯合样本一个peak，杂合样本2个peak。</li>
<li><font color="red">纯合峰的覆盖度</font>: <code>[M::purge_dups] homozygous read coverage threshold: X</code> , 一般会由hifiasm自动推断。</li>
<li><font color="red">杂合/纯合碱基数目（Hi-C模式）</font>: Hi-C模式下，如果纯合的碱基数超过杂合碱基数，那么hifiasm就不容易找对纯合read的所在峰。</li>
</ul>
<p>对于日志信息，最主要关注<font color="red">k-mer图</font>，从而判断hifiasm是否能够正确的找到纯合峰，杂合峰所在位置。如果hifiasm没有找对纯合峰所在的位置，就需要<font color="red">根据k-mer图手动指定?</font> <code>--hom-cov</code>。</p>
<p>对于一个组装结果，最直接的<strong>评估标准</strong>就是<font color="red">基因组大小是否符合预期</font>，分型的<font color="red">两套基因组是否相差不大</font>，序列<strong>是否足够长</strong>，<strong>是否存在错误组装</strong>的情况。</p>
<p>如果基因组<font color="red"><strong>大小不符合预期</strong></font>，一般都是hifiasm<strong>找错纯合峰的位置</strong>，需要手动指定 <code>--hom-cov</code>；</p>
<p>如果分型的两套基因组<font color="red"><strong>差别过大</strong></font>，则通过降低 <code>-s</code> 调整。</p>
<p>如果<font color="red"><strong>序列不够长，片段化明显</strong></font>，则可尝试<font color="red">增加</font>  <code>-D</code> 和  <code>-N</code>, 虽增加运行时间，但会<font color="red">提高重复区域的分辨率</font>。</p>
<p>如果后续的Hi-C，或者BioNano发现hifiasm组装结果<font color="red"><strong>有比较多错误组装</strong></font>，则可以适当降低 <code>--purge-max</code>, <code>-s</code>和 <code>-O</code>。或者设置 <code>-u</code> 关闭post-join 步骤，hifiasm通过该步骤提高组装的连续性。</p>
<h2 id="输入格式-fq还是fa"><a href="#输入格式-fq还是fa" class="headerlink" title="输入格式 fq还是fa"></a>输入格式 fq还是fa</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># bam --&gt; fasta</span><br><span class="line">samtools view *.bam | awk &#x27;&#123;print &quot;&gt;&quot;$1&quot;\n&quot;$10&#125;&#x27; &gt; fasta</span><br><span class="line"># bam2fastq</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="HiCanu-https-canu-readthedocs-io-en-latest-index-html"><a href="#HiCanu-https-canu-readthedocs-io-en-latest-index-html" class="headerlink" title="HiCanu[https://canu.readthedocs.io/en/latest/index.html]"></a>HiCanu[<a href="https://canu.readthedocs.io/en/latest/index.html]">https://canu.readthedocs.io/en/latest/index.html]</a></h1><hr>
<p>ref <a href="https://www.jianshu.com/p/c1aeeae77cb5">https://www.jianshu.com/p/c1aeeae77cb5</a></p>
<p>Canu分三个步骤，<font color="red"><strong>纠错</strong></font>，<font color="red"><strong>修整</strong></font>和<font color="red"><strong>组装</strong></font>，每一步<font color="red">步骤<strong>相似</strong></font>：</p>
<ul>
<li>加载read到read数据库，gkpStore</li>
<li>对k-mer进行记数，用于计算序列间的overlap</li>
<li>计算overlap</li>
<li>加载overlap到overlap数据库，OvlStore</li>
<li>根据read和overlap完成特定分析目标<ul>
<li>read<font color="blue"><strong>纠错</strong></font>时会从overlap中挑选一致性序列替换原始的噪声read</li>
<li>read<font color="blue"><strong>修整</strong></font>时会使用overlap确定read哪些区域是高质量区域，哪些区域质量较低需要修整。最后保留单个最高质量的序列块</li>
<li>序列<font color="blue"><strong>组装</strong></font>时根据一致的overlap对序列进行编排(layout), 最后得到contig</li>
</ul>
</li>
</ul>
<p>三步<font color="blue">可分开</font>运行，既可用<font color="blue">Canu纠错后结果</font>作为<font color="blue">其他组装软件输入</font>，也可将其他软件的纠错结果作为Canu的输入。</p>
<p><font color="red">几个<strong>全局参数</strong></font>：</p>
<ul>
<li><font color="red"><strong>genomeSize</strong></font>设置预估基因组大小，用于Canu<font color="blue">估计测序<strong>深度</strong></font>, The genome size should be your best guess of the haploid genome size of what is being assembled, It is used primarily to estimate coverage in reads, NOT as the desired assembly size.</li>
<li><font color="red">maxThreads</font>设置最大<font color="blue">线程</font></li>
<li><font color="red">rawErrorRate</font>设置<font color="blue">两个<strong>未纠错read之间</strong>最大<strong>期望差异碱基数</strong></font></li>
<li><font color="red">correctedErrorRate</font>设置<font color="blue"><strong>纠错后</strong>read之间最大<strong>期望差异碱基数</strong>，<strong>组装</strong>步骤<strong>多次调整</strong></font></li>
<li><font color="red">minReadLength</font>表示<font color="blue">只使用大于阈值的序列</font></li>
<li><font color="red">minOverlapLength</font>表示<font color="blue">Overlap最小长度</font></li>
<li>提高minReadLength可<strong>提</strong>高运行<strong>速</strong>度，增加minOverlapLength可<strong>降</strong>低<strong>假阳性overlap</strong></li>
</ul>
<p><font color="blue">测试数据</font> “<a href="https://links.jianshu.com/go?to=https://www.nature.com/articles/s41467-018-03016-2">High contiguity Arabidopsis thaliana genome assembly with a single nanopore flow cell</a>“。 提供 <em>Arabidopsis thaliana</em> KBS-Mac-74 的30X短片段文库二代测序、PacBio和Nanopore的三代测序以及Bionano测序数据, 拟南芥基因组被认为是植物金标准，数据适合练习。项目编号”PRJEB21270”, 在European Nucleotide Archive上找到下载地址。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## PacBio Sequal</span><br><span class="line">wget -c -q ftp://ftp.sra.ebi.ac.uk/vol1/ERA111/ERA1116568/bam/pb.bam</span><br><span class="line">## MinION</span><br><span class="line">wget -c -q ftp://ftp.sra.ebi.ac.uk/vol1/ERA111/ERA1116595/fastq/ont.fq.gz</span><br><span class="line"># Illuminia MiSeq</span><br><span class="line">wget -c -q ftp://ftp.sra.ebi.ac.uk/vol1/ERA111/ERA1116569/fastq/il_1.fq.gz</span><br><span class="line">wget -c -q ftp://ftp.sra.ebi.ac.uk/vol1/ERA111/ERA1116569/fastq/il_2.fq.gz</span><br></pre></td></tr></table></figure>

<p><font color="blue">PacBio数据以BAM格式存储</font>，通过安装PacBio的smrtlink工具套装，使用其中<font color="blue">bam2fasta</font>转换</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;build index for convert&#x27;</span></span><br><span class="line">~/opt/biosoft/smrtlink/smrtcmds/bin/pbindex pb.bam &amp;</span><br><span class="line"><span class="comment"># convert bam to fasta</span></span><br><span class="line">~/opt/biosoft/smrtlink/smrtcmds/bin/bam2fasta -o pb pb.bam &amp;</span><br></pre></td></tr></table></figure>

<p>PacBio的smrtlink工具套装大小1.4G，下载速度慢，安装手动确认各种选项, 好处是工具全。</p>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p>latest: <a href="https://github.com/marbl/canu/releases/tag/v2.2">https://github.com/marbl/canu/releases/tag/v2.2</a></p>
<h2 id="Run-Canu"><a href="#Run-Canu" class="headerlink" title="Run Canu"></a>Run Canu</h2><p><strong>第一步</strong>：<font color="red"><strong>纠错</strong></font>。三代测序错误率高，原始数据充满噪音。通过<strong>序列</strong>间<strong>相互比较纠错得到高可信度的碱基</strong>。<font color="blue">主要<strong>调整两个参数</strong></font></p>
<ul>
<li><font color="blue">corOutCoverage</font>: 控制<strong>多少数据</strong>用于纠错。如拟南芥120M基因组，100X测序12G数据，如果只用最长6G数据纠错，参数设置为50(120m x 50)。<strong>设置大于测序深度的值</strong>如120表示<strong>使用所有数据</strong>。<font color="green"><strong>-pacbio-raw</strong></font></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">canu -correct \</span><br><span class="line">    -p ath -d pb_ath \</span><br><span class="line">    Threads=10 gnuplotTested=<span class="literal">true</span>\</span><br><span class="line">    genomeSize=120m minReadLength=2000 minOverlapLength=500\</span><br><span class="line">    corOutCoverage=120 corMinCoverage=2 \</span><br><span class="line">    -pacbio-raw pb.fasta.gz</span><br></pre></td></tr></table></figure>

<p>注: 有些服务器<strong>没有安装gnuplot</strong>, <strong>gnuplotTested=true</strong> 跳过检查。</p>
<p><strong>第二步</strong>：<font color="red"><strong>修整</strong></font>。为获取更高质量的序列，<font color="blue">移除可疑区域</font>（如残留的SMRTbell接头)。<font color="green"><strong>-pacbio-corrected</strong></font></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">canu -trim \</span><br><span class="line">        -p ath -d pb_ath</span><br><span class="line">        maxThreads=20 gnuplotTested=<span class="literal">true</span>\</span><br><span class="line">        genomeSize=120m minReadLength=2000 minOverlapLength=500\</span><br><span class="line">        -pacbio-corrected ath/pb_ath.correctedReads.fasta.gz</span><br></pre></td></tr></table></figure>

<p><strong>第三步</strong>: <font color="red"><strong>组装</strong></font>。前两步获得高质量序列后正式组装。 主要调整参数是<font color="red">纠错后的<strong>序列错误率 correctedErrorRate</strong></font>，它会影响utgOvlErrorRate。可尝试多个参数，因为速度较块。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># error rate 0.035</span></span><br><span class="line">canu -assemble \</span><br><span class="line">    -p ath -d ath-erate-0.035 \</span><br><span class="line">    maxThreads=20 gnuplotTested=<span class="literal">true</span> \</span><br><span class="line">    genomeSize=120m\</span><br><span class="line">    correctedErrorRate=0.035 \</span><br><span class="line">    -pacbio-corrected atg/pb_ath.trimmedReads.fasta.gz</span><br><span class="line"><span class="comment"># error rate 0.050</span></span><br><span class="line">canu -assemble \</span><br><span class="line">    -p ath -d ath-erate-0.050 \</span><br><span class="line">    maxThreads=20 gnuplotTested=<span class="literal">true</span> \</span><br><span class="line">    genomeSize=120m\</span><br><span class="line">    correctedErrorRate=0.050 \</span><br><span class="line">    -pacbio-corrected atg/pb_ath.trimmedReads.fasta.gz</span><br></pre></td></tr></table></figure>

<p>输出文件<font color="red"><strong>ath.contigs.fasta</strong></font>结果文件。</p>
<h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#qsub: submit error (No default queue specified MSG=requested queue not found)</span></span><br><span class="line"><span class="comment">#invalid useGrid (1) and gridEngine (PBS); found no execution hosts - is grid available from this host?.</span></span><br></pre></td></tr></table></figure>

<p>issue: <a href="https://github.com/marbl/canu/issues/1040">https://github.com/marbl/canu/issues/1040</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">advice : Canu uses the <span class="string">&quot;PBS command pbsnodes&quot;</span> to poll your available resources. On your compute nodes this is not working. See the FAQ: http://canu.readthedocs.io/en/latest/faq.html<span class="comment">#my-run-stopped-with-the-error-failed-to-submit-batch-jobs</span></span><br><span class="line">If your nodes <span class="string">&#x27;cannot access/submit&#x27;</span> to the <span class="string">&#x27;grid&#x27;</span> <span class="keyword">then</span> Canu <span class="string">&#x27;wont work with your grid system&#x27;</span>. These are grid configuration issues so youll have to check with your sysadmin <span class="keyword">if</span> it can be changed. If not, youll have to run Canu on a single node or use useGrid=remote from the head node <span class="built_in">which</span> will <span class="built_in">print</span> the commands <span class="keyword">for</span> you to manually run (see issue <span class="comment">#822).</span></span><br></pre></td></tr></table></figure>

<p><a href="https://canu.readthedocs.io/en/latest/faq.html#my-run-stopped-with-the-error-failed-to-submit-batch-jobs">canu FAQ</a></p>
<p><strong>How do I run Canu on my SLURM / SGE / PBS / LSF / Torque system?</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Canu will <span class="string">&#x27;detect and configure&#x27;</span> itself to use on most <span class="string">&#x27;grids&#x27;</span>. You <span class="keyword">do</span> not need to submit Canu to the grid <span class="keyword">in</span> this <span class="keyword">case</span>. Canu will query the system <span class="keyword">for</span> <span class="string">&#x27;grid support&#x27;</span>, configure itself <span class="keyword">for</span> the machines <span class="string">&#x27;available in the grid&#x27;</span>, <span class="keyword">then</span> submit itself to the grid <span class="keyword">for</span> execution. You can <span class="keyword">then</span> monitor the run <span class="string">&#x27;using your grid&#x27;</span>.</span><br><span class="line"></span><br><span class="line">Canu will <span class="string">&#x27;NOT request explicit time limits or queues/partitions&#x27;</span>. You can supply your own grid options, such as a partition on SLURM, an account code on SGE, and/or time limits with gridOptions=<span class="string">&quot;&lt;your options list&gt;&quot;</span> <span class="built_in">which</span> will passed to every job submitted by Canu. Similar options exist <span class="keyword">for</span> every stage of Canu, <span class="built_in">which</span> could be used to, <span class="keyword">for</span> example, restrict overlapping to a specific partition or queue.</span><br><span class="line"></span><br><span class="line">【【【<span class="string">&#x27;To disable grid support and run only on the local machine, specify useGrid=false&#x27;</span>】】】</span><br><span class="line"></span><br><span class="line">It is possible to <span class="built_in">limit</span> the number of grid <span class="built_in">jobs</span> running at the same time, but this isn’t directly supported by Canu. The various gridOptions parameters can pass grid-specific parameters to the submit commands used; see Issue <span class="comment">#756 for Slurm and SGE examples.</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#common options:</span></span><br><span class="line">useGrid=string</span><br><span class="line">      - Run under grid control (<span class="literal">true</span>), <span class="string">&#x27;locally (false)&#x27;</span>, or <span class="built_in">set</span> up <span class="keyword">for</span> grid control</span><br><span class="line">        but dont submit any <span class="built_in">jobs</span> (remote)</span><br></pre></td></tr></table></figure>



<h2 id="Advice"><a href="#Advice" class="headerlink" title="Advice"></a>Advice</h2><h3 id="后续分析要去冗余"><a href="#后续分析要去冗余" class="headerlink" title="后续分析要去冗余"></a>后续分析要去冗余</h3><p>Canu2.0之前的contig尽管运行日志说没有bubble，其实是没有检测到。Canu2.0才加上该信息。但作者强烈推荐先用purge_dups去冗余，避免软件难以检测到的冗余序列存在影响后续分析。</p>
<p>作者：旧版Canu没有真正检测到bubble，因此contig包含着buble，建议后续分析用purge_dups 处理这些冗余序列</p>
<p>Canu改动基本上是增加新功能，提高组装准确性，提高组装速度，常规bug修复。</p>
<p>1.8版本更改了Nanopore的错误率，提高10倍左右组装速度，同时完整支持了trio-binning</p>
<p>1.9版开始增加PacBio的HiFi数据，极大提高相互比对速度</p>
<p>这些修改，可以直接将组装得到的contig用于后续分析</p>
<p>而2.0做了许多优化用来保证contig组装更长更准确，其中一个是在contig构建期间会检测bubbles, 防止他们打断杂合基因组</p>
<p>例如组装发现染色体明显偏大，用新Canu组装该物种时候发现，前后两次组装结果在bubbles一栏有明显差别。1.8版本是0，2.0版本是136，约6M基因组大小。</p>
<p>查看之前所有组装物种的日志，发现bubble一栏都是0（即便是杂合基因组）。</p>
<p>意味着，2.0版本装的基因组不能直接用于下游的HiC，而需要先把bubble这部分序列给过滤掉，不然基因组偏离实际值。</p>
<h3 id="高杂合物种组装"><a href="#高杂合物种组装" class="headerlink" title="高杂合物种组装"></a>高杂合物种组装</h3><p>高杂合物种组装，Canu建议是用 <code>batOptions=-dg 3 -db 3 -dr 1 -ca 500 -cp 50</code>参数尽量分出两套单倍型，然后对基因组去冗余。</p>
<p><code>batOptions</code>表示传递后续的参数给组装软件<code>bogart</code>, <code>-dg 3 -db3</code>降低自动确定阈值时的错误率离差(deviation)，从而更好分开单倍型。<code>-dr 1 -ca 500 -cp 50</code>会影响错误组装的拆分，对于一个模棱两可的contig，如果另一条可选路径的overlap长度至少是500bp，或另一条可选路径时在长度上和当前最佳路径存在50%的差异，那么将contig拆分。</p>
<p>关于杂合物种组装的讨论，参考<a href="https://links.jianshu.com/go?to=https://github.com/marbl/canu/issues/201%23issuecomment-233750764">https://github.com/marbl/canu/issues/201#issuecomment-233750764</a></p>
<h3 id="购买SSD避免服务器IO瓶颈"><a href="#购买SSD避免服务器IO瓶颈" class="headerlink" title="购买SSD避免服务器IO瓶颈"></a>购买SSD避免服务器IO瓶颈</h3><p>如果服务器线程数很多，在普通机械硬盘上组装，而且系统还是CentOS，那么需要调整一个参数，避免其中一步的IO严重影响服务器性能。</p>
<p>Canu通过两个策略进行并行，bucketizing (‘ovb’ 任务) 和 sorting (‘ovs’ 任务)。 bucketizing会从1-overlap读取输出的overlap，将他们<strong>复制</strong>一份作为中间文件。sorting一步将这些文件加载到内存中进行排序然后<strong>写出</strong>到硬盘上。 如果你的overlap输出特别多，那么该步骤将会瞬间挤爆的你的IO.</p>
<p>为了避免悲剧发生，请增加如下参数: <code>ovsMemory=16G ovbConcurrency=15 ovsConcurrency=15</code>， 也就是降低这两步同时投递的任务数，缓解IO压力。</p>
<hr>
<h1 id="HiFI组装实例"><a href="#HiFI组装实例" class="headerlink" title="HiFI组装实例"></a>HiFI组装实例</h1><p>Contiguity, Completeness, and Correctness</p>
<h2 id="2018-10"><a href="#2018-10" class="headerlink" title="2018.10"></a>2018.10</h2><p>PacBio公司 高保真 单分子 长读长 测序【HiFi】模式</p>
<h2 id="2019-01"><a href="#2019-01" class="headerlink" title="2019.01"></a>2019.01</h2><p>首篇利用HiFi数据进行人基因组 结构变异检测 和 基因组组装 文章发布</p>
<h2 id="2020-01"><a href="#2020-01" class="headerlink" title="2020.01"></a>2020.01</h2><p>HiFi在 四倍体玫瑰 燕麦 大麻 白蛉 等多个物种基因组组装</p>
<h2 id="2020-03-27Gb六倍体加州红杉"><a href="#2020-03-27Gb六倍体加州红杉" class="headerlink" title="2020.03 27Gb六倍体加州红杉"></a>2020.03 27Gb六倍体加州红杉</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIzNzY3Mw==&mid=2247489444&idx=2&sn=e6e9e4eebac756a0d518ee4a0fa09956&source=41#wechat_redirect">PacBio科学家利用HiFi测序两周内完成基因组高达27Gb的六倍体加州红杉基因组组装</a></p>
<h3 id="初衷"><a href="#初衷" class="headerlink" title="初衷"></a>初衷</h3><p><font color="blue">15Gb六倍体小麦</font>基因组，选择<font color="blue">HiFi还是CLR？</font><font color="blue">11Gb燕麦</font>基因组组装说明<font color="blue">HiFi组装<strong>超大基因组</strong>的能力</font>，<strong>Contig N50</strong>高达<strong>20Mb</strong>！HiFi Reads <font color="blue"><strong>读取长度</strong></font> 和 <font color="blue"><strong>准确性</strong></font> 之间的 <font color="blue"><strong>平衡</strong></font> 是否能克服最艰巨的基因组（大且复杂）挑战？</p>
<h3 id="测序过程"><a href="#测序过程" class="headerlink" title="测序过程"></a>测序过程</h3><p>斯坦福大学校园内采样，DNA提取文库构建。</p>
<p>使用<font color="blue">BluePippin[高分子量DNA核酸片段分离和回收]</font>将DNA片段选择大小设为<strong>15 kb</strong>，更长的插入片段允许HiFi读长达到<strong>50 kb</strong>。 HiFi reads 的准确率分布可以发现所有reads准确率<strong>都在Q20以上</strong>，HiFi reads<strong>最密集</strong>的插入片段在<strong>20k-30k区间</strong>，最长的插入片段达到<strong>50k精度都高于Q20</strong>(99％)，大约有<strong>超过一半的reads</strong>准确率接近或超过<strong>Q30</strong>(99.9%)。</p>
<p><strong>7天连续测序</strong>共获得<strong>606Gb</strong> HiFi数据，相当于<strong>22X</strong>。在之前很多使用HiFi进行组装的项目中发现，只需<strong>20倍</strong>左右的覆盖度就能够产生<strong>出色</strong>的组装结果，且<strong>不需要NGS纠错</strong>。</p>
<h3 id="组装结果"><a href="#组装结果" class="headerlink" title="组装结果"></a>组装结果</h3><p>在获得HiFi数据之后，PacBio负责<strong>超大基因组组装</strong>的资深生信科学家<strong>Greg Concepcion</strong>开始了加州红杉基因组的组装工作。Greg选择的工具是<font color="red">Hifiasm</font>，因为这是目前<font color="blue"><strong>最快</strong>的且<strong>专注于解析单倍型</strong>的组装软件</font>。</p>
<p>Hifiasm软件运行<font color="red">6天</font>后，组装工作顺利完成。具体消耗计算资源如下；</p>
<p>服务器配置：64核512Gb RAM</p>
<p>生成HiFi数据：46,000 CPU hours</p>
<p>基因组组装：7,200 CPU hours，总共分析时间6天</p>
<p>对比2019年Oxford Nanopore + NGS同样组装加州红杉，使用2Tb内存,最终花费5-6个月才完成组装。</p>
<p>Sequencing and assembling mega-genomes of mega-trees: the giant sequoia and coast redwood genomes，<strong>Nanopore Community Meeting 2019</strong>【最大内存使用：2T；error correction：330，000CPU hours；Assembly post-error-correction：700，000CPU hours；wall clock time：5-6month】</p>
<p>获得的结果惊人，结果几乎是<font color="blue">预期基因大小<strong>两倍</strong></font>，而<font color="blue">Contig N50</font>达到<font color="blue"><strong>1.92Mb</strong></font> ！相对2019年Oxford Nanopore + NGS组装<font color="blue"><strong>提升18倍</strong></font>。大于预期基因组大小的组装中，大部分可是<font color="blue"><strong>两个类似的单倍型</strong></font>，而<font color="red"><strong>并非完全不同的六倍体</strong></font>，这与最近Scott发表的红杉相关研究类似，印证了加州红杉的多倍体化是<font color="red"><strong>自多倍体事件</strong></font>。</p>
<p><img src="/blog/./640.jpeg" alt="图片"></p>
<p><font color="blue">加州红杉组装结果中<strong>BUSCO评分只有59%??</strong> </font>不是一般<strong>较好</strong>的组装结果BUSCO值都要高达<font color="blue"><strong>90%以上吗？</strong></font>因为<font color="blue">裸子植物（加州红杉属于裸子植物）的BUSCO基因集与被子植物的<strong>BUSCO基因集相差很</strong>多</font>。意味着针对加州红杉使用<font color="red"><strong>通用BUSCO基因集</strong></font>来<font color="red"><strong>评估</strong>基因组完整性<strong>不准确</strong></font>，只是<strong>目前没有</strong>其它<strong>更好</strong>评估方法。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从加州红杉基因组研究中得到什么呢？</p>
<p>首先，对PacBio SMRT测序充满信心，建议使用HiFi数据从任何生物体生成高质量的基因组数据。 </p>
<p>其次，它将彻底改变对<strong>大型，复杂</strong>的基因组装配的认知。之前经验是<strong>超大型复杂基因组</strong>组装需要花费<strong>大量时间</strong>和生信<strong>计算资源</strong>，还不包括测序时间。而加州红杉庞大基因组在短短17天内就可完成（包括4天样品准备和建库，7天测序和6天组装）。 </p>
<p><strong>通过PacBio HiFi数据，可以对<font color="blue">任何生物</font>进行<font color="blue">高质量</font>的基因组测序。</strong></p>
<h2 id="2020-05"><a href="#2020-05" class="headerlink" title="2020.05"></a>2020.05</h2><p>HiFi助力同源四倍体紫花苜蓿基因组组装，NC发表</p>
<p>Allele-aware chromosome-level genome assembly and efficient transgene-free genome editing for the autotetraploid cultivated alfalfa</p>
<p>（1）使用Canu默认参数，利用CCS clean reads组装contigs。组装得到的Contig N50值为459kb，总长度为3.15GB。</p>
<p>（2）使用HiC-Pro将Hi-C reads与contigs 进行比对，产生比对BAM文件。</p>
<p>（3）使用注释的蒺藜苜蓿蛋白作为参考，完全基于同源的策略注释contigs。对138,729个同源基因进行了结构注释。用MCscan用于鉴定contigs和参考基因组之间的共线性。显示紫花苜蓿和蒺藜苜蓿之间的高共线性。【下载父母本petunia ref】</p>
<p>（4）使用内部脚本处理BAM文件，去除等位基因contigs之间的links。使用ALLHiC软件，提取、聚类和重排Contigs (Contigs syntenic与蒺藜苜蓿染色体一致)，得到原始的scaffolds。</p>
<p>（5）Juicebox用于以图形和交互方式微调组装的scaffolds。剪裁了40个总长度达1800Mb的scaffolds 。</p>
<p>（6） 基于组装的scaffold，通过Hi-C数据，每个unplaced contig被分配到互作最强的那些contig cluster里。</p>
<p>（7）使用ALLHiC对那些contig clusters再次进行重排和构建scaffold。</p>
<p>（8）使用Juicebox对scaffolds进行微调，并从scaffolds上去除不一致的contigs，产生最终的染色体基因组，其包含32条染色体(8个同源组，每个组中有4个等位基因染色体)，总长度为2738Mb，和419Mb未挂载到染色体水平的序列。</p>
<h2 id="2020-07"><a href="#2020-07" class="headerlink" title="2020.07"></a>2020.07</h2><p>加州大学HiFi组装人完整X染色体，Nature</p>
<p>Miga Karen H,Koren Sergey,Rhie Arang et al. Telomere-to-telomere assembly of a complete human X chromosome.[J] .Nature, 2020.</p>
<h1 id="HiFi与不同类型基因组组装"><a href="#HiFi与不同类型基因组组装" class="headerlink" title="HiFi与不同类型基因组组装"></a><a href="https://www.jianshu.com/p/4d42719d8b01">HiFi与不同类型基因组组装</a></h1><h2 id="高重复基因组—玉米"><a href="#高重复基因组—玉米" class="headerlink" title="高重复基因组—玉米"></a><strong>高重复基因组—玉米</strong></h2><p>玉米（<em>Z.mays</em>）是世界上产量最高种植最广的作物，也是遗传学和基因组学的基础model。玉米基因组经历<font color="blue"><strong>全基因组复制事件</strong></font>和<font color="blue"><strong>长末端重复转座子扩增</strong></font>导致基因组<strong>急剧扩大</strong>（<font color="red">2.3Gb</font>）。最终导致玉米基因组中<font color="red"><strong>转座子占比高达85%</strong></font>。</p>
<p>利用<strong>HiFi</strong>组装的<font color="blue"><strong>玉米B73</strong></font>基因组大小为<font color="blue"><strong>2.164 Gb</strong></font>，<strong>略大于</strong>2017年发表的利用PacBio <font color="blue">CLR</font>的组装版本（<font color="blue">2.104 Gb</font>）。在连续性方面，HiFi组装<font color="blue"><strong>Contig N50则达到28.2 Mb</strong></font>，提升近<font color="red"><strong>23倍</strong></font>，甚至<strong>超过</strong>最近发表的<strong>NC358</strong>基因组。<font color="red"><strong>BUSCO评估表明</strong></font>，HiFi组装版本的组装质量也<font color="red"><strong>高于所有</strong></font>已发表的<strong>玉米基因组版本</strong>。在时间和资源消耗上，最近发表的<strong>75× CLR数据</strong>组装NC358基因组花费了<strong>11,520 CPU hours</strong>，而HiFi数据组装仅在6小时完成，仅花费360 CPU hours，<font color="red"><strong>资源消耗节省了31倍</strong></font>。体现了HiFi在<font color="blue">高重复基因组组装</font>的明显<font color="blue">优势</font>。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/10.png" alt="img"></p>
<p>HiFi 组装 <strong>玉米B73</strong> 基因组结果</p>
<h2 id="大型复杂基因组—黄腿山蛙"><a href="#大型复杂基因组—黄腿山蛙" class="headerlink" title="大型复杂基因组—黄腿山蛙"></a><strong>大型复杂基因组—黄腿山蛙</strong></h2><p>黄腿山蛙（<em>R. muscosa</em>）是一种两栖动物。<font color="blue"><strong>两栖动物</strong>是<strong>脊椎动物</strong>中<strong>基因组大小变化最大</strong>的一类</font>，已完成基因组测序的<strong>美西钝口螈</strong>高达<strong>32 Gb</strong>。蛙科物种中，最大基因组达10 Gb以上，黄腿山蛙的基因组<strong>预计9 Gb</strong>左右。</p>
<p>利用HiFi数据组装的黄腿山蛙基因组获得<font color="blue">两套单倍型基因组</font>，单倍型基因组大小分别为<font color="blue">9.03G和5.23 Gb</font>，<font color="red"><strong>主要单倍型基因组</strong></font>大小<strong>接近预估</strong>基因组大小。<font color="red"><strong>主要单倍型基因组</strong>Contig <strong>N50达2.8 M</strong>，<strong>远高于</strong>已发表的蛙科物种基因组</font>。HiFi 组装的<font color="blue"><strong>黄腿山蛙</strong>基因组的<strong>BUSCO评估结果</strong>也<strong>明显高于</strong>另外两个物种的基因组</font>。此外，虽然黄腿山蛙的基因组高达9 Gb，利用HiFi 组装也仅花费<strong>12小时</strong>。上述表明，HiFi快速组装<font color="blue">高质量大型基因组</font>出色。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/11.png" alt="img"></p>
<p>HiFi组装 <strong>黄腿山蛙</strong> 基因组结果</p>
<h2 id="异源多倍体基因组—草莓"><a href="#异源多倍体基因组—草莓" class="headerlink" title="异源多倍体基因组—草莓"></a><strong>异源多倍体基因组—草莓</strong></h2><p>栽培草莓（<em>F. x ananassa</em>）是一个<font color="blue"><strong>异源</strong>八倍体物种（2n=8x=56）</font>，由两种<font color="blue">野生八倍体物种天然杂交</font>产生，这<font color="blue"><strong>两种野生八倍体</strong>都是<strong>100多万年</strong>前<strong>四种二倍体祖先物种合并</strong>的产物</font>。</p>
<p>利用HiFi数据组装的八倍体草莓基因组获得了<font color="blue">两套单倍型基因组</font>，大小分别为<font color="blue">776M和304 M</font>，<font color="red"><strong>主要单倍型基因组</strong></font>的大小与<strong>2019年</strong>最新<strong>发表</strong>的<strong>栽培草莓基因组相当</strong>，但<font color="blue">Contig N50达<strong>15.5 Mb</strong>，提升<strong>193倍</strong></font>。此外，整个基因组组装仅花费<strong>3小时</strong>。上述结果体现HiFi测序在<font color="blue">多倍体基因组组装中的良好表现</font>。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/12.png" alt="img"></p>
<p>HiFi 数据组装 <strong>八倍体草莓</strong> 基因组结果</p>
<h2 id="同源多倍体基因组—苜蓿-√"><a href="#同源多倍体基因组—苜蓿-√" class="headerlink" title="同源多倍体基因组—苜蓿 √"></a><strong>同源多倍体基因组—苜</strong>蓿 √</h2><p>栽培紫花苜蓿（<em>M. sativa</em>）是一种<font color="blue">自交不亲和的<strong>同源</strong>四倍体（2n=4×=32）</font>植物。5月昆明动物研究所等单位利用HiFi测序（约23×）实现栽培紫花苜蓿的基因组组装 <a href="https://pubmed.ncbi.nlm.nih.gov/32427850/">paper</a>。</p>
<p>利用专门针对HiFi数据开发的组装软件<font color="red"><strong>HiCanu和Hifiasm</strong></font>重新对该基因组进行组装。<font color="blue">HiCanu组装版本</font>基因组大小为<font color="blue">2.66 G</font>，<strong>略低</strong>于<font color="blue">Canu版本</font>；<font color="blue"><strong>Hifiasm组装版本</strong></font>的基因组大小（<font color="blue">3.22 G</font>）则略高于Canu版本。<font color="red"><strong>HiCanu</strong>和<strong>Hifiasm</strong>的组装的<strong>Contig N50</strong>分别为<strong>1.67</strong>和<strong>1.73</strong> Mb，<strong>明显高于Canu</strong>版本</font>。测试结果及已发表的苜蓿基因组均表明，HiFi能够实现<font color="blue">同源多倍体基因组的高质量组装</font>。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/14.png" alt="同源四倍体苜蓿基因组组装结果比较"></p>
<h2 id="单倍型基因组-人"><a href="#单倍型基因组-人" class="headerlink" title="单倍型基因组   人"></a><strong>单倍型基因组   人</strong></h2><p>目前已发表多个高质量人基因组序列，且已有多个利用HiFi组装人基因组的案例，利用HiFi组装出<strong>人两套单倍型基因组</strong>也已经被报道。</p>
<p>利用HiFi 对人基因组组装，获得两套单倍型基因组。<font color="blue"><strong>两套单倍型基因组</strong>大小分别为<strong>3.14G</strong>和<strong>2.50 G</strong>，<strong>Contig N50</strong>分别为<strong>42.2M</strong>和<strong>1.6 M</strong></font>。这一结果与<strong>已发表的利用HiFi数据组装的HG002和HG00733基因组相当。整个组装过程仅花费2小时。</strong>上述结果体现HiFi在<font color="blue">单倍型基因组组装中的优势</font>。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/13.png" alt="img"></p>
<p>HiFi 组装 人 基因组结果</p>
<hr>
<h1 id="？Pacbio序列结构变异germline-SV-calling"><a href="#？Pacbio序列结构变异germline-SV-calling" class="headerlink" title="？Pacbio序列结构变异germline SV calling"></a>？Pacbio序列结构变异germline SV calling</h1><p><a href="https://blog.csdn.net/weixin_36416921/article/details/112277318">https://blog.csdn.net/weixin_36416921/article/details/112277318</a> ？？</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/2.png" alt="img"></p>
<ul>
<li><p>获取bam文件（Pacbio下机数据）。</p>
</li>
<li><p>subreads.bam文件 到ccs.bam文件</p>
</li>
<li><p>bam到fastq文件</p>
</li>
<li><p>数据分析，变异检测</p>
<ul>
<li><strong>mapping &amp; calling 【</strong>nextSV2流程】</li>
<li>常用的长序列比对软件有<strong>ngmlr</strong> 和 <strong>minimap2</strong>，不同的mapping软件得到结果略有差别，minimap2比对得到的结果较多？</li>
<li><strong>sniffles calling</strong> </li>
</ul>
</li>
</ul>
<hr>
<p>一般认为只有CLR的subreads需要用NGS校正，ccs或hifi reads已经自身校正了，不用额外校正。当ccs的阈值设定为3时，得到的序列就是HIFI reads了。</p>
<h1 id="HiFi-HiCanu"><a href="#HiFi-HiCanu" class="headerlink" title="HiFi+HiCanu"></a>HiFi+HiCanu</h1><p>ref: <a href="http://www.genome.cn/News/Industry/1099.html">http://www.genome.cn/News/Industry/1099.html</a></p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/32801147/">HiCanu: accurate assembly of segmental duplications, satellites, and allelic variants from high-fidelity long reads</a> <strong>2020.09 Genom Res</strong></p>
<p><strong>PacBio HiFi+HiCanu</strong>完成准确度超99.999%，<strong>Contig N50</strong>达到<strong>77Mb</strong>的<strong>人类</strong>基因组组装结果！</p>
<p>NIH科学家使用PacBio HiFi Reads组装基因组文章 <strong>HiCanu</strong>。使用HiCanu组装工具（专门针对 HiFi Reads优化组装流程），对<font color="red"><strong>果蝇</strong></font>和<font color="red"><strong>人类</strong></font><strong>标准基因组</strong>组装，重点探索HiFi Reads对<font color="blue"><strong>基因组单倍型的区分</strong></font>，主要<font color="blue"><strong>组织相容性复合体（MHC）变异</strong></font>，染色体<font color="blue"><strong>卫星区域</strong></font>和<font color="blue"><strong>片段重复</strong></font>的检测能力。</p>
<h2 id="基因组连续性和准确性提升"><a href="#基因组连续性和准确性提升" class="headerlink" title="基因组连续性和准确性提升"></a><strong>基因组连续性和准确性提升</strong></h2><p>30X HiFi Reads通过HiCanu将人CHM13细胞系的基因组组装的<strong>Contig N50</strong> 提升至<strong>77M</strong>，单碱基准确性超过99.999%（Q50）！在组装的准确性连续性两个方面，HiFi Reads的组装结果都超过了最新 高覆盖度 超长 牛津 纳米孔测序 的结果。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/3.png" alt="3.png"></p>
<p>使用PacBio HiFi和Ultra-Long (Oxford Nanoproe) 组装人CHM13基因组结果对比，都<strong>未经短读长测序数据polish</strong>。Peregrine, Canu和HiCanu是不同的组装工具。</p>
<h2 id="基因组单倍型检测的提升-做此图类似评估"><a href="#基因组单倍型检测的提升-做此图类似评估" class="headerlink" title="基因组单倍型检测的提升[做此图类似评估]"></a><strong>基因组单倍型检测的提升</strong>[做此图类似评估]</h2><p>组装多倍体时，组装软件要能区分<font color="blue"><strong>不同等位基因</strong></font>，并将它们<font color="blue"><strong>保存为不同的序列</strong></font>，以<font color="blue"><strong>主要Contig</strong>和<strong>替代Contig</strong>模式</font>表示。对于<font color="blue">双倍体人</font>基因组组装，HiCanu组装结果<font color="blue">包含<strong>超过2 Gbp</strong>的<strong>替代Contig</strong></font>，而<font color="blue">其它组装软件</font>只能产生<font color="blue">不到400 Mbp的替代Contig [hifiasm如何?]</font>。说明<font color="blue">HiCanu</font>结合HiFi Reads具有<font color="blue">更强的<strong>区分单倍型能力</strong></font>。如下图，HiCanu组装的<font color="red">主要Contig和替代Contig<strong>都</strong></font>具有<font color="red">较高的<strong>BUSCO完整性</strong></font>（分别**&gt; 94％<strong>和</strong>&gt; 75％<strong>），而采用 <strong>超长 牛津纳米孔测序</strong>的BUSCO完整性分别只有</strong>63%<strong>和</strong>0.3%**。并且HiCanu + HiFi Reads的<font color="red"><strong>Phase Block NG50?</strong></font>是高覆盖度超长牛津纳米孔测序的2.5倍！</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/4.png" alt="4"></p>
<p>HiCanu与其它组装软件 <strong>组装 双倍体基因组 结果对比</strong>，其中HG00733的Haplotype asm hap1(hap2)a和HG002的Haplotype asm hap1(hap2)b 的数据是<font color="red"><strong>HiFi结合Hi-C的组装结果</strong></font>。</p>
<p>为了<font color="red">评估</font>不同组装工具对<strong>难以检测</strong>的<font color="red"><strong>复杂临床相关等位基因分型结果</strong></font>，通过HiCanu+ HiFi 得到的六个经典的<font color="blue">人类白细胞抗原（HLA）基因</font>的<font color="blue">装配分型结果</font>与之前通过<strong>多种检测方法</strong>获得的<strong>已知HG002和HG00733等位基因</strong>进行比较。<font color="red">只有HiCanu和TrioCanu能够<strong>恢复</strong>具有<strong>100％序列同一性</strong>的<strong>所有等位基因</strong></font>。这也体现HiCanu+ HiFi对于潜在的复杂临床相关基因的精确检测能力。</p>
<h2 id="应对复杂片段重复序列"><a href="#应对复杂片段重复序列" class="headerlink" title="应对复杂片段重复序列"></a><strong>应对复杂片段重复序列</strong></h2><p>为了评估对<font color="red"><strong>片段重复（SD，segmental duplications）</strong>序列的组装能力</font>，使用了BAC文库挑战。被<strong>选择</strong>的<strong>BAC文库序列包含大量片段重复序列</strong>，而片段重复区域是基因组<font color="blue"><strong>最难组装区域之一</strong></font>。经过初步比对，HiCanu+ HiFi在所有组装方案中<font color="red">解析最多的BAC</font>，并且实现<font color="red">最高的BAC对比质量</font>。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/5.png" alt="不同测序数据与组装工具在BAC文库挑战中的结果"></p>
<p>不同测序数据与组装工具在BAC文库挑战中的结果</p>
<p>针对<font color="blue">CHM13中<strong>未能</strong>成功解析的BAC深入研究</font>，发现其中【11个BAC本身可能包含组装错误或克隆伪像?】。手动检查11个BAC的HiFi组装结果，并没有发现明显组装错误（如下图）。这表明HiCanu+ HiFi 实际上成功解析CHM13 341个BAC中的<strong>337个</strong>。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/6.png" alt="1585618676593848.png"></p>
<p>人工检查可能本身存在错误的BAC</p>
<h2 id="人类染色体着丝粒的组装-how"><a href="#人类染色体着丝粒的组装-how" class="headerlink" title="人类染色体着丝粒的组装 [how?]"></a>人类染色体着丝粒的组装 [how?]</h2><p>使用HiCanu+HiFi 成功生成包括CHM13 <font color="blue"><strong>19号染色体着丝粒在内</strong></font>的<font color="blue"><strong>共9个人类染色体着丝粒装配图</strong></font>。CHM13 <font color="red"><strong>19号染色体着丝粒区域被认为是最难组装的着丝粒之一</strong></font>，因为它<font color="red"><strong>由多个HOR（Higher Order Repeat）区域组成</strong></font>并<font color="red"><strong>与1号和5号染色体的着丝粒区域共享α卫星序列</strong></font>。</p>
<p>HiCanu+HiFi 不仅能<font color="red">组装<strong>覆盖整个着丝粒</strong>的contig<strong>群</strong></font>，而且可以<font color="red">准确<strong>区分</strong>三个<strong>不同的HOR区域???</strong></font>：<strong>D19Z1，D19Z2和D19Z3</strong>。在之前的<font color="red"><strong>X染色体T2T研究</strong>中</font>，为了达到如此完整的人类染色体<strong>着丝粒组装</strong>结果，需要<font color="blue">使用包括<strong>高深度超长纳米孔测序</strong>，<strong>60X PacBio CLR</strong>测序和<strong>illumina短读长</strong>测序的数据<strong>共同</strong>组装</font>才能达到这样的效果。而现在<font color="blue">仅使用<strong>一种</strong>测序技术</font>，即<strong>HiFi 结合HiCanu</strong>就能<strong>解析</strong>人类染色体<strong>着丝粒</strong>结构。</p>
<p><img src="/blog/2022/03/02/2022-03-02-HiFi-3-software/7.png" alt="1585618881806532.png"></p>
<p>CHM13 19号染色体<font color="blue"><strong>着丝粒的HiCanu装配</strong></font>。tig00006497的<font color="red"><strong>RepeatMasker</strong>揭示了位于<strong>19号着丝粒</strong>（D19Z1，D19Z2α和D19Z3；标有黑条）中的<strong>三个α卫星HOR区域</strong></font>。这些<strong>HOR序列长度</strong>分别为<strong>606 kbp，289 kbp和3.96 Mbp</strong>，分别由<strong>13-mer</strong>，复杂的<strong>高阶HOR</strong>和<strong>二聚体HOR单元</strong>组成?</p>
<h2 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a><strong>总结与展望</strong></h2><p>通过本研究，证明<font color="blue">HiFi 结合HiCanu</font>能够生成迄今为止<font color="blue">最准确，最完整</font>的人类基因组<font color="blue">装配体</font>。其他应用，例如同样需要高精度Reads的<strong>宏基因组组装</strong>。<font color="red">HiFi擅长解决<strong>大型高度相似</strong>（但<strong>不完全相同</strong>）的<strong>重复序列</strong></font>。HiCanu+HiFi 对人类<strong>1号，7号，9号和16号</strong>染色体的重建<strong>显著改善</strong>先前<strong>超长纳米孔测序的组装连续性</strong>。这些染色体包含<font color="blue">多个长度超过<strong>200 kbp的片段重复</strong></font>，需要 <font color="blue">HiFi 才能<strong>识别</strong>变异并<strong>分离</strong>出<strong>单个拷贝</strong></font>。使用 <strong>HiFi <font color="red">独立完成</font><strong>人类染色体</strong>九个着丝粒区域</strong>的装配草图，这也是T2T项目的最难挑战之一。</p>
<p><font color="blue">HiFi 的长度</font>对组装结果有很大影响，目前最新HiFi Reads已经达到25k。HiCanu在亚马逊<strong>云平台</strong>上组装一个<strong>人</strong>类基因组只需要<strong>22小时</strong>，这还<strong>不是目前最快</strong>的针对 HiFi数据的组装软件，最快的软件只需要<strong>2小时</strong>。相信未来随着HiFi Reads的长度不断提高，以及更多针对PacBio HiFi Reads优化的组装软件出现，基因组的从头组装会<strong>更快更准</strong>。</p>
<h1 id><a href="#" class="headerlink" title></a></h1>]]></content>
      <categories>
        <category>Software</category>
      </categories>
      <tags>
        <tag>denovo-III</tag>
      </tags>
  </entry>
  <entry>
    <title>Sequencing data and fastq.gz</title>
    <url>/blog/2022/03/01/2022-03-01-sequencing-data/</url>
    <content><![CDATA[<h1 id="fastq压缩之gzip文件大小与样本数据量关系"><a href="#fastq压缩之gzip文件大小与样本数据量关系" class="headerlink" title="fastq压缩之gzip文件大小与样本数据量关系"></a>fastq压缩之gzip文件大小与样本数据量关系</h1><span id="more"></span>

<p>ref : <a href="https://www.zxzyl.com/archives/1011">https://www.zxzyl.com/archives/1011</a></p>
<p>测序时，先拿到的是样本fastq压缩后的gz文件，若关心数据量够不够，则需计算fastq.gz文件大小和测序数据量的关系。</p>
<p>用Miseq测序数据（gz文件200M），Hiseq panel（gz文件50M）和WES测序数据（gz文件4G）进行简单分析。发现，<font color="green"><strong>虽然R1和R2数据量是一样，解压出来的文件大小一样，但R2的gzip文件总比R1大</strong></font>。不管是Miseq还是Hiseq的panel测序，压缩后的R2均大于R1文件，且文件越小，差异越大。</p>
<p>因R1和R2数据量相同，只看R1的真实文件和gz文件大小与数据量之间的关系。<br><font color="green"><strong>数据量</strong></font>=FASTQ文件行数/4x<font color="green"><strong>151</strong></font>/1000/<font color="green"><strong>1000</strong></font> 单位为<strong>M</strong><br><font color="green"><strong>真实文件大小估计</strong></font>=FASTQ文件行数/4x<font color="green"><strong>357</strong></font>/1024/<font color="green"><strong>1024</strong></font> 单位为<strong>M</strong>，预测值，差别不大，<strong>因为FASTQ文件中每四行357个字符</strong>（和平台和设置有关系），每个字符1byte。</p>
<p>GZ文件大小通过ll -h查看</p>
<p>因为FASTQ文件是<strong>规范</strong>的，<strong>每四行字符基本一致</strong>，所以<font color="green"><strong>FASTQ真实文件大小和数据量成正比</strong></font>。<strong>前面提到每四行有357个字符，其中序列只占151个字符，FASTQ文件大小大概是测序量的357/151≈2.3倍多</strong>。但因FASTQ文件为文本文件，占用空间较大，所以一般将FASTQ文件压缩成gz。</p>
<p>用gz文件大小除以估计的真实文件大小，得到压缩比，发现压缩比和测序平台有关系，<font color="green"><strong>Miseq</strong>的压缩比在<strong>0.35</strong>左右，<strong>Hiseq</strong>平台中的panel测序在<strong>0.24</strong>左右，<strong>WES</strong>在<strong>0.2</strong>左右</font>。可以发现WES的数据的压缩效率最高，猜测不同平台在压缩过程中设置的压缩比例不同。Hiseq测序平台的gz文件压缩性能大于Miseq平台。</p>
<ul>
<li><p>以Miseq的gzip文件大小和数据量<strong>作图</strong>，可以很直观的发现gz文件大小和数据量之间的线性关系。斜率是1.245，截距可以忽略不计，因为纵坐标很大。也就是说R1文件的数据量约等于gzip文件的1.245倍。</p>
</li>
<li><p><strong>从另外一个角度计算</strong>，<font color="green"><strong>R1文件数据量=gzip文件大小/压缩效率/2.3</strong></font>，则因为Miseq的压缩效率在0.35，Hiseq在0.23左右，所以Miseq R1文件的数据量大概是gzip文件的<font color="green">1.242倍（1/0.35/2.3）</font>，和上图拟合的结果很相近，<strong>Hiseq约在1.89(1/0.23/2.3)倍</strong>。真实的数据量其实是R1文件数据量的2倍（R2文件中的数据量和R1文件相同）。</p>
</li>
</ul>
<p><strong>结论：</strong>不同平台和不同测序方法之间的<font color="green">fastq文件压缩比例并不一致</font>，但同一种方法和平台内的压缩比例是相近的，因而可以根据gzip文件的大小推测出测序的数据量。</p>
<p><strong>Miseq的测序量约是R1 gzip文件大小的2.49倍(R1+R2)，Hiseq的测序量约是R1 gzip文件大小的3.78倍。</strong>不同平台和方法之间，这个值是不固定的，可以根据手头的数据计算一下这个比例，就能迅速的估算出样本的数据量。</p>
]]></content>
      <categories>
        <category>assemble</category>
      </categories>
      <tags>
        <tag>fastq</tag>
      </tags>
  </entry>
  <entry>
    <title>Genome assemble pipeline</title>
    <url>/blog/2022/02/28/2022-02-28-genome-assemble/</url>
    <content><![CDATA[<p>Genome assemble pipeline</p>
<span id="more"></span>

<blockquote>
<p>内容均来自菲沙基因（<a href="https://links.jianshu.com/go?to=http://www.frasergen.com/">Frasergen</a>）暑期生信培训班课堂笔记</p>
<p><a href="https://www.jianshu.com/p/c7663d2cf337">https://www.jianshu.com/p/c7663d2cf337</a></p>
</blockquote>
<h2 id="Genome-de-nove-基础知识"><a href="#Genome-de-nove-基础知识" class="headerlink" title="Genome de nove 基础知识"></a>Genome <em>de nove</em> 基础知识</h2><ul>
<li>基因组是物种所含有的一套遗传物质(单倍体细胞核、细胞器所含的全部DNA分子) , 包括全套基因和间隔序列</li>
<li>基因组=物种所拥有的一套完整单倍体序列</li>
<li>利用测序技术对物种体内所有DNA分子进行测序,获取碱基组成,明确基因结构信息,外显子及内含子区域、启动子位置,以及基因的排列顺序及功能</li>
<li>基因组<em>de nove</em>,又称基因组从头测序,是指对基因组序列未知(或仅有基因组草图)的物种进行全基因组测序,然后进行拼装,从而得到该物种的全基因组序列,为后续功能基因挖掘、调控代谢网络构建、物种进化分析等奠定基础。</li>
</ul>
<h2 id="构建参考基因组pipeline"><a href="#构建参考基因组pipeline" class="headerlink" title="构建参考基因组pipeline"></a>构建参考基因组pipeline</h2><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/1.png" alt="1"></p>
<h3 id="基因组Survey分析"><a href="#基因组Survey分析" class="headerlink" title="基因组Survey分析"></a>基因组Survey分析</h3><ul>
<li><p>基因组Survey基于小片段文库的低深度测序数据( 50X-100X ) ;</p>
</li>
<li><p>通过K-mer分析 ,有效的<strong>评估基因组大小、GC含量、杂合度以及重复序列的含量等信息</strong>;</p>
</li>
<li><p>是全面了解某一物种基因组特征的有效方法;</p>
</li>
<li><p>为后续的全基因组 <em>de novo</em> 测序的组装策略的制定提供理论依据。</p>
</li>
</ul>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/2.png" alt="2"></p>
<h4 id="补充知识1：基因组复杂度评估"><a href="#补充知识1：基因组复杂度评估" class="headerlink" title="补充知识1：基因组复杂度评估"></a>补充知识1：基因组复杂度评估</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/3.png" alt="3"></p>
<h4 id="补充知识2：根据kmer-图确认物种倍型"><a href="#补充知识2：根据kmer-图确认物种倍型" class="headerlink" title="补充知识2：根据kmer-图确认物种倍型"></a>补充知识2：根据kmer-图确认物种倍型</h4><blockquote>
<p>二倍体：杂合峰：主峰：重复峰=1：2：4（x）</p>
</blockquote>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/4.png" alt="4"></p>
<blockquote>
<p>三倍体：正常情况下杂合峰：主峰：重复峰 = 1:2:3（左图）。主峰和重复峰深度低则可能重叠在一起：杂合峰：主峰：重复峰 = 1:2（右图）</p>
</blockquote>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/5.png" alt="5"></p>
<blockquote>
<p><strong>异源四倍体</strong>：2个峰，呈现1:2的关系</p>
</blockquote>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/6.png" alt="6"></p>
<blockquote>
<p><strong>同源四倍体</strong>：同源四倍体的峰就是1 : 2 : 3 : 4 ,其中3和4经常重叠在一起</p>
</blockquote>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/7.png" alt="7"></p>
<h4 id="补充知识3：Survey优势"><a href="#补充知识3：Survey优势" class="headerlink" title="补充知识3：Survey优势"></a>补充知识3：Survey优势</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/8.png" alt="8"></p>
<h3 id="基因组组装与注释"><a href="#基因组组装与注释" class="headerlink" title="基因组组装与注释"></a>基因组组装与注释</h3><ul>
<li><strong>Contig</strong>：使用短reads之间的overlap关系拼接所得的无GAP序列片段</li>
<li><strong>Scaffold</strong>：通过大片段文库将Contig进-步连接所得的长序列片段，各个Contig之间用”N”填补</li>
</ul>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/9.png" alt="9"></p>
<ul>
<li><p>组装质量评价基本指标：<strong>ContigN50</strong>与<strong>ScaffoldN50</strong></p>
</li>
<li><p>将组装所得序列<strong>从大到小</strong>排列，并依次相加，当<strong>累加长度达到总长度一半时，最后一条序列的长度</strong>即为N50;N50越大，组装结果连续性越好</p>
</li>
</ul>
<h4 id="组装流程"><a href="#组装流程" class="headerlink" title="组装流程"></a>组装流程</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/10.png" alt="10"></p>
<h4 id="组装"><a href="#组装" class="headerlink" title="组装"></a>组装</h4><p>常用软件有**<a href="https://links.jianshu.com/go?to=https://canu.readthedocs.io/en/latest/">Canu</a>, <a href="https://links.jianshu.com/go?to=https://github.com/xiaochuanle/MECAT">MECAT</a>, <a href="https://links.jianshu.com/go?to=https://github.com/PacificBiosciences/pb-assembly">FALCON</a><strong>。从项目周期、组装结果、资源消耗等方面综合来看,菲沙基因（<a href="https://links.jianshu.com/go?to=http://www.frasergen.com/">Frasergen</a>）首选</strong>Mecat 2**进行基因组组装。</p>
<p>####Hi-C辅助组装</p>
<p>Hi-C数据的一般规律:<br>➢ 染色体内的互作高于染色体间的互作<br>➢ 染色体内互作强度随线性距离增加而减弱</p>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/11.png" alt="11"></p>
<h4 id="组装结果评估"><a href="#组装结果评估" class="headerlink" title="组装结果评估"></a>组装结果评估</h4><p>数据回比：为了评估组装的完整性和测序覆盖的均匀性,选择CLR (Continuous Long Reads) subreads ,使用比对工具Minimap2 ( v2.5默认参数)比对回组装好的基因组,统计reads的比对率、覆盖基因组的程度以及深度的分布情况,由此评估组装的完整性和测序覆盖的均匀性,结果如下表所示。</p>
<p>BUSCO评估：基于OrthoDB中的单拷贝同源基因集,使用BUSCO ( V3.0.2 )预测这些基因并统计其完整度,碎片化程度及可能的丢失率。由此评估整个组装结果中基因区的完整性(大于90%较好)。BUSCO评估结果如下表所示。</p>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/12.png" alt="12"></p>
<h4 id="基因结构注释"><a href="#基因结构注释" class="headerlink" title="基因结构注释"></a>基因结构注释</h4><p>基因结构预测包括预测基因组中的基因位点、开放性阅读框架（ORF）、翻译起始位点和终止位点、内含子和外显子区域、启动子和终止子、可变剪切位点以及蛋白编码序列（CDS）等</p>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/13.png" alt="13"></p>
<h4 id="基因功能注释"><a href="#基因功能注释" class="headerlink" title="基因功能注释"></a>基因功能注释</h4><p>全基因组测序将产生大量数据，此前普遍采用比对方法对对预测出来的<strong>编码基因</strong>进行功能注释，通过与各种功能数据库（NR、Swiss-Prot 、GO、KOG、KEGG）进行蛋白质比对，获取该基因的功能信息。其中GO和KEGG数据库分别在基因功能和代谢通路研究中占据重要地位。</p>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/14.png" alt="14"></p>
<h4 id="非编码RNA注释"><a href="#非编码RNA注释" class="headerlink" title="非编码RNA注释"></a>非编码RNA注释</h4><p>非编码RNA（ncRNA），指不翻译成蛋白质的RNA，如<br> miRNA(MicroRNA),<br> tRNA(转运RNA)，<br> rRNA(核糖体RNA),<br> snRNA（小核RNA）等。<br> 利用tRNAscan-SE对全基因组进行tRNA预测；利用RNAmmer预测全基因的rRNA；利用Rfam数据库通过cmscan鉴定全基因组非编码RNA</p>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/15.png" alt="15"></p>
<h4 id="重复序列分析"><a href="#重复序列分析" class="headerlink" title="重复序列分析"></a>重复序列分析</h4><p>重复序列广泛存在于真核生物基因组中，这些重复序列或集中成簇，或分散在基因之间，根据分布把重复序列分为分散重复序列（Interpersed repeat）和串联重复序列（Tendam repeat）</p>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/16.png" alt="16"></p>
<h4 id="基因组圈图结果展示"><a href="#基因组圈图结果展示" class="headerlink" title="基因组圈图结果展示"></a>基因组圈图结果展示</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/18.png" alt="18"></p>
<h3 id="比较基因组学"><a href="#比较基因组学" class="headerlink" title="比较基因组学"></a>比较基因组学</h3><ul>
<li><p>比较基因组学是从基因组中解析生物学意义</p>
<p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/19.png" alt="19"></p>
</li>
</ul>
<h4 id="基因家族聚类"><a href="#基因家族聚类" class="headerlink" title="基因家族聚类"></a>基因家族聚类</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/20.png" alt="20"></p>
<h4 id="系统进化树"><a href="#系统进化树" class="headerlink" title="系统进化树"></a>系统进化树</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/21.png" alt="21"></p>
<h4 id="物种分歧时间计算"><a href="#物种分歧时间计算" class="headerlink" title="物种分歧时间计算"></a>物种分歧时间计算</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/22.png" alt="22"></p>
<h4 id="基因家族扩展收缩分析"><a href="#基因家族扩展收缩分析" class="headerlink" title="基因家族扩展收缩分析"></a>基因家族扩展收缩分析</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/23.png" alt="23"></p>
<h4 id="正选择分析"><a href="#正选择分析" class="headerlink" title="正选择分析"></a>正选择分析</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/24.png" alt="24"></p>
<h4 id="共线性分析-需到染色体水平"><a href="#共线性分析-需到染色体水平" class="headerlink" title="共线性分析(需到染色体水平)"></a>共线性分析(需到染色体水平)</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/25.png" alt="25"></p>
<h4 id="全基因组复制分析-WGD"><a href="#全基因组复制分析-WGD" class="headerlink" title="全基因组复制分析(WGD)"></a>全基因组复制分析(WGD)</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/26.png" alt="26"></p>
<h4 id="泛基因组分析（需要多份基因组de-nove测序数据）"><a href="#泛基因组分析（需要多份基因组de-nove测序数据）" class="headerlink" title="泛基因组分析（需要多份基因组de nove测序数据）"></a>泛基因组分析（需要多份基因组<em>de nove</em>测序数据）</h4><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/27.png" alt="27"></p>
<h2 id="文章"><a href="#文章" class="headerlink" title="文章"></a>文章</h2><p><img src="/blog/2022/02/28/2022-02-28-genome-assemble/28.png" alt="28"></p>
<p><a href="https://links.jianshu.com/go?to=https://pan.baidu.com/s/1t_xbRf4Bj3DoHTQV-y6xAQ">https://pan.baidu.com/s/1t_xbRf4Bj3DoHTQV-y6xAQ</a></p>
<p>yyds</p>
]]></content>
      <categories>
        <category>assemble</category>
      </categories>
      <tags>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>Soapdenovo2</title>
    <url>/blog/2022/02/24/2022-02-25-soapdenovo2/</url>
    <content><![CDATA[<h1 id="soapdenovo2"><a href="#soapdenovo2" class="headerlink" title="soapdenovo2:"></a>soapdenovo2:</h1><span id="more"></span>

<p>SOAPdenovo使用说明，内容包括程序<font color="green"><strong>使用</strong></font>、<font color="green"><strong>参数说明</strong></font>、<font color="green"><strong>参数调整</strong></font>、主要<font color="green"><strong>输出文件</strong></font>的格式说明等。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/1.png" alt="img"></p>
<h1 id="contiging"><a href="#contiging" class="headerlink" title="contiging"></a>contiging</h1><p><em><strong>a.</strong></em>  基因组DNA随机打断，使用paired-end测序。长度在150-500bp的short clones扩增直接测序。在2-10kb的长paired-end libraries 通过DNA环化、fragmentation破碎，然后净化400-600bp的碎片为了cluster 结构。</p>
<p><em><strong>b.</strong></em>  raw reads 或预修正reads被存储，de Bruijn graph data structure 被用于表示reads间overlap。</p>
<p>Kmer-graph构建：所有reads被切割成某一固定Kmer长度的序列（21bp=&lt;kmer&lt;=127bp），形成等长的Kmers。将Kmers连成图。<font color="green"><strong>相邻的kmers是通过K-1 overlaping连接</strong></font>，所以它不需要成对序列比对（The neighboring kmers are K-1 overlaping which generated from read sequences, so it doesn’t need pair-wise reads alignment.）。重复序列在图中被压缩。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/2.png" alt="img"></p>
<p><em><strong>c.</strong></em>  产生<font color="red"><strong>tips翼尖、bubbles气泡、low coverage links低覆盖率链接、tiny repeat微小重复</strong></font>等问题。</p>
<p><font color="blue"><strong>tips翼尖（a）</strong></font>和<font color="blue"><strong>bubbles气泡（c）</strong></font>：由于<strong>测序错误</strong>或<strong>杂合</strong>或<strong>高重复序列</strong>相似性，将会导致翼尖和气泡出现。</p>
<p><font color="blue"><strong>low coverage links低覆盖率链接：（b）（d）</strong></font>。</p>
<p><font color="blue"><strong>tiny repeat微小重复(e)</strong></font>：重复在graph中被压缩，并作为不同路径的共享边缘，但是能够通过reads 穿过来解决。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/3.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/4.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/5.png" alt="img"></p>
<p>移除错误链接和graph simplification图形简化，得到contigs or contig  graphs：tips翼尖移除；删除低覆盖链接；bubbles合并气泡；解决微小重复；</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/6.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/7.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/8.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/9.png" alt="img"></p>
<p> <em><strong>d.</strong></em>  contig  graphs,在重复的节点处剪断?，输出contigs</p>
<h1 id="scaffolding"><a href="#scaffolding" class="headerlink" title="scaffolding"></a>scaffolding</h1><p><em><strong>e.</strong></em>  重新用reads和contigs进行比对，使用<font color="red"><strong>paired-end信息</strong></font>把单一的contigs连接成scaffolds。reads 比对到contigs上，临近的contig建立连接；repeat将会引来冲突矛盾信息；<font color="red"><strong>在组装成scaffold时，repeat contigs将会被屏蔽</strong></font>；paired-end信息的不同插入片段被用来一步步从短到长的建立scaffold graph(Scaffolding iteratively from short to long insert PEs./Various insert size of paired-end information is used to build contig graph step by step from short to long)。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/10.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/11.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/12.png" alt="img"></p>
<h1 id="Gap-Filling"><a href="#Gap-Filling" class="headerlink" title="Gap Filling:"></a>Gap Filling:</h1><p><em><strong>f.</strong></em>  使用paired-end reads来填补scaffolds内部可能是由重复序列所造成的Gap。contig N50 通常比较小（&lt;3KB）,但是，gap filling之后能够显著提高N50值（i.e.,&gt;20KB）;Most of the gaps are repeat relative sequences.;Reads locate at gaps can collected by their paired-end which uniquely map to the contig.</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/13.png" alt="img"></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>SOAPdenovo（目前最新版是SOAPdenovo2）是利用一种新的组装短read的方法，它以kerm为节点单位，利用<font color="green"><strong>de Bruijn图</strong></font>的方法实现全基因组的组装，和其他短序列组装软件相比，它可以进行大型基因组比如人类基因组的组装，组装结果更加准确可靠，可以通过组装的结果非常准确地鉴别出基因组上的序列结构性变异，为构建全基因组参考序列和以低测序成本对未知基因组实施精确分析创造了可能。</p>
<p>SOAPdenovo aims for large plant and animal genomes, although it also works well on bacteria and fungi genomes. It runs on 64-bit Linux system with a minimum of 5G physical memory. For <strong>big genomes</strong> like human, about <strong>150 GB memory</strong> would be required.</p>
<p>程序的下载及安装：<br>下载地址：<a href="http://soap.genomics.org.cn/soapdenovo.html">http://soap.genomics.org.cn/soapdenovo.html</a><br>安装：<br>(a) 下载SOAPdenovo的压缩包   </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/aquaskyline/SOAPdenovo2.git</span><br><span class="line"><span class="built_in">cd</span> SOAPdenovo2</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>(b) 解压缩<br>(c)将得到可执行文件SOAPdenovo和一个配置文件的模板example.contig</p>
<p><strong>3个可执行文件</strong></p>
<ol>
<li><font color="green"><strong>SOAPdenovo-63mer</strong></font></li>
<li><font color="green"><strong>SOAPdenovo-127mer</strong></font></li>
<li><font color="green"><strong>SOAPdenovo-fusion</strong></font></li>
</ol>
<p>第一个支持最大k-mer为63，第二个最大kmer为127，第三个文件用于单细胞测序和宏基因组测序数据。</p>
<h1 id="使用程序及参数"><a href="#使用程序及参数" class="headerlink" title="使用程序及参数"></a>使用程序及参数</h1><p>SOAPdenovo可以一步跑完，也可以分成四步单独跑<br><font color="green"><strong>一步跑完脚本:</strong></font><br>./ SOAPdenovo <font color="red"><strong>all</strong></font> <strong>-s</strong> lib.cfg <strong>-K</strong> 29 <strong>-D</strong> 1 <strong>-o</strong> ant &gt;&gt;ass.log<br><font color="green"><strong>四步单独跑的脚本</strong></font><br>./ SOAPdenovo <font color="red"><strong>pregraph</strong></font> <strong>-s</strong> lib.cfg <strong>-d</strong> 1  <strong>-K</strong> 29 <strong>-o</strong> ant &gt;pregraph.log<br>./ SOAPdenovo <font color="red"><strong>contig</strong></font> <strong>-g</strong> ant <strong>-D</strong> 1 <strong>-M</strong> 3 &gt;contig.log<br>./ SOAPdenovo <font color="red"><strong>map</strong></font> <strong>-s</strong> lib23.cfg <strong>-g</strong> ant &gt;map.log<br>./ SOAPdenovo <font color="red"><strong>scaff</strong></font> <strong>-g</strong> ant <strong>-F</strong> &gt;scaff.log</p>
<h1 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h1><p>用法：/PathToProgram/SOAPdenovo all -s configFile [-K kmer -d KmerFreqCutOff -D EdgeCovCutoff -M mergeLevel -R -u -G gapLenDiff -L minContigLen -p n_cpu] -o Output</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-s    STR     配置文件√</span><br><span class="line">-o    STR     图形输出的文件名前缀 √</span><br><span class="line">-g    STR     输入文件的文件名前缀</span><br><span class="line">-K    INT     输入的K-mer值大小，默认值23，取值范围 13-63 √</span><br><span class="line">-p    INT     程序运行时设定的cpu线程数，默认值8</span><br><span class="line">-R            <span class="string">&quot;利用read鉴别短的重复序列，默认值不进行此操作&quot;</span> √</span><br><span class="line">-d    INT     去除频数不大于该值的k-mer，默认值为0;<span class="string">&quot;最小化错误测序带来的影响&quot;</span> √</span><br><span class="line">-D    INT     去除频数不大于该值的由k-mer连接的边，默认值为1，即该边上每个点的频数都小于等于1时才去除,最小化错误测序带来的影响 ?</span><br><span class="line">-M    INT     连接contig时合并相似序列的等级(强度)，默认值为1，最大值3。</span><br><span class="line">-F            利用<span class="built_in">read</span>对scaffold中的gap进行填补，默认不执行</span><br><span class="line">-u            构建scaffold前不屏蔽高覆盖度的contig，这里高频率覆盖度指平均contig覆盖深度的2倍。默认屏蔽</span><br><span class="line">-G    INT     估计gap的大小和实际补gap的大小的差异，默认值为50bp。</span><br><span class="line">-L            用于构建scaffold的contig的最短长度，默认为：Kmer参数值 ×2</span><br></pre></td></tr></table></figure>

<p><font color="blue"><strong>全局配置</strong></font></p>
<p><code>max_rd_len</code></p>
<p><font color="blue"><strong>文库配置</strong></font></p>
<p>每个文库的配置以<code>[LIB]</code>开头，主要指定输入文件的路径，支持多种格式的输入文件，用不同的前缀表示， <code>q</code>代表输入序列为fastq格式；<code>f</code>代笔输入序列为fasta格式，<code>b</code>代表输入文件为bam格式，对于双端数据，分别用后缀<code>1</code>和<code>2</code>表示R1端和R2端的reads。</p>
<p><font color="blue"><strong>主要参数</strong></font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-avg_ins    This value indicates the average insert size of this library or the peak value position <span class="keyword">in</span> the <span class="string">&quot;insert size distribution figure?&quot;</span>. <span class="comment">#文库平均插入长度(或取插入大小分布图中的峰值位置)，根据建库情况设置。 </span></span><br><span class="line"></span><br><span class="line">-reverse_seq    This option takes value 0 or 1. It tells the assembler <span class="keyword">if</span> the <span class="built_in">read</span> sequences need to be complementarily reversed. Illumima GA produces two types of paired-end libraries: a) <span class="string">&quot;forward-reverse&quot;</span>, generated from fragmented DNA ends with typical <span class="string">&quot;insert size less than 500 bp&quot;</span>; b) <span class="string">&quot;reverse-forward&quot;</span>, generated from <span class="string">&quot;circularizing libraries&quot;</span> with typical <span class="string">&quot;insert size greater than 2 Kb&quot;</span>. The parameter <span class="string">&quot;reverse_seq&quot;</span> should be <span class="built_in">set</span> to indicate this: 0, forward-reverse; 1, reverse-forward. </span><br><span class="line"></span><br><span class="line">-asm_flags    This indicator decides <span class="keyword">in</span> <span class="built_in">which</span> part(s) the reads are used. It takes value 1(only contig assembly), 2 (only scaffold assembly), <span class="string">&quot;3(both contig and scaffold assembly)&quot;</span><span class="string">&quot;, or 4 (only gap closure). </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-rd_len_cutof    The assembler will &quot;</span>cut the reads from the current library to this length<span class="string">&quot;.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-rank    It takes integer values and decides in which &quot;</span>order the reads are used <span class="keyword">for</span> scaffold assembly<span class="string">&quot;. Libraries with the same &quot;</span>rank<span class="string">&quot; are used at the same time during scaffold assembly.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-pair_num_cutoff    This parameter is the cutoff value of pair number for a &quot;</span>reliable connection<span class="string">&quot; between two contigs or pre-scaffolds. The minimum number for &quot;</span>paired-end reads and mate-pair reads is 3 and 5 respectively<span class="string">&quot;. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-map_len    This takes effect in the &quot;</span>map<span class="string">&quot; step and is the minimun alignment length between a read and a contig required for a reliable read location. The minimum length for &quot;</span>paired-end reads and mate-pair reads is 32 and 35 respectively<span class="string">&quot;.</span></span><br></pre></td></tr></table></figure>

<p><font color="blue"><strong>实例</strong></font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">max_rd_len=100</span><br><span class="line">[LIB]</span><br><span class="line"><span class="comment">#avg_ins 文库插入片段的平均长度，在实际设置时，可以参考文库size分布图，取峰值即可???</span></span><br><span class="line">avg_ins=200</span><br><span class="line"><span class="comment">#reverse_seq 是否需要将序列反向互补，pair-end数据，不需反向互补，设置为0；mate-pair需要设置为1</span></span><br><span class="line">reverse_seq=0</span><br><span class="line"><span class="comment">#asm_flags 1只组装contig. 2只组装scaffold,3同时组装contig和scaffold,4只补gap</span></span><br><span class="line">asm_flags=3</span><br><span class="line"><span class="comment">#序列长度阈值，作用和max_rd_len相同，大于该长度的序列会被切除到该长度</span></span><br><span class="line">rd_len_cutoff=100</span><br><span class="line"><span class="comment">#设置不同文库数据的优先级顺序，取值范围为整数，rank值相同的多个文库，在组装scaffold时，会同时使用。</span></span><br><span class="line">rank=1</span><br><span class="line">q1=fastq1_read_1.fq</span><br><span class="line">q2=fastq1_read_2.fq</span><br><span class="line">-pair_num_cutoff</span><br><span class="line"><span class="comment">#contig或者scaffold之前的最小overlap个数，pair-end数据默认为3；mate-paird数据默认为5</span></span><br><span class="line">-map_len</span><br><span class="line"><span class="comment">#比对长度的最小阈值，pair-end数据默认为32；mate-pair数据默认为35</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">SOAPdenovo-63mer all -s config_file -K 63 -R -o graph_prefix</span><br></pre></td></tr></table></figure>



<h1 id="使用方法及示例"><a href="#使用方法及示例" class="headerlink" title="使用方法及示例"></a>使用方法及示例</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#（1）示例</span></span><br><span class="line">SOAPdenovo all -s HCB.lib -K 25 -d -o <span class="built_in">test</span></span><br><span class="line"><span class="comment">#（2）配置文件 configFile</span></span><br><span class="line"><span class="comment">#maximal read length （read的最大长度），该值【一般设置的比实际read读长稍微短一些？】，截去测序最后的部分，具体长度看测序质量</span></span><br><span class="line">max_rd_len=50    </span><br><span class="line"></span><br><span class="line"><span class="comment">#[LIB]文库信息以此开头</span></span><br><span class="line"></span><br><span class="line">avg_ins=200<span class="comment">#?</span></span><br><span class="line"></span><br><span class="line">reverse_seq=0</span><br><span class="line"><span class="comment">#序列是否需反转，目前测序技术，插入片段大于等于2k的采用了环化，对于插入长度大于等于2k文库，序列需要反转，reverse_seq＝1，小片段设为0</span></span><br><span class="line"></span><br><span class="line">asm_flags=3</span><br><span class="line"><span class="comment">#该文库中的read序列在组装的哪些过程（contig/scaff/fill）中用到</span></span><br><span class="line"><span class="comment">#短插入片段(&lt;2K)的设为3，同时构建contig和scaffold，长插入片段(&gt;=2k)设为2，不构建contig，只构建scaffold，454single 长reads只用于补洞。</span></span><br><span class="line"></span><br><span class="line">rank=1</span><br><span class="line"><span class="comment">#该值取整数，决定了reads用于构建scaffold的次序，值越低数据越优先用于构建scaffold。【相同rank的文库数据会同时用于组装scaffold】。一般将短插入片段设为1；2k设为2；5k设为3；10k设为4；当【某个档的数据量较大】时可以将其分为多个档，同样当【某档数据量不足够】时，可以将多个档的数据合在一起构建scaffold?。这里说的数据量够与不够是从该档的测序覆盖度和物理覆盖度两个方面考虑。</span></span><br><span class="line"></span><br><span class="line">pair_num_cutoff=3</span><br><span class="line"><span class="comment">#【可选参数】，该参数规定连接两个contig 或者是pre-scaffold 的可信连接的阈值，当连接数大于该值，连接才算有效。短插入片段(&lt;2k)默认值为3，长插入长度序列默认值为5</span></span><br><span class="line"></span><br><span class="line">map_len=32</span><br><span class="line"><span class="comment">#map_len该参数规定在map过程中 reads和contig的比对长度必须达到该值（比对不容mismacth和gap），该比对才能作为一个可信的比对。可选参数，短插入片段(&lt;2k)一般设置为32，长插入片段设置为35，默认值是K＋2。</span></span><br><span class="line"></span><br><span class="line">q1=/path/LIBNAMEA/fastq_read_1.fq<span class="comment">#read 1的fastq</span></span><br><span class="line">q2=/path/LIBNAMEA/fastq_read_2.fq<span class="comment">#read 2的fastq【注意顺序】</span></span><br><span class="line">f1=/path/LIBNAMEA/fasta_read_1.fa<span class="comment">#read 1的fa</span></span><br><span class="line">f2=/path/LIBNAMEA/fasta_read_2.fa</span><br><span class="line">q=/path/LIBNAMEA/fastq_read_single.fq<span class="comment">#单向测序fastq</span></span><br><span class="line">f=/path/LIBNAMEA/fasta_read_single.fa<span class="comment">#单向测序fa</span></span><br><span class="line">p=/path/LIBNAMEA/pairs_in_one_file.fa<span class="comment">#双向测序一个fasta</span></span><br></pre></td></tr></table></figure>





<h1 id="输出文件及说明"><a href="#输出文件及说明" class="headerlink" title="输出文件及说明"></a>输出文件及说明</h1><p>SOAPdenovo 分四部分别对应的输出文件：<br>  ● pregraph  生成7个文件 *.kmerFreq  *.edge  *.preArc  *.markOnEdge  *.path  *.vertex  *.preGraphBasic<br>  ● contig       生成4个文件 <font color="red"> ***.contig**</font>  *.ContigIndex  *.updated.edge  *.Arc<br>  ● map          生成3个文件 *.readOnContig  *.peGrads  *.readInGap<br>  ● scaff          生成6个文件 *.newContigIndex  *.links  *.scaf  *.scaf_gap  <font color="red"> ***.scafSeq**</font>  *.gapSeq</p>
<p>*.kmerFreq             #每行显示一个数，这个数是kmer值出现的频率等于行号的kmer个数。</p>
<p><font color="red"><em><strong>.contig</strong></em></font>：没有使用mate pair 信息的contig sequences<br><font color="red"><strong>.scafSeq</strong></font>：fasta格式scaffold序列文件，contig之间的gap用N填充；<br><strong>对于得到的.scafSeq文件还需要用<font color="red">GapCloser</font>去合并其中的gap，最后的contig文件则是对补洞之后的scaffold文件通过打断N区的方法得到?</strong><br>以上两个文件是组装结果中最主要的输出。</p>
<p><font color="red"><em><strong>.scaf</strong></em></font>：包括scaffold中contig的详细信息；<br>在*scaffold行<strong>中包括scaffold名字、contig长度和该scaffold长度。<br>在</strong>contig行**包括contig名字、contig在scaffold上的起始位置、正反链、长度和contig间的链接信息<br><font color="red"> *.links</font>：contig间的pair-end连接信息<br><font color="red"> *.readOnContig</font>：reads在contig上的位置<br><font color="red"> *.peGrads</font>： 通过调整本文件中参数来显示构建scaffold所用到的插入片段库的个数，总共用到的read数，最长read，每个库对应的哪些reads，rank设置，pair_num_cutoff设置。例如：</p>
<blockquote>
<p>grads&amp;num: 10   522083934       70<br>323     104577616       1       3<br>334     180770522       1       3<br>345     226070520       1       3<br>486     361955834       2       3<br>2200    392088076       3       5<br>2290    422272580       3       5<br>2400    445522690       3       5<br>4870    475666064       4       5<br>9000    511030930       5       8<br>9110    522083934       5       5</p>
<p>该文件中共分成4列。<strong>组装的配置文件中有n个文库，该文件则有n+1行，且按照文库大小顺序排列。</strong><br><strong>第1行</strong>，二三四列分别是所用文库数目，reads总数和<font color="red">组装中用到的最长的reads长度？</font>。<br><strong>第2行</strong>，四列分别是文库大小，文库reads数目，文库reads的rank等级和pair_num_cutoff。<br><strong>第3～n+1行</strong>，四列分别是文库大小，文库reads数目加上前面文库中的reads总数，文库reads的rank等级pair_num_cutoff。#contig或者scaffold之前的最小overlap个数，pair-end数据默认为3；mate-paird数据默认为5,若配置文件没设置pair_num_cutoff，即使用默认参数0。</p>
</blockquote>
<p><strong>对于SOAPdenovo的每个步骤都有日志文件输出，要保存好日志文件，日志文件中包含有很多有用的信息。</strong></p>
<p>SOAPdenovo日志输出说明：</p>
<p>1）<font color="red">pregraph.log</font>:  其中有很多的统计信息，包括构建debruijn-graph所用reads数目，构图产生多少uniq的kmer以及设置-d参数后去除了多少kmer。</p>
<blockquote>
<p>-R            利用read鉴别短的重复序列，默认值不进行此操作</p>
<p>-d    INT     去除频数不大于该值的k-mer，默认值为0</p>
</blockquote>
<p>在pregraph中，可选参数有 –R –K –d  结果如：<br>5467781332 <strong>nodes</strong> allocated, 70662750348 <strong>kmer</strong> <strong>in reads</strong>, 70662750348 <strong>kmer processed</strong><br>3283081670 <strong>kmer removed</strong><br>其中Kmer 数取决于k值和数据量，nodes数即特异性kmer数，当nodes数目过高<strong>（一般和基因组大小差不多大小），可能是数据的错误率比较高，也可能是存在杂合</strong>。若nodes数目偏小，且kmer数目多，则基因组重复度较高。</p>
<p>k值的选取，当数据量充足（&gt;=40X），<strong>植物基因组一般采用大kmer效果较好</strong>，而<strong>动物基因组k值一般取27和29足够</strong>。kmer removed表示的 <strong>–d 参数所去除的低频的kmer</strong>。</p>
<p>2）<font color="red">contig.log</font>: contig 中，可选参数 –R –D –M，注，-R 参数的选定，必须pregraph和contig中同时选择才有效。</p>
<blockquote>
<p>-R            利用read鉴别短的重复序列，默认值不进行此操作</p>
</blockquote>
<p>结果例子：<br>16430183 pairs found, 2334584 pairs of paths compared, 1674493 pairs merged<br><strong>merged的数量可作为估计杂合以及测序错误的程度</strong>。<br>sum up 1932549703bp, with average length 1170<br>the longest is 36165bp, contig N50 is 2871 bp,contig N90 is 553 bp<br>相关统计信息，通常<strong>植物基因组的contig N90在200bp左右</strong>，若<strong>N90高于200bp则该基因组scaffold构建不会有太大问题</strong>。动物基因组scaffold构建很少有出问题的。</p>
<p>3）<font color="red">map.log</font>:<br>Output 415219610 out of 1956217742 (21.2)% reads in gaps<br><strong>1661094582 out of 1956217742 (84.9)% reads mapped to contigs</strong><br>一般情况下，reads in gap比例和map to contig 比例<strong>总和大于1（21.2%+84.9%）</strong>。因为reads map到多个地方都被统计。当map to contig的比例很高（80%左右时），但组装效果不好可能是重复序列较多。reads in gap比例较高（大于40%）是因为基因组组装的较碎gap区域较多。<br>map_len 默认值=K+5，短插入片段(&lt;2k)一般设置为32，长插入片段为35。取值为max{K+5,map_len}</p>
<p>4）<font color="red">scaff.log</font>:<br>average contig coverage is 23, 5832270 contig masked<br>构建scaffold是对高频覆盖的contig进行屏蔽（即<strong>频率高于average contig coverage的两倍的contig不用于构建scaffold(average-dep 2倍以上repeat sequences)?<strong>），从这里可以看出组装的基因组一定的重复情况。<br><strong>estimated PE size 162</strong>, by 40034765 pairs<br>on contigs longer than 173, 38257479 pairs found,SD=8, insert_size estimated: 163<br><font color="green"><strong>173 是配置文件文库insertsize</strong></font>，<font color="green"><strong>163 是reads  map到contig上的距离的估计值</strong></font>，8是分布标准偏差。一般考虑比对上去的pair数目和SD值。若pair对数很多且SD值很小？（小片段文库数据不超过三位数，大片段文库数据不超过500），<font color="green">一般可将配置文件中</font></strong>文库插入片段值修改</strong>为对短插入片段文库（&lt;1k）的大小<strong>估计值<strong>，下次</strong>组装<strong>以及</strong>补洞<strong>时应根据估计值对原配置文件中的</strong>insertsize修正**。对于大片段文库（&gt;=2K），因为是把reads map到contig上，若最长contig较短，可能找不到成pair比对上去的reads，无法估计文库大小，需要自己将大片段一级一级的map到前一级的组装结果上，然后再分析大片段文库的插入片段大小。注，</strong>需要调整insertsize时，只需修改* .peGrads文件中第一列，后删除*.links文件，重跑scaff即可*<em>。即构建scaffold时，主要是根据</em>.links文件的信息进行连接。<br>Cutoff for number of pairs to make a reliable connection: 3<br>1124104 weak connects removed (there were 4773564 active cnnects))<br>Cutoff for number是在配置文件中设的pair_num_cutoff值，weak connects是低于这个值被认定为无效的连接数，active connects是满足cutoff的连接数，根据这个数值可对pair_num_cutoff做调整<br>Picked  25241 subgraphs,4 have conflicting connections<br>conflicting connections 是表示构建scaffold时的矛盾数，矛盾数比较高（&gt;100）时，可根据前面的有效连接数，适当提高pair_num_cutoff值，即提高scaffold连接要求的最少关系数<br>182483 scaffolds&amp;singleton sum up 1990259817bp, with average length 10906<br>the longest is 6561520bp,scaffold N50 is 836795 bp, scaffold N90 is 157667 bp<br>scaffold 统计信息，将是根据rank分梯度的统计<br>Done with 13301 scaffolds, 2161915 gaps finished, 2527441 gaps overall<br><strong>-F 参数补洞的统计信息。</strong></p>
<blockquote>
<p>发现scafstatistics 文件中的sca N50是整个scafSeq文件中的N50（包括不存在于scaf内的contig）。log文件中的sca N50只包括scaf 中的N50.</p>
<p>sacf.seq中可能有N，也可能无N。大部分有</p>
<p>gap finish？</p>
</blockquote>
<h1 id="参数调整"><a href="#参数调整" class="headerlink" title="参数调整"></a>参数调整</h1><p>组装时需调整的参数，主要分两种：</p>
<p>一种是脚本中参数改动：如调整  -K  -R  -d  -D  -M<br>-K 值一般与基因组的特性和数据量相关，目前用到的SOAPdenovo软件主要有两个版本，SOAPdenovo-63mer是可使用大kmer组装，K值范围13-63。<br>【<strong>经验</strong>】：植物基因组组装采用大kmer效果会比较好（要求短片段reads长度75bp），动物基因组很少有用到大kmer后有明显改进效果的，且<strong>动物基因组组装K值一般设置为27和29较多</strong>。</p>
<p><font color="red"><strong>组装杂合子基因组的K-mer值应该小一点；组装含有高repeats基因组且要求其有高的测序深度和长的reads,的K-mer应该大一点。</strong></font></p>
<p>-R参数，对于<font color="green">动物基因组R参数一般不设置</font>，<font color="red"><strong>植物基因组</strong>由于<strong>较多的repeat区</strong>则<strong>设置R参数</strong>后效果更好</font>。注意<strong>设置-R时，一般使用-M 的默认值</strong>。（熊猫基因组组装时得出的结论）</p>
<p>-M 参数，0-3,<strong>默认值1</strong>。一般杂合率为千分之几就设为几。熊猫基因组组装时-M 2 。</p>
<p>-d 参数，对于没有纠错，没有处理的质量又较差的原始数据，kmer频数为1数据较多的组装，<font color="red"><strong>设置为-d 1 足够</strong></font>。对于处理过或是测序质量较好数据可不设置。数据量较多时，也可设置-d 去除部分质量稍差数据。</p>
<p>-D 参数，默认为1，一般不用另行设置。</p>
<p>第二种，从<strong>map</strong>过程去调节参数。可以<font color="red"> 调整配置文件map_len的值和调整文件 * .peGrads  </font>。<br>当<strong>文库插入片段分布图</strong>中文库大小与<strong>实验给出的文库大小</strong><font color="red">差异很大</font>，<font color="red"><em><em>调整</em>.peGrad</em>*s</font>文件中的插入片段大小。</p>
<p>根据每一档数据的数据量去调整文库的<strong>rank等级</strong>。</p>
<p>当该文库的数据量很多或者是在构建scaffold的过程中的冲突数很多时，可是适当的调大第四列的<strong>pair_num_cutoff</strong>，把条件设置的更严。</p>
<h1 id="内存估计"><a href="#内存估计" class="headerlink" title="内存估计"></a>内存估计</h1><p>SOAPdenovo四个步骤消耗的内存不一样</p>
<p>第一步消耗内存最多，使用没有纠错的的reads，(<font color="blue"> <strong>K&lt;=31**</strong></font>)第一步消耗的内存在<font color="blue"><strong>基因组大小80－100倍</strong>左右</font>，<font color="blue">纠过错在40－50倍**左右</font></p>
<p>第二步相对消耗内存会少很多</p>
<p>第三步消耗内存仅次于第一步，在第一步的一半左右</p>
<p>第四步消耗的内存也会比较少</p>
<p>对于CPU的使用，默认是8个，如果申请内存时申请一个计算节点的所有内存, CPU就设置为该计算节点的CPU个数充分利用计算资源，如果仅申请一个节点的部分内存则根据实际情况考虑。</p>
<p>对于<font color="blue"><strong>大kemr(K&gt;31)</strong></font>其内存使用是<font color="blue">**(k&lt;=31)**</font>的<font color="blue"><strong>1.5倍</strong></font>左右，有时甚至更多，要充分估计内存使用，在第一次运行时考虑不能太保守。</p>
<h1 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h1><p>1）配置文件reads存储路径错误<br>只输出日志文件。<br>pregraph.log中的错误信息：“Cannot open /path/LIBNAMEA/fastq_read_1.fq. Now exit to system…”<br>2）-g 后所跟参数与pregraph（第一步） -o  后所跟参数名不一致【**-o对应后面的-g**】<br>contig  map  scaff 这三个步骤都只是输出日志文件。<br><font color="green">contig.log</font>错误信息：“Cannot open *.preGraphBasic. Now exit to system…”<br><font color="green">map.log</font>错误信息：“Cannot open *.contig. Now exit to system…”<br><font color="green">scaff.log</font>错误信息：“Cannot open *.preGraphBasic. Now exit to system…”<br>3）<font color="blue">从map开始重新跑时，需要删除 *.links文件</font>，否则会生成core文件，程序退出。</p>
<hr>
<h1 id="Github-Readme-md"><a href="#Github-Readme-md" class="headerlink" title="Github-Readme.md"></a>Github-Readme.md</h1><h2 id="Configuration-file"><a href="#Configuration-file" class="headerlink" title="Configuration file"></a>Configuration file</h2><p>For big genome projects with deep sequencing, <font color="red">the data is usually organized as <strong>multiple read sequence files</strong> generated from <strong>multiple libraries</strong></font>. The configuration file: where? information? example.config</p>
<p>The configuration file has a section for <font color="red"><strong>global information</strong></font>, and then <font color="red"><strong>multiple library sections</strong></font>. Right now only “max_rd_len” is included in the global information section. Any read longer than max_rd_len will be cut to this length.</p>
<p>The library information and the information of sequencing data generated from the library should be organized in the corresponding library section. <font color="red"><strong>Each library section starts with tag [LIB]</strong></font> and includes the following items:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-avg_ins</span><br><span class="line">-reverse_seq</span><br><span class="line">-asm_flags</span><br><span class="line">-rd_len_cutof</span><br><span class="line">-rank</span><br><span class="line">-pair_num_cutoff</span><br><span class="line">-map_len</span><br></pre></td></tr></table></figure>



<p>The assembler accepts read file in three kinds of formats: <font color="green">FASTA, FASTQ and BAM</font>. Mate-pair relationship could be indicated in two ways: two sequence files with reads in the same order belonging to a pair, or two adjacent reads in a single file (FASTA only) belonging to a pair. If a read in <strong>bam</strong> file <strong>fails</strong> platform/vendor <strong>quality checks</strong>(the flag field 0x0200 is set), itself and it’s <strong>paired read</strong> would be <strong>ignored</strong>.</p>
<p>All the above items in each library section are optional. The assembler assigns default values for most of them. <strong>If you are not sure how to set a parameter, you can remove it from your configuration file</strong>.</p>
<h2 id="Get-started"><a href="#Get-started" class="headerlink" title="Get started"></a>Get started</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;one step&quot;</span></span><br><span class="line">SOAPdenvo all -s config_file -K 63 -R -o graph_prefix 1&gt;ass.log 2&gt;ass.err</span><br><span class="line"><span class="comment">#-R            利用read鉴别短的重复序列，默认值不进行此操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#step by step </span></span><br><span class="line"><span class="string">&quot;step1:&quot;</span></span><br><span class="line">SOAPdenvo pregraph -s config_file -K 63 -R -o graph_prefix 1&gt;pregraph.log 2&gt;pregraph.err</span><br><span class="line"><span class="string">&quot;OR&quot;</span></span><br><span class="line">SOAPdenvo sparse_pregraph -s config_file -K 63 -z 5000000000 -R -o graph_prefix 1&gt;pregraph.log 2&gt;pregraph.err</span><br><span class="line"><span class="comment">#-z genomize(required):estimated genome size</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;step2:&quot;</span></span><br><span class="line">SOAPdenvo contig -g graph_prefix -R 1&gt;contig.log 2&gt;contig.err</span><br><span class="line"><span class="comment">#-g    STR     输入文件的文件名前缀</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;step3:&quot;</span></span><br><span class="line">SOAPdenvo map -s config_file -g graph_prefix 1&gt;map.log 2&gt;map.err</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;step4:&quot;</span></span><br><span class="line">SOAPdenvo scaff -g graph_prefix -F 1&gt;scaff.log 2&gt;scaff.err</span><br><span class="line"><span class="comment">#-F            利用read对scaffold中的gap进行填补，默认不执行       </span></span><br></pre></td></tr></table></figure>



<h2 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h2><h3 id="Options-for-all-pregraph-contig-map-scaff"><a href="#Options-for-all-pregraph-contig-map-scaff" class="headerlink" title="Options for all (pregraph-contig-map-scaff)"></a>Options for all (<font color="red">pregraph-contig-map-scaff</font>)</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;-s&quot;</span>    configFile: the config file of solexa reads</span><br><span class="line"><span class="string">&quot;-o&quot;</span>     outputGraph: prefix of <span class="string">&quot;output graph file name&quot;</span></span><br><span class="line"><span class="string">&quot;-K&quot;</span>        kmer(min 13, max 63/127): kmer size, [23]</span><br><span class="line"><span class="string">&quot;-p&quot;</span>        n_cpu: number of cpu <span class="keyword">for</span> use, [8]</span><br><span class="line"><span class="string">&quot;-a?&quot;</span>        initMemoryAssumption: memory assumption initialized to avoid further reallocation, unit G, [0]</span><br><span class="line"><span class="string">&quot;-d&quot;</span>        KmerFreqCutoff: kmers with frequency no larger than KmerFreqCutoff will be deleted, [0]	INT     去除频数不大于该值的k-mer，默认值为0</span><br><span class="line"><span class="string">&quot;-R&quot;</span> (optional)  resolve repeats by reads, [NO]</span><br><span class="line"><span class="string">&quot;-D&quot;</span>        EdgeCovCutoff: edges with coverage no larger than EdgeCovCutoff will be deleted, [1]	INT     去除频数不大于该值的由k-mer连接的边，默认值为1，即该边上每个点的频数都小于等于1时才去除</span><br><span class="line"><span class="string">&quot;-M&quot;</span>        mergeLevel(min 0, max 3): the strength of merging similar sequences during contiging, [1]	INT     连接contig时合并相似序列的等级，默认值为1，最大值3。</span><br><span class="line">-m        max k when using multi kmer</span><br><span class="line">-e        weight to filter arc when linearize two edges(default 0)</span><br><span class="line">-r (optional)  keep available <span class="built_in">read</span>(*.<span class="built_in">read</span>)</span><br><span class="line">-E (optional)  merge clean bubble before iterate</span><br><span class="line">-f (optional)  output gap related reads <span class="keyword">in</span> map step <span class="keyword">for</span> using SRkgf to fill gap, [NO]</span><br><span class="line">-k        kmer_R2C(min 13, max 63): kmer size used <span class="keyword">for</span> mapping <span class="built_in">read</span> to contig, [K]</span><br><span class="line">-F (optional)  fill gaps <span class="keyword">in</span> scaffold, [NO]利用<span class="built_in">read</span>对scaffold中的gap进行填补，默认不执行</span><br><span class="line">-u (optional)  un-mask contigs with high/low coverage before scaffolding, [mask]构建scaffold前不屏蔽高覆盖度的contig，这里高频率覆盖度指平均contig覆盖深度的2倍。默认屏蔽</span><br><span class="line">-w (optional)  keep contigs weakly connected to other contigs <span class="keyword">in</span> scaffold, [NO]</span><br><span class="line">-G        gapLenDiff: allowed length difference between estimated and filled gap, [50]INT     估计gap的大小和实际补gap的大小的差异，默认值为50bp。</span><br><span class="line">-L        minContigLen: shortest contig <span class="keyword">for</span> scaffolding, [K+2]用于构建scaffold的contig的最短长度，默认为：Kmer参数值 ×2</span><br><span class="line">-c      minContigCvg: <span class="string">&quot;minimum contig coverage&quot;</span> (c*avgCvg), contigs shorter than 100bp with coverage smaller than c*avgCvg will be masked before scaffolding unless -u is <span class="built_in">set</span>, [0.1]</span><br><span class="line">-C      maxContigCvg: <span class="string">&quot;maximum contig coverage&quot;</span> (C*avgCvg), contigs with coverage larger than C*avgCvg or contigs shorter than 100bp with coverage larger than 0.8*C*avgCvg will be masked before scaffolding unless -u is <span class="built_in">set</span>, [2]</span><br><span class="line">-b      insertSizeUpperBound: (b*avg_ins) will be used as upper bound of insert size <span class="keyword">for</span> large insert size ( &gt; 1000) when handling pair-end connections between contigs <span class="keyword">if</span> b is <span class="built_in">set</span> to larger than 1, [1.5]</span><br><span class="line">-B      bubbleCoverage: remove contig with lower cvoerage <span class="keyword">in</span> bubble structure <span class="keyword">if</span> both contigs<span class="string">&#x27; coverage are smaller than bubbleCoverage*avgCvg, [0.6]</span></span><br><span class="line"><span class="string">-N        genomeSize: genome size for statistics, [0]</span></span><br><span class="line"><span class="string">-V (optional)  output visualization information of assembly, [NO]</span></span><br></pre></td></tr></table></figure>

<h3 id="Options-for-sparse-pregraph"><a href="#Options-for-sparse-pregraph" class="headerlink" title="Options for sparse_pregraph"></a>Options for sparse_pregraph</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Usage: ./SOAPdenovo2 sparse_pregraph -s configFile -K kmer -z genomeSize -o outputGraph [-g maxKmerEdgeLength -d kmerFreqCutoff -e kmerEdgeFreqCutoff -R -r runMode -p n_cpu]</span><br><span class="line">  -s      configFile: the config file of solexa reads</span><br><span class="line">  -K         kmer(min 13, max 63/127): kmer size, [23]</span><br><span class="line">  -g         maxKmerEdgeLength(min 1, max 25): number of skipped intermediate kmers, [15]</span><br><span class="line">  <span class="string">&quot;-z&quot;</span>         genomeSize(mandatory): estimated genome size</span><br><span class="line">  <span class="string">&quot;-d&quot;</span>         kmerFreqCutoff: delete kmers with frequency no larger than,[1]</span><br><span class="line">  -e         kmerEdgeFreqCutoff: delete kmers<span class="string">&#x27; related edge with frequency no larger than [1]</span></span><br><span class="line"><span class="string">  -R (optional)   output extra information for resolving repeats in contig step, [NO]</span></span><br><span class="line"><span class="string">  -r         runMode: 0 build graph &amp; build edge and preArc, 1 load graph by prefix &amp; build edge and preArc, 2 build graph only, 3 build edges only, 4 build preArcs only [0]</span></span><br><span class="line"><span class="string">  &quot;-p&quot;         n_cpu: number of cpu for use,[8]</span></span><br><span class="line"><span class="string">  -o         outputGraph: prefix of output graph file name</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">contigs：</span><br><span class="line">      -g  &lt;string&gt;      输入graph file文件名前缀 </span><br><span class="line">    -R  (optional)    移除repeats，使用pregraph步骤中产生的结果，如果参数-R在pregraph步骤中被设置的话，默认[NO]</span><br><span class="line">    -D  &lt;int&gt;         去除频数不大于该值（edgeCovCutoff）的由k-mer连接的边，默认值[1]，即该边上每个点的频数都小于等于1时才去除。edges with coverage no larger than EdgeCovCutoff will be deleted, [1] <span class="comment">#最小化错误测序带来的影响</span></span><br><span class="line">    -M  &lt;int&gt;         在contiging操作时，合并相似序列的强度，默认值为[1]，最小值0，最大值3。<span class="comment">#deal with heterozygosis</span></span><br><span class="line">    -e  &lt;int&gt;         两边缘之间的弧的权重大于该值（arcWeight），将被线性化，默认值[0]</span><br><span class="line">    -m  &lt;int&gt;         最大的kmer size（max 127）用于multi-kmer，默认[NO]</span><br><span class="line">    -E  (optional)    在iterate迭代之前，合并clean bubble功能，仅在当使用multi-kmer时且设置-M参数，默认[NO]</span><br><span class="line"> </span><br><span class="line">map：</span><br><span class="line">    -g  &lt;string&gt;      输入graph file文件名前缀 </span><br><span class="line">    -k  &lt;int&gt;         该值（kmer_R2C）是kmer size用于mapping reads到contigs上时的值，默认值[K]</span><br><span class="line">    -f  (optional)    在map那一步中，对于使用SRkgf去填充gap，输出与gap相关的reads,默认[NO]</span><br><span class="line"> </span><br><span class="line">scaffold：</span><br><span class="line">      -F  (optional)    利用<span class="built_in">read</span>对scaffold中的gap进行填补，默认[NO]</span><br><span class="line">    -u  (optional)    构建scaffolding前不屏蔽高/低覆盖度的contigs，这里高频率覆盖度指平均contig覆盖深度的2倍。默认[mask]屏蔽</span><br><span class="line">    -w  (optional)    在scaffold中，保持contigs弱连接于其他contigs，默认[NO]</span><br><span class="line">    -G  &lt;int&gt;         估计gap的大小和实际补gap的大小的差异值，默认值[50]bp。</span><br><span class="line">    -L  &lt;int&gt;         用于构建scaffold的contig的最短长度(minContigLen)，默认为：[Kmer参数值+2]</span><br><span class="line">    -c  &lt;<span class="built_in">float</span>&gt;       在scaffolding之前，contigs小于100bp，且覆盖率小于该最小contig覆盖率（c*avgCvg），将被屏蔽，除非参数-u已设定，默认值[0.1]</span><br><span class="line">    -C  &lt;<span class="built_in">float</span>&gt;       在scaffolding之前，contigs覆盖率大于该最大contigs覆盖率（C*avgCvg），或者contigs小于100bp且覆盖率大于0.8*（C*avgCvg），将被屏蔽，除非参数-u已设定，默认值[2]</span><br><span class="line">    -b  &lt;<span class="built_in">float</span>&gt;       当处理contigs间的pair-end连接时，如果参数-b&gt;1，该插入片段的上限值（b*avg_ins）将被用来作为大的插入片段（&gt;1000）的上限，默认值[1.5]</span><br><span class="line">    -B  &lt;<span class="built_in">float</span>&gt;       如果两个contigs的覆盖率都小于bubble覆盖率（bubbleCoverage）乘以contigs平均覆盖率（bubbleCoverage*avgCvg），则去除在bubble结构中的低覆盖率contig，默认值[0.6]</span><br><span class="line">    -N  &lt;int&gt;         统计基因组大小，默认值[0]</span><br><span class="line">    -V  (optional)    输出相关信息为了可视化组装，默认[NO]</span><br></pre></td></tr></table></figure>



<h2 id="Output-files"><a href="#Output-files" class="headerlink" title="Output files"></a>Output files</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. <span class="string">&quot;*.contig&quot;</span></span><br><span class="line">  contig sequences without using mate pair information.</span><br><span class="line">b. <span class="string">&quot;*.scafSeq&quot;</span></span><br><span class="line">  scaffold sequences (final contig sequences can be extracted by breaking down scaffold sequences at gap regions).</span><br></pre></td></tr></table></figure>



<h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><h3 id="How-to-set-K-mer-size"><a href="#How-to-set-K-mer-size" class="headerlink" title="How to set K-mer size?"></a>How to set K-mer size?</h3><p>The program accepts odd numbers between 13 and 31? <strong>Larger K-mers would have higher rate of uniqueness in the genome and would make the graph simpler, but it requires deep sequencing depth and longer read length to guarantee the overlap at any genomic location.</strong> <font color="red"><strong>Balance?</strong></font></p>
<p>The <strong>sparse_pregraph</strong> module usually needs <strong>2-10bp smaller kmer</strong> length to achieve the same performance as the original <strong>pregraph</strong> module. <font color="red"><strong>Difference?</strong></font></p>
<h3 id="How-to-set-genome-size-z-for-sparse-pregraph-module"><a href="#How-to-set-genome-size-z-for-sparse-pregraph-module" class="headerlink" title="How to set genome size(-z) for sparse_pregraph module?"></a>How to set genome size(-z) for sparse_pregraph module?</h3><p>The -z parameter for sparse pregraph should be set <font color="red"><strong>a litter larger than the real genome size</strong></font>, it is used to allocate memory.</p>
<h3 id="How-to-set-library-rank"><a href="#How-to-set-library-rank" class="headerlink" title="How to set library rank?"></a>How to set library rank?</h3><p>SOAPdenovo will <font color="red">use the <strong>pair-end libraries</strong> with <strong>insert size</strong> from <strong>smaller to larger</strong> to <strong>construct</strong> scaffolds</font>. Libraries with the same rank would be used at the same time. For example, in a dataset of a human genome, we set <strong><font color="red">five ranks</font> for five libraries with insert size 200-bp, 500-bp, 2-Kb, 5-Kb and 10-Kb</strong>, separately. It is desired that the pairs in each rank provide adequate physical coverage of the genome.</p>
<h2 id="APPENDIX-A-an-example-config"><a href="#APPENDIX-A-an-example-config" class="headerlink" title="APPENDIX A: an example.config"></a>APPENDIX A: an example.config</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#maximal read length</span></span><br><span class="line">max_rd_len=100</span><br><span class="line"><span class="string">&quot;[LIB]&quot;</span></span><br><span class="line"><span class="comment">#average insert size</span></span><br><span class="line">avg_ins=200</span><br><span class="line"><span class="comment">#if sequence needs to be reversed</span></span><br><span class="line">reverse_seq=0</span><br><span class="line"><span class="comment">#in which part(s) the reads are used</span></span><br><span class="line">asm_flags=3</span><br><span class="line"><span class="comment">#use only first 100 bps of each read</span></span><br><span class="line">rd_len_cutoff=100</span><br><span class="line"><span class="comment">#in which order the reads are used while scaffolding</span></span><br><span class="line">rank=1</span><br><span class="line"><span class="comment"># cutoff of pair number for a reliable connection (at least 3 for short insert size)</span></span><br><span class="line">pair_num_cutoff=3</span><br><span class="line"><span class="comment">#minimum aligned length to contigs for a reliable read location (at least 32 for short insert size)</span></span><br><span class="line">map_len=32</span><br><span class="line"><span class="comment">#a pair of fastq file, read 1 file should always be followed by read 2 file</span></span><br><span class="line">q1=/path/**LIBNAMEA**/fastq1_read_1.fq</span><br><span class="line">q2=/path/**LIBNAMEA**/fastq1_read_2.fq</span><br><span class="line"><span class="comment">#another pair of fastq file, read 1 file should always be followed by read 2 file</span></span><br><span class="line">q1=/path/**LIBNAMEA**/fastq2_read_1.fq</span><br><span class="line">q2=/path/**LIBNAMEA**/fastq2_read_2.fq</span><br><span class="line"><span class="comment">#a pair of fasta file, read 1 file should always be followed by read 2 file</span></span><br><span class="line">f1=/path/**LIBNAMEA**/fasta1_read_1.fa</span><br><span class="line">f2=/path/**LIBNAMEA**/fasta1_read_2.fa</span><br><span class="line"><span class="comment">#another pair of fasta file, read 1 file should always be followed by read 2 file</span></span><br><span class="line">f1=/path/**LIBNAMEA**/fasta2_read_1.fa</span><br><span class="line">f2=/path/**LIBNAMEA**/fasta2_read_2.fa</span><br><span class="line"><span class="comment">#fastq file for single reads</span></span><br><span class="line">q=/path/**LIBNAMEA**/fastq1_read_single.fq</span><br><span class="line"><span class="comment">#another fastq file for single reads</span></span><br><span class="line">q=/path/**LIBNAMEA**/fastq2_read_single.fq</span><br><span class="line"><span class="comment">#fasta file for single reads</span></span><br><span class="line">f=/path/**LIBNAMEA**/fasta1_read_single.fa</span><br><span class="line"><span class="comment">#another fasta file for single reads</span></span><br><span class="line">f=/path/**LIBNAMEA**/fasta2_read_single.fa</span><br><span class="line"><span class="comment">#a single fasta file for paired reads</span></span><br><span class="line">p=/path/**LIBNAMEA**/pairs1_in_one_file.fa</span><br><span class="line"><span class="comment">#another single fasta file for paired reads</span></span><br><span class="line">p=/path/**LIBNAMEA**/pairs2_in_one_file.fa</span><br><span class="line"><span class="comment">#bam file for single or paired reads, reads 1 in paired reads file should always be followed by reads 2</span></span><br><span class="line"><span class="comment">#	<span class="doctag">NOTE:</span> If a read in bam file fails platform/vendor quality checks(the flag field 0x0200 is set), itself and it&#x27;s paired read would be ignored.</span></span><br><span class="line">b=/path/**LIBNAMEA**/reads1_in_file.bam</span><br><span class="line"><span class="comment">#another bam file for single or paired reads</span></span><br><span class="line">b=/path/**LIBNAMEA**/reads2_in_file.bam</span><br><span class="line"><span class="string">&quot;[LIB]&quot;</span></span><br><span class="line">avg_ins=2000</span><br><span class="line">reverse_seq=1</span><br><span class="line">asm_flags=2</span><br><span class="line">rank=2</span><br><span class="line"><span class="comment"># cutoff of pair number for a reliable connection (at least 5 for large insert size)</span></span><br><span class="line">pair_num_cutoff=5</span><br><span class="line"><span class="comment">#minimum aligned length to contigs for a reliable read location (at least 35 for large insert size)</span></span><br><span class="line">map_len=35</span><br><span class="line">q1=/path/**LIBNAMEB**/fastq_read_1.fq</span><br><span class="line">q2=/path/**LIBNAMEB**/fastq_read_2.fq</span><br><span class="line">f1=/path/**LIBNAMEA**/fasta_read_1.fa</span><br><span class="line">f2=/path/**LIBNAMEA**/fasta_read_2.fa</span><br><span class="line">p=/path/**LIBNAMEA**/pairs_in_one_file.fa</span><br><span class="line">b=/path/**LIBNAMEA**/reads_in_file.bam</span><br></pre></td></tr></table></figure>

<h2 id="Appendix-B-output-files"><a href="#Appendix-B-output-files" class="headerlink" title="Appendix B: output files"></a>Appendix B: output files</h2><h3 id="1-Output-files-from-the-command-“pregraph”"><a href="#1-Output-files-from-the-command-“pregraph”" class="headerlink" title="1. Output files from the command “pregraph”"></a>1. Output files from the command “pregraph”</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. *.kmerFreq</span><br><span class="line">   Each row shows the number of Kmers with a frequency equals the row number. Note that those peaks of frequencies <span class="built_in">which</span> are the integral multiple of 63 are due to the data structure.</span><br><span class="line">b. *.edge</span><br><span class="line">   Each record gives the information of an edge <span class="keyword">in</span> the pre-graph: length, Kmers on both ends, average kmer coverage, whether it<span class="string">&#x27;s reverse-complementarily identical and the sequence.</span></span><br><span class="line"><span class="string">c. *.markOnEdge &amp; *.path</span></span><br><span class="line"><span class="string">   These two files are for using reads to solve small repeats.</span></span><br><span class="line"><span class="string">e. *.preArc</span></span><br><span class="line"><span class="string">   Connections between edges which are established by the read paths.</span></span><br><span class="line"><span class="string">f. *.vertex</span></span><br><span class="line"><span class="string">   Kmers at the ends of edges.</span></span><br><span class="line"><span class="string">g. *.preGraphBasic</span></span><br><span class="line"><span class="string">   Some basic information about the pre-graph: number of vertex, K value, number of edges, maximum read length etc.</span></span><br></pre></td></tr></table></figure>

<h3 id="2-Output-files-from-the-command-“contig”"><a href="#2-Output-files-from-the-command-“contig”" class="headerlink" title="2. Output files from the command “contig”"></a>2. Output files from the command “contig”</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. *.contig</span><br><span class="line">      Contig information: corresponding edge index, length, kmer coverage, whether it<span class="string">&#x27;s tip and the sequence. Either a contig or its reverse complementry counterpart is included. Each reverse complementary contig index is indicated in the *.ContigIndex file.</span></span><br><span class="line"><span class="string">   b. *.Arc</span></span><br><span class="line"><span class="string">      Arcs coming out of each edge and their corresponding coverage by reads</span></span><br><span class="line"><span class="string">   c. *.updated.edge</span></span><br><span class="line"><span class="string">      Some information for each edge in graph: length, Kmers at both ends, index difference between the reverse-complementary edge and this one.</span></span><br><span class="line"><span class="string">   d. *.ContigIndex</span></span><br><span class="line"><span class="string">      Each record gives information about each contig in the *.contig: it&#x27;</span>s edge index, length, the index difference between its reverse-complementary counterpart and itself.</span><br></pre></td></tr></table></figure>

<h3 id="3-Output-files-from-the-command-“map”"><a href="#3-Output-files-from-the-command-“map”" class="headerlink" title="3. Output files from the command “map”"></a>3. Output files from the command “map”</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. *.peGrads</span><br><span class="line">      Information <span class="keyword">for</span> each <span class="built_in">clone</span> library: insert-size, <span class="built_in">read</span> index upper bound, rank and pair number cutoff <span class="keyword">for</span> a reliable link. This file can be revised manually <span class="keyword">for</span> scaffolding tuning.</span><br><span class="line">   b. *.readOnContig</span><br><span class="line">      Reads<span class="string">&#x27; locations on contigs. Here contigs are referred by their edge index. Howerver about half of them are not listed in the *.contig file for their reverse-complementary counterparts are included already.</span></span><br><span class="line"><span class="string">   c. *.readInGap</span></span><br><span class="line"><span class="string">      This file includes reads that could be located in gaps between contigs. This information will be used to close gaps in scaffolds if &quot;-F&quot; is set.</span></span><br></pre></td></tr></table></figure>

<h3 id="4-Output-files-from-the-command-“scaff”"><a href="#4-Output-files-from-the-command-“scaff”" class="headerlink" title="4. Output files from the command “scaff”"></a>4. Output files from the command “scaff”</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">a. *.newContigIndex</span><br><span class="line">      Contigs are sorted according their length before scaffolding. Their new index are listed <span class="keyword">in</span> this file.  This is useful <span class="keyword">if</span> one wants to corresponds contigs <span class="keyword">in</span> *.contig with those <span class="keyword">in</span> *.links.</span><br><span class="line">   b. *.links</span><br><span class="line">      Links between contigs <span class="built_in">which</span> are established by <span class="built_in">read</span> pairs. New index are used.</span><br><span class="line">   c. *.scaf_gap</span><br><span class="line">      Contigs <span class="keyword">in</span> gaps found by contig graph outputted by the contiging procedure. Here new index are used.</span><br><span class="line">   d. *.scaf</span><br><span class="line">      Contigs <span class="keyword">for</span> each scaffold: contig index (concordant to index <span class="keyword">in</span> *.contig),  approximate start position on scaffold, orientation, contig length, and its links to others contigs.</span><br><span class="line">   e. *.gapSeq</span><br><span class="line">      Gap sequences between contigs.</span><br><span class="line">   f. *.scafSeq</span><br><span class="line">      Sequences of each scaffolds.</span><br><span class="line">   g. *.contigPosInscaff</span><br><span class="line">      Contigs<span class="string">&#x27; positions in each scaffold.</span></span><br><span class="line"><span class="string">   h. *.bubbleInScaff</span></span><br><span class="line"><span class="string">      Contigs that form bubble structures in scaffolds. Every two contigs form a bubble and the contig with higher coverage will be kept in scaffold.</span></span><br><span class="line"><span class="string">   i. *.scafStatistics</span></span><br><span class="line"><span class="string">      Statistic information of final scaffold and contig.</span></span><br></pre></td></tr></table></figure>

<hr>
<h1 id="小记1"><a href="#小记1" class="headerlink" title="小记1"></a>小记1</h1><p> ref：<a href="https://www.cnblogs.com/Formulate0303/p/6879841.html">https://www.cnblogs.com/Formulate0303/p/6879841.html</a></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>确定基因组缺失什么；确定难以生化研究的基因和pathways；研究感兴趣pathway通路中每一个基因；研究基因组非编码区（introns、promoters、telomeres端粒等）的调控机理和结构特征；基因组提供可进行各种统计的大型数据库（provide large databases that are amenable to statistical methods）;识别不同可能有细微表型的序列；研究物种和基因组的进化过程。一般都是用不同梯度的插入片段来测序，小片段（200,500,800）和大片段（1k, 2kb 5kb 10kb 20kb 40kb）。</p>
<h2 id="测序前准备"><a href="#测序前准备" class="headerlink" title="测序前准备"></a>测序前准备</h2><p>搜集物种相关信息（染色体的倍型、基因组大小、杂合度、重复序列比例、是否有可用的遗传图谱、GC含量 和 GC分布）。提供已经发表的近源物种。根据近源物种分析以上信息，尤其是GC含量以及对应的GC分布，重复程度。</p>
<h3 id="1-获取基因组大小"><a href="#1-获取基因组大小" class="headerlink" title="1 获取基因组大小"></a>1 获取基因组大小</h3><ul>
<li><p>基因组太大（&gt;10Gb）超出了目前denovo组装基因组软件对机器内存的要求，则无法实现组装；对组装结果的大小的进行正确性与否判断。</p>
</li>
<li><p>动物基因组大小数据库（ANIMAL GENOME SIZE DATABASE）: <a href="http://www.genomesize.com/%EF%BC%9B%E5%AF%B9%E4%BA%8E%E6%9F%A5%E4%B8%8D%E5%88%B0%E7%9A%84%E7%89%A9%E7%A7%8D%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%A4%A7%E5%B0%8F%E7%9A%84%EF%BC%8C%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E4%B8%80%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8E%BB%E4%BC%B0%E8%AE%A1%E3%80%82">http://www.genomesize.com/；对于查不到的物种基因组大小的，可以通过一些方法去估计。</a></p>
</li>
<li><p>实验（流式细胞仪）估计基因组大小的例子： “A full-length enriched cDNA library and expressed sequence tag analysis of the parasitic weed, Striga hermonthica.” BMC Plant Biol (2010)</p>
</li>
<li><p>基于福尔摩根染色估计基因组大小：书The evolution of the genome《基因组进化》, Gregory, T. (2005).</p>
</li>
<li><p>定量PCR估计基因组大小: “Real-time PCR-based method for the estimation of genome sizes.” Nucleic Acids Res (2003); “The nuclear genome of the phytoseiid Metaseiulus occidentalis (Acari: Phytoseiidae) is among the smallest known in arthropods.” Exp Appl Acarol (2009)</p>
</li>
<li><p>通过Kmer估计基因组大小：Kim, E. B., X. Fang, et al. (2011). “<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3319411/"><strong>Genome sequencing reveals insights into physiology and longevity of the naked mole rat</strong></a>.” Nature 479(7372): 223-227. [Obtained 2.5 G contig sequences with N50 19.3 kbp and N90 4.7 kbp, and 2.7 G scaffold sequences with N50 1.6 Mbp and N90 0.3 Mbp.]</p>
</li>
</ul>
<h3 id="2-杂合度评估"><a href="#2-杂合度评估" class="headerlink" title="2 杂合度评估"></a>2 杂合度评估</h3><ul>
<li><p>主要体现在<font color="green">不能合并姊妹染色体</font>，杂合度高的区域，会把两条姊妹染色单体都组装出来，造成组装的基因组<font color="green">偏大</font>。</p>
</li>
<li><p><font color="red"><strong>杂合度&gt;0.5%则组装有一定难度</strong></font>。杂合度&gt;1%则很难组装出来。</p>
</li>
<li><p>杂合度高则组装的序列不适合用于后续生物学分析（eg:拷贝数、基因完整结构等）。</p>
</li>
</ul>
<h3 id="3-是否有遗传图谱可用"><a href="#3-是否有遗传图谱可用" class="headerlink" title="3 是否有遗传图谱可用"></a>3 是否有遗传图谱可用</h3><p>随着测序对质量提高和相关技术成熟，<font color="red"><strong>遗传图谱？</strong></font>也快成了denovo基因组的必须组成。</p>
<p><a href="https://cdmd.cnki.com.cn/Article/CDMD-10504-1019065822.htm">矮牵牛遗传图谱构建及重瓣分子标记筛选</a></p>
<p>遗传图谱是某一物种的染色体图，显示所知的基因和/或遗传标记的相对位置，而不是在每条染色体上特殊的物理位置。由<a href="https://baike.baidu.com/item/%E9%81%97%E4%BC%A0%E9%87%8D%E7%BB%84/6391485">遗传重组</a>测验结果推算出来的、在一条染色体上可以发生的突变座位的直线排列（<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E4%BD%8D%E7%82%B9/3613206">基因位点</a>的排列）图。</p>
<p>Genetic map，<a href="https://baike.baidu.com/item/%E9%81%97%E4%BC%A0%E5%9B%BE/2951032">遗传图</a>或遗传<a href="https://baike.baidu.com/item/%E8%BF%9E%E9%94%81%E5%9B%BE/1586423">连锁图</a>是以<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E8%BF%9E%E9%94%81/7740242">基因连锁</a>、重组<a href="https://baike.baidu.com/item/%E4%BA%A4%E6%8D%A2%E5%80%BC/5106108">交换值</a>构建的图谱，图距为cM（<a href="https://baike.baidu.com/item/%E5%8E%98%E6%91%A9/1586351">厘摩</a>），1%交换值为1cM，约相当于1000kb。人基因组全长约3300cM，如两个标记之间相距1cM，则需3300个标记，如相距2～5cM，则需660～l650个标记。标记可以是体质性状，也可以是可检出的DNA序列，例如基因、<a href="https://baike.baidu.com/item/%E9%99%90%E5%88%B6%E7%89%87%E6%AE%B5%E9%95%BF%E5%BA%A6%E5%A4%9A%E6%80%81%E6%80%A7/3841692">限制片段长度多态性</a>（<a href="https://baike.baidu.com/item/RFLP/5060944">RFLP</a>）和特定的<a href="https://baike.baidu.com/item/%E5%8D%95%E4%B8%80%E5%BA%8F%E5%88%97/1851974">单一序列</a>等。每一个标记都要用专一序列位点（STS）作鉴定。STS是指其位置及核苷酸序列均已知的、人基因组中只有一份拷贝的DNA短片段（一般长200～500碱基对），它很容易用多聚酶链反应（PCR）加以验证。当各个实验室报道定位和测序的数据时，可用STS来确定这些DNA片段的定位与取向。人类基因组计划的研究目标是，完成一个完全连接的人类遗传图，标记之间平均相距2～5cM。</p>
<p>遗传图谱构建相关概念推荐参考书：<strong>The handbook of plant genome mapping: genetic and physical mapping</strong> </p>
<h3 id="4-生物学问题的调研"><a href="#4-生物学问题的调研" class="headerlink" title="4 生物学问题的调研"></a>4 生物学问题的调研</h3><h2 id="组装"><a href="#组装" class="headerlink" title="组装"></a>组装</h2><ul>
<li><p>BAC-by-BAC:测序和组装每一个BAC, 合并BAC和移除BAC冗余部分，获得参考基因组序列。</p>
</li>
<li><p>whole genome shotgun：全基因组鸟枪法，染色体DNA被随机打断成片段，依次测序和组装。</p>
</li>
</ul>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>二代测序数据从头组装的解决overlap的三种算法</p>
<ul>
<li><p>overlap-layout-consensus：重叠布局一致OLC法，【软件：PHRAP.NEWBLER.CABOG.CELERA.SHORTY.EDENA,popular for long reads】，1. Overlap discovery involves all-against-all, pair-wise read comparison. 2. Construction an approximate read layout according to the pair-wise alignment 3. Multiple sequence alignment determines the precise layout and the consensus.</p>
</li>
<li><p>De bruijn graph:DBG法，【软件：SOAPdenovo2.Velvet.EULER,popular for illumina ，for short reads】,1.所有的测序reads都被切割成某一固定Kmer长度的序列（21bp=&lt;kmer&lt;=127bp）.2.相邻kmers链接是来自read序列，所以它不需要成对序列比对(The links between neighboring Kmers are derived from read sequences,so it doesn’t need pair-wise reads alignment.）3.冗余的数据自动被压缩。</p>
</li>
<li><p>greedy method：贪婪法(use OLC or DBG)，【软件：SSAKE.SHARCGS.VCAKE】，从给定的reads和contigs开始，使用下一个得分最高的overlap去做下一个连接，这样一直做下去，直到不能进行下去为止。 </p>
</li>
</ul>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>组装short reads的挑战</p>
<p>1.基因组的复杂性，<strong>重复序列</strong>、<strong>杂合</strong>的<strong>二倍体</strong>基因组heterozygous diploid genome、<strong>多倍性</strong>polyploidy.</p>
<p>2.illumina reads 的数据特征，<strong>测序错误</strong>率<del>1%、short read 长度</del>100bp、<del>100X的高测序深度、不同级别的文库插入片段（200bp</del>40Kbp）。</p>
<p>3.Complexity of computation</p>
<h2 id><a href="#" class="headerlink" title></a></h2><hr>
<h1 id="小记2"><a href="#小记2" class="headerlink" title="小记2"></a>小记2</h1><p>ref <a href="https://www.jianshu.com/p/e02ecd537c83">https://www.jianshu.com/p/e02ecd537c83</a></p>
<h2 id="reads质量控制"><a href="#reads质量控制" class="headerlink" title="reads质量控制"></a>reads质量控制</h2><ul>
<li>认识数据。(read类型，read数量，其GC含量，可能的污染和其他问题)</li>
<li>数据清理。(组装前清理原始数据可以使组装结果更好,因为移除了低质量和污染的reads)</li>
<li>为组装软件提供一些组装的参数</li>
</ul>
<h2 id="检查原始read数据的质量"><a href="#检查原始read数据的质量" class="headerlink" title="检查原始read数据的质量"></a>检查原始read数据的质量</h2><p>(1)read长度:在设置组装的最大k-mer值时将很重要。</p>
<p>(2)质量编码类型:对于quality trimming软件很重要。(Phred33、64)</p>
<p>(3)GC含量:<strong>高GC的生物体往往组装得不好，并且read覆盖率分布可能不均匀</strong></p>
<p>(4)总的reads数:<strong>了解coverage范围</strong></p>
<p>(4)在read的开始、中间或结尾附近质量下降:确定可能的修整/清除方法和参数。</p>
<p>(5)出现<strong>高度重复的k-mers</strong>:说明序列可能存在污染。</p>
<p>(6)reads中存在<strong>大量N</strong>:可能表明测序质量较差。你需要修剪这些read，以删除N.</p>
<h2 id="genome-survey"><a href="#genome-survey" class="headerlink" title="genome survey"></a>genome survey</h2><p>正式组装前进行kmer分析，以了解以下信息。</p>
<p>(1)基因组杂合度。</p>
<p>(2)重复序列比例。</p>
<p>(3)预估基因组大小。</p>
<p>(4)测序深度。</p>
<p>所用软件为kmergenie，<a href="https://links.jianshu.com/go?to=http://kmergenie.bx.psu.edu/">http://kmergenie.bx.psu.edu/</a> </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装(使用时，确保服务器装有Pthon与R)</span></span><br><span class="line">tar -xzvf kmergenie-1.7051.tar.gz &amp;&amp; <span class="built_in">cd</span> kmergenie-1.7051</span><br><span class="line">python setup.py install</span><br><span class="line"> </span><br><span class="line"><span class="comment">#添加可执行权限</span></span><br><span class="line">chmod -R 755 *</span><br></pre></td></tr></table></figure>

<p>接下来介绍怎么用，参考：<a href="https://links.jianshu.com/go?to=http://wap.sciencenet.cn/blog-3406804-1159967.html">http://wap.sciencenet.cn/blog-3406804-1159967.html</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">touch fq_501.txt                                 <span class="comment">#存储fastq文件的路径。</span></span><br><span class="line">vim fq_501.txt                                   <span class="comment">#编辑fq.txt，输入fastq文件路径。</span></span><br><span class="line">mkdir kmergenie_result     </span><br><span class="line">./tools/kmergenie-1.7051/kmergenie fq_501.list -o ./kmergenie_result/PB_501 -k 105 -</span><br><span class="line">l 15 -s 10 -t 12                               </span><br><span class="line"><span class="comment">#-o:输出文件存放的地址。</span></span><br><span class="line"><span class="comment">#-k:最大的k值</span></span><br><span class="line"><span class="comment">#-l:最小的k值</span></span><br><span class="line"><span class="comment">#-s:从最小的k----最大的k，每次增加的k。</span></span><br><span class="line"><span class="comment">#-t:线程数。</span></span><br><span class="line"><span class="comment">#注:刚开始s可以设大点，可以根据判断出的最佳k值，缩小s再进行判断((第一次:I:15,k:105,s:10 第二次I:85,k:140,s:6)。</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">usage:</span><br><span class="line"></span><br><span class="line">    ./kmergenie reads_file</span><br><span class="line"></span><br><span class="line">reads_file is either a single FASTA, FASTQ, FASTA.gz, FASTQ.gz file or a list of file names, one per line. For example:</span><br><span class="line">    </span><br><span class="line">    ls -1 *.fastq.gz &gt; list_files</span><br><span class="line">    ./kmergenie list_files</span><br><span class="line"></span><br><span class="line">    type ./kmergenie to see extra options</span><br><span class="line"></span><br><span class="line">input:</span><br><span class="line"></span><br><span class="line">    Input reads should be exactly those the de novo assembler will use to create contigs, i.e. the list of all single and paired-end reads.</span><br><span class="line"></span><br><span class="line">    The order does not matter, KmerGenie treats the reads as an unordered set of k-mers. Orientation of the reads also does not matter.</span><br><span class="line">    With Velvet, if you have mate-pairs, Velvet uses them to create contigs, so do include them in KmerGenie.</span><br><span class="line">    Otherwise, if the mate-pairs are used only for scaffolding (i.e. asm_flag=2 in SOAPdenovo), do not include them.</span><br><span class="line"></span><br><span class="line">tips:</span><br><span class="line"></span><br><span class="line">    * Take a look at the generated HTML report. It provides a summary of the results, and contains an Advanced Help section to help analysis.</span><br><span class="line"></span><br><span class="line">    * There is no need to use Kmergenie for a multi-k assembler, like SPAdes. Default parameters of multi-k assemblers are generally better than a single best k.</span><br><span class="line"></span><br><span class="line">    * By default, KmerGenie will perform another pass to estimate k more precisely. You may skip it by using the &quot;--one-pass&quot; option (roughly 2x faster).</span><br><span class="line"></span><br><span class="line">    * To run multiple instances of KmerGenie on the same folder, specify the &quot;-o&quot; and &quot;-t&quot; parameters (output prefix, number of threads per instance).</span><br><span class="line"></span><br><span class="line">    * The sampling value e (&quot;-e&quot; parameter) makes sure that roughly n/e k-mers are sampled out of the n distinct kmers in the dataset. The datasets are fully analyzed, though. Kmergenie samples from the set of distinct kmers, not from the set of reads.</span><br><span class="line"></span><br><span class="line">    * The diploid model should only be used for moderate-high heterozygosity rates. The haploid model works better when only one peak is visible in the histograms (indicating low heterozygosity).</span><br><span class="line"></span><br><span class="line">outputs:</span><br><span class="line"></span><br><span class="line">    histograms_report.html</span><br><span class="line">        html report of all the results</span><br><span class="line">    histograms.dat</span><br><span class="line">        file containing the raw data for the number of genomic kmers for each k value</span><br><span class="line">    histograms-k*.histo</span><br><span class="line">        files containing raw sampled histograms for each k value</span><br><span class="line">    histograms-k*.histo.pdf</span><br><span class="line">        plots of the histograms and the fits. Colors: red is the fit of the complete statistical model of the histogram (erroneous k-mers + genomic k-mers). With the diploid model, green are only the heterozygous k-mers, blue are only the homozygous k-mers.</span><br><span class="line">    &lt;stdout&gt;</span><br><span class="line">        last line is the best k value</span><br><span class="line">    &lt;return code / error code&gt;</span><br><span class="line">        0 if and only if a best k was found (note: no longer returns the best k as error code)</span><br></pre></td></tr></table></figure>



<p>结果文件生成report。报告以折线图形式给出每种长度的kmer下，估计的基因组大小，同时给出了最佳的kmer(评估基因组总大小最高)</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/14.png" alt="img"></p>
<p>理想条件该图应该为一条平滑的曲线，有明确最大值。然而在一些情况下有多个局部最大值。</p>
<p>这些情况表明，对于某些k值，Kmergenie中的统计模型并不总是正确地拟合输入数据。因此由Kmergenie预测的最佳k值可能不是最佳的。在随后的分析中，还尝试使用比Kmergenie预测的k大的k(其他峰值)</p>
<p>若基因组k-mers的数量不会随着k值的升高而下降，则是一个高覆盖率(high coverage)数据集的迹象？<br>什么是覆盖率呢？<br>覆盖率(coverage)：指的是测序过程中读取单个碱基的平均次数。如果覆盖度为100×，说明平均每个碱基测序了100次。对碱基测序的频率越高，数据的质量越高。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/15.png" alt="img"></p>
<h2 id="soapdevovo2"><a href="#soapdevovo2" class="headerlink" title="soapdevovo2"></a>soapdevovo2</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#正式组装(kmer选103,113,123,127分别跑)</span></span><br><span class="line"><span class="comment">#SOAPdenovo2既可以一步组装也可以分四步，如果基因组大且复杂建议分四步。</span></span><br><span class="line"> nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer all -s config_file -d 1 -R -F -K 113 -p 60 -o PB_501_113 &gt; PB_501_113.log &amp;  <span class="comment">#注:加nohup和&amp;是为了让它在后台运行(防止远程连接断开程序停止)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#分四步(在k=103、113、123、及127(支持的最大kmer)跑了后发现127在同样参数下contig N50最大)，下面是为了优化结果跑的。</span></span><br><span class="line"><span class="comment">#pregraph(d=1,2,3,4)</span></span><br><span class="line">nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer pregraph -s config_file -o PB_501_127_d_3 -R -K 127 -p 60 -d 2 &gt;PB_501_127_d_3_pre.log &amp;</span><br><span class="line">nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer contig -g PB_501_127_d_3 -R -p 60 &gt;PB_501_127_d_3_con.log &amp;</span><br><span class="line">nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer map -s config_file -g PB_501_127_d_3 -p 60 -k 127 &gt;PB_501_127_d_3_map.log &amp;  </span><br><span class="line">nohup ./tools/SOAPdenovo2-master/SOAPdenovo-127mer scaff -g PB_501_127_d_3 -F -p 60 &gt;PB_501_127_d_3_scaf.log &amp;</span><br></pre></td></tr></table></figure>

<h2 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h2><p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/16.png" alt="img"></p>
<h2 id="组装评估"><a href="#组装评估" class="headerlink" title="组装评估"></a>组装评估</h2><p>QUAST软件下载:<a href="https://links.jianshu.com/go?to=https://sourceforge.net/projects/quast/files/quast-5.0.2.tar.gz/download">https://sourceforge.net/projects/quast/files/quast-5.0.2.tar.gz/download</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#解压安装</span></span><br><span class="line">tar -zxvf quast-5.0.2.tar.gz &amp;&amp; <span class="built_in">cd</span> quast-5.0.2</span><br><span class="line">python  setup.py install_full</span><br></pre></td></tr></table></figure>

<h3 id="参考基因组下载"><a href="#参考基因组下载" class="headerlink" title="参考基因组下载"></a>参考基因组下载</h3><h3 id="QUAST使用"><a href="#QUAST使用" class="headerlink" title="QUAST使用"></a>QUAST使用</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./tools/quast-5.0.2/quast.py -o ./quast_results -R ./reference/IRGSP-1.0_genome.fasta.gz -t 70 ./PB_501_results/PB_501_127_d_1/PB_501_127_d_1.scafSeq ./PB_501_results/PB_501_127_d_2/PB_501_127_d_2.scafSeq ./PB_501_results/PB_501_127_d_3/PB_501_127_d_3.scafSeq ./PB_501_results/PB_501_127_d_6/PB_501_127_d_6.scafSeq</span><br><span class="line"><span class="comment">#-o输出目录</span></span><br><span class="line"><span class="comment">#-R参考基因组序列</span></span><br><span class="line"><span class="comment">#-t线程数</span></span><br><span class="line"><span class="comment">#后面为要比较的contig/scaffold所在目录。</span></span><br></pre></td></tr></table></figure>

<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><h3 id="统计结果"><a href="#统计结果" class="headerlink" title="统计结果"></a>统计结果</h3><p>将contig/scaffold比对到参考基因组上，下面是比对得到的结果。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/17.png" alt="img"></p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/18.png" alt="img"></p>
<p>累计长度:若与灰色线重合越好，组装结果越好。</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/19.png" alt="img"></p>
<p>错误组装情况：</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/20.png" alt="img"></p>
<p>GC含量:</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/21.png" alt="img"></p>
<h3 id="contig-scaffold大小可视化"><a href="#contig-scaffold大小可视化" class="headerlink" title="contig/scaffold大小可视化"></a>contig/scaffold大小可视化</h3><p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/22.png" alt="img"></p>
<h3 id="比对到每条染色体情况"><a href="#比对到每条染色体情况" class="headerlink" title="比对到每条染色体情况"></a>比对到每条染色体情况</h3><p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/23.png" alt="img"></p>
<p>比对到每条染色体可视化情况:</p>
<p><img src="/blog/2022/02/24/2022-02-25-soapdenovo2/24.png" alt="img"></p>
]]></content>
      <categories>
        <category>assemble</category>
      </categories>
      <tags>
        <tag>SOAPdenovo2</tag>
      </tags>
  </entry>
  <entry>
    <title>seqkit</title>
    <url>/blog/2022/02/24/2022-02-24-Seqkit/</url>
    <content><![CDATA[<h1 id="SeqKit-a-cross-platform-and-ultrafast-toolkit-for-FASTA-Q-file-manipulation"><a href="#SeqKit-a-cross-platform-and-ultrafast-toolkit-for-FASTA-Q-file-manipulation" class="headerlink" title="SeqKit - a cross-platform and ultrafast toolkit for FASTA/Q file manipulation"></a>SeqKit - a cross-platform and ultrafast toolkit for FASTA/Q file manipulation</h1><span id="more"></span>

<p><a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">Official doc</a></p>
<h1 id="Quick-Guide"><a href="#Quick-Guide" class="headerlink" title="Quick Guide"></a>Quick Guide</h1><ul>
<li>Basic: <a href="https://bioinf.shenwei.me/seqkit/usage/#seq">seq</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#stats">stats</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#subseq">subseq</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#sliding">sliding</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#faidx">faidx</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#watch">watch</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#sana">sana</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#scat">scat</a></li>
<li>Format conversion: <a href="https://bioinf.shenwei.me/seqkit/usage/#fq2fa">fq2fa</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">fx2tab</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">tab2fx</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#convert">convert</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#translate">translate</a></li>
<li>Searching: <a href="https://bioinf.shenwei.me/seqkit/usage/#grep">grep</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#locate">locate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#amplicon">amplicon</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fish">fish</a></li>
<li>Set operation: <a href="https://bioinf.shenwei.me/seqkit/usage/#sample">sample</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#rmdup">rmdup</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#common">common</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#duplicate">duplicate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#split">split</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#split2">split2</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#head">head</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#head-genome">head-genome</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#range">range</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#pair">pair</a></li>
<li>Edit: <a href="https://bioinf.shenwei.me/seqkit/usage/#concat">concat</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#replace">replace</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#restart">restart</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#mutate">mutate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#rename">rename</a></li>
<li>Ordering: <a href="https://bioinf.shenwei.me/seqkit/usage/#sort">sort</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#shuffle">shuffle</a></li>
<li>BAM processing: <a href="https://bioinf.shenwei.me/seqkit/usage/#bam">bam</a></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">conda install -c bioconda seqkit</span><br></pre></td></tr></table></figure>

<h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">amplicon        通过引物检索扩增子(或其周围的特定区域)</span><br><span class="line">bam             检查和在线绘制BAM记录文件的直方图</span><br><span class="line">common          通过id/名称/序列查找多个文件的公共序列</span><br><span class="line">concat          连接多个文件中具有相同ID的序列</span><br><span class="line">convert         转换FASTQ质量编码格式：支持格式包括：桑格，Solexa和Illumina</span><br><span class="line">duplicate       重复序列N次</span><br><span class="line">faidx           创建FASTA索引文件并提取子序列</span><br><span class="line">fish            使用局部比对在较大的序列中寻找短序列</span><br><span class="line">fq2fa           转换FASTQ到FASTA</span><br><span class="line">fx2tab          将FASTA/Q转换为表格格式(包含长度/GC含量/GC偏好)</span><br><span class="line">genautocomplete 生成shell自动完成脚本</span><br><span class="line">grep            通过ID/name/sequence/sequence motif搜索序列，允许错配</span><br><span class="line">head            打印第一条序列</span><br><span class="line"><span class="built_in">help</span>            打印帮助信息</span><br><span class="line">locate          定位序列，或者motifs，允许错配</span><br><span class="line">mutate          编辑序列(点突变、插入、删除)</span><br><span class="line">pair            匹配双端序列文件</span><br><span class="line">range           打印一个范围内的序列</span><br><span class="line">rename          重命名重复序列ID</span><br><span class="line">replace         使用正则表达式修改名称或者序列</span><br><span class="line">restart         重置环状基因组的起始位置</span><br><span class="line">rmdup           通过id/名称/序列删除重复的序列</span><br><span class="line">sample          按数量或比例对序列进行抽样</span><br><span class="line">sana            清理损坏的单行fastq文件</span><br><span class="line">scat            real time recursive concatenation and streaming of fastx files</span><br><span class="line">seq             转换序列(反向，补充，提取ID…)</span><br><span class="line">shuffle         随机序列</span><br><span class="line">sliding         序列滑窗提取，支持环形基因组</span><br><span class="line">sort            按id/名称/序列/长度排序序列</span><br><span class="line">split           按id/seq区域/大小/部件将序列拆分为文件(主要用于FASTA)</span><br><span class="line">split2          按序列数量/文件数将序列拆分为多个文件(FASTA, PE/SE FASTQ)</span><br><span class="line">stats           FASTA/Q文件的简单统计</span><br><span class="line">subseq          通过region/gtf/bed得到子序列，包括侧翼序列</span><br><span class="line">tab2fx          转换表格格式为FASTA/Q格式</span><br><span class="line">translate       翻译DNA/RNA到蛋白质序列(支持歧义碱基)</span><br><span class="line">version         打印版本信息并检查是否更新</span><br><span class="line">watch           序列特征的监测和在线直方图</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Parameter"><a href="#Parameter" class="headerlink" title="Parameter:"></a>Parameter:</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Flags:</span><br><span class="line">      --alphabet-guess-seq-length int   seqkit根据第一个FASTA记录猜测序列类型的序列前缀的长度(0表示整个序列)(默认10000)</span><br><span class="line">  -h, --<span class="built_in">help</span>                            显示帮助</span><br><span class="line">      --id-ncbi                         FASTA头是ncbi风格的，例如&gt;gi|110645304|ref|NC_002516.2 </span><br><span class="line">      --id-regexp string                用于解析ID的正则表达式(default <span class="string">&quot;^(\\S+)\\s?&quot;</span>)，匹配空格前的部分为序列名</span><br><span class="line">      --infile-list string              输入文件列表中的文件 (one file per line), <span class="keyword">if</span> given, they are appended to files from cli arguments</span><br><span class="line">  -w, --line-width int                  输出FASTA格式时的行宽 (0 <span class="keyword">for</span> no wrap) (default 60)</span><br><span class="line">  -o, --out-file string                 输出 (<span class="string">&quot;-&quot;</span> <span class="keyword">for</span> stdout, suffix .gz <span class="keyword">for</span> gzipped out) (default <span class="string">&quot;-&quot;</span>) -代表标准输出，加.gz可输出压缩文件</span><br><span class="line">      --quiet                           保持安静，不要显示额外的信息</span><br><span class="line">  -t, --seq-type string                 序列类型 (dna|rna|protein|<span class="built_in">unlimit</span>|auto) (auto, 按第一个序列自动检测) (default <span class="string">&quot;auto&quot;</span>)</span><br><span class="line">  -j, --threads int                     CPU数量 (默认单核为1，多核为2) (default 2)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="stats-FASTA-Q文件的简单统计"><a href="#stats-FASTA-Q文件的简单统计" class="headerlink" title="stats FASTA/Q文件的简单统计"></a>stats FASTA/Q文件的简单统计</h1><p>统计序列格式fa/fq、内容类型DNA/RNA/Protein，<font color="red">序列数量、总长度，最小、平均和最大长度</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># FASTA DNA</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nacgtryswkmbdhvACGTRYSWKMBDHV&quot;</span> | seqkit stats</span><br><span class="line">file  format  <span class="built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len</span><br><span class="line">-     FASTA   DNA          1       28       28       28       28</span><br><span class="line"></span><br><span class="line"><span class="comment"># RNA </span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nACGUN\nACGUN&quot;</span> | seqkit stats</span><br><span class="line">file  format  <span class="built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len</span><br><span class="line">-     FASTA   RNA          1       10       10       10       10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Protein</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nabcdefghijklmnpqrstvwyz&quot;</span> | seqkit stats</span><br><span class="line">file  format  <span class="built_in">type</span>     num_seqs  sum_len  min_len  avg_len  max_len</span><br><span class="line">-     FASTA   Protein         1       23       23       23       23</span><br><span class="line"></span><br><span class="line"><span class="comment"># FASTQ DNA</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;@read\nACTGCN\n+\n@IICCG&quot;</span> | seqkit stats</span><br><span class="line">file  format  <span class="built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len</span><br><span class="line">-     FASTQ   DNA          1        6        6        6        6</span><br><span class="line"></span><br><span class="line">file                             format  <span class="built_in">type</span>     num_seqs         sum_len  min_len  avg_len  max_len</span><br><span class="line">R1.fastq.gz  FASTQ   DNA   254,677,261  34,439,769,981       50    135.2      138</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 一般模式</span><br><span class="line">seqkit stats C1_1.fq.gz</span><br><span class="line">#--输出结果tab分隔</span><br><span class="line">seqkit stats C1_1.fq.gz -T</span><br><span class="line">#--输出文件转化其他格式</span><br><span class="line">seqkit stats C1_1.fq.gz -T| csvtk pretty -t</span><br><span class="line">seqkit stats C1_1.fq.gz -T| csvtk csv2md -t</span><br><span class="line"># 统计更多信息 -a</span><br><span class="line">seqkit stats C1_1.fq.gz -a</span><br><span class="line"># j多线程加速，尤其是对于具有多个序列文件会加速</span><br><span class="line"># seqkit stats -j 2 *.fq.gz</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="seq-转换序列-（反向、互补-提取ID）"><a href="#seq-转换序列-（反向、互补-提取ID）" class="headerlink" title="seq 转换序列 （反向、互补/提取ID）"></a>seq 转换序列 （反向、互补/提取ID）</h1><p>“-n”: 提取序列ID，包括“&gt;”后面的全部内容</p>
<p>“-n -i”: 仅提取第一个空格前的ID</p>
<h1 id="按长度过滤-常用"><a href="#按长度过滤-常用" class="headerlink" title="按长度过滤(常用)"></a>按长度过滤(常用)</h1><p>扩增子分析时要筛选扩增长度相近的片段，过长或过短一般都要删除。宏基因组中比如组装的结果，经常要过滤&lt;200/300bp的短片段，分箱时要筛选&gt;1000/2000的长片段使用。本条命令非常多的应用场景。筛选后结果可用 &gt; 写入文件</p>
<p>-m 按照序列长度过滤，表示保留的最小长度，-M 此为保留的最大长度</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#--提取序列长度大于60的并统计长度信息</span></span><br><span class="line">zcat hairpin.fa.gz | seqkit seq -m 60 | seqkit stats</span><br><span class="line"><span class="comment"># 设置最小序列长度和最大序列长度，用于过滤序列，并统计</span></span><br><span class="line">zcat hairpin.fa.gz | seqkit seq -m 100 -M 1000 | seqkit stats</span><br><span class="line"><span class="comment"># 保存&gt;100且&lt;1000长度的序列</span></span><br><span class="line">seqkit seq -m 100 -M 1000 hairpin.fa.gz &gt; hairpin100-1000.fa</span><br><span class="line">seqkit <span class="built_in">stat</span> hairpin100-1000.fa</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="提取ID"><a href="#提取ID" class="headerlink" title="提取ID"></a>提取ID</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">head gene.fa</span><br><span class="line"><span class="comment">## 名称全行</span></span><br><span class="line">seqkit seq gene.fa -n | head</span><br><span class="line"><span class="comment"># 仅仅打印ID</span></span><br><span class="line">seqkit seq gene.fa -n -i | head</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用正则表达式提取名字中的信息</span></span><br><span class="line">zcat hairpin.fa.gz | head</span><br><span class="line"><span class="comment"># 提取ID中第二个字段作为ID</span></span><br><span class="line">seqkit seq hairpin.fa.gz -n -i --id-regexp <span class="string">&quot;^[^\s]+\s([^\s]+)\s&quot;</span> | head</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="单行-多行转换"><a href="#单行-多行转换" class="headerlink" title="单行/多行转换"></a>单行/多行转换</h1><ul>
<li>-s提取并展示序列</li>
<li>-w 代表每行的碱基数量，0代表不换行</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#仅仅提取序列 -s</span></span><br><span class="line">seqkit seq gene.fa -s -w 0|head</span><br><span class="line"><span class="comment">#--将多行序列转化为标准4行FASTQ</span></span><br><span class="line">seqkit seq C1_1.fq.gz -w 0|head</span><br></pre></td></tr></table></figure>

<h1 id="反向-互补"><a href="#反向-互补" class="headerlink" title="反向/互补"></a>反向/互补</h1><ul>
<li>-r 序列反向</li>
<li>-p序列互补</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 序列反向互补,-r反向，-p互补</span></span><br><span class="line">seqkit seq hairpin.fa.gz -r -p|head</span><br></pre></td></tr></table></figure>

<h1 id="删除gap-大小写转换"><a href="#删除gap-大小写转换" class="headerlink" title="删除gap/大小写转换"></a>删除gap/大小写转换</h1><ul>
<li>-g 去除序列中的间隔,将中间的横杠去掉</li>
<li>-u转化序列为大写字母展示</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nACGT-ACTGC-acc&quot;</span> | seqkit seq -g -u</span><br></pre></td></tr></table></figure>

<h1 id="RNA转为DNA"><a href="#RNA转为DNA" class="headerlink" title="RNA转为DNA"></a>RNA转为DNA</h1><ul>
<li>—rna2dna 将RNA序列转化为DNA序列</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;&gt;seq\nUCAUAUGCUUGUCUCAAAGAUUA&quot;</span> | seqkit seq --rna2dna</span><br></pre></td></tr></table></figure>

<h1 id="subseq通过指定区域"><a href="#subseq通过指定区域" class="headerlink" title="subseq通过指定区域"></a>subseq通过指定区域</h1><ul>
<li>-r 通过区域来截取序列</li>
</ul>
<p>如1:12提取前12个碱基，-12:-1提取序列结尾12个碱基；<br>for last 12 bases, 13:-1 for cutting first 12 bases. type “seqkit subseq -h” for more examples</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#-提取序列前1：12个碱基</span><br><span class="line">zcat C1_1.fq.gz | seqkit subseq -r 1:12 |head</span><br><span class="line">#-提取序列最后1：12个碱基</span><br><span class="line">zcat C1_1.fq.gz | seqkit subseq -r -12:-1 |head</span><br><span class="line"> </span><br><span class="line">#取第12至倒数第12个碱基，即前11和后11个碱基去掉</span><br><span class="line">zcat C1_1.fq.gz | seqkit subseq -r 12:-12| head</span><br></pre></td></tr></table></figure>

<p>基于gtf/bed信息挑选子序列。</p>
<p>—gtf  根据gtf文件挑选基因，这部分功能用于根据基因注释快速提取基因序列，在宏基因组、转录组、重测序中常用。—chr 选择染色体，—feature cds选择序列类型</p>
<p>以拟南芥基因组的序列和注释数据演示：提取第一条染色体上的CDS基因信息，并统计基本信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit subseq --gtf Arabidopsis_thaliana.TAIR10.49.gtf.gz --chr 1 --feature cds  Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz  &gt; chr1.gtf.cds.fa</span><br><span class="line">seqkit stats chr1.gtf.cds.fa</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>-u 可以提取目标基因上游的序列</li>
<li>-f 目标区域不展示</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#--挑选序列并多加上上游的3个碱基</span><br><span class="line">seqkit subseq --gtf Arabidopsis_thaliana.TAIR10.49.gtf.gz Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz -u 3 |head</span><br><span class="line"> </span><br><span class="line"># 仅提取上游序列，如提取启动子区2k：-f仅定位不输出位置序列，-u输出上游序列，此处示例3bp</span><br><span class="line">seqkit subseq --gtf Arabidopsis_thaliana.TAIR10.49.gtf.gz Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz -u 3 -f |head</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="sliding-滑窗提取序列，支持环状基因组"><a href="#sliding-滑窗提取序列，支持环状基因组" class="headerlink" title="sliding 滑窗提取序列，支持环状基因组"></a>sliding 滑窗提取序列，支持环状基因组</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#-s 步长为3，-W 序列长度为6个碱基</span><br><span class="line">echo -e &quot;&gt;seq\nACGTacgtNN&quot; | seqkit sliding -s 3 -W 6</span><br><span class="line"># -g 贪婪模式，后面不足6个那也取</span><br><span class="line">echo -e &quot;&gt;seq\nACGTacgtNN&quot; | seqkit sliding -s 3 -W 6 -g</span><br><span class="line"># 环状DNA模式-C，首尾不算中断，环状</span><br><span class="line">echo -e &quot;&gt;seq\nACGTacgtNN&quot; | seqkit sliding -s 3 -W 6 -C</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>步长为5，取30个碱基序列，然后统计GC含量</li>
</ul>
<ul>
<li>fx2tab：统计fasta/fastq序列的信息为表格</li>
<li>-n仅输出ID，不输出序列</li>
<li>-g为GC含量</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zcat hairpin.fa.gz | seqkit sliding -s 5 -W 30 | seqkit fx2tab -n -g |head</span><br></pre></td></tr></table></figure>

<h1 id="faidx-创建FASTA索引文件并提取子序列"><a href="#faidx-创建FASTA索引文件并提取子序列" class="headerlink" title="faidx 创建FASTA索引文件并提取子序列"></a>faidx 创建FASTA索引文件并提取子序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 解压</span><br><span class="line">zcat hairpin.fa.gz &gt; hairpin.fa</span><br><span class="line"> </span><br><span class="line"># 建索引*.fai文件</span><br><span class="line">seqkit faidx hairpin.fa</span><br><span class="line"> </span><br><span class="line"># ID信息：hsa-let-7a-1 hsa-let-7a-2</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1 hsa-let-7a-2</span><br><span class="line"># -f 标题行全部显示</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1 hsa-let-7a-2 -f</span><br><span class="line"># 提取序列并选择区域显示</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1:1-10</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1:-10--1</span><br><span class="line">seqkit faidx hairpin.fa hsa-let-7a-1:1</span><br><span class="line"># 检查hsa开头的序列并统计</span><br><span class="line">seqkit faidx hairpin.fa hsa -r | seqkit stats</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="watch-序列质量的监测和在线直方图"><a href="#watch-序列质量的监测和在线直方图" class="headerlink" title="watch 序列质量的监测和在线直方图"></a>watch 序列质量的监测和在线直方图</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#-取对数展示直方图</span><br><span class="line">seqkit watch -L -f ReadLen hairpin.fa</span><br><span class="line"> </span><br><span class="line"># 每五千个做一个图保存在pdf文件中</span><br><span class="line">seqkit watch -p 500000 -O qhist.pdf -f MeanQual C1_1.fq.gz</span><br></pre></td></tr></table></figure>

<p>从有错误记录的fastq文件中挽救可用的读取</p>
<h1 id="sana：清理损坏fastq文件"><a href="#sana：清理损坏fastq文件" class="headerlink" title="sana：清理损坏fastq文件"></a>sana：清理损坏fastq文件</h1><p>这里我专门将C1_1.fq的第一个序列进行了错位，进行测试。这个操作往往在进行数据整合的时候可以有很大作用。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zcat C1_1.fq.gz|sed &#x27;2 s/^/A/&#x27; &gt; C1_1_bad.fq</span><br><span class="line">seqkit sana C1_1_bad.fq -o rescued.fq.gz</span><br></pre></td></tr></table></figure>

<h1 id="fq2fa-将fq转为fa格式"><a href="#fq2fa-将fq转为fa格式" class="headerlink" title="fq2fa 将fq转为fa格式"></a>fq2fa 将fq转为fa格式</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit fq2fa C1_1.fq.gz -o C1_1.fa</span><br></pre></td></tr></table></figure>

<h1 id="fx2tab-amp-tab2fx-序列转化表格格式"><a href="#fx2tab-amp-tab2fx-序列转化表格格式" class="headerlink" title="fx2tab &amp; tab2fx 序列转化表格格式"></a>fx2tab &amp; tab2fx 序列转化表格格式</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">这一转化很有用，往往用于表格/矩阵处理的时候。</span><br><span class="line">seqkit fx2tab hairpin.fa.gz | head -n 2</span><br><span class="line">通过矩阵格式的序列文件统计序列长度和质量值</span><br><span class="line"></span><br><span class="line">-l 统计序列长度</span><br><span class="line"></span><br><span class="line">-g 统计平均GC含量</span><br><span class="line"></span><br><span class="line">-i 只打印名称(不打印序列)</span><br><span class="line"></span><br><span class="line">-H 打印标题行</span><br><span class="line"># 打印序列长度、GC含量</span><br><span class="line">seqkit fx2tab hairpin.fa.gz -l -g -n -i -H | head</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>tab2fx 和表格格式转化为序列格式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># seqkit tab2fx 表格形式转化为序列形式</span><br><span class="line">zcat hairpin.fa.gz | seqkit fx2tab | seqkit tab2fx | head</span><br><span class="line"> </span><br><span class="line"># 转化为表格，然后排序，然后转化回去</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit fx2tab -l \</span><br><span class="line">    | sort -t &quot;`echo -e &#x27;\t&#x27;`&quot; -n -k4,4 \</span><br><span class="line">    | seqkit tab2fx | head</span><br><span class="line"># 等同于下面的命令</span><br><span class="line">seqkit sort -l hairpin.fa.gz | head</span><br><span class="line"> </span><br><span class="line"># 通过这个转化可以将很多在表格中实现的数据处理方法用于序列</span><br><span class="line">例如下面的提取1000个序列：seqkit fx2tab hairpin.fa.gz | head -n 1000 | seqkit tab2fx | head</span><br></pre></td></tr></table></figure>

<h1 id="translate-翻译DNA-RNA为蛋白质序列"><a href="#translate-翻译DNA-RNA为蛋白质序列" class="headerlink" title="translate 翻译DNA/RNA为蛋白质序列"></a>translate 翻译DNA/RNA为蛋白质序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#--转化为蛋白序列</span><br><span class="line">seqkit translate gene.fa|head</span><br><span class="line"> </span><br><span class="line"># 去除&#x27;X&#x27; 和 &#x27;*&#x27;</span><br><span class="line">seqkit translate hairpin.fa </span><br><span class="line">seqkit translate hairpin.fa --trim | head</span><br></pre></td></tr></table></figure>

<h1 id="grep-序列匹配"><a href="#grep-序列匹配" class="headerlink" title="grep  序列匹配"></a>grep  序列匹配</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 生成一个ID列表</span><br><span class="line">grep &#x27;&gt;&#x27; C1_1.fa|cut -c2-|head -n 10 &gt; id.txt</span><br><span class="line"> </span><br><span class="line"># 使用序列id列表进行搜索(不包含空格)</span><br><span class="line">seqkit grep -f id.txt C1_1.fq.gz -o result.fq.gz</span><br><span class="line"># 使用序列名称列表进行搜索(它们可能包含空格)</span><br><span class="line">seqkit grep -n -f id.txt C1_1.fq.gz -o result.fa.gz</span><br><span class="line">zcat  result.fa.gz</span><br><span class="line"># 提取hsa开头的序列</span><br><span class="line">zcat hairpin.fa.gz | seqkit grep -r -p ^hsa |head</span><br><span class="line"> </span><br><span class="line"># -v参数v用于移除序列</span><br><span class="line">zcat hairpin.fa.gz | seqkit grep -r -p ^hsa -p ^mmu -v | head</span><br><span class="line"> </span><br><span class="line"># 提取ID</span><br><span class="line">zcat miRNA.diff.gz | grep ^# -v | grep NEW | cut -f 2 &gt; list</span><br><span class="line">head list</span><br><span class="line"># 根据ID提取文件</span><br><span class="line">zcat hairpin.fa.gz | seqkit grep -f list &gt; new.fa</span><br><span class="line">head new.fa</span><br><span class="line"> </span><br><span class="line"># 提取包含特定碱基组合的序列</span><br><span class="line">cat hairpin.fa.gz | seqkit grep -s -i -p aggcg |head</span><br><span class="line"># 统计</span><br><span class="line">cat hairpin.fa.gz | seqkit grep -s -i -p aggcg | seqkit stats</span><br><span class="line"> </span><br><span class="line">#  去除 包含特定组合碱基的序列</span><br><span class="line">zcat hairpin.fa.gz | seqkit grep -s -r -i -p ^aggcg |head</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="locate-输出匹配位置"><a href="#locate-输出匹配位置" class="headerlink" title="locate 输出匹配位置"></a>locate 输出匹配位置</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">＃　其他两种输出格式</span><br><span class="line">zcat hairpin.fa.gz | seqkit locate -i -d -p AUGGACUN --bed</span><br><span class="line">zcat hairpin.fa.gz | seqkit locate -i -d -p AUGGACUN --gtf</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="fish-使用局部比对在较大的序列中寻找短序列"><a href="#fish-使用局部比对在较大的序列中寻找短序列" class="headerlink" title="fish 使用局部比对在较大的序列中寻找短序列"></a>fish 使用局部比对在较大的序列中寻找短序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -e &#x27;&gt;seq\nACGACGACGA&#x27; \</span><br><span class="line">    | seqkit locate -p ACGA -G | csvtk -t pretty</span><br><span class="line"> </span><br><span class="line">echo -e &#x27;&gt;seq\nACGACGACGA&#x27; \</span><br><span class="line">    | seqkit fish -F ACGA -a 2&gt;&amp;1 | csvtk -t pretty</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="amplicon-通过引物检索扩增子-或其周围的特定区域"><a href="#amplicon-通过引物检索扩增子-或其周围的特定区域" class="headerlink" title="amplicon 通过引物检索扩增子(或其周围的特定区域)"></a>amplicon 通过引物检索扩增子(或其周围的特定区域)</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -ne &quot;&gt;seq\nacgcccactgaaatga\n&quot; \</span><br><span class="line">    | seqkit amplicon -F ccc -R ttt</span><br><span class="line"> </span><br><span class="line"># 设置输出格式为bed，匹配的位点等信息</span><br><span class="line">echo -ne &quot;&gt;seq\nacgcccactgaaatga\n&quot; \</span><br><span class="line">    | seqkit amplicon -F ccc -R ttt --bed</span><br><span class="line"> </span><br><span class="line">#- 使用引物文件，这用于刘老师组的高通量分菌的序列拆分速度应该很客观</span><br><span class="line"># cat seqs4amplicon.fa | seqkit amplicon -p primers.tsv --bed</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 输出除去引物之外的部分，-r输出几个碱基</span><br><span class="line">echo -ne &quot;&gt;seq\nacgcccactgaaatga\n&quot; \</span><br><span class="line">    | seqkit amplicon -F ccc -R ttt -r 4:7</span><br><span class="line"># 输出格式为bed</span><br><span class="line">echo -ne &quot;&gt;seq\nacgcccactgaaatga\n&quot; \</span><br><span class="line">    | seqkit amplicon -F ccc -R ttt -r 4:7 --bed</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="duplicate-对序列重复N次"><a href="#duplicate-对序列重复N次" class="headerlink" title="duplicate 对序列重复N次"></a>duplicate 对序列重复N次</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 重复序列1次，但是名字没有修改</span><br><span class="line">cat hairpin.fa | seqkit head -n 1 \</span><br><span class="line">    | seqkit duplicate -n 2</span><br><span class="line"># 对重复序列改名，使其独一无二</span><br><span class="line">cat hairpin.fa | seqkit head -n 1 \</span><br><span class="line">    | seqkit duplicate -n 2 | seqkit rename</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="rmdup-通过id-名称-序列删除重复的序列"><a href="#rmdup-通过id-名称-序列删除重复的序列" class="headerlink" title="rmdup 通过id/名称/序列删除重复的序列"></a>rmdup 通过id/名称/序列删除重复的序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 去除重复的序列</span><br><span class="line">zcat hairpin.fa.gz | seqkit rmdup -s -o clean.fa.gz</span><br><span class="line"> </span><br><span class="line"># 保存重复序列得到文件 -D duplicated.detail.txt</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit rmdup -s -i -o clean.fa.gz -d duplicated.fa.gz -D duplicated.detail.txt</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="common-：通过id-名称-序列查找多个文件的公共序列"><a href="#common-：通过id-名称-序列查找多个文件的公共序列" class="headerlink" title="common ：通过id/名称/序列查找多个文件的公共序列"></a>common ：通过id/名称/序列查找多个文件的公共序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 通过ID匹配，文件夹下全部的fa序列公共部分输出来</span><br><span class="line">seqkit common *.fq.gz</span><br><span class="line"> </span><br><span class="line"># 通过-n实现全部名字匹配，-o输出结果</span><br><span class="line">seqkit common *.fq.gz -n -o common.fq </span><br><span class="line"># 通过-s序列匹配</span><br><span class="line">seqkit common *.fq.gz -s -i -o common.fq</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="split-拆分序列为子文件"><a href="#split-拆分序列为子文件" class="headerlink" title="split 拆分序列为子文件"></a>split 拆分序列为子文件</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">按名称ID、给定区域的子序列、文件大小或序列数量将序列拆分为文件</span><br><span class="line"></span><br><span class="line">可用于将大文件拆分后，并行处理，加速分析。如从contig中预测基因。</span><br><span class="line">#按照10000个序列为一个文件拆分，结果为hairpin.fa.gz.split/目录 ，文件名为hairpin.part_00x.fasta，-s</span><br><span class="line">seqkit split hairpin.fa.gz -s 10000 -2</span><br><span class="line"> </span><br><span class="line"># 将序列拆分为四个部分(常用，等分然后并行)</span><br><span class="line">seqkit split hairpin.fa.gz -p 5 -2</span><br><span class="line"> </span><br><span class="line"># 复杂一点的就是按照ID区分</span><br><span class="line">seqkit split hairpin.fa.gz -i --id-regexp &quot;^([\w]+)\-&quot; -2</span><br><span class="line"> </span><br><span class="line"># 按照前三个序列碱基来区分</span><br><span class="line">seqkit split hairpin.fa.gz -r 1:3 -2</span><br></pre></td></tr></table></figure>

<h1 id="split2-拆分文件-升级版本"><a href="#split2-拆分文件-升级版本" class="headerlink" title="split2 拆分文件 升级版本"></a>split2 拆分文件 升级版本</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Flags:</span><br><span class="line">  -l, --by-length string   split sequences into chunks of &gt;=N bases, supports K/M/G suffix</span><br><span class="line">  -p, --by-part int        按照拆分出来的数量，比如：拆分成两个子文件2。-s, --by-size int        按照序列数量拆分</span><br><span class="line">  -f, --force              强制覆盖文件</span><br><span class="line">  -h, --help               查看帮助文件</span><br><span class="line">  -O, --out-dir string     输出文件夹 (default value is $infile.split)</span><br><span class="line">  -1, --read1 string       (gzipped) 双端序列第一个</span><br><span class="line">  -2, --read2 string       (gzipped) 双端序列第二个</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>同时支持fa和fq文件。单端和双端序列拆分实例</p>
<p>-f强制覆盖结果，适合重复计算时使用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit split2 hairpin.fa.gz -s 10000 -f</span><br><span class="line"> </span><br><span class="line"># 双端序列拆分(重点)，p指定拆分数量，-O指定输出目录，-f覆盖结果，默认为压缩</span><br><span class="line">seqkit split2 -1 C1_1.fq.gz -2 C1_2.fq.gz -p 2 -O out -f</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="pair-拼接两个fastq文件"><a href="#pair-拼接两个fastq文件" class="headerlink" title="pair 拼接两个fastq文件"></a>pair 拼接两个fastq文件</h1><p>留下匹配的，去除不匹配的，这里我们使用扩增子的双端序列做一个演示：</p>
<p>注意：双端序列在两个文件中的顺序最好是一样的，否则会消耗大量内存去匹配。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit pair -1 C1_1.fq.gz -2 C1_2.fq.gz -O result</span><br><span class="line"># -u 输出未匹配上的文件</span><br><span class="line">seqkit pair -1 C1_1.fq.gz -2 C1_2.fq.gz -O result -u -f</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="sample-按数量或比例对序列进行抽样。"><a href="#sample-按数量或比例对序列进行抽样。" class="headerlink" title="sample 按数量或比例对序列进行抽样。"></a>sample 按数量或比例对序列进行抽样。</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">按照百分比例和序列数量进行抽样</span><br><span class="line"># 抽样百分之十</span><br><span class="line">zcat C1_1.fq.gz | seqkit sample -p 0.1 -o sample.fq.gz</span><br><span class="line"># 抽样1000条</span><br><span class="line">zcat C1_1.fq.gz | seqkit sample -n 1000 -o sample.fq.gz</span><br><span class="line"></span><br><span class="line">注意：1000条并不是很准确，可能是900多条，为什么呢？看这里了解问题。https://bioinf.shenwei.me/seqkit/note/#effect-of-random-seed-on-results-of-seqkit-sample</span><br></pre></td></tr></table></figure>



<p>这里为大家展示一下减少内存的序列抽样方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 抽样 seqkit sample </span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit sample -p 0.1 \</span><br><span class="line">    | seqkit head -n 1000 -o sample.fa.gz</span><br><span class="line"> </span><br><span class="line"># 设置随机种子，方便重复结果: -s 11</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit sample -p 0.1 -s 11 |head</span><br><span class="line"> </span><br><span class="line"># 抽样后打乱序列 :seqkit shuffle</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit sample -p 0.1 \</span><br><span class="line">    | seqkit shuffle -o sample.fa.gz</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="range-打印序列-按照一个范围"><a href="#range-打印序列-按照一个范围" class="headerlink" title="range 打印序列 按照一个范围"></a>range 打印序列 按照一个范围</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 打印一个范围内的序列</span><br><span class="line">cat hairpin.fa | seqkit range -r 1:10</span><br><span class="line"># 打印最后几行的序列</span><br><span class="line">cat hairpin.fa | seqkit range -r -100:-1 | seqkit stats</span><br><span class="line"># 打印中间范围的序列</span><br><span class="line">cat hairpin.fa | seqkit range -r 101:150 | seqkit stats</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="repeat-使用正则表达式替换名称-序列。"><a href="#repeat-使用正则表达式替换名称-序列。" class="headerlink" title="repeat 使用正则表达式替换名称/序列。"></a>repeat 使用正则表达式替换名称/序列。</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改序列名称：删除空格后内存</span><br><span class="line">echo -e &quot;&gt;seq1 abc-123\nACGT-ACGT&quot; \</span><br><span class="line">    | seqkit replace -p &quot;\s.+&quot;</span><br><span class="line"> </span><br><span class="line"># 修改序列名：替换</span><br><span class="line">echo -e &quot;&gt;seq1 abc-123\nACGT-ACGT&quot; \</span><br><span class="line">    | seqkit replace -p &quot;\-&quot; -r &#x27;=&#x27;</span><br><span class="line"> </span><br><span class="line"># 修改序列：去除序列间隔</span><br><span class="line">echo -e &quot;&gt;seq1 abc-123\nACGT-ACGT&quot; \</span><br><span class="line">    | seqkit replace -p &quot; |-&quot; -s</span><br><span class="line"> </span><br><span class="line"># 修改序列：给每一个碱基加上空格</span><br><span class="line">echo -e &quot;&gt;seq1 abc-123\nACGT-ACGT&quot; \</span><br><span class="line">    | seqkit replace -p &quot;(.)&quot; -r &#x27;$1 &#x27; -s</span><br><span class="line"> </span><br><span class="line"># 使用字符加数据重命名序列-用于扩增子代表序列改名非常优秀</span><br><span class="line">echo -e &quot;&gt;abc\nACTG\n&gt;123\nATTT&quot; \</span><br><span class="line">    |  seqkit replace -p .+ -r &quot;ASV_&#123;nr&#125;&quot;</span><br><span class="line"> </span><br><span class="line">echo -e &quot;&gt;abc\nACTG\n&gt;123\nATTT&quot; \</span><br><span class="line">    |  seqkit replace -p .+ -r &quot;SAV_&#123;nr&#125;&quot; --nr-width 5</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="rename-重命名重复的ID"><a href="#rename-重命名重复的ID" class="headerlink" title="rename 重命名重复的ID"></a>rename 重命名重复的ID</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 重命名：相同序列会在后面加上_2 来处理</span><br><span class="line">echo -e &quot;&gt;a comment\nacgt\n&gt;b comment of b\nACTG\n&gt;a comment\naaaa&quot; \</span><br><span class="line">    | seqkit rename</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="concat-连接多个文件中具有相同ID的序列"><a href="#concat-连接多个文件中具有相同ID的序列" class="headerlink" title="concat 连接多个文件中具有相同ID的序列"></a>concat 连接多个文件中具有相同ID的序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#这里演示组合前面两个碱基和最后两个碱基的用法</span><br><span class="line">seqkit concat &lt;(seqkit subseq -r 1:2 C1_1.fq.gz) &lt;(seqkit subseq -r -2:-1 C1_2.fq.gz)|head</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="shuffle-随机打乱序列-默认全部读入内存"><a href="#shuffle-随机打乱序列-默认全部读入内存" class="headerlink" title="shuffle 随机打乱序列 默认全部读入内存"></a>shuffle 随机打乱序列 默认全部读入内存</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit shuffle hairpin.fa.gz -2  &gt; shuffled.fa</span><br></pre></td></tr></table></figure>



<h1 id="sort-按id-名称-序列-长度排序序列"><a href="#sort-按id-名称-序列-长度排序序列" class="headerlink" title="sort 按id/名称/序列/长度排序序列"></a>sort 按id/名称/序列/长度排序序列</h1><p>—quiet 屏幕不输出过程</p>
<p>-i 排序忽略大小写</p>
<p>-l 按照序列长度排序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ID排序</span><br><span class="line">echo -e &quot;&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAA&quot; \</span><br><span class="line">    | seqkit sort --quiet</span><br><span class="line"> </span><br><span class="line"># 按照ID排序，忽略大小写</span><br><span class="line">echo -e &quot;&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAA&quot; \</span><br><span class="line">    | seqkit sort --quiet -i</span><br><span class="line"> </span><br><span class="line"># 按照序列长度排序，由小到大</span><br><span class="line">echo -e &quot;&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAAnnn\n&gt;seq3\nacgt&quot; \</span><br><span class="line">    | seqkit sort --quiet -l</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="mutate-编辑序列-点突变、插入、删除"><a href="#mutate-编辑序列-点突变、插入、删除" class="headerlink" title="mutate 编辑序列(点突变、插入、删除)"></a>mutate 编辑序列(点突变、插入、删除)</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot;</span><br><span class="line"> </span><br><span class="line"># 修改第一个碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -p 1:x</span><br><span class="line"> </span><br><span class="line"># 修改第五个位置的碱基，输出信息隐藏    </span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -p 5:x --quiet</span><br><span class="line"> </span><br><span class="line"># 可以同时修改多个碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -p 1:x -p -1:x --quiet</span><br><span class="line"> </span><br><span class="line"># 删除碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -d 1:1 --quiet</span><br><span class="line"> </span><br><span class="line"># 删除倒数三个碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -d -3:-1 --quiet</span><br><span class="line"> </span><br><span class="line"># 插入碱基</span><br><span class="line">echo -ne &quot;&gt;1\nACTGNactgn\n&gt;2\nactgnACTGN\n&quot; \</span><br><span class="line">    | seqkit mutate -i 0:xx --quiet</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="head-展示开头N行的序列"><a href="#head-展示开头N行的序列" class="headerlink" title="head 展示开头N行的序列"></a>head 展示开头N行的序列</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit head -n 1 hairpin.fa.gz</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="locate-定位子序列或者保守序列位置"><a href="#locate-定位子序列或者保守序列位置" class="headerlink" title="locate 定位子序列或者保守序列位置"></a>locate 定位子序列或者保守序列位置</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat gene.fa | seqkit locate -p ACT | csvtk pretty -t</span><br><span class="line"># 调整错配 最大错配为1</span><br><span class="line">cat gene.fa \</span><br><span class="line">  | seqkit locate -p ACTG -m 1 \</span><br><span class="line">  | csvtk pretty -t</span><br><span class="line"> </span><br><span class="line"># 简并碱基</span><br><span class="line">zcat hairpin.fa.gz \</span><br><span class="line">    | seqkit locate -i -d -p AUGGACUN \</span><br><span class="line">    | head -n 4</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="restart-重置循环基因组的起始位置"><a href="#restart-重置循环基因组的起始位置" class="headerlink" title="restart 重置循环基因组的起始位置"></a>restart 重置循环基因组的起始位置</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -e &quot;&gt;seq\nacgtnACGTN&quot;</span><br><span class="line"> </span><br><span class="line">echo -e &quot;&gt;seq\nacgtnACGTN&quot; | seqkit restart -i 2</span><br><span class="line">echo -e &quot;&gt;seq\nacgtnACGTN&quot; | seqkit restart -i -2</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="convet-二代测序质量值的转化为-Sanger"><a href="#convet-二代测序质量值的转化为-Sanger" class="headerlink" title="convet 二代测序质量值的转化为 Sanger"></a>convet 二代测序质量值的转化为 Sanger</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Illumina-1.8+ -&gt; Sanger</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz  | seqkit head -n 1</span><br><span class="line"># 40分以上的都认为40 Illumina-1.8+ -&gt; Sanger</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz -f | seqkit head -n 1</span><br><span class="line"> </span><br><span class="line">#Illumina-1.8+ -&gt; Illumina-1.5+</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz --to Illumina-1.5+ | seqkit head -n 1</span><br><span class="line"> </span><br><span class="line"># Illumina-1.8+ -&gt; Illumina-1.5+ -&gt;  Sanger.</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz --to Illumina-1.5+ | seqkit convert | seqkit head -n 1</span><br><span class="line"> </span><br><span class="line"># Solexa -&gt; Sanger</span><br><span class="line"># seqkit convert tests/Illimina1.8.fq.gz --from Solexa</span><br><span class="line"> </span><br><span class="line"># Illumina-1.5+ -&gt; Sanger</span><br><span class="line"># seqkit convert tests/Illimina1.5.fq | seqkit head -n 1</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="技术细节和使用"><a href="#技术细节和使用" class="headerlink" title="技术细节和使用"></a>技术细节和使用</h1><p>seqkit处理压缩文件</p>
<p>pigz 或者 gzip 在部分操作中不能加速，所以在v.0.8.1版本以便关注了，然而还是可以使用命令：</p>
<p>pigz -d -c seqs.fq.gz | seqkit xxx<br>因为seqkit使用了pgzip去写gzip。这比gzip和pigz更快。（10X of gzip, 4X of pigz），而且gzip压缩文件比较大。</p>
<p>从数据处理格式来讲</p>
<p>seqkit无缝支持fa和fq格式数据，并且可以自动识别。除了 faidx之外，全部命令都可以处理这两种格式的数据。</p>
<p>只有fa格式支持命令(subseq, split, sort和shuffle)利用FASTA索引(by flag -two-pass)下提高大文件的性能。</p>
<p>序列类型的检测DNA/RNA/Protein，会使用子序列进行，默认检测第一条子序列，通过—alphabet-guess-seq-length参数默认为10000，如果长度小于10000，则检查整条序列。</p>
<p>序列名字</p>
<p>所有的软件，包括seqkit，使用第一个空格之前的字符作为序列的名字：<br>需要注意的NCBI等一些序列的格式并不是如此，例如：</p>
<blockquote>
<p>gi|110645304|ref|NC_002516.2| Pseudomona<br>想要在seqkit中识别出来的序列ID为：NC_002516.2。</p>
</blockquote>
<p>此时使用参数–id-regexp “|([^|]+)| “，或者添加参数–id-ncbi，但如果是只要前面的gi数字作为ID的话，添加参数：–id-regexp “^gi|([^|]+)|“。</p>
<p>注意：.seqkit.fai不同于samtools产生的.fai格式文件，seqkit使用整个序列开头而不是ID作为索引。</p>
<p>并行运算</p>
<p>单核CPU默认线程：—threads 1，多个CPU，线程默认2.</p>
<p>内存占用</p>
<p>seqkit许多的命令都不需要将整个序列读入到内存中。包括：stat, fq2fa, fx2tab, tab2fx, grep, locate, replace, seq, sliding, subseq。</p>
<p>注意：如果使用subseq —gtf | —bed时，如果GTF或者BED文件太大，内存使用量会暴增，可以通过指定染色体：—chr，或者—feature去限制特征。</p>
<p>有一些命令需要将文件读入内存，但是可以用过rmdup 和 common减少内存使用。</p>
<p>随机—抽样</p>
<p>抽样命令sample和shuffle使用了随机功能，为了保证重现性，可以使用-s设置随机种子。这可以保证在不同的环境中可以有相同的抽样结果。</p>
<h1 id="序列长度分布"><a href="#序列长度分布" class="headerlink" title="序列长度分布"></a>序列长度分布</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -j 是线程数</span></span><br><span class="line">seqkit fx2tab -j 30 -l  -n -i -H file.fastq.gz | cut -f 4 &gt; Length.txt</span><br><span class="line"><span class="comment"># 查看Length.txt</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library(tidyverse)</span><br><span class="line"></span><br><span class="line">length &lt;- read_tsv(<span class="string">&quot;Length.txt&quot;</span>) %&gt;% group_by(<span class="built_in">length</span>) %&gt;%</span><br><span class="line">  summarise(Count = n())</span><br><span class="line"><span class="built_in">length</span>$length &lt;- <span class="built_in">as.character</span>(<span class="built_in">length</span>$<span class="built_in">length</span>)</span><br><span class="line">sum &lt;- <span class="built_in">sum</span>(<span class="built_in">length</span>$Count)</span><br><span class="line">ggplot(<span class="built_in">length</span>) + geom_col(aes(<span class="built_in">length</span>, Count), width = <span class="number">0.8</span>) + </span><br><span class="line">  geom_line(aes(<span class="built_in">length</span>, Count), group = <span class="number">1</span>) + geom_point(aes(<span class="built_in">length</span>, Count)) + </span><br><span class="line">  scale_y_continuous(sec.axis = sec_axis(~.*<span class="number">100</span>/<span class="built_in">sum</span>, name = <span class="string">&quot;% Relative Abundance&quot;</span>)) + xlab(<span class="string">&quot;Length&quot;</span>) +</span><br><span class="line">  theme_bw() + theme(panel.grid = element_blank(), </span><br><span class="line">                     axis.title = element_text(size = <span class="number">15</span>))</span><br><span class="line"></span><br><span class="line">ggsave(<span class="string">&quot;Length.png&quot;</span>, height = <span class="number">5</span>, width = <span class="number">8</span>)</span><br><span class="line">ggsave(<span class="string">&quot;Length.pdf&quot;</span>, height = <span class="number">5</span>, width = <span class="number">8</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>sequence-tool</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 内存 存储</title>
    <url>/blog/2022/02/24/2022-02-24-memory/</url>
    <content><![CDATA[<h1 id><a href="#" class="headerlink" title></a></h1><span id="more"></span>

<h1 id="内存是什么"><a href="#内存是什么" class="headerlink" title="内存是什么"></a>内存是什么</h1><ul>
<li><p>内存又称主存，是 CPU 能直接寻址的存储空间，由半导体器件制成</p>
</li>
<li><p>内存的特点是存取速率快</p>
</li>
<li><p>CPU、IO、磁盘、内存可以说是影响计算机性能关键因素</p>
</li>
<li><p>内存为进程的运行提供物理空间，同时作为快速CPU和慢速磁盘之间的适配器，</p>
</li>
</ul>
<h1 id="内存的作用"><a href="#内存的作用" class="headerlink" title="内存的作用"></a>内存的作用</h1><ul>
<li><p>暂时存放 cpu 的运算数据</p>
</li>
<li><p>硬盘等外部存储器交换的数据</p>
</li>
<li><p>保障 cpu 计算的稳定性和高性能</p>
</li>
</ul>
<h1 id="查看内存情况"><a href="#查看内存情况" class="headerlink" title="查看内存情况"></a>查看内存情况</h1><p>free命令是一个快速查看内存使用情况的方法，它是对 /proc/meminfo 收集到的信息的一个概述。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">free -h</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zds@ubuntu ~ $ free -m   <span class="comment"># 以 Mb 为单位显示</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line"><span class="comment"># 物理内存</span></span><br><span class="line">Mem:           2990        1528         383          49        1078        1217</span><br><span class="line"><span class="comment"># 虚拟内存</span></span><br><span class="line">Swap:          2044           0        2044</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zds@ubuntu ~ $ top</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">top - 23:43:07 up 32 min,  1 user,  load average: 0.17, 0.36, 0.34</span><br><span class="line">Tasks: 230 total,   1 running, 229 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s): 12.9 us,  5.6 sy,  0.0 ni, 81.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem :  2029876 total,   148224 free,   998788 used,   882864 buff/cache</span><br><span class="line">KiB Swap:  2094076 total,  2087304 free,     6772 used.   819128 avail Mem </span><br><span class="line"></span><br><span class="line">   PID 进程号    PR 优先级  VIRT 进程占用的虚拟内存值</span><br><span class="line">       USER 进程所有者              RES 进程占用的物理内存值</span><br><span class="line">                     NI 优先级相对值       SHR 进程使用的共享内存值</span><br><span class="line"></span><br><span class="line">   PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND</span><br><span class="line">   978 root      20   0  356740  84104  37752 S  8.9  4.1   0:19.39 Xorg    </span><br><span class="line">  1909 zds       20   0 1023828 118576  80360 S  4.6  5.8   0:18.36 compiz       </span><br><span class="line">  2439 zds       20   0  630364  52556  42052 S  4.3  2.6   0:08.29 gnome-terminal-   </span><br><span class="line">  1945 zds       20   0  633568  35384  28860 S  0.7  1.7   0:10.46 sogou-qimpanel- </span><br><span class="line">     7 root      20   0       0      0      0 S  0.3  0.0   0:01.94 rcu_sched   </span><br><span class="line">   845 root      20   0  187344   9684   8508 S  0.3  0.5   0:03.35 vmtoolsd  </span><br><span class="line">  1631 zds       20   0   43736   4216   2924 S  0.3  0.2   0:01.82 dbus-daemon </span><br><span class="line">  1795 zds       20   0  564648  29760  24496 S  0.3  1.5   0:01.08 unity-panel-ser</span><br><span class="line">  1958 zds       20   0 1026996  95708  27980 S  0.3  4.7   0:07.03 gnome-software</span><br><span class="line">  1966 zds       20   0  496776  28904  25224 S  0.3  1.4   0:03.52 vmtoolsd   </span><br><span class="line">  7336 zds       20   0   43652   3948   3340 R  0.3  0.2   0:01.25 top  </span><br><span class="line">     1 root      20   0  119836   5652   4024 S  0.0  0.3   0:03.27 systemd </span><br><span class="line">     2 root      20   0       0      0      0 S  0.0  0.0   0:00.00 kthreadd </span><br><span class="line">     3 root      20   0       0      0      0 S  0.0  0.0   0:00.52 ksoftirqd/0</span><br><span class="line">     5 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 kworker/0:0H </span><br><span class="line">     8 root      20   0       0      0      0 S  0.0  0.0   0:00.00 rcu_bh</span><br><span class="line">     9 root      rt   0       0      0      0 S  0.0  0.0   0:00.00 migration/0</span><br><span class="line">    10 root      rt   0       0      0      0 S  0.0  0.0   0:00.01 watchdog/0</span><br><span class="line">    11 root      20   0       0      0      0 S  0.0  0.0   0:00.00 kdevtmpfs </span><br><span class="line">    12 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 netns </span><br><span class="line">    13 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 perf </span><br><span class="line">    14 root      20   0       0      0      0 S  0.0  0.0   0:00.00 khungtaskd  </span><br></pre></td></tr></table></figure>



<p><strong>htop</strong>命令显示了每个进程的内存实时使用率。它提供了所有进程的常驻内存大小、程序总内存大小、共享库大小等的报告。列表可以水平及垂直滚动。</p>
<p><strong>top</strong>命令提供了实时的运行中的程序的资源使用统计。你可以根据内存的使用和大小来进行排序。</p>
<h1 id="Core-Dump"><a href="#Core-Dump" class="headerlink" title="Core Dump"></a>Core Dump</h1><ul>
<li>Core意思是内存, Dump的意思是扔出来, 堆出来。在开发（或使用）一个程序时，有时程序莫名其妙的down了, 却没有任何提示(有时提示core dumped)。虽然系统没事，但下次仍可能遇到相同问题。这时可查看有无形如core.PID的core文件生成，这个文件便是操作系统把程序down掉时的内存内容扔出来生成的，让debugger 做参考。这个动作叫 core dump。<ul>
<li>core dump又叫<strong>核心转储</strong>, 当程序运行过程中发生异常, 程序异常退出时, 由操作系统把程序当前的内存状况存储在一个core文件中, 叫core dump。简而言之，<font color="red">进程异常终止，进程用户空间的数据就会被写到磁盘core文件</font>。</li>
</ul>
</li>
</ul>
<h2 id="为何有时程序Down了，却没生成-Core文件"><a href="#为何有时程序Down了，却没生成-Core文件" class="headerlink" title="为何有时程序Down了，却没生成 Core文件"></a>为何有时程序Down了，却没生成 Core文件</h2><ul>
<li><font color="red">有时候程序down了, 不像编译错误会提示到文件某一行，而是没有任何信息</font>。一种办法是用gdb的step（linux下调试工具gdb是很强大的调试器）, 一步一步寻找，但要step一个上万行的代码让人难以想象。 更好的办法就是core file。</li>
<li><font color="red">如果core文件没有生成</font>，是因为core.PID的core文件的生成跟当前系统的环境设置有关系，<font color="red">系统默认core文件的大小为0</font>（注意core file size (blocks, -c) 0 这行，表示分配给core文件的长度（单位为字节，一个块的大小要分系统而定了），为0肯定无core文件，可修改之）</li>
<li>用ulimit命令查看和修改core文件的大小，使用<code>ulimit -a</code>查看大小，使用 <code>ulimit -c unlimited</code>表示对core文件不做限制 或 使用<code>ulimit -c 1024</code> 对core文件分配1024个字节</li>
<li><font color="red">程序运行过程出现aborted(core dumped)，ulimit -a，结果确实 core file size (blocks, -c) 0，无法生成中断文件</font></li>
<li>若修改后再运行程序便生成<code>core.PID</code>的core文件（<strong>core文件生成的位置一般和运行程序的路径相同, 文件名一般为core.进程号</strong>）。</li>
</ul>
<h2 id="如何使用core文件"><a href="#如何使用core文件" class="headerlink" title="如何使用core文件?"></a>如何使用core文件?</h2><ul>
<li>发生core dump后，使用gdb查看core文件内容, 以定位文件中引发core dump的行，在Linux下，查看core文件中的出错堆栈信息有二种方式，使用：<font color="red">gdb -c core.pid program_name</font>或gdb [program_name] [core.pid]可以进入gdb模式</li>
<li>在进入gdb后输入<font color="red">where并回车</font>，就可以指出是在哪一行被Down掉，在哪个函数内，由谁调用等等。</li>
<li>在进入gdb后输入<font color="red"> bt</font>，用bt命令查看backtrace以检查发生程序运行到哪里，来定位core dump的文件-&gt;行。</li>
</ul>
<h2 id="core-dump-原因"><a href="#core-dump-原因" class="headerlink" title="core dump 原因"></a>core dump 原因</h2><ul>
<li><p><font color="red">batch_size过大导致的。Aborted(core dumped)</font></p>
</li>
<li><p>线程被谋杀， 被谋杀者所在线程会抛出一个异常。Cancellation &amp; C++ Exception</p>
</li>
<li><p>pure virtual method called terminate called without an active exception 解决方案</p>
</li>
</ul>
<p>对于多线程的程序，这个错误的主要原因是当前对象已经被销毁或者正在被销毁，但是其又在被调用，导致了冲突。</p>
<ul>
<li>pure virtual method called</li>
</ul>
<hr>
<h1 id="查看存储空间："><a href="#查看存储空间：" class="headerlink" title="查看存储空间："></a>查看存储空间：</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zds@ubuntu ~ $ df -hl</span><br><span class="line">文件系统         容量   已用  可用 已用% 挂载点</span><br><span class="line">udev            972M     0  972M    0% /dev</span><br><span class="line">tmpfs           199M  6.3M  192M    4% /run</span><br><span class="line">/dev/sda1        23G  5.3G   17G   25% /</span><br><span class="line">tmpfs           992M  212K  991M    1% /dev/shm</span><br><span class="line">tmpfs           5.0M  4.0K  5.0M    1% /run/lock</span><br><span class="line">tmpfs           992M     0  992M    0% /sys/fs/cgroup</span><br><span class="line">tmpfs           199M   60K  199M    1% /run/user/1000 </span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>Genome Survey</title>
    <url>/blog/2022/02/23/2022-02-21-Survey/</url>
    <content><![CDATA[<h1 id><a href="#" class="headerlink" title></a></h1><span id="more"></span>

<p>基因组杂合度和重复序列对后续基因组组装有很大影响。</p>
<p><strong>高杂合</strong>基因组往往无法合并姊妹染色体，导致组装结果<strong>偏大</strong>。</p>
<p>而<strong>重复序列</strong>在组装中被折叠，使组装中出现缺口、错误，导致组装结果<strong>偏小</strong>。</p>
<p>不同的生物基因组之间杂合率和重复序列含量差异巨大，因此在基因组测序前需要对基因组特征进行调研，以确定测序方案，周期等。</p>
<p>目前常用的调研手段有三种：</p>
<ol>
<li>用流式细胞仪测定细胞核内的<strong>DNA总量</strong></li>
<li>用核型分析方法，识别<strong>染色体数量、倍性</strong></li>
<li>用调研图，通过二代测序，估算<strong>基因组大小、杂合度、重复序列比例、GC含量</strong>等。</li>
</ol>
<p>不同技术手段不同侧重，其中<font color="red">调研图</font>以<font color="green">低成本，低难度和更多的评估内容</font>使用最多，同时<font color="red"><strong>Survey所测二代数据还可用于回比基因组，评估组装质量</strong></font>。调研图<font color="green">基于数学统计学手段</font>获取物种信息的方式，因此对于已经研究的较为清晰的物种——主要是<font color="green"><strong>普通二倍体和简单多倍体</strong></font>，其<font color="green">染色体条数、倍性、大概基因组大小是已知</font>，此时仅选择<strong>survey</strong>足以满足基因组特征需要，但对于<strong>多倍体复杂基因组</strong>更推荐<strong>补充核型分析和流式</strong>，以和调研图相互印证补充。</p>
<hr>
<p><strong>Survey 方案</strong></p>
<p>通过质控、NT比对，获得高质量的clean data，为后续分析奠定良好基础；</p>
<p>基因组Survey基于小片段文库的低深度测序数据（50X）左右；</p>
<p>通过K-mer分析，有效的评估基因组大小、GC含量、杂合度以及重复序列的含量等信息；</p>
<p>全面了解某一物种基因组特征的有效方法；</p>
<p>为后续的全基因denove测序的组装策略的制定提供理论依据。</p>
<p><strong>分析内容</strong>：污染程度评估，基因组大小评估，杂合度评估，重复率评估，GC含量评估。【初步了解三代组装难度和预期大小】</p>
<p><strong>基因组复杂度预估?</strong></p>
<blockquote>
<p>普通基因组的定义？<br>单倍体、纯合二倍体或者杂合度&lt;0.5%，且重复序列含量&lt;50%，GC含量为35%到65%之间的二倍体。</p>
<p>复杂基因组的定义？<br>杂合度&gt;0.5%，重复序列含量&gt;50%，多倍体，GC含量处于异常的范围（GC含量&lt;35%或者GC含量&gt;65%的二倍体）。</p>
<p><font color="red">二倍体复杂基因组进一步细分为</font><br><font color="red"> 微杂合基因组（0.5%&lt;杂合率&lt;=0.8%)</font><br><font color="red"> 高杂合基因组（杂合率&gt;0.8%)</font><br> <font color="red">高重复基因组（重复序列比例&gt;50%）</font></p>
<p>基因组大小：<br> 基因组越大，测序花钱越多</p>
</blockquote>
<blockquote>
<ul>
<li>简单基因组: 杂合度低于0.5%, GC含量在35%~65%, 重复序列低于50%</li>
<li>二倍体普通基因组: 杂合度在0.5%~1.2%中间，重复序列低于50%。或杂合度低于0.5%，重复序列低于65%</li>
<li>高复杂基因组: 杂合度&gt;1.2% 或 重复率大于65%</li>
</ul>
</blockquote>
<hr>
<h1 id="质控"><a href="#质控" class="headerlink" title="质控"></a>质控</h1><p><img src="https://upload-images.jianshu.io/upload_images/11004598-2ca590314cf3d635.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/374/format/webp" alt="img"></p>
<p>各提出10,000对比对到<strong>NT库</strong>，如果都比对到同源物种，说明无污染，如果比对到细菌真菌，可能数据有污染。</p>
<h2 id="rawdata-qc"><a href="#rawdata-qc" class="headerlink" title="rawdata qc"></a>rawdata qc</h2><h2 id="trim"><a href="#trim" class="headerlink" title="trim"></a>trim</h2><h2 id="cleandata-qc"><a href="#cleandata-qc" class="headerlink" title="cleandata qc"></a>cleandata qc</h2><h2 id="NT数据库比对"><a href="#NT数据库比对" class="headerlink" title="NT数据库比对"></a>NT数据库比对</h2><p>Partially non-redundant nucleotide from all traditional divisions of GenBank, EMBL, and DDBJ excluding GSS,STS, PAT, EST, HTG, and WGS.</p>
<p><a href="https://ftp.ncbi.nih.gov/blast/db/FASTA/">NT库</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">blastn \</span><br><span class="line">-query reads_2.fa \</span><br><span class="line">-db /local_data1/public_data/database/genome_DB/nt/20190417_all/nt \</span><br><span class="line">-out reads_2.csv \</span><br><span class="line">-outfmt <span class="string">&quot;10 evalue length qseqid qlen qstart qend sacc slen sstart send pident nident sstrand qcovs qseq sseq sgi stitle&quot;</span> \</span><br><span class="line">-num_threads 4 -evalue 1e-5 -max_target_seqs 1</span><br></pre></td></tr></table></figure>



<hr>
<p><a href="https://blog.csdn.net/u012110870/article/details/82500748">https://blog.csdn.net/u012110870/article/details/82500748</a></p>
<h1 id="k-mers"><a href="#k-mers" class="headerlink" title="k-mers"></a>k-mers</h1><p>最简单的策略就是基于k-mer对基因组做一个简单的了解, 使用jellyfish统计k-mers，然后作图</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish count  -m 21 -s 20G -t 20 -o 21mer_out  -C --min-qual-char=? &lt;(zcat test_1.fq.gz) &lt;(zcat test_2.fq.gz)</span><br><span class="line"><span class="comment"># -m k-mers的K</span></span><br><span class="line"><span class="comment"># -s Hash大小, 根据文件大小确定</span></span><br><span class="line"><span class="comment"># -t 线程</span></span><br><span class="line"><span class="comment"># -o 输出前缀</span></span><br><span class="line"><span class="comment"># -C 统计正负链</span></span><br><span class="line"><span class="comment"># --min-qual-char 过滤低质量碱基。 在Phred+33中,?=30</span></span><br><span class="line">jellyfish histo -o 21mer_out.histo 21mer_out</span><br></pre></td></tr></table></figure>

<p>用R作图</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pdf(&quot;21_mer.out.pdf&quot;)</span><br><span class="line">dataframe19 &lt;- read.table(&quot;21mer_out.histo&quot;)</span><br><span class="line">plot(dataframe19[1:200,], type=&quot;l&quot;)</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure>

<p>由于只有一个主峰，说明该物种的杂合度并不高，基本上也就是二倍体。如果图中出现多个峰，说明它可能是多倍体或者是基因组杂合度高。</p>
<p>推荐文献: Genomic DNA k-mer spectra: models and modalities</p>
<h1 id="基于组装"><a href="#基于组装" class="headerlink" title="基于组装"></a>基于组装</h1><p>基于K-mers可以较好的预测基因组大小，并定性的了解基因组的复杂情况，如果想更具体的了解基因组的复杂度，可以先将50X以上的段片段进行组装，然后进行分析。</p>
<p>组装的工具比较多，推荐用SOAPdenovo，因为速度快。abyss?</p>
<p>新建一个contig.config, 增加如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">max_rd_len=150</span><br><span class="line">[LIB]</span><br><span class="line">avg_ins=200</span><br><span class="line">reverse_seq=0</span><br><span class="line">asm_flags=3</span><br><span class="line">rd_len_cutoff=100</span><br><span class="line">rank=1</span><br><span class="line">pair_num_cutoff=3</span><br><span class="line">map_len=32</span><br><span class="line">q1=read_1.fq</span><br><span class="line">q2=read_2.fq</span><br></pre></td></tr></table></figure>

<p>组装出参考序列</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/opt/biosoft/SOAPdenovo2/SOAPdenovo-63mer all -s contig.config -R -K 63 -p 30 -o assembly/graph</span><br></pre></td></tr></table></figure>

<p>最后graph.scafSeq是拼接后的序列, 提取出大于300bp的序列.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># adjust format</span><br><span class="line">bioawk -c fastx -v name=1 &#x27;&#123;if(length($seq)&gt;300) print &quot;&gt;&quot;name &quot;\n&quot; $seq;name+=1&#125;&#x27; assembly/graph.scafSeq &gt;contig.fa</span><br></pre></td></tr></table></figure>

<h1 id="杂合度估计"><a href="#杂合度估计" class="headerlink" title="杂合度估计"></a>杂合度估计</h1><p>将原来的序列回贴到contig上，并用samtools+bcftools进行snp calling.统计变异的碱基占总体的比例。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir -p index</span><br><span class="line">bwa index contig.fa -p index/contig</span><br><span class="line">bwa mem -v 2 -t 10 index/contig read_1.fq read_2.fq | samtools sort -n &gt; align.bam</span><br><span class="line">samtools mpileup -f contig align.bam | bcftools call -mv -Oz -o variants.gz</span><br></pre></td></tr></table></figure>

<p>一方面由于SOAPdenovo组装过程中会出错, 另一方面samtools在变异检测上也存在很高的假阳性, 所以总得先按照深度和质量过滤一批假阳性。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bcftools view -i &#x27; DP &gt; 30 &amp;&amp; MQ &gt; 30&#x27; -H variants.vcf.gz | wc -l</span><br><span class="line"># 325219, 无过滤是445113</span><br></pre></td></tr></table></figure>

<p>变异数目占基因组大小的比例就是杂合度。我的contig大概是200M，找到0.3M左右的变异，也就是0.0015，即0.15%.</p>
<h1 id="重复序列估计"><a href="#重复序列估计" class="headerlink" title="重复序列估计"></a>重复序列估计</h1><p>基于同源注释，用RepeatMasker寻找重复序列. 这里要注意分析的fasta的ID不能过长，也就是最好是<code>&gt;scaffold_1</code>这种形式，不然会报错。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/opt/biosoft/RepeatMsker/RepeatMasker -e ncbi -species arabidopsis -pa 10 -gff -dir ./ contig.fa</span><br><span class="line"># -e ncbi</span><br><span class="line"># -species 选择物种 用~/opt/biosoft/RepeatMasker/util/queryRepeatDatabase.pl -tree 了解</span><br><span class="line"># -pa 并行计算</span><br><span class="line"># -gff 输出gff注释</span><br><span class="line"># -dir 输出路径</span><br></pre></td></tr></table></figure>

<p>输出结果中主要关注如下三个</p>
<ul>
<li>output.fa.masked, 将重复序列用N代替</li>
<li>output.fa.out.gff, 以gff2形式存放重复序列出现的位置</li>
<li>output.fa.tbl, 该文件记录着分类信息</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">==================================================</span><br><span class="line">file name: anno.fasta</span><br><span class="line">sequences:         62027</span><br><span class="line">total length:  273135210 bp  (273135210 bp excl N/X-runs)</span><br><span class="line">GC level:         36.80 %</span><br><span class="line">bases masked:   79642191 bp ( 29.16 %)</span><br><span class="line">==================================================</span><br></pre></td></tr></table></figure>

<p>也就是说我们的物种有30%的重复序列，作为参考，拟南芥125Mb 14%重复序列, 水稻389M，36%重复</p>
<hr>
<h1 id="Grand-Omics"><a href="#Grand-Omics" class="headerlink" title="Grand Omics"></a><font color="green">Grand Omics</font></h1><p>快速：K-mer分析方法，可快速确定基因组特征</p>
<p>专业：简单基因组和复杂基因组（高杂合、多倍体等）采用不同算法软件</p>
<p>建库：Illumina PE150普通文库；或MGI PE150 普通文库。总量 ≥ 1μg；推荐数据量 ≥ 50X</p>
<p>分析内容：原始数据质控；数据污染检测；基因组大小预估；基因组杂合度预估</p>
<h2 id="数据质控及污染评估"><a href="#数据质控及污染评估" class="headerlink" title="数据质控及污染评估"></a>数据质控及污染评估</h2><p>对原始数据质控过滤，然后对原始数据（Raw data）及过滤后数据（Clean data）进行质量统计。随机取100,000条质控后的reads，统计reads在<font color="red">nt库</font>中的分布情况及比对上的物种分布，以评估数据污染情况。</p>
<h2 id="基因组大小和杂合度估计"><a href="#基因组大小和杂合度估计" class="headerlink" title="基因组大小和杂合度估计"></a>基因组大小和杂合度估计</h2><p>利用<font color="red">偏正态分布模型（skew normal distribution model）</font>，<font color="red">负二项式模型 (negative binomial model)</font> 对K-mer 数据进行拟合分析，进行基因组大小以及杂合度的评估，并生成最终基因组评估结果。</p>
<p>一般选择<strong>17-mer</strong>评估基因组大小，ATCG四种碱基组成长度为17的核苷酸片段有4(17次方)<del>17G，足以覆盖一般的正常基因组；15mer</del>1G。对于正常基因组可能覆盖度不够，导致估计不准确。&gt;15G，采用19-mer或21-mer。K-mer越大，包含错误位点的K-mer越多。为了<strong>避免回文序列，K为奇数</strong>。</p>
<h2 id="GC-depth-分析及污染评估"><a href="#GC-depth-分析及污染评估" class="headerlink" title="GC-depth 分析及污染评估"></a>GC-depth 分析及污染评估</h2><p>对<font color="red">组装的基因组序列</font>以<font color="red">5kb为windows</font>，无重复计算片段的<font color="red">平均GC含量和平均深度</font>并作图。基于每一个windows对应的平均GC和平均深度进行绘图。可以根据此图分析测序数据是否存在GC偏向性以及样本是否存在污染。</p>
<h1 id="Biomarker"><a href="#Biomarker" class="headerlink" title="Biomarker"></a><font color="green">Biomarker</font></h1><p>基因组survey以测序技术为基础，基于小片段文库的低深度测序，通过K-mer分析，快速获得基因组大小、杂合度、重复序列比例等基本信息，为制定该物种的全基因组de novo测序策略提供有效依据。</p>
<h2 id="调研图分析原理"><a href="#调研图分析原理" class="headerlink" title="调研图分析原理"></a>调研图分析原理</h2><p><img src="http://www.biomarker.com.cn/wp-content/uploads/2017/03/5-12.png" alt="5"></p>
<p>k-mer，将核酸序列以滑窗分成包含k个碱基的短序列，“mer”这个单词的来源<font color="red">monomeric unit，单体单元</font>。K一般为奇数（避免正反链混淆?）。统计所有reads中所出现的k-mer类型及各类型k-mer的深度（或者频率），绘制特定k-mer下不同深度k-mer片段的频数统计图，通常选择K-mer分布最多的峰为主峰，从而得到<font color="red"><strong>基因组大小=K-mer总数/K-mer主峰深度值</strong></font>。</p>
<p>由于基因组存在<font color="red">杂合位点和重复序列</font>，k-mer曲线不是标准泊松分布，在主峰前后出现其他的峰，如果存在一定<font color="red">杂合度</font>，会导致在<font color="red">主峰横坐标的二分之一处</font>出现<font color="red">杂合峰</font>，而一定的<font color="red">重复度</font>则会在<font color="red">主峰对应的横坐标整数倍</font>处出现<font color="red">重复峰</font>。</p>
<h2 id="调研图分析内容"><a href="#调研图分析内容" class="headerlink" title="调研图分析内容"></a>调研图分析内容</h2><p>评估基因组<font color="red">大小</font>；评估基因组<font color="red">杂合</font>情况；评估<font color="red">重复序列</font>含量；评估基因组<font color="red">GC含量</font>；为后续精细图阶段的文库构建提供策略建议。</p>
<h2 id="基因组调研图survey的意义"><a href="#基因组调研图survey的意义" class="headerlink" title="基因组调研图survey的意义"></a>基因组调研图survey的意义</h2><p>启动全基因组测序的<font color="red">必要前提</font></p>
<p>了解与<font color="red"><strong>近缘物种间</strong>的<strong>基因组差异</strong>信息</font></p>
<p>获得某<font color="red">物种基因组的基本信息及难易程度</font></p>
<h1 id="Novogene"><a href="#Novogene" class="headerlink" title="Novogene"></a><font color="green">Novogene</font></h1><p>方案：DNA10 ug；文库350bp；PE150测序，测序深度为50X</p>
<h2 id="分析内容"><a href="#分析内容" class="headerlink" title="分析内容"></a>分析内容</h2><ul>
<li>K-mer分析</li>
<li>预估物种基因组大小</li>
<li>GC含量和外源污染分析</li>
<li>杂合度评估</li>
<li>重复序列评估</li>
<li>初步组装</li>
<li>基于初步组装的版本，可以进行SSR标记开发和同源注释【highlevel】simple sequence repeats</li>
</ul>
<h1 id="BerryGenomics"><a href="#BerryGenomics" class="headerlink" title="BerryGenomics"></a><font color="green">BerryGenomics</font></h1><p>基于小片段文库低深度测序数据，通过K-mer分析，有效评估基因组大小、GC含量、杂合度高低及重复序列含量等信息，为后续的组装策略的制定提供理论依据。</p>
<p><a href="https://pdf.sciencedirectassets.com/272196/1-s2.0-S0092867419X0015X/1-s2.0-S0092867420306188/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOj//////////wEaCXVzLWVhc3QtMSJHMEUCIEP3b6JimIkwVtoSmPnQ7fbUGBl4eNBBDDnBn4Sgw6y2AiEA9ob5g/J4zQrFLsTKjhs51/F/1tP61OMYZBAruOkb0fgq+gMIQRAEGgwwNTkwMDM1NDY4NjUiDMQhUFOWJRI31LL0UyrXA4jlyI72DidSpx8zf2iw85fV3Vmv5GwQ6zAU0go3NjgbvnEQeGHSyjCD3bfuIdLxx9+JR3iu8nTJwgeiw9+Pub8vYWrjzALVOyDRYnN4C6P68gzwDtI75rViTKSOYGpm0LXGHIuNV3O6NG9GNYo9nKQUdsmQfjBcBVHGBhXgRhFbmvWhLVufPeyZIY/sw6wiX3diCmbAuE7tTj4O0tA4ht9m/9y/rMizkGh9ZPtbzZ7JDkZm0+cpNEzpq3cQrGGNFrTcYFMQLf9YYSiY5LNr+zDXEI/cud8Oj8u3J75X7AtKXVgDFx3WOLQId9J+kxO1tSZ5/glrj2Mrth4nSXKk2TcSj6sirRM7+QbGIcYbhUHe+97GuZSfy6tJSD8POUgAUJZwoh9mtVgEIgRBR3uHjlgquc2QL4w5HsPkDpKmCRjT5ZIlJKfBli2DLWB81D9uot9Aw5SNzZ+mx3uR2mpTibb5v54gw7HtVunol7a5sq4awm3L8KRSRvUwk+fwX38TdFUH7OxZaFWIlBk536NC4ceJTACy5V5Ae+f7lhfpLN5wHzi3JomqhWFjfqqDLY11VHUBE2hJ2MtKtSQwilpBH+qtouIVYoOLFsKgJGfh0HvzkymqMQdxizDUhM2QBjqlAa9D4CUBq0ExkdHUsNdoKZ3Mz+0m1f72NRgmttBXR/CcVH6PUnSta5nZU2WQy6dUTWTx6pl8YHzW/DDLcwdU82BkQOE1n6CSzHGjaKA75v3T4RWRU9wOiObTdjqpmmMKTp2xohm4N78+/ZejYhLhk1Tx/CnUl2ue4z1/Utn17JSca5oVGbePorLRmqyYs5F3oL08SP73vwHxeNaoI7f7ucpUWqEcHA==&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220221T081720Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYYN624BKH/20220221/us-east-1/s3/aws4_request&X-Amz-Signature=16e8a26f9b71e59d421ff693fe49b021ce1222b688728bb93ce93ea82fb5968d&hash=ccc160836e462b394593db49a0b599b8a106fca7b355f59e9e05635b2a62f335&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0092867420306188&tid=spdf-0c4aa40e-20ae-4f30-8d50-b9cee2090b93&sid=5071d2f0595c814bfc9b6e825f0c6315e333gxrqa&type=client&ua=570456075759005851&rr=6e0e89a71f5d7c4a">大豆高质量泛基因组图谱构建</a></p>
<p>我国大豆消费对外依赖严重，而提高大豆产量则必须对大豆种质的遗传多样性进行综合评价。中科院遗传与发育生物学研究所等单位与贝瑞基因合作，利用最新组装策略构建了高质量的基于图形的泛基因组。该研究利用Illumina平台对来自世界大豆主产国的2,898份大豆种质进行重测序（13×），利用PacBio（96×）、Bionano和Hi-C技术对26份代表性种质进行基因组组装和泛基因组构建。并以ZH13基因组为基准基因组，整合PAVs后构建基于基因组图谱。将重测序数据重新比对到该基因组进行SVs检测和GWAS分析。在开花的主效位点<em>E3</em>发现了5种不同的单倍型；种皮颜色相关基因<em>CHS</em>的<em>I</em>位点发现5种主要单倍型；14号染色体上的缺铁褪绿症QTL内存在一个调控Fe2+/Zn2+转运蛋白基因<em>SoyZH13_14G179600</em>。</p>
<hr>
<h1 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a><font color="green">Pipeline</font></h1><ul>
<li><p><strong>K-mer analysis</strong> (genome size,  repetive seq, heterozygous)</p>
<ul>
<li><p><a href="http://www.cbcb.umd.edu/software/jellyfish/">JELLYFISH</a>是<a href="http://www.cbcb.umd.edu/">CBCB(Center for Bioinformatics and Computational Biology)</a>的Guillaume Marçais 和 <a href="http://www.cs.cmu.edu/~ckingsf/">Carl Kingsford</a> 研发的一款计数 DNA 的 k-mers 的软件。该软件运用 Hash 表来存储数据，同时能多线程运行，速度快，内存消耗小。该软件只能运行在64位的Linux系统下。其<a href="http://bioinformatics.oxfordjournals.org/content/27/6/764">文章</a>于2011年发表在杂志 <a href="http://bioinformatics.oxfordjournals.org/">Bioinformatics</a> 上。<a href="https://www.cnblogs.com/zhanmaomao/p/9285582.html">https://www.cnblogs.com/zhanmaomao/p/9285582.html</a>,  <a href="https://github.com/gmarcais/Jellyfish#:~:text=Jellyfish%20Overview%20Jellyfish%20is%20a%20tool%20for%20fast%2C,central%20step%20in%20many%20analyses%20of%20DNA%20sequence">https://github.com/gmarcais/Jellyfish#:~:text=Jellyfish%20Overview%20Jellyfish%20is%20a%20tool%20for%20fast%2C,central%20step%20in%20many%20analyses%20of%20DNA%20sequence</a>.</p>
</li>
<li><pre><code class="sh">$ wget 最新targz
$ tar zxvf .tar.gz
$ mkdir jellyfish
$ cd jellyfish-2.3.0
$ ./configure --prefix=Your/Path/to/jellyfish
如果安装在当前目录中，会报错。
$ make -j 8
$ make install
</code></pre>
</li>
</ul>
<table>
<thead>
<tr>
<th>jellyfish</th>
<th>Kmer</th>
<th>Clean</th>
<th>Insert</th>
<th>Depth</th>
<th>Kpeak</th>
<th>HetP</th>
<th>Heter</th>
<th>repeatP</th>
<th>Repeat</th>
<th>Size</th>
</tr>
</thead>
<tbody><tr>
<td>[4]</td>
<td>17</td>
<td>30.29G</td>
<td>220 bp</td>
<td>62.99X</td>
<td>54.98X</td>
<td>26X</td>
<td>0.18%</td>
<td>106X</td>
<td>291.49Mb?(60.60%)</td>
<td>480.97 Mb</td>
</tr>
<tr>
<td>[5]</td>
<td>21</td>
<td>54.23G</td>
<td>270bp</td>
<td>83.69×</td>
<td>69 ×</td>
<td>34 ×</td>
<td>0.72%</td>
<td>139 ×</td>
<td>43.22%</td>
<td>648.07 Mb</td>
</tr>
<tr>
<td>[6]?</td>
<td>17</td>
<td>89G</td>
<td>350bp</td>
<td></td>
<td>48x</td>
<td>24x</td>
<td>0.69%</td>
<td>96x</td>
<td><strong>91.05%</strong></td>
<td>1.86G</td>
</tr>
<tr>
<td>[7]</td>
<td>19[21,23,25,27]</td>
<td>54.99G</td>
<td>270bp</td>
<td>45.37x</td>
<td>38x</td>
<td>19x</td>
<td>0.33%</td>
<td>76x</td>
<td><strong>70.62%</strong></td>
<td>1.2G</td>
</tr>
<tr>
<td>[8]自源四倍</td>
<td>17</td>
<td>27G</td>
<td>220</td>
<td></td>
<td>57</td>
<td>28</td>
<td><strong>1.37%</strong></td>
<td>114</td>
<td>42.81%</td>
<td>800M</td>
</tr>
<tr>
<td>[9]</td>
<td>17</td>
<td></td>
<td></td>
<td></td>
<td>52</td>
<td>26</td>
<td><strong>2.28%</strong></td>
<td>104</td>
<td><strong>89.2%</strong></td>
<td>4159 M</td>
</tr>
</tbody></table>
<ul>
<li>[6] : K-mer analysis:1.8G; flow cytometry: 8.50 ± 0.38 Gb. 巨大偏差？杂合度0.69%，重复ratio 91.05%</li>
</ul>
</li>
<li><p><strong>assembly</strong></p>
<ul>
<li><p>[4] : soap devovo, abyss. </p>
<ul>
<li>K-mer 31, 54, 63, 70, 77 ,83. 结果只有77，105 Kmer soapdenovo； AByss K43</li>
<li>optimal k-mer size was selected from the N50 length</li>
<li>usable reads &gt; 200 bases were selected to realign the contig </li>
<li>paired-end relationship between reads was coincident between contigs</li>
<li>scaffolds were constructed using insert size paired-ends</li>
</ul>
</li>
<li><p>[5] :</p>
</li>
<li><p>[8] :conduct de novo assembly. K-mer sizes of 20, 37, 55, 63, 71, 77, 83, and 95 were examined using default parameters. Assembly with k-mer 63 by SOAP de novo was selected because it has the optimal reading for N50</p>
<table>
<thead>
<tr>
<th>SOAPdenovo2</th>
<th>K-mer</th>
<th>ConN50</th>
<th>N90</th>
<th>TotalCon</th>
<th>ScaN50</th>
<th>N90</th>
<th>TotalSca</th>
<th>Genome</th>
</tr>
</thead>
<tbody><tr>
<td>[4]</td>
<td>77</td>
<td>1.48k</td>
<td>236</td>
<td>405M</td>
<td>3.55k</td>
<td>375</td>
<td>409M</td>
<td>480.97 M</td>
</tr>
<tr>
<td>[5]</td>
<td>65</td>
<td>1.59k</td>
<td>379</td>
<td>449M</td>
<td>3.5k</td>
<td>1262</td>
<td>543M</td>
<td>648.07 M</td>
</tr>
<tr>
<td>[6]?</td>
<td>41</td>
<td>287</td>
<td>127</td>
<td></td>
<td>1138</td>
<td>150</td>
<td></td>
<td></td>
</tr>
<tr>
<td>[7]</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>191bp</td>
<td></td>
<td>1.37G</td>
<td>1.2G</td>
</tr>
<tr>
<td>[8]</td>
<td>63</td>
<td>1.08k</td>
<td>219</td>
<td>170M</td>
<td>1.96k</td>
<td>1110</td>
<td>173M</td>
<td>800M</td>
</tr>
<tr>
<td>[9]</td>
<td></td>
<td>533</td>
<td></td>
<td></td>
<td>778</td>
<td>119</td>
<td>4.5G</td>
<td>4159M</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>GC</p>
<ul>
<li>[4] mid GC: 38%,  too high (&gt;65%) and too low (&lt;25%)</li>
<li>[4] GC depth two layer: only one of the two sets of homologous chromosomes in the diploid was assembled, which resulted in the emergence of the lower layer</li>
<li>[5] GC depth map was divided into 2 layers (Fig. 2), which was mainly due to the high heterozygosity.</li>
<li><font color="red"><strong>找近缘的GC做比较；看是否GC分层</strong></font></li>
<li>[8] the GC depth was slightly blocked into 4 layers (Fig. 2), which was in part caused by the polyploidy and the 1.37% high heterozygosity rate. 自源四倍体</li>
</ul>
</li>
<li><p><strong>Repetitive sequences</strong></p>
<ul>
<li>[4] :<strong>LTR_FINDER, MITE-Hunter, RepeatScout, and PILER-DF, PASTEClassifier, Repeat Masker, SciRoKo</strong> <ul>
<li>repetitive sequences ~147.89 Mb, 47.55% of the genome,</li>
<li>class I transposable element; class II transposable element</li>
<li>SSR(167,859SSR);  motif types</li>
</ul>
</li>
<li>[5] : total of 851,957 SSRs were identified,<strong>MISA</strong>. <ul>
<li>245 motif types</li>
</ul>
</li>
<li>[7] : <strong>MIcro-SAtellite(MISA)</strong><ul>
<li>Identification and characterisation of SSR motifs.</li>
<li>SSR marker verification</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Gene predition &amp; annotation</strong></p>
</li>
</ul>
<hr>
<p>ref</p>
<p><a href="https://www.jianshu.com/p/092103a24ce4">https://www.jianshu.com/p/092103a24ce4</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/366933242">https://zhuanlan.zhihu.com/p/366933242</a></p>
<p>[4] Genome Survey Sequencing for the Characterization of the Genetic Background of Rosa roxburghii Tratt and Leaf Ascorbate Metabolism Genes [Plos one]</p>
<p>[5] Genome survey sequencing and genetic diversity of cultivated <em>Akebia trifoliata</em> assessed via phenotypes and SSR markers [Molecular Biology Reports <strong>2.3IF</strong>]</p>
<p>[6] : Genome survey sequencing of red swamp crayfish <em>Procambarus clarkii</em> [<strong>2.3IF</strong>] </p>
<p>[7] Genome survey sequencing and characterization of simple sequence repeat (SSR) markers in Platostoma palustre (Blume) A.J.Paton (Chinese mesona) [scientific reports <strong>4.3IF</strong>]</p>
<p>[8] Genome survey sequencing of *Dioscorea zingiberensis [genome <strong>2.1IF</strong>]</p>
<p>[9]Genome survey sequencing of Atractylodes lancea and identification of its SSR markers[Bioscience Reports, IF3.84]</p>
]]></content>
      <categories>
        <category>assemble</category>
      </categories>
      <tags>
        <tag>survey</tag>
      </tags>
  </entry>
  <entry>
    <title>jellyfish &amp; Genomescope</title>
    <url>/blog/2022/02/23/2022-02-23-jellyfish-genomescope/</url>
    <content><![CDATA[<h1 id="A-fast-lock-free-approach-for-efficient-parallel-counting-of-occurrences-of-k-mers"><a href="#A-fast-lock-free-approach-for-efficient-parallel-counting-of-occurrences-of-k-mers" class="headerlink" title="A fast, lock-free approach for efficient parallel counting of occurrences of k-mers"></a>A fast, lock-free approach for efficient parallel counting of occurrences of k-mers</h1><span id="more"></span>

<h1 id="1-Paper-2011"><a href="#1-Paper-2011" class="headerlink" title="1. Paper-2011 :"></a><a href="https://pubmed.ncbi.nlm.nih.gov/21217122/">1. Paper-2011</a> :</h1><ul>
<li><p><font color="red">Counting the number of occurrences of every k-mer</font> </p>
</li>
<li><p> <font color="green">genome assembly</font></p>
</li>
<li><p><font color="purple">error correction</font> of sequencing reads</p>
</li>
<li><p><font color="daekred">fast multiple sequence alignment</font> </p>
</li>
<li><p><font color="blue">repeat detection</font></p>
</li>
<li><p><strong>current</strong> k-mer counting tools <strong>too slow</strong> , <strong>memory intensive</strong></p>
</li>
<li><p>multicore computers facilities <strong>parallel computational paradigm</strong></p>
</li>
<li><p>multithreaded, <font color="red">lock-free hash table</font> </p>
</li>
<li><p><strong>k-mers up to 31</strong> </p>
</li>
<li><p><strong>suffix arrays</strong> </p>
</li>
</ul>
<hr>
<h1 id="2-github-doc"><a href="#2-github-doc" class="headerlink" title="2. github-doc :"></a><font color="red"><a href="https://github.com/gmarcais/Jellyfish/tree/master/doc">2. github-doc</a></font> :</h1><h2 id="2-1-Counting-k-mers-in-sequencing-reads"><a href="#2-1-Counting-k-mers-in-sequencing-reads" class="headerlink" title="2.1 Counting k-mers in sequencing reads"></a>2.1 Counting k-mers in sequencing reads</h2><ul>
<li><p>The <code>-C</code> switch instructs to save in the hash only canonical规范 k-mers, while the count is the number of occurrences of both a k-mer and it reverse complement.</p>
</li>
<li><p><font color="green"><strong>-s</strong></font> 预估值设置：The size parameter (given with <font color="red">-s</font>) is an indication of <font color="red">the number k-mers [N*(L-K+1)]</font> that will be <font color="red"><strong>stored in the hash</strong></font>. For sequencing reads, this size should be the size of <font color="red">the genome plus the k-mers generated by sequencing errors</font>. For example, if the error rate is <font color="red">e</font> (e.g.Illumina reads, usually e~<font color="red">1%</font>), with an estimated genome size of G and a coverage of <font color="red">c</font>, the number of expected k-mers is <font color="red"><strong>G+Gcek</strong></font>.</p>
</li>
</ul>
<blockquote>
<p>NOTE: unlike in Jellyfish 1, this <code>-s</code> parameter is <font color="red">only an estimation</font>. <font color="red">If the size given is too small to fit all the k-mers, the hash size will be increased automatically or partial results will be written to disk and finally merged automatically</font>. Running <code>jellyfish merge</code> should never be necessary, as now jellyfish now takes care of this task on its own. </p>
</blockquote>
<ul>
<li><font color="green"><strong>-s 预估kmer以hash表存储所需内存大小，设置小了会自动扩大，并自动merge</strong></font>。</li>
<li>If the low frequency k-mers (k-mers occurring only once), which are mostly due to sequencing errors, are not of interest, one might consider counting only high-frequency k-mers (see section <a href="https://github.com/gmarcais/Jellyfish/tree/master/doc#Counting-high-frequency-k-mers">Counting high frequency k-mers</a>), which uses less memory and is potentially faster. <font color="green"><strong>低频k-mers由测序错误导致，只考虑高频减少内存使用提高速度</strong></font>。</li>
</ul>
<h2 id="2-2-Counting-k-mers-in-a-genome"><a href="#2-2-Counting-k-mers-in-a-genome" class="headerlink" title="2.2 Counting k-mers in a genome"></a>2.2 Counting k-mers in a genome</h2><ul>
<li>In an 【actual genome or finished sequence？】, a k-mer and its reverse complement are not equivalent, hence using the <code>-C</code> switch does not make sense. In addition, the size for the hash can be set directly to the size of the genome.</li>
<li>-C没有意义？哈希表的size直接设置为基因组大小？不够自动调整？</li>
</ul>
<h2 id="2-3-Counting-high-frequency-k-mers"><a href="#2-3-Counting-high-frequency-k-mers" class="headerlink" title="2.3 Counting high-frequency k-mers"></a>2.3 Counting high-frequency k-mers</h2><p>Jellyfish offers <font color="red">two way</font> to count only high-frequency k-mers (<font color="red"><strong>count &gt;1</strong></font>), which reduces significantly the memory usage. Both methods are based on using <font color="red">Bloom filters</font>. The first method is a one pass method, which <font color="red">provides approximate count for some percentage of the k-mers</font>. The second method is a two pass method which <font color="red">provides exact count</font>. In both methods, most of the low-frequency k-mers are not reported.</p>
<h3 id="2-3-1-One-pass-method"><a href="#2-3-1-One-pass-method" class="headerlink" title="2.3.1 One pass method"></a>2.3.1 One pass method</h3><h3 id="2-3-2-Two-passes-method"><a href="#2-3-2-Two-passes-method" class="headerlink" title="2.3.2 Two passes method"></a>2.3.2 Two passes method</h3><h2 id="2-4-Counting-a-subset-of-k-mers"><a href="#2-4-Counting-a-subset-of-k-mers" class="headerlink" title="2.4 Counting a subset of k-mers"></a>2.4 Counting a subset of k-mers</h2><ul>
<li>It is possible to count the number of occurrences of <font color="red">only a subset of</font> predefined k-mers, using the <font color="red"><strong>–if</strong></font> switch. Only count the 20-mers of chromosome 20 in chromosome 1 of human </li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish count -m 20 -s 100M -C -t 10 -o 20and1.jf --<span class="keyword">if</span> chr20.fa chr1.fa</span><br></pre></td></tr></table></figure>

<ul>
<li><p>This <strong>reads all the canonical 20-mers from the file chr20.fa</strong> (<font color="green"><strong>but don’t count them</strong></font>) and <font color="green"><strong>loads them in memory</strong></font>. Then it <strong>reads chr1.fa and counts the number of occurrences of the 20-mers</strong> <font color="green"><strong>only of the k-mers already loaded in memory</strong></font>.</p>
</li>
<li><p>把chr20的kmer，存储。统计chr1的20-mer在上一步存储中已存在的部分的数目。？chr1和20的关联？</p>
</li>
<li><p>Now, the histogram will also report k-mers with a <font color="green"><strong>0 count</strong></font> (<font color="green"><strong>the 20-mers of chr20</strong></font> which <font color="green"><strong>do not exists in chr1</strong></font>):</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ jellyfish histo 20and1.jf | head </span><br><span class="line">0 49401674</span><br><span class="line">1 1116213</span><br><span class="line">2 425471</span><br></pre></td></tr></table></figure>

<p>Note that the file given to <code>--if</code> is a fasta file. If a list of k-mers is available instead (say one per line in a text file), it can be transformed into a fasta file with one k-mer per line using the following one liner Perl command:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">perl -ne <span class="string">&#x27;print(&quot;&gt;\n$_&quot;)&#x27;</span></span><br><span class="line"><span class="comment">#kmer line转fa，一行&gt;号，一行kmer</span></span><br></pre></td></tr></table></figure>

<h2 id="2-5-如何读取压缩文件"><a href="#2-5-如何读取压缩文件" class="headerlink" title="2.5 如何读取压缩文件"></a>2.5 如何读取压缩文件</h2><p> jellyfish只读入fq或fa</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zcat *.fastq.gz | jellyfish count /dev/fd/0 ...</span><br><span class="line"><span class="comment">#using the &lt;() redirection provided by the shell (e.g. bash, zsh):</span></span><br><span class="line"><span class="comment">#!/usr/bin/bash</span></span><br><span class="line">jellyfish count &lt;(zcat file1.fastq.gz) &lt;(zcat file2.fasta.gz) ...</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="3-Jellyfish介绍"><a href="#3-Jellyfish介绍" class="headerlink" title="3. Jellyfish介绍"></a>3. Jellyfish介绍</h1><p><a href="http://www.cbcb.umd.edu/software/jellyfish/">JELLYFISH</a>是<a href="http://www.cbcb.umd.edu/">CBCB(Center for Bioinformatics and Computational Biology)</a>的Guillaume Marçais 和 <a href="http://www.cs.cmu.edu/~ckingsf/">Carl Kingsford</a> 研发的一款计数 DNA 的 k-mers 的软件。该软件运用 Hash 表来存储数据，同时能多线程运行，速度快，内存消耗小。该软件只能运行在64位的Linux系统下。其<a href="http://bioinformatics.oxfordjournals.org/content/27/6/764">文章</a>于2011年发表在杂志 <a href="http://bioinformatics.oxfordjournals.org/">Bioinformatics</a> 上。</p>
<h1 id="4-Jellyfish安装"><a href="#4-Jellyfish安装" class="headerlink" title="4. Jellyfish安装"></a>4. Jellyfish安装</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ wget 最新targz</span><br><span class="line">$ tar zxvf .tar.gz</span><br><span class="line">$ mkdir jellyfish</span><br><span class="line">$ <span class="built_in">cd</span> jellyfish-2.3.0</span><br><span class="line">$ ./configure --prefix=Your/Path/to/jellyfish</span><br><span class="line">如果安装在当前目录中，会报错。</span><br><span class="line">$ make -j 8</span><br><span class="line">$ make install</span><br></pre></td></tr></table></figure>

<h1 id="5-Jellyfish使用"><a href="#5-Jellyfish使用" class="headerlink" title="5. Jellyfish使用"></a>5. Jellyfish使用</h1><h2 id="jellyfish-count-【count-kmers-to-estimate-genome-size】"><a href="#jellyfish-count-【count-kmers-to-estimate-genome-size】" class="headerlink" title="jellyfish count 【count kmers to estimate genome size】"></a>jellyfish count 【count kmers to estimate genome size】</h2><p>Theory:</p>
<ul>
<li>If k is large enough so that each kmer found is unique in the genome,</li>
<li>and if the genome length (e.g. 1,000,000) is much larger than the kmer length (e.g. 21),</li>
<li>and if no PCR or sequencing errors,</li>
<li>then the number of kmers will be approximately equal to the length of the genome.</li>
</ul>
<p>！！！！<font color="red">Kmer counting tutorial</font>: <a href="https://bioinformatics.uconn.edu/genome-size-estimation-tutorial/#">https://bioinformatics.uconn.edu/genome-size-estimation-tutorial/#</a></p>
<ul>
<li>Jellyfish: <a href="https://github.com/gmarcais/Jellyfish">https://github.com/gmarcais/Jellyfish</a></li>
<li>Further jellyfish steps : <a href="https://github.com/gmarcais/Jellyfish/tree/master/doc">https://github.com/gmarcais/Jellyfish/tree/master/doc</a></li>
</ul>
<p>Note: Aug 2019: conda install seems to work only with: conda install jellyfish=2.2.3</p>
<p>Steps:</p>
<ul>
<li><font color="green">“&gt;Go through</font> the sequencing reads</li>
<li>For each <font color="green">new kmer seen</font>, <font color="green">add to table with count</font>.</li>
<li>If kmer <font color="green">seen before</font>, <font color="green">increment count</font>.</li>
<li>Find the <font color="green">average kmer frequency</font> (sequencing depth), e.g. 50</li>
<li><font color="green">Exclude kmers with a count of ~ 1</font>, as these are likely from <font color="green">errors</font></li>
<li>Add all the other kmers, and <font color="green"><strong>divide by average kmer frequency</strong></font> =&gt; This is the approx genome length</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish count -m 21 -s 100M -t 10 -C reads.fasta</span><br></pre></td></tr></table></figure>

<p>To use gzipped files: and <font color="green">paired-end reads</font>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish count -m 21 -s 100M -t 10 -C &lt;zcat R1.fq.gz) &lt;(zcat R2.fq.gz)</span><br></pre></td></tr></table></figure>

<ul>
<li>-m: kmer length, 21 is commonly used, <strong>17</strong></li>
<li>-s: size of hash table: should be genome size + extra kmers from seq errors. <font color="green">However, it does say that hash size <strong>will be increased automatically if needed</strong>.</font></li>
<li>-C: canonical. <font color="green">Reverse complement kmers are considered to be identical and are counted as the same thing</font>. <font color="green"><strong>This is recommended</strong></font>.</li>
<li>-t: number of threads</li>
<li>output: mer_counts.jf</li>
</ul>
<p>Plot the histogram:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish histo -t 10 mer_counts.jf &gt; reads.histo</span><br></pre></td></tr></table></figure>

<p><strong>???Plot the histogram with an x axis of one million instead of default 10,000</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish histo -t 10 --high=1000000 mer_counts.jf &gt; reads.histo</span><br></pre></td></tr></table></figure>

<ul>
<li>Discussion on setting to 1 million: <a href="https://github.com/schatzlab/genomescope/issues/22">https://github.com/schatzlab/genomescope/issues/22</a></li>
<li>There may be very high counts of some kmers due to chloroplast sequences, spike-in sequences, etc.</li>
</ul>
<blockquote>
<p>使用fastq文件在默认参数上和fasta文件没有区别。生成的hash结果为二进制文件。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-m | --mer-len=&lt;num&gt;</span><br><span class="line"> 使用的k-mer的长度。如果基因组大小为G，则k-mer长度选择为: k ~= <span class="built_in">log</span>(200G)</span><br><span class="line">/<span class="built_in">log</span>(4)。</span><br><span class="line">-s | --size=&lt;num&gt;</span><br><span class="line"> Hash 的大小。最好设置的值大于总的独特的(distinct)k-mer数,这样生成的文件只</span><br><span class="line">有一个。若该值不够大，则会生成多个<span class="built_in">hash</span>文件，以数字区分文件名。该值识别 </span><br><span class="line">M 和 G。</span><br><span class="line">-t | --threads=&lt;num&gt;  default: 1</span><br><span class="line"> 使用的CPU线程数</span><br><span class="line">-o | --output=&lt;string&gt;  default: mer_counts.jf</span><br><span class="line"> 输出的结果文件前缀</span><br><span class="line">-c | --counter-len=&lt;num&gt;  default:7</span><br><span class="line"> k-mer的计数结果所占的比特数,默认支持的最大数字是2^7=128。对于基因组测序覆盖</span><br><span class="line">度为N，则要使设置的该值要大于N。该值越大，消耗内存越大。</span><br><span class="line">-out-counter-len=&lt;num&gt;  default:4</span><br><span class="line"> 输出的二进制<span class="built_in">hash</span>文件中的计数结果所占的字节数,一个字节是8比特。则默认支持的最大</span><br><span class="line">数字是2^32=4.3G</span><br><span class="line"><span class="comment">#The count of k-mers which cannot be represented with the given number of bytes will have a value equal to the maximum value that can be represented. Meaning, if the counter field uses 1 byte, any k-mers with count greater or equal to 255 will be reported of having a count of 255.</span></span><br><span class="line">-C | --both-strand  default: <span class="literal">false</span></span><br><span class="line"> 【对正义链和反义链都进行计数】</span><br><span class="line">-q | --quake  default: <span class="literal">false</span></span><br><span class="line"> quake兼容模式</span><br><span class="line">--quality-start=&lt;num&gt;  default: 64</span><br><span class="line"> 起始碱基质量的ASCII值，默认为PHRED64</span><br><span class="line">--min-quality=&lt;num&gt;  default: 0</span><br><span class="line"> 支持的最小的碱基质量值，低于此值的碱基将由N代替</span><br><span class="line">-L | --lower-count=&lt;num&gt;</span><br><span class="line"> 【不输出数目低于此值的k-mer】</span><br><span class="line">-U | --upper-count=&lt;num&gt;</span><br><span class="line"> 【不输出数目高于此值的k-mer】</span><br><span class="line"><span class="comment">#low frequency and high frequency k-mers can be skipped using the --L and --U` switches respectively. Although it might be more appropriate to filter out the low frequency $k$-mers using Bloom filters, as shown in section Counting-high-frequency-k-mers.</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="jellyfish-merge-合并"><a href="#jellyfish-merge-合并" class="headerlink" title="jellyfish merge 合并"></a>jellyfish merge 合并</h2><p>Count的输出结果为二进制文件，可能输出多个hash文件，需要hash文件合并一个文件, merge 命令。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#The merge subcommand is of little direct use with version version 2 of Jellyfish</span></span><br><span class="line"><span class="comment">#The count subcommand will merge intermediary files automatically as needed.</span></span><br><span class="line">jellyfish merge -o mer_counts_merged.jf hash1 hash2 ...</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-o | –output=<string>  default: mer_counts_merged.jf<br>    输出的结果文件<br>–out-counter-len=<num>  default: 4<br>输出的二进制hash文件中的计数结果所占的字节数,一个字节是8比特。则默认支持的最大数字是2^32=4.3G</num></string></p>
</blockquote>
<h2 id="jellyfish-stats-统计"><a href="#jellyfish-stats-统计" class="headerlink" title="jellyfish stats 统计"></a>jellyfish stats 统计</h2><p>k-mer的结果以hash的二进制文件结果给出，需要统计出k-mer总数，特异的k-mer数目，只出现过一次的kmer数，出现了最多的k-mer的数目等信息。以stats命令来运行。使用方法：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Although these statistics could be computed from the histogram, it provides quick summary information</span></span><br><span class="line">$ jellyfish stats <span class="built_in">hash</span></span><br><span class="line">示例结果为：</span><br><span class="line">Unique:    32355544    <span class="comment">#只出现过一次的k-mer的数目</span></span><br><span class="line">Distinct:  88414020    <span class="comment">#特异性的k-mer数目，包含上一个的数据</span></span><br><span class="line">Total:     432232807   <span class="comment">#总的k-mer数目</span></span><br><span class="line">Max_count: 85348       <span class="comment">#同一个k-mer出现的最多的数目</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>-L | –lower-count=<num><br>    不统计数目低于此值的k-mer<br>-U | –upper-count=<num><br>    不统计数目高于此值的k-mer</num></num></p>
</blockquote>
<h2 id="jellyfish-histo-绘图"><a href="#jellyfish-histo-绘图" class="headerlink" title="jellyfish histo 绘图"></a>jellyfish histo 绘图</h2><p>对k-mer的计数结果有个直观的认识，则需要统计出现了x(x=1,2,3…)次的kmer的数目y,以x，y为横纵坐标画出直方图。使用 histo 命令能给出 x 和 y 对应的值，将结果默认输出到标准输出。其使用方法为</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish histo -l 1 -h 1000 <span class="built_in">hash</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>-l | –low=<num>  default: 1<br>    最低的 x 轴的值。同时结果会将低于此值的所有的k-mer的数目作为 (x-1) 的值。因<br>此该值为 2 和 1 的结果是一致的。<br>-h | –high=<num>  【default: 10000？？】<br>    最高的 x 轴的值。同时结果会将高于此值的所有的k-mer的数目的和作为 (x+1) 的值。<br>-i | –increment=<num>  default: 1<br>    x 轴取值是每隔该数值取值<br>-t | –threads=<num>  default: 1<br>    使用的CPU线程数<br>-f | –full  default: false<br>    全部的直方图</num></num></num></num></p>
</blockquote>
<h2 id="jellyfish-dump-结果文件格式转换"><a href="#jellyfish-dump-结果文件格式转换" class="headerlink" title="jellyfish dump 结果文件格式转换"></a>jellyfish dump 结果文件格式转换</h2><p>由于count命令生成的结果为二进制的，如有需要，则可以转换成可读文本文件。使用 dump 命令，使用方法：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish dump -c -t -U 1000 <span class="built_in">hash</span></span><br><span class="line"><span class="comment">#To output all the counts for all the k-mers in the file</span></span><br><span class="line"><span class="comment">#By default, the output is in FASTA format</span></span><br><span class="line">jellyfish dump mer_counts.jf &gt; mer_counts_dumps.fa</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-c | --colum  default: <span class="literal">false</span></span><br><span class="line"> 生成结果为2列，第一列为k-mer序列，第二列为对应的数目。默认情况下是是fasta格</span><br><span class="line">式，fasta的头为k-mer的数目，fasta的序列为k-mer的序列。</span><br><span class="line">-t | --tab  default: <span class="literal">false</span></span><br><span class="line"> 当 -c 参数存在时，以tab来进行分隔两行。默认是以空格来分开的。</span><br><span class="line"><span class="comment"># Low frequency and high frequency k-mers can be skipped with the `-L` and `-U` switches respectively.</span></span><br><span class="line">-L | --lower-count=&lt;num&gt;</span><br><span class="line"> 不输出小于该值的k-mer</span><br><span class="line">-U | --upper-count=&lt;num&gt;</span><br><span class="line"> 不输出高于该值的k-mer</span><br><span class="line">-o | --output=&lt;file&gt;</span><br><span class="line"> 输出文件的路径和名称</span><br></pre></td></tr></table></figure>



<h2 id="jellyfish-query-查询"><a href="#jellyfish-query-查询" class="headerlink" title="jellyfish query 查询"></a>jellyfish query 查询</h2><p>如果需要从Hash结果中查询指定的k-mer出现的次数，则要是用 query 命令。从标准输入读取k-mer的序列，从标准输出得到k-mer对应的数目。使用方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish query hash</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-C | –both-strands  default: false<br>   同时查询k-mer序列的正负链<br>-i | –input=<file><br>   输入的文件<br>-o | –output=<file><br>   输出的文件</file></file></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish query mer_counts.jf AACGTTG</span><br></pre></td></tr></table></figure>



<h2 id="jellyfish-info"><a href="#jellyfish-info" class="headerlink" title="jellyfish info"></a>jellyfish info</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#To get some information on 【how, when and where】 this jellyfish file was 【generated】, use the info subcommand</span></span><br><span class="line"><span class="comment">#outputs some information about the jellyfish file and the command used to generated it, in which directory and at what time the command was run</span></span><br><span class="line">jellyfish info mer_counts.jf</span><br></pre></td></tr></table></figure>

<h2 id="jellyfish-mem"><a href="#jellyfish-mem" class="headerlink" title="jellyfish mem"></a>jellyfish mem</h2><p>The <code>mem</code> subcommand shows how much memory a count subcommand will need or conversely how large of a hash size will fit in a given amount of memory.</p>
<hr>
<p>ref：</p>
<p><a href="https://www.annasyme.com/docs/jellyfish.html">https://www.annasyme.com/docs/jellyfish.html</a></p>
<hr>
<h1 id="Genomescope"><a href="#Genomescope" class="headerlink" title="Genomescope"></a>Genomescope</h1><p>安装github最新</p>
<p><font color="red">githubdoc</font>  : <a href="https://github.com/schatzlab/genomescope">https://github.com/schatzlab/genomescope</a></p>
<p><font color="red">paperlink</font> : <a href="https://doi.org/10.1093/bioinformatics/btx153">https://doi.org/10.1093/bioinformatics/btx153</a></p>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>将paired-end数据整合？将read2数据的序列反向重复后与read1文件合并？使用Trinity附带的fastool程序完成转换。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ zcat read_1.clean.fq.gz | <span class="variable">$Trinity_Home</span>/trinity-plugins/fastool/fastool --illumina-trinity --to-fasta &gt; reads_1.fasta</span><br><span class="line">$ zcat read_2.clean.fq.gz | <span class="variable">$Trinity_Home</span>/trinity-plugins/fastool/fastool --rev --illumina-trinity --to-fasta &gt; reads_2.fasta</span><br><span class="line">$ cat reads_1.fasta reads_2.fasta &gt; both.fasta</span><br></pre></td></tr></table></figure>

<h2 id="统计kmer"><a href="#统计kmer" class="headerlink" title="统计kmer"></a>统计kmer</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">jellyfish count -C -m [] -s [] -t [] s.fasta -o s.jf</span><br></pre></td></tr></table></figure>

<h2 id="绘直方图"><a href="#绘直方图" class="headerlink" title="绘直方图"></a>绘直方图</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jellyfish histo -t 10 s.jf &gt; s.histo</span><br></pre></td></tr></table></figure>

<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-s 预估哈希表的大小，即G+Gce*k。G是Genome Size；c是coverage（genome survey测序通常低于100x）；e是测序错误率（illumina为1%）；k是kmer大小。</span><br><span class="line">-C 表示考虑DNA正义与反义链，遇到反义kmer时，计入正义kmer频数中。</span><br></pre></td></tr></table></figure>

<h2 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Rscript genomescope.R histogram_file k-mer_length read_length output_dir [kmer_max] [verbose]</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>assemble</category>
      </categories>
      <tags>
        <tag>survey</tag>
      </tags>
  </entry>
  <entry>
    <title>HiFi-2-SMRT Sequencing - HiFi Reads [High fidelity reads]</title>
    <url>/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/</url>
    <content><![CDATA[<h1 id="主流三代测序平台Oxford-的-Nanopore，Pacific-Biosciences（-PacBio）的-Single-Molecule-Real-Time（SMRT）Sequencing"><a href="#主流三代测序平台Oxford-的-Nanopore，Pacific-Biosciences（-PacBio）的-Single-Molecule-Real-Time（SMRT）Sequencing" class="headerlink" title="主流三代测序平台Oxford 的 Nanopore，Pacific Biosciences（ PacBio）的 Single Molecule Real-Time（SMRT）Sequencing"></a>主流三代测序平台Oxford 的 Nanopore，Pacific Biosciences（ PacBio）的 Single Molecule Real-Time（SMRT）Sequencing</h1><span id="more"></span>

<p>Ref:<a href="https://zhuanlan.zhihu.com/p/339875837">https://zhuanlan.zhihu.com/p/339875837</a></p>
<p><a href="http://pacbiofileformats.readthedocs.io/en/5.0/">http://pacbiofileformats.readthedocs.io/en/5.0/</a></p>
<p>PacBio优势：</p>
<ul>
<li>在不影响吞吐量和准确性前提下，提供目前<font color="green">最长的读取长度</font></li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/1.png" alt="img"></p>
<ul>
<li>如果不含系统误差，准确度可达<font color="green"> 99.999％</font></li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/2.png" alt="img"></p>
<ul>
<li>可测取富<font color="green">含AT或GC区域</font>，<font color="green">高度重复序列</font>，<font color="green">回文序列</font>等，不会产生GC的较大偏差</li>
<li>可以直接<font color="green">测取化学修饰</font>，在<font color="green">表观遗传学</font>中有重要应用</li>
</ul>
<h1 id="文库构建"><a href="#文库构建" class="headerlink" title="文库构建"></a>文库构建</h1><p>将样本中的DNA或RNA分子提取后，构建<font color="green">哑铃状分子结构<strong>SMRTbell</strong></font>：</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/3.png" alt="img"></p>
<p>黄色，紫色：双链DNA分子; 蓝色：接头（Adapter）</p>
<p>文库分子展开，一个完整的<font color="green">圆环</font>：</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/4.png" alt="img"></p>
<p>圆环结构有利于周而复始的滚环复制，利于纠错。</p>
<p>将样本中所有的DNA片段都构建哑铃状分子结构，组成的集合叫<font color="green">文库</font>（SMRTbell Library），随后被放到测序芯片中。</p>
<p>以基因组HiFi文库为例（15-20K文库）。当得到gDNA后，先利用G-tube管或Megaruptor System将基因组<strong>片段化</strong>至合适大小，而后通过<strong>去除单链悬突</strong>、<strong>损伤修复</strong>和<strong>末端修复</strong>等步骤，得到完整的双链插入片段。接下来，通过将<strong>接头连接</strong>至双链DNA来创建SMRTbell文库，从而得到环状模板。完成接头连接后，需要对连接产物进行纯化，利用<strong>酶处理</strong>来消化线性或内部损伤环形DNA分子（游离的Hairpin Adapter、两端未连接Adapter的DNA模板、已成环但内部有损伤的DNA模板），酶处理完毕后，一般会利用<strong>Bulepippin</strong>或Sage ELF System切胶<strong>回收目标大小范围</strong>内的文库。文库质检</p>
<h1 id="测序芯片"><a href="#测序芯片" class="headerlink" title="测序芯片"></a>测序芯片</h1><p>以 RSII 测序平台为例，测序仪芯片（SMRT Cell）：</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/5.png" alt="img"></p>
<p>放大：上面整齐排列着<font color="green">15万个</font>直径为<font color="green">70纳米的测序微孔</font>（<font color="red">Zero-Model Waveguides，ZMWs</font>）。</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/6.png" alt="img"></p>
<h1 id="上机测序"><a href="#上机测序" class="headerlink" title="上机测序"></a>上机测序</h1><h2 id="1-构建测序复合物"><a href="#1-构建测序复合物" class="headerlink" title="1. 构建测序复合物"></a>1. <strong>构建测序复合物</strong></h2><p>测序复合物：聚合酶，测序模板，测序引物</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/7.png" alt="img"></p>
<h2 id="2-复合物撒入测序小孔"><a href="#2-复合物撒入测序小孔" class="headerlink" title="2. 复合物撒入测序小孔"></a>2. <strong>复合物撒入测序小孔</strong></h2><p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/8.png" alt="img"></p>
<h2 id="3-固定测序复合物"><a href="#3-固定测序复合物" class="headerlink" title="3. 固定测序复合物"></a>3. <strong>固定测序复合物</strong></h2><p>由于<font color="green">聚合酶加了<strong>生物素</strong></font>，在<font color="green">芯片玻璃底板有<strong>链酶亲和素</strong></font>。利用生物素和链酶亲和素的亲和力，包含聚合酶的<strong>测序复合物会被<font color="green">固定</font>在玻璃底板。</strong></p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/9.png" alt="img"></p>
<h2 id="4-构建带有荧光基团的dNTP"><a href="#4-构建带有荧光基团的dNTP" class="headerlink" title="4. 构建带有荧光基团的dNTP"></a>4. <strong>构建带有荧光基团的dNTP</strong></h2><p>在芯片溶液中含有许多游离dNTP，所谓游离dNTP就是随机飘在溶液中的dNTP。</p>
<p>ATGC四种碱基的dNTP，在磷酸基团上分别带有<font color="green">四种颜色的荧光基团</font>。</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/10.png" alt="img"></p>
<h2 id="5-边合成边测序"><a href="#5-边合成边测序" class="headerlink" title="5. 边合成边测序"></a>5. <strong>边合成边测序</strong></h2><p>在合成时，游离的dNTP被固定在底板上的酶捕获，<font color="green">激发光会从玻璃板底部发出</font>。</p>
<p><video src="2022-02-20-SMRT-sequencing/11.mp4"></video><br><strong>怎么保证每次测取一个碱基？</strong></p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/12.png" alt="img"></p>
<p>由于测序小孔直径很小，激发光的穿透能力会逐渐衰减，只能在小孔中传输很短的距离，所以<font color="green">只有当dNTP足够靠近底部，荧光基团才会被激发光照到，发出荧光</font>。其他游离dNTP虽然也有可能飘到小孔底部被激发光照到，但这种情况极少。<br>在一个碱基合成结束后，带有荧光基团的磷酸基团会从dNTP上掉落，发生猝灭，不影响其他碱基的信号检测。 在发生测序的小孔有各自的DNA片段和测序复合物，同一时间发出不同颜色的激发光，机器会检测到如下的光信号，实际同时会得到多达几万个光点。</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/13.png" alt="img"></p>
<p>重复上述步骤，经过计算机分析光谱，最终我们拿到样本的测序文件。SMRT Sequencing 测序过程中，<font color="green">每秒读取三个碱基</font>，一个小时可检测大约一万多碱基。</p>
<h2 id="6-检测碱基甲基化"><a href="#6-检测碱基甲基化" class="headerlink" title="6. 检测碱基甲基化"></a>6. <strong>检测碱基甲基化</strong></h2><p>在SMRT Sequencing测序过程中，可以<font color="green">直接测到碱基被修饰状态</font>，聚合酶遇到碱基上带有甲基化的碱基，<font color="green">合成速度明显变慢</font>，而且<font color="green">光谱也会发生改变</font>。SMRT Sequencing 可以检测到碱基的甲基化修饰。</p>
<h1 id="测序模型"><a href="#测序模型" class="headerlink" title="测序模型"></a>测序模型</h1><h2 id="1-Circular-Consensus-Sequencing-CCS-–-HiFi"><a href="#1-Circular-Consensus-Sequencing-CCS-–-HiFi" class="headerlink" title="1. Circular Consensus Sequencing (CCS) – HiFi"></a>1. Circular Consensus Sequencing (CCS) – HiFi</h2><p>说这种测序模型前，就不得不提三代测序最大的缺点：<font color="green">碱基读取不准，错误率在12.5%</font>。每八个碱基读错一个。</p>
<p>碱基读取<font color="green">错误随机</font>，重读一遍同样位置的碱基，不一定发生相同错误。</p>
<p>对同一个序列，多测几遍，<font color="red">矫正</font>读错碱基。</p>
<p>滚环复制的优势: 利用测序复合物在<font color="red">环状文库分子循环测序</font><strong>同一个片段</strong>来<font color="green">消除错误率</font>。</p>
<p>HiFi reads（High Fidelity reads）是2019年由PacBio推出的基于<font color="red">环化共有序列（Circular Consensus Sequencing，CCS）</font>模式产生的既兼顾长读长（<font color="red">10-20kb</font>长度）又具有高精度（&gt;99%准确率）的测序结果。</p>
<p>超长酶读长中，去掉接头序列，即可获得多条subreads。多条subreads合并生成高度一致性的hifi reads。</p>
<p><video src="2022-02-20-SMRT-sequencing/14.mp4"></video><br>这种测序模型，复制出的 Reads叫 <font color="red">HiFi Reads [High fidelity reads]</font>，测序准确率 &gt; 99%。</p>
<p>HiFi reads are a <strong>type of data produced using the circular consensus sequencing (CCS) mode on one of the PacBio Sequel Systems</strong>.</p>
<p>HiFi reads（High fidelity reads）是 <font color="red">Sequel II</font>三代测序平台推出的兼顾长读长和高准确度的测序序列，一般采用CCS（Circular Consensus Sequencing）模式测序。</p>
<p>在单次测序中得到更多的HiFi reads往往需要<strong>平衡</strong>测序的 <font color="red">酶读长</font>和 <font color="red">插入片段的长度</font>，插入片段太长会导致酶无法进行滚环测序，插入片段太短又牺牲了三代长读长测序的优势。</p>
<p>根据前期的官方经验推荐，目前HiFi文库构建的<font color="red">插入片段一般为8-13 kb</font>左右。安诺优达构建约10 kb的HiFi文库在<font color="red">Sequel II</font>平台进行测序。原始下机数据单cell产出268 Gb数据，其中<font color="red">酶平均读长51 kb</font>，<font color="red">酶读长N50 124 kb</font>，<font color="red">subreads平均读长11 kb</font>，<font color="red">subreads N50 13 kb</font>。</p>
<ul>
<li>下机数据产出统计表</li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/15.png" alt="1562200674629303.png"></p>
<p>进一步利用官方软件调取CCS，设置最小pass数为3，经过调取获得CCS总数据量为<strong>22.43 Gb</strong>，CCS 序列数目为<strong>172.5万</strong>条<strong>，平均长度</strong>13 kb<strong>。与下机总数据量相比，</strong>目前CCS reads的得率约为8%，并且能够兼顾reads的读长，达到平均13 kb左右，数据质量相当不错??</p>
<ul>
<li>CCS数据产出统计表</li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/16.png" alt="1562200759526715.png"></p>
<p>对拿到的HiFi reads进行进一步的<font color="red">质量评估</font>，我们发现大部分HiFi reads的<font color="red">准确度?</font>都在0.95以上，其中约35%的reads（pass≥10）质量值达到QV30（99.9%），这样高质量的reads非常有助于研究者开展下游深入的研究。</p>
<ul>
<li>CCS质量分布图</li>
</ul>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/17.png" alt="1562200823347872.png"></p>
<p>同时兼顾长读长和高准确度的HiFi reads究竟有何用处呢？2019年<em>BioRxiv</em>题为“<strong>Highly-accurate long-read sequencing improves variant detection and assembly of a human genome</strong>”的文章。在这篇文章里研究者利用约30X的CCS reads组装人基因组，通过<font color="green">FALCON、Canu3和 wtdbg2</font>等不同软件进行组装，<font color="red">contig N50达到15.43-28.95 Mb</font>。从组装连续性来看，<strong>CCS reads能够做到与<font color="red">传统的CLR reads</font>组装相当的结果，重要的是基因组碱基准确度得到了明显提升，基因组组装消耗的计算资源和时间大幅下降</strong>。进一步利用CCS reads进行<font color="red">SNP、InDel等变异检测</font>，发现CCS reads在小的变异检出率和准确度上都有显著提升，数据结果与30X的Illumina数据分析结果基本接近。</p>
<ul>
<li>文章中CCS reads进行SNV和InDel calling统计表</li>
</ul>
<p><img src="/blog/./18.png" alt="1562200919110586.png"></p>
<p>综上，HiFi reads无论在<font color="red">基因组全变异检测（SNV、InDel、SV）</font>还是<font color="red">基因组<em>de novo</em></font>领域都适用。目前<font color="red">唯一的限制因素</font>是要获得足够的HiFi reads，测序成本投入比较<font color="red">昂贵</font>，从组装<strong>计算资源节省</strong>和<strong>项目时间缩短</strong>的角度看，HiFi reads未尝不是更好的选择。<strong>对于基因组<font color="red">重复序列较多的复杂基因组</font>，目前市场上<font color="red">传统长读长测序准确度不高</font>的特点给组装造成了一定的困难，高准确度的HiFi reads未来可能是一个更好的解决方案。</strong>而对于昆虫、中草药、藻类等重复序列较高、基因组较小的物种（＜700 Mb），目前利用一个8 M SMRT Cell 产出的数据量基本足以支持CCS组装，性价比更高。需要完善的HiFi文库建库流程和基于CCS reads组装的生信流程！</p>
<h2 id="2-Continuous-Long-Read-CLR-Sequencing"><a href="#2-Continuous-Long-Read-CLR-Sequencing" class="headerlink" title="2. Continuous Long Read (CLR) Sequencing"></a>2. Continuous Long Read (CLR) Sequencing</h2><p>这种测序的优势在于可以读取更长的 Reads。<font color="red">？为什么更长</font></p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/19.gif" alt="img"></p>
<h1 id="其他影响因素"><a href="#其他影响因素" class="headerlink" title="其他影响因素"></a>其他影响因素</h1><h2 id="1-GC-bias-影响"><a href="#1-GC-bias-影响" class="headerlink" title="1. GC bias 影响"></a>1. <font color="red">GC bias 影响</font></h2><blockquote>
<p>什么是 GC bias？<br>PCR 时，如果模板里的<font color="red">G、C碱基含量高，PCR效率低</font>，A、T碱基含量高，PCR效率高。一般测序过程，如二代测序，都会有大量的PCR过程。这样就会有一个问题，<font color="red">G、C含量高的片段，读到的 Reads 数少</font>。</p>
</blockquote>
<p>SMRT 没有 PCR ，因此GC含量高低的 Reads 片段都会有相似的概率被测序， GC Bias 影响小。</p>
<h2 id="2-读长的限制因素"><a href="#2-读长的限制因素" class="headerlink" title="2. 读长的限制因素"></a>2. 读长的限制因素</h2><ul>
<li><strong>DNA模板断裂</strong>，用激发光长时间照射DNA链时，会发生断裂，DNA链会从酶上掉下来，测序终止。</li>
<li><strong>酶变性</strong>，酶被长时间照射时，酶会变性，失去聚合酶活性，测序终止。</li>
<li><strong>文库序列短</strong>，如果做文库序列片段大于 20~30 K ，且保证质量的文库是有技术难度的</li>
</ul>
<h2 id="3-测序通量"><a href="#3-测序通量" class="headerlink" title="3. 测序通量"></a>3. 测序通量</h2><p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/20.png" alt="img"></p>
<p>目前，主流的测序平台有三种，各有利弊，可以根据自己的课题来选择。</p>
<p>以RSII为例，将测序复合物，随机撒到15万个小孔中，正好有一个<font color="red">复合物进入到单个小孔的概率符合泊松分布</font>。理论情况是</p>
<ul>
<li>1/3 的小孔中有<font color="red">一个</font>测序复合物，正常信号</li>
<li>1/3 的小孔什么都<font color="red">没有</font>，无信号</li>
<li>1/3 的小孔中有<font color="red">两个以上的测序复合物</font>，杂乱信号</li>
</ul>
<p>五万个小孔 * 10kb，所以一张芯片大约会产出500M的数据。</p>
<hr>
<h1 id="三代下机数据（以sequel-平台为主）"><a href="#三代下机数据（以sequel-平台为主）" class="headerlink" title="三代下机数据（以sequel 平台为主）"></a>三代下机数据（以sequel 平台为主）</h1><h2 id="测序过程"><a href="#测序过程" class="headerlink" title="测序过程"></a>测序过程</h2><ul>
<li><font color="green">A adapter</font>通用接头，两端的接头可以一样也可以不一样</li>
<li><font color="green">B barcode</font>(客户自己设计)</li>
<li><font color="green">I insert </font>插入片段，即我们测序的目的片段</li>
<li>由于SMRTbell是环状的，测序过程是边合成边测序，因此可以沿着新链合成的方向不停地读取序列，读取一圈又一圈</li>
</ul>
<h2 id="测序结果"><a href="#测序结果" class="headerlink" title="测序结果"></a>测序结果</h2><ul>
<li>根据SMRTbell的形状以及测序的过程，我们容易知道，测序出来的reads如上图所示，由接头序列, 条码序列, 插入序列间隔线性分布，即ABIB-ABIB—ABIB-ABIB—…（A: adapter, B: barcode, I: insert）</li>
<li> <font color="green">ZMW read</font> 是测序出来的完整结果，也即是<font color="green">polymerase read</font>，聚合酶合成过的所有的序列。</li>
<li> PostPrimary 分析后输出<font color="green">HQ region</font>，由ZMW read <font color="green">去除两端低质量</font>区域得到。</li>
</ul>
<h2 id="测序文件"><a href="#测序文件" class="headerlink" title="测序文件"></a>测序文件</h2><ul>
<li><p>RS II：<a href="https://www.itdaan.com/blog/2017/05/26/6e59c682169d236cb41a2b6ba146125e.html">https://www.itdaan.com/blog/2017/05/26/6e59c682169d236cb41a2b6ba146125e.html</a></p>
</li>
<li><p>Sequel</p>
<ul>
<li>在下机文件中，主要有三类文件，<font color="red">bam 文件</font>，<font color="red">bam.pbi 文件</font>，以及<font color="red">xml文件</font>。</li>
<li>无fastq文件，sequel平台中bam 文件成为了fq的替代者，更节约储存空间。这是文件格式的一个重大更新。</li>
<li> 用于后续分析的文件一般是<font color="red">.subreads.bam</font>，这等同于<font color="red">RS II </font>中的<font color="red">.subreads.fastq</font></li>
<li>下面介绍三类主要文件的具体格式</li>
</ul>
</li>
</ul>
<h3 id="BAM"><a href="#BAM" class="headerlink" title="BAM"></a>BAM</h3><ul>
<li><p><font color="green">普通bam</font>文件大多是<font color="green">比对结果文件</font>，例如用重测序分析中BWA生成的bam文件就是reads与基因组的比对文件。但<font color="red">pacbio的下机文件是没有与基因组进行过比对过</font>的，其主要作用是<font color="red">储存序列</font>。</p>
</li>
<li><p>Bam文件主要分为两个部分，头一部分是<font color="red">Header</font>，储存测序的相关信息，另一部分也即是文件的主要部分是records，保存<font color="red">序列信息</font>。就以subreads.bam文件为例，分析下bam文件的具体格式。</p>
</li>
<li><p>可以用samtools view 命令查看bam文件</p>
<blockquote>
<p>第一列：reads信息</p>
<p>{movieName}/{holeNumber}/{qStart}_{qEnd}<br>[对于CCS：{movieName}/{holeNumber}/ccs]<br>MovieName 是cell的名字，holeNumer是ZMW孔的编号，qStart和qEnd是subreads相对于ZMW reads的位置。<br>第二列 (sum of flags)：比对信息 均为4 代表没有比对上，也表明了bam文件只储存了序列信息，而没有比对信息。<br>第三列 (RNAM)：参考序列 值为 ，代表无参考序列<br>第四列 (position) : 比对上的第一个碱基位置 0<br>第五列 (Mapping quality) : 比对质量分数 255<br>第六列 (CIGAR值) : 比对的具体情况<br>第七列 (MRNM, ) : mate 对应的染色体<br>第八列 (mate position) : mate对应的位置 0<br>第九列 (ISIZE, Inferred fragment size) : 推断的插入片段大小 0</p>
<p>第十列 (Sequence) : 序列信息 具体的ATCG<br>第十一列 (ASCII码) : 碱基质量分数 ASCII+33<br>第十二列: 可选区域 记录Reads 的总体属性包括信号长度，信号强度等信息。</p>
</blockquote>
</li>
</ul>
<ol>
<li>zmws.bam 以及ccs.bam似乎公司并不一定会提供</li>
<li>经过检查，一条zmw reads 可以产生多条 subreads，也就是说subreads.bam 中，序列只是被剪下来了。</li>
<li>scraps.bam 格式保存的是获取subreads时废弃的序列，包括adapter，以及一些低质量的序列</li>
<li><strong>CCS.bam保存的是矫正后的一致性序列</strong>。</li>
</ol>
<h3 id="BAM-pbi"><a href="#BAM-pbi" class="headerlink" title="BAM.pbi"></a>BAM.pbi</h3><ul>
<li><p>是bam文件的<font color="red">索引文件</font>(PacBio BAM index)，与上一个版本（<font color="red">RS II</font>）的<font color="red">*cmp.h5</font>文件<font color="red">兼容</font>，其格式类似于<font color="red">HDF5</font>， 通过<font color="red"><strong>BGZF格式压缩</strong></font>。</p>
</li>
<li><p> 其存在主要有两个作用</p>
</li>
<li><h5 id="随机访问"><a href="#随机访问" class="headerlink" title="随机访问"></a><font color="red">随机</font>访问</h5><p>通过参考序列，基因组区域；通过read 组别；通过qurey name；通过ZMW；通过barcode；其他</p>
</li>
<li><h5 id="在无需完全访问BAM文件的情况下，获取信息"><a href="#在无需完全访问BAM文件的情况下，获取信息" class="headerlink" title="在无需完全访问BAM文件的情况下，获取信息"></a>在无需完全访问BAM文件的情况下，获取信息</h5></li>
</ul>
<p>   获取<font color="red">统计信息</font>；通过提供index访问记录信息</p>
<h3 id="xml"><a href="#xml" class="headerlink" title="xml"></a>xml</h3><ul>
<li>MetaData, 储存数据描述。可用于<strong>filter</strong> 或者<strong>subset</strong>等功能。</li>
<li> sts.xml 储存数据的统计信息。</li>
<li> SMRT Link CL tools in 5.0.0 dataset命令可以进行方便的操作。</li>
</ul>
<hr>
<h1 id="Pacbio-Sequel-下机数据实例"><a href="#Pacbio-Sequel-下机数据实例" class="headerlink" title="Pacbio Sequel 下机数据实例"></a>Pacbio Sequel 下机数据实例</h1><blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;m54134_180724_220656.scraps.bam</span><br><span class="line">&gt;m54134_180724_220656.subreads.bam</span><br><span class="line">&gt;m54134_180724_220656.scraps.bam.pbi</span><br><span class="line">&gt;m54134_180724_220656.subreads.bam.pbi</span><br><span class="line">&gt;m54134_180724_220656.baz2bam_1.log</span><br><span class="line">&gt;m54134_180724_220656.sts.xml</span><br><span class="line">&gt;m54134_180724_220656.subreadset.xml</span><br><span class="line">&gt;m54134_180724_220656.transferdone</span><br><span class="line">&gt;m54134_180724_220656.adapters.fasta</span><br></pre></td></tr></table></figure>
</blockquote>
<p>m54134_180724_220656.subreads.bam</p>
<p><font color="red">m: 是movie 的缩写</font></p>
<p><font color="red">54134： 是设备的编号</font></p>
<p><font color="red">180724_220656： 是测序运行的开始时间，为2018年07月24日22时06分56秒</font></p>
<p><font color="red">subreads: 这部分是不同的数据类型，一般有scraps， subreads等</font></p>
<p><font color="red">bam: 这是数据的格式，一般有bam格式，xml，fasta格式等</font></p>
<p>BAM文件官网：<a href="https://pacbiofileformats.readthedocs.io/en/3.0/BAM.html">https://pacbiofileformats.readthedocs.io/en/3.0/BAM.html</a></p>
<p><a href="https://github.com/PacificBiosciences/PacBioFileFormats/blob/3.0/BAM.rst">https://github.com/PacificBiosciences/PacBioFileFormats/blob/3.0/BAM.rst</a></p>
<h1 id="CLR-HiFi-选择"><a href="#CLR-HiFi-选择" class="headerlink" title="CLR HiFi 选择"></a>CLR HiFi 选择</h1><p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/29.png" alt="img"></p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-2-SMRT/30.png" alt="img"></p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>HiFi-1-three-generation-sequencing-techniqie</title>
    <url>/blog/2022/02/20/2022-02-20-HiFi-1/</url>
    <content><![CDATA[<h1 id="第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。"><a href="#第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。" class="headerlink" title="第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。"></a>第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。</h1><span id="more"></span>

<h1 id="技术原理"><a href="#技术原理" class="headerlink" title="技术原理"></a>技术原理</h1><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p><font color="green">单分子荧光测序</font>，代表性技术为<font color="green">美国螺旋生物(Helicos)</font>的<font color="green">SMS技术</font>和<font color="green">美国太平洋生物(Pacific Bioscience)</font>的<font color="green">SMRT技术</font>。脱氧核苷酸荧光标记，显微镜实时记录荧光强度变化。当荧光标记脱氧核苷酸被掺入DNA链时，荧光同时在DNA链上测到。当它与DNA链形成化学键时，荧光基团被DNA聚合酶切除，荧光消失。荧光标记脱氧核苷酸不影响DNA聚合酶活性，荧光基团切除后，合成的DNA链和天然DNA链完全一样。</p>
<p>PacBio采用<font color="green">边合成边测序</font>方式，以其中一条DNA链为模板，通过DNA聚合酶合成另外一条链，进一步将荧光信号转变为碱基信号。同时PacBio已升级<font color="green">CCS测序模式</font>以获得<font color="green">长读长高保真（HiFi）15 kb reads</font>，由此提升基因组组装准确性。</p>
<h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><p><font color="green">纳米孔测序</font>，<font color="green">英国牛津纳米孔公司</font>。新型纳米孔测序法（nanopore sequencing）是采用电泳技术，借助<font color="green">电泳驱动单个分子逐一通过纳米孔</font>实现测序。纳米孔直径非常细小，仅允许单个核酸聚合物通过，而ATCG<font color="green">单个碱基带电性质</font>不一样，通过<font color="green">电信号差异</font>检测出通过碱基类别，实现测序。</p>
<p>Nanopore当单链DNA分子穿过纳米孔，相对于每个核苷酸，获得不同电流信号。记录每个孔的离子电流变化，并基于<font color="red">马尔可夫模型</font>或<font color="red">递归神经网络</font>的方法将其转换为碱基序列。此外，<font color="green">Ultra-long reads (ULRs) </font>是ONT平台的另一重要特征，并具有促进<font color="green">大型基因组组装</font>潜力。</p>
<table>
<thead>
<tr>
<th>De novo研究</th>
<th>研究内容</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>基因组组装</td>
<td>多软件组装、组装结果评估</td>
<td></td>
</tr>
<tr>
<td>基因预测与注释</td>
<td>编码基因预测；重复序列注释和转座元件分类；非编码RNA注释；假基因注释等</td>
<td></td>
</tr>
<tr>
<td>Hi-C辅助基因组组装</td>
<td>有效数据评估；Contig聚类、排序及定向分析；挂载结果评估</td>
<td></td>
</tr>
<tr>
<td>生物学问题解析</td>
<td>比较基因组学研究</td>
<td>基因家族聚类；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>系统发育树的构建；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>基因家族扩张与收缩分析；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>物种分化时间推算；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LTR形成时间估算；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>全基因组复制事件；</td>
</tr>
<tr>
<td></td>
<td></td>
<td>选择压力分析</td>
</tr>
<tr>
<td></td>
<td>特定生物学问题剖析</td>
<td>结合组学研究方法，深入对某物种生物学问题进行解析</td>
</tr>
</tbody></table>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/13.png" alt="33"></p>
<p>草莓基因家族聚类分析</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/14.png" alt="44"></p>
<p>薏苡全基因组复制事件分析</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/15.png" alt="img"></p>
<p>开心果系统进化树与基因家族收缩扩张分析</p>
<p><img src="/blog/./16.png" alt="img"></p>
<p>陆地棉亚基因组共线性分析</p>
<h1 id="关键点"><a href="#关键点" class="headerlink" title="关键点"></a>关键点</h1><p>第一：<font color="green">显微镜</font>实时记录DNA链荧光时，<font color="green">DNA链周围众多荧光标记脱氧核苷酸</font>形成非常强大的<font color="green">荧光背景</font>。强大荧光背景阻碍单分子荧光探测。Pacific Biosciences公司发明了一种<font color="green">直径只有几十纳米的纳米孔</font>[zero-mode waveguides (ZMWs)]，单分子的<font color="green">DNA聚合酶</font>被固定在孔内。在小孔内，DNA链<font color="green">周围荧光标记</font>的脱氧核苷酸<font color="green">有限</font>，而且由于A，T，C，G这四种荧光标记的脱氧核苷酸非常快速地从外面进入到孔内又出去，形成了非常<font color="green">稳定的背景荧光信号</font>。当某一种荧光标记的脱氧核苷酸被掺入到DNA链时，特定颜色的<font color="green">荧光会持续一小段时间</font>，直到新的化学键形成，荧光基团被DNA聚合酶切除为止。</p>
<p>第二：<font color="green">共聚焦显微镜</font>实时快速地对集成在<font color="green">板上的无数纳米小孔同时记录</font>。</p>
<h1 id="技术特点"><a href="#技术特点" class="headerlink" title="技术特点"></a>技术特点</h1><p>1、实现DNA聚合酶内在自身的<font color="green">反应速度</font>，一秒测10个碱基，测序速度是<font color="green">化学法测序2万倍</font>。</p>
<p>2、实现了DNA聚合酶内在自身的<font color="green">延续性</font>，一个反应可测非常长的序列。二代测序可以测到上百个碱基，但是三代测序可测几千个碱基。</p>
<p>3、<font color="green">精度</font>非常高，达到<font color="green">99.9999%</font>。</p>
<p>4、直接测<font color="green">RNA序列</font> (<strong>ISO</strong>)。既然<font color="green">DNA聚合酶</font>能够实时观测，那么以RNA为模板复制<font color="green">DNA的逆转录酶</font>也同样可以。RNA直接测序，将大大降低体外逆转录产生的系统误差。</p>
<p>5、第二个是直接测<font color="green">甲基化DNA序列</font>。实际上DNA聚合酶<font color="red"><strong>复制A、T、C、G的速度不一样</strong></font>。<font color="red"><strong>正常的C或者甲基化的C为模板，DNA聚合酶停顿的时间不同</strong></font>。根据时间不同，可以<font color="red"><strong>判断模板的C是否甲基化</strong></font>。</p>
<h1 id="平台比较"><a href="#平台比较" class="headerlink" title="平台比较"></a>平台比较</h1><table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>测序方法/平台</td>
<td>公司</td>
<td>方法/酶</td>
<td>测序长度</td>
<td>每个循环的数据产出量</td>
<td>每个循环耗时</td>
<td>主要错误来源</td>
<td></td>
</tr>
<tr>
<td>第三代测序技术</td>
<td>Heliscope/HelicosGenetic AnalysisSystem</td>
<td>Helicos</td>
<td>边合成边测序/DNA聚合酶</td>
<td>30-35 bp</td>
<td>21-28 Gb</td>
<td>8 d</td>
<td>替换</td>
</tr>
<tr>
<td>SMRT</td>
<td>Pacific Biosciences</td>
<td>边合成边测序/DNA聚合酶</td>
<td>100000 bp</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>纳米孔单分子</td>
<td>Oxford Nanopore</td>
<td>电信号测序/核酸外切酶</td>
<td>无限长</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="基因组测序"><a href="#基因组测序" class="headerlink" title="基因组测序"></a>基因组测序</h2><p>由于具有读长长的特点，SMRT测序平台在基因组测序中能<font color="green"><strong>降低测序后的Contig数量</strong></font>，明显<font color="green"><strong>减少</strong></font>后续基因组<font color="green"><strong>拼接和注释工作量</strong></font>，节省大量时间。Christophern等仅仅用0.5的Pacbio RS系统长度的数据与二代测序(NGS)的测序数据，对<strong>马达加斯加指猴</strong>基因组进行拼装，大幅度<font color="green">提高</font>数据的<font color="green">质量和完整度</font>，同时借助Pacbio RS将原有<font color="green">Contig数量减少10倍</font>。DavidA．等利用Pachio RS平台C2试剂通过全球合作几天内就完成了从<font color="green"><strong>德国大肠杆菌疫情</strong></font>中获得的<font color="green">大肠杆菌样品</font>以及<font color="green">近似菌株</font>的测序和数据分析，最终获得<font color="green">2900bp平均读长</font>以及<font color="green">99.998%一致性准确度</font>。在对<font color="green"><strong>霍乱病菌</strong></font>的研究中第三代测序技术已初现锋芒。研究人员对<font color="green">5株霍乱菌株</font>的基因组进行了测序研究，并与其他<font color="green">23株霍乱弧菌</font>的<font color="green">基因组进行对比</font>。结果发现海地霍乱菌株与2002年和2008年孟加拉国变异霍乱弧菌ElTorO1菌株之间关系密切，而与1991年拉丁美洲霍乱分离株的关系较远。相对NGS的优势就是能<font color="red">更快获得结果</font>，因此该系统在<font color="red">鉴定新的病原体和细菌</font>的基因组测序方面得到广泛应用。</p>
<h2 id="甲基化研究"><a href="#甲基化研究" class="headerlink" title="甲基化研究"></a>甲基化研究</h2><p><strong>SMRT技术</strong>对DNA<strong>聚合酶</strong>的工作状态<strong>实时监测</strong>，聚合酶<strong>合成每一个碱基</strong>，都有<strong>一个时间段</strong>，而当模板碱基<strong>带有修饰时</strong>，聚合酶会<strong>慢下来</strong>，使<strong>带有修饰的碱基两个相邻的脉冲峰</strong>之间的<strong>距离</strong>和<strong>参考序列的距离之间的比值</strong>结果<strong>大于1</strong>，由此就可以推断这个位置有修饰。甲基化研究中关于<strong>5mC和5hmC</strong>（5mC的羟基化形式）是甲基化研究中的热点。但<strong>现有测序方法无法区分</strong>5mC和5hmC。<strong>美国芝加哥大学</strong>利用<strong>SMRT</strong>测序技术和<strong>5hmC的选择性化学标记方法</strong>来高通量检测5hmC。通过聚合酶动力学提供的信息，可直接检测到<font color="green">DNA甲基化</font>，包括<font color="red">N6甲基腺嘌呤、5mC和5hmC</font>，为表观遗传学研究打开了一条通路。</p>
<h2 id="突变鉴定（SNP检测）"><a href="#突变鉴定（SNP检测）" class="headerlink" title="突变鉴定（SNP检测）"></a>突变鉴定（SNP检测）</h2><p>单分子测序的分辨率具有不可比拟的优势，而且没有PCR扩增，就<font color="green">没有扩增引入的碱基错误</font>，该优势使其在<font color="green">特定序列的SNP检测</font>，<font color="green">稀有突变及其频率测定</font>中大显身手。例如在医学研究中，对于FLT3基因是否是急性髓细胞白血病（AML）的有效治疗靶标一直存在质疑。研究人员用单分子测序分析耐药性患者基因，意外发现耐药性与FLT3基因下游出现的稀有新突变有关，重新证明了FLT3基因是这种最常见白血病—急性髓细胞白血病（AML）的有效治疗靶标，打破了一直以来对于这一基因靶标的疑惑。凭借PacBio平均3000bp的读长，获得了更多基因下游的宝贵信息，而基于单核酸分子的测序能够<font color="red"><strong>检测到低频率（低至1%）罕见突变</strong></font>，正是这项成果的关键所在。</p>
<hr>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/1.png" alt="img"></p>
<h1 id="第一代测序"><a href="#第一代测序" class="headerlink" title="第一代测序"></a>第一代测序</h1><p>第一代DNA测序技术用的是1975年由桑格（Sanger）和考尔森（Coulson）开创的链终止法或者是1976-1977年由马克西姆（Maxam）和吉尔伯特（Gilbert）发明的化学法（链降解）. 并在1977年，桑格测定了第一个基因组序列，是噬菌体X174的，全长5375个碱基1。自此，人类获得了窥探生命遗传差异本质的能力，并以此为开端步入基因组学时代。研究人员在Sanger法的多年实践之中不断对其进行改进。在2001年，完成的首个人类基因组图谱就是以改进了的Sanger法为其测序基础，Sanger法核心原理是：由于ddNTP的2’和3’都不含羟基，其在DNA的合成过程中不能形成磷酸二酯键，因此可以用来中断DNA合成反应，在4个DNA合成反应体系中分别加入一定比例带有放射性同位素标记的ddNTP（分为：ddATP,ddCTP,ddGTP和ddTTP），通过凝胶电泳和放射自显影后可以根据电泳带的位置确定待测分子的DNA序列（图2）。这个<a href="http://smcg.cifn.unam.mx/enp-unam/03-EstructuraDelGenoma/animaciones/secuencia.swf">网址</a>为sanger测序法制作了一个小短片，形象而生动。</p>
<p>　　值得注意的是，就在测序技术起步发展的这一时期中，除了Sanger法之外还出现了一些其他的测序技术，如焦磷酸测序法、链接酶法等。其中，焦磷酸测序法是后来Roche公司454技术所使用的测序方法2–4，而连接酶测序法是后来ABI公司SOLID技术使用的测序方法2,4，但他们的共同核心手段都是利用了Sanger1中的可中断DNA合成反应的dNTP。</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/2.png" alt="img"></p>
<h1 id="第二代测序"><a href="#第二代测序" class="headerlink" title="第二代测序"></a>第二代测序</h1><p>总的说来，第一代测序技术的主要特点是测序读长可达1000bp，准确性高达99.999%，但其测序成本高，通量低等方面的缺点，严重影响了其真正大规模的应用。因而第一代测序技术并不是最理想的测序方法。经过不断的技术开发和改进，以Roche公司的454技术、illumina公司的Solexa，Hiseq技术和ABI公司的Solid技术为标记的第二代测序技术诞生了。第二代测序技术大大降低了测序成本的同时，还大幅提高了测序速度，并且保持了高准确性，以前完成一个人类基因组的测序需要3年时间，而使用二代测序技术则仅仅需要1周，但在序列读长方面比起第一代测序技术则要短很多。表1和图3对第一代和第二代测序技术各自的特点以及测序成本作了一个简单的比较5，以下我将对这三种主要的第二代测序技术的主要原理和特点作一个简单的介绍。 </p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/3.png" alt="img"></p>
<h2 id="Illumina"><a href="#Illumina" class="headerlink" title="Illumina"></a>Illumina</h2><p>　　Illumina公司的Solexa和Hiseq应该说是目前全球使用量最大的第二代测序机器，这两个系列的技术核心原理是相同的2,4。这两个系列的机器采用的都是边合成边测序的方法，它的测序过程主要分为以下4步，如图4.</p>
<p>​     （1）DNA待测文库构建</p>
<p>　　利用超声波把待测的DNA样本打断成小片段，目前除了组装之外和一些其他的特殊要求之外，主要是打断成200-500bp长的序列片段，并在这些小片段的两端添加上不同的接头，构建出单链DNA文库。</p>
<p>​     （2）Flowcell</p>
<p>　　Flowcell是用于吸附流动DNA片段的槽道，当文库建好后，这些文库中的DNA在通过flowcell的时候会随机附着在flowcell表面的channel上。每个Flowcell有8个channel，每个channel的表面都附有很多接头，这些接头能和建库过程中加在DNA片段两端的接头相互配对（这就是为什么flowcell能吸附建库后的DNA的原因），并能支持DNA在其表面进行桥式PCR的扩增。</p>
<p>​     （3）桥式PCR扩增与变性</p>
<p>　　桥式PCR以Flowcell表面所固定的接头为模板，进行桥形扩增，如图4.a所示。经过不断的扩增和变性循环，最终每个DNA片段都将在各自的位置上集中成束，每一个束都含有单个DNA模板的很多分拷贝，进行这一过程的目的在于实现将碱基的信号强度放大，以达到测序所需的信号要求。 </p>
<p>（4）测序</p>
<p>　　测序方法采用边合成边测序的方法。向反应体系中同时添加DNA聚合酶、接头引物和带有碱基特异荧光标记的4中dNTP（如同Sanger测序法）。这些dNTP的3’-OH被化学方法所保护，因而每次只能添加一个dNTP。在dNTP被添加到合成链上后，所有未使用的游离dNTP和DNA聚合酶会被洗脱掉。接着，再加入激发荧光所需的缓冲液，用激光激发荧光信号，并有光学设备完成荧光信号的记录，最后利用计算机分析将光学信号转化为测序碱基。这样荧光信号记录完成后，再加入化学试剂淬灭荧光信号并去除dNTP 3’-OH保护基团，以便能进行下一轮的测序反应。Illumina的这种测序技术每次只添加一个dNTP的特点能够很好的地解决同聚物长度的准确测量问题，它的主要测序错误来源是碱基的替换，目前它的测序错误率在1%-1.5%之间，测序周期以人类基因组重测序为例，30x测序深度大约为1周。</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/4.png" alt="img"></p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/5.png" alt="img"></p>
<h2 id="Roche-454"><a href="#Roche-454" class="headerlink" title="Roche 454"></a>Roche 454</h2><p>Roche 454测序系统是第一个商业化运营二代测序技术的平台。它的主要测序原理是（图5 abc）2：</p>
<p>（1）DNA文库制备</p>
<p>　　454测序系统的文件构建方式和illumina的不同，它是利用喷雾法将待测DNA打断成300-800bp长的小片段，并在片段两端加上不同的接头，或将待测DNA变性后用杂交引物进行PCR扩增，连接载体，构建单链DNA文库（图5a）。</p>
<p>（2）Emulsion PCR （乳液PCR，其实是一个注水到油的独特过程）</p>
<p>454当然DNA扩增过程也和illumina的截然不同，它将这些单链DNA结合在水油包被的直径约28um的磁珠上，并在其上面孵育、退火。</p>
<p>　　乳液PCR最大的特点是可以形成数目庞大的独立反应空间以进行DNA扩增。其关键技术是“注水到油”（水包油），基本过程是在PCR反应前，将包含PCR所有反应成分的水溶液注入到高速旋转的矿物油表面，水溶液瞬间形成无数个被矿物油包裹的小水滴。这些小水滴就构成了独立的PCR反应空间。理想状态下，每个小水滴只含一个DNA模板和一个磁珠。</p>
<p>　　这些被小水滴包被的磁珠表面含有与接头互补的DNA序列，因此这些单链DNA序列能够特异地结合在磁珠上。同时孵育体系中含有PCR反应试剂，所以保证了每个与磁珠结合的小片段都能独立进行PCR扩增，并且扩增产物仍可以结合到磁珠上。当反应完成后，可以破坏孵育体系并将带有DNA的磁珠富集下来。进过扩增，每个小片段都将被扩增约100万倍，从而达到下一步测序所要求的DNA量。</p>
<p>（3）焦磷酸测序</p>
<p>　　测序前需要先用一种聚合酶和单链结合蛋白处理带有DNA的磁珠，接着将磁珠放在一种PTP平板上。这种平板上特制有许多直径约为44um的小孔，每个小孔仅能容纳一个磁珠，通过这种方法来固定每个磁珠的位置，以便检测接下来的测序反应过程。　　</p>
<p>　　测序方法采用焦磷酸测序法，将一种比PTP板上小孔直径更小的磁珠放入小孔中，启动测序反应。测序反应以磁珠上大量扩增出的单链DNA为模板，每次反应加入一种dNTP进行合成反应。如果dNTP能与待测序列配对，则会在合成后释放焦磷酸基团。释放的焦磷酸基团会与反应体系中的ATP硫酸化学酶反应生成ATP。生成的ATP和荧光素酶共同氧化使测序反应中的荧光素分子并发出荧光，同时由PTP板另一侧的CCD照相机记录，最后通过计算机进行光信号处理而获得最终的测序结果。由于每一种dNTP在反应中产生的荧光颜色不同，因此可以根据荧光的颜色来判断被测分子的序列。反应结束后，游离的dNTP会在双磷酸酶的作用下降解ATP，从而导致荧光淬灭，以便使测序反应进入下一个循环。由于454测序技术中，每个测序反应都在PTP板上独立的小孔中进行，因而能大大降低相互间的干扰和测序偏差。454技术最大的优势在于其能获得较长的测序读长，当前454技术的平均读长可达400bp，并且454技术和illumina的Solexa和Hiseq技术不同，它最主要的一个缺点是无法准确测量同聚物的长度，如当序列中存在类似于PolyA的情况时，测序反应会一次加入多个T，而所加入的T的个数只能通过荧光强度推测获得，这就有可能导致结果不准确。也正是由于这一原因，454技术会在测序过程中引入插入和缺失的测序错误。 </p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/6.png" alt="img"></p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/7.png" alt="img"></p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/8.png" alt="img"></p>
<h2 id="Solid技术"><a href="#Solid技术" class="headerlink" title="Solid技术"></a>Solid技术</h2><p>Solid测序技术是ABI公司于2007年开始投入用于商业测序应用的仪器。它基于连接酶法，即利用DNA连接酶在连接过程之中测序（图6）2,4。它的原理是：</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/9.png" alt="img"></p>
<p>　（1）DNA文库构建</p>
<p>​              　　片段打断并在片段两端加上测序接头，连接载体，构建单链DNA文库。</p>
<p>​           （2）Emulsion PCR</p>
<p>　　Solid的PCR过程也和454的方法类似，同样采用小水滴emulsion PCR，但这些微珠比起454系统来说则要小得多，只有1um。在扩增的同时对扩增产物的3’端进行修饰，这是为下一步的测序过程作的准备。3’修饰的微珠会被沉积在一块玻片上。在微珠上样的过程中，沉积小室将每张玻片分成1个、4个或8个测序区域（图6-a）。Solid系统最大的优点就是每张玻片能容纳比454更高密度的微珠，在同一系统中轻松实现更高的通量。</p>
<p>​           （3）连接酶测序</p>
<p>　　这一步是Solid测序的独特之处。它并没有采用以前测序时所常用的DNA聚合酶，而是采用了连接酶。Solid连接反应的底物是8碱基单链荧光探针混合物，这里将其简单表示为：3’-XXnnnzzz-5’。连接反应中，这些探针按照碱基互补规则与单链DNA模板链配对。探针的5’末端分别标记了CY5、Texas Red、CY3、6-FAM这4种颜色的荧光染料（图6-a）。这个8碱基单链荧光探针中，第1和第2位碱基（XX）上的碱基是确定的，并根据种类的不同在6-8位（zzz）上加上了不同的荧光标记。这是Solid的独特测序法，两个碱基确定一个荧光信号，相当于一次能决定两个碱基。这种测序方法也称之为两碱基测序法。当荧光探针能够与DNA模板链配对而连接上时，就会发出代表第1，2位碱基的荧光信号，图6-a和图6-b中的比色版所表示的是第1，2位碱基的不同组合与荧光颜色的关系。在记录下荧光信号后，通过化学方法在第5和第6位碱基之间进行切割，这样就能移除荧光信号，以便进行下一个位置的测序。不过值得注意的是，通过这种测序方法，每次测序的位置都相差5位。即第一次是第1、2位，第二次是第6、7位……在测到末尾后，要将新合成的链变性，洗脱。接着用引物n-1进行第二轮测序。引物n-1与引物n的区别是，二者在与接头配对的位置上相差一个碱基（图6-a. 8）。也即是，通过引物n-1在引物n的基础上将测序位置往3’端移动一个碱基位置，因而就能测定第0、1位和第5、6位……第二轮测序完成，依此类推，直至第五轮测序，最终可以完成所有位置的碱基测序，并且每个位置的碱基均被检测了两次。该技术的读长在2×50bp，后续序列拼接同样比较复杂。由于双次检测，这一技术的原始测序准确性高达99.94%，而15x覆盖率时的准确性更是达到了99.999%，应该说是目前第二代测序技术中准确性最高的了。但在荧光解码阶段，鉴于其是双碱基确定一个荧光信号，因而一旦发生错误就容易产生连锁的解码错误。</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/10.png" alt="img"></p>
<h1 id="第三代测序技术"><a href="#第三代测序技术" class="headerlink" title="第三代测序技术"></a>第三代测序技术</h1><p>以PacBio公司的<font color="red">SMRT</font>和<font color="red">Oxford Nanopore Technologies纳米孔单分子测序技术</font>，被称之为第三代测序技术。与前两代相比，最大的特点是单分子测序，测序过程<font color="red">无需PCR</font>扩增。</p>
<p>　　PacBio SMRT技术也应用了边合成边测序思想，并以SMRT芯片为测序载体。基本原理： DNA聚合酶和模板结合,4色荧光标记 4 种碱基（即是dNTP）,在碱基配对阶段,不同碱基加入,发不同光,根据<font color="green">光的波长与峰值</font>判断进入碱基类型。 DNA 聚合酶是实现超长读长的关键之一,读长主要跟<font color="red">酶的活性保持</font>有关,它主要受激光对其造成的损伤所影响。</p>
<p>​        PacBio SMRT技术的一个关键是怎样将反应信号与周围游离碱基的<font color="red">强大荧光背景</font>区别。<font color="red"><strong>ZMW（零模波导孔）原理</strong></font>：如同微波炉壁上可看到的很多密集小孔。小孔直径有考究,如果直径大于微波波长,能量就会在衍射效应的作用下穿透面板而泄露出来，从而与周围小孔相互干扰。如果孔径小于波长,能量不会辐射到周围，而是保持直线状态（光衍射的原理）,从而可起保护作用。同理,在一个反应管(SMRTCell:单分子实时反应孔)中有许多这样的圆形纳米小孔, 即 ZMW(零模波导孔),外径 100多纳米,比检测激光波长小(数百纳米),激光从底部打上去后不能穿透小孔进入上方溶液区,能量被限制在一个小范围(体积20X 10-21 L)里,正好足够覆盖需要检测的部分,使得信号仅来自这个小反应区域,孔外过多游离核苷酸单体依然留在黑暗中,从而实现将背景降到最低。另外，可以通过检测相邻两个碱基之间的测序时间，来检测一些碱基修饰情况，既如果碱基存在修饰，则通过聚合酶时的速度会减慢，相邻两峰之间的距离增大，可以通过这个来之间检测甲基化等信息（图7）。SMRT技术的测序速度很快，每秒约10个dNTP。但是，同时其测序<font color="red">错误率比较高</font>（这几乎是目前单分子测序技术的通病），达到<font color="red">15%</font>,但好在它的出错是随机的，并不会像第二代测序技术那样存在测序错误的偏向，因而可以通过<font color="red">多次测序来进行有效的纠错</font>。</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/11.png" alt="img"></p>
<p>Oxford Nanopore Technologies公司所开发的纳米单分子测序技术与以往的测序技术皆不同，它是基于电信号而不是光信号的测序技术。该技术的关键之一是，他们设计了一种特殊的纳米孔，孔内共价结合有分子接头。当DNA碱基通过纳米孔时，它们使电荷发生变化，从而短暂地影响流过纳米孔的电流强度（每种碱基所影响的电流变化幅度是不同的），灵敏的电子设备检测到这些变化从而鉴定所通过的碱基。</p>
<p>　　该公司在去年基因组生物学技术进展年会(AGBT)上推出第一款商业化的纳米孔测序仪，引起了科学界的极大关注。纳米孔测序（和其他第三代测序技术）有望解决目前测序平台的不足，纳米孔测序的主要特点是：读长很长，大约在几十kb，甚至100 kb;错误率目前介于1%至4%，且是随机错误，而不是聚集在读取的两端;数据可实时读取;通量很高(30x人类基因组有望在一天内完成);起始DNA在测序过程中不被破坏;以及样品制备简单又便宜。理论上，它也能直接测序RNA。</p>
<p>　　纳米孔单分子测序计算还有另一大特点，它能够直接读取出甲基化的胞嘧啶，而不必像传统方法那样对基因组进行bisulfite处理。这对于在基因组水平直接研究表观遗传相关现象有极大的帮助。并且改方法的测序准确性可达99.8%，而且一旦发现测序错误也能较容易地进行纠正。但目前似乎还没有应用该技术的相关报道。</p>
<p><img src="/blog/2022/02/20/2022-02-20-HiFi-1/12.png" alt="img"></p>
<h1 id="其他测序技术"><a href="#其他测序技术" class="headerlink" title="其他测序技术"></a>其他测序技术</h1><p>目前还有一种基于半导体芯片的新一代革命性测序技术——Ion Torrent6。该技术使用了一种布满小孔的高密度半导体芯片， 一个小孔就是一个测序反应池。当DNA聚合酶把核苷酸聚合到延伸中的DNA链上时，会释放出一个氢离子，反应池中的PH发生改变，位于池下的离子感受器感受到H+离子信号，H+离子信号再直接转化为数字信号，从而读出DNA序列（图9）。这一技术的发明人同时也是454测序技术的发明人之一——Jonathan Rothberg，它的文库和样本制备跟454技术很像，甚至可以说就是454的翻版，只是测序过程中不是通过检测焦磷酸荧光显色，而是通过检测H+信号的变化来获得序列碱基信息。Ion Torrent相比于其他测序技术来说，不需要昂贵的物理成像等设备，因此，成本相对来说会低，体积也会比较小，同时操作也要更为简单，速度也相当快速，除了2天文库制作时间，整个上机测序可在2-3.5小时内完成，不过整个芯片的通量并不高，目前是10G左右，但非常适合小基因组和外显子验证的测序。    </p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上，对各代测序技术的原理做了简要的阐述，这三代测序技术的特点比较汇总在以下表1和表2中。其中测序成本，读长和通量是评估该测序技术先进与否的三个重要指标。第一代和第二代测序技术除了通量和成本上的差异之外，其测序核心原理（除Solid是边连接边测序之外）都是基于边合成边测序的思想。第二代测序技术的优点是成本较之一代大大下降，通量大大提升，但缺点是所引入PCR过程会在一定程度上增加测序的错误率，并且具有系统偏向性，同时读长也比较短。第三代测序技术是为了解决第二代所存在的缺点而开发的，它的根本特点是单分子测序，不需要任何PCR的过程，这是为了能有效避免因PCR偏向性而导致的系统错误，同时提高读长，并要保持二代技术的高通量，低成本的优点。</p>
<table>
<thead>
<tr>
<th><strong>第<strong><strong>X</strong></strong>代</strong></th>
<th><strong>公司</strong></th>
<th><strong>平台名称</strong></th>
<th><strong>测序方法</strong></th>
<th><strong>检测方法</strong></th>
<th><strong>大约读长</strong><strong>(<strong><strong>碱基数</strong></strong>)</strong></th>
<th><strong>优点</strong></th>
<th><strong>相对局限性</strong></th>
</tr>
</thead>
<tbody><tr>
<td>第一代</td>
<td>ABI/生命技术公司</td>
<td>3130xL-3730xL</td>
<td>桑格-毛细管电泳测序法</td>
<td>荧光/光学</td>
<td>600-1000</td>
<td>高读长，准确度一次性达标率高，能很好处理重复序列和多聚序列</td>
<td>通量低；样品制备成本高，使之难以做大量的平行测序</td>
</tr>
<tr>
<td>第一代</td>
<td>贝克曼</td>
<td>GeXP遗传分析系统</td>
<td>桑格-毛细管电泳测序法</td>
<td>荧光/光学</td>
<td>600-1000</td>
<td>高读长，准确度一次性达标率高，能很好处理重复序列和多聚序列；易小型化</td>
<td>通量低；单个样品的制备成本相对较高</td>
</tr>
<tr>
<td>第二代</td>
<td>Roche/454</td>
<td>基因组测序仪FLX系统</td>
<td>焦磷酸测序法</td>
<td>光学</td>
<td>230-400</td>
<td>在第二代中最高读长；比第一代的测序通量大</td>
<td>样品制备较难；难于处理重复和同种碱基多聚区域；试剂冲洗带来错误累积；仪器昂贵</td>
</tr>
<tr>
<td>第二代</td>
<td>Illumina</td>
<td>HiSeq2000,HiSeq2500/MiSeq</td>
<td>可逆链终止物和合成测序法</td>
<td>荧光/光学</td>
<td><strong>2x150</strong></td>
<td>很高测序通量</td>
<td>仪器昂贵；用于数据删节和分析的费用很高</td>
</tr>
<tr>
<td>第二代</td>
<td>ABI/Solid</td>
<td>5500xlSolid系统</td>
<td>连接测序法</td>
<td>荧光/光学</td>
<td>25-35</td>
<td>很高测序通量；在广为接受的几种第二代平台中，所要拼接出人类基因组的试剂成本最低</td>
<td>测序运行时间长；读长短，造成成本高，数据分析困难和基因组拼接困难；仪器昂贵</td>
</tr>
<tr>
<td>第二代</td>
<td>赫利克斯</td>
<td>Heliscope</td>
<td>单分子合成测序法</td>
<td>荧光/光学</td>
<td>25-30</td>
<td>高通量；在第二代中属于单分子性质的测序技术</td>
<td>读长短，推高了测序成本，降低了基因组拼接的质量；仪器非常昂贵</td>
</tr>
<tr>
<td>第三代</td>
<td>太平洋生物科学公司</td>
<td>PacBio RS</td>
<td>实时单分子DNA测序</td>
<td>荧光/光学</td>
<td>~1000</td>
<td>高平均读长，比第一代的测序时间降低；不需要扩增；最长单个读长接近3000碱基</td>
<td>并不能高效地将DNA聚合酶加到测序阵列中；准确性一次性达标的机会低（81-83%）；DNA聚合酶在阵列中降解；总体上每个碱基测序成本高（仪器昂贵）；</td>
</tr>
<tr>
<td>第三代</td>
<td>全基因组学公司</td>
<td>GeXP遗传分析系统</td>
<td>复合探针锚杂交和连接技术</td>
<td>荧光/光学</td>
<td>10</td>
<td>在第三代中通量最高；在所有测序技术中，用于拼接一个人基因组的试剂成本最低；每个测序步骤独立，使错误的累积变得最低</td>
<td>低读长； 模板制备妨碍长重复序列区域测序；样品制备费事；尚无商业化供应的仪器</td>
</tr>
<tr>
<td>第三代</td>
<td>Ion Torrent/生命技术公司</td>
<td>个人基因组测序仪（PGM）</td>
<td>合成测序法</td>
<td>以离子敏感场效应晶体管检测pH值变化</td>
<td>100-200</td>
<td>对核酸碱基的掺入可直接测定；在自然条件下进行DNA合成（不需要使用修饰过的碱基）</td>
<td>一步步的洗脱过程可导致错误累积；阅读高重复和同种多聚序列时有潜在困难；</td>
</tr>
<tr>
<td>第三代</td>
<td>牛津纳米孔公司</td>
<td>gridION</td>
<td>纳米孔外切酶测序</td>
<td>电流</td>
<td>尚未定量</td>
<td>有潜力达到高读长；可以成本生产纳米孔；无需荧光标记或光学手段</td>
<td>切断的核苷酸可能被读错方向；难于生产出带多重平行孔的装置</td>
</tr>
</tbody></table>
<hr>
<p>ref</p>
<p><a href="https://www.cnblogs.com/huangshujia/p/3233693.html">https://www.cnblogs.com/huangshujia/p/3233693.html</a></p>
<p><a href="http://www.biomarker.com.cn/technology-services/denovo3">http://www.biomarker.com.cn/technology-services/denovo3</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/339875837">https://zhuanlan.zhihu.com/p/339875837</a></p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>assemble</title>
    <url>/blog/2022/02/19/2022-02-19_assembly/</url>
    <content><![CDATA[<p>Pacbio</p>
<span id="more"></span>

<p><a href="https://www.bilibili.com/video/BV1pD4y1R7nK">https://www.bilibili.com/video/BV1pD4y1R7nK</a></p>
<h1 id="1目标，现状和影响因素"><a href="#1目标，现状和影响因素" class="headerlink" title="1目标，现状和影响因素"></a>1目标，现状和影响因素</h1><h2 id="追求"><a href="#追求" class="headerlink" title="追求"></a>追求</h2><p>基因组组装：连续度contigN50，准确度，速度。</p>
<p>仪器：Pacbio</p>
<p>实验：CLR，CCS文库</p>
<p>软件：Canu，Falcon，Smartdenovo，WTDBG</p>
<h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>复杂度：基因组重复度，杂合度。<strong>Survey</strong></p>
<p>数据量：CLR：100X左右；HIFI：25X（纠错后）</p>
<p>算法是否合适：OLC，DBG</p>
<p>数据质量：Pacbio：碱基质量（纠错CDS？Q40？）；ONT：序列长度</p>
<h1 id="2基因组组装的软件使用方法"><a href="#2基因组组装的软件使用方法" class="headerlink" title="2基因组组装的软件使用方法"></a>2基因组组装的软件使用方法</h1><h2 id="组装软件"><a href="#组装软件" class="headerlink" title="组装软件"></a>组装软件</h2><ul>
<li>Canu：三代数据主流软件，具有纠错，修正和组装功能</li>
</ul>
<p>比较慢，准确度高，连续度表现优秀的概率高</p>
<ul>
<li>Falcon：PB公司推荐，可用于杂合度较高或亲缘关系较远物种组装</li>
</ul>
<p>适合一定的杂合基因组，可以装出haplotype区域，一定杂合的基因可以利用hic数据进行Mb级别的phasing</p>
<ul>
<li>Smart Denovo适用PB和ONT，无纠错</li>
<li>WTDBG：内存及存储占用少，速度快</li>
</ul>
<p>速度快，对重复序列敏感，简单基因组组装效果比较好</p>
<ul>
<li>Hifiasm：适用HiFi。速度快，连续度高，完整性高</li>
<li>HiCanu：适用HiFi</li>
<li>根据基因组特征，选择合适软件进行组装或者多软件配合使用组装获得高质量物种基因组</li>
</ul>
<h2 id="评估软件"><a href="#评估软件" class="headerlink" title="评估软件"></a>评估软件</h2><ul>
<li>BUSCO</li>
<li></li>
</ul>
<h1 id="3超大基因组的组装经验"><a href="#3超大基因组的组装经验" class="headerlink" title="3超大基因组的组装经验"></a>3超大基因组的组装经验</h1><p>数据量大：运算量大，软件适应性，组装结果，存储需求</p>
<h1 id="4基因组组装展望"><a href="#4基因组组装展望" class="headerlink" title="4基因组组装展望"></a>4基因组组装展望</h1><p>CSS组装，未来趋势。</p>
<hr>
<h1 id="三代数据预处理"><a href="#三代数据预处理" class="headerlink" title="三代数据预处理"></a>三代数据预处理</h1><h2 id="了解三代数据预处理中的输入和输出数据"><a href="#了解三代数据预处理中的输入和输出数据" class="headerlink" title="了解三代数据预处理中的输入和输出数据"></a>了解三代数据预处理中的输入和输出数据</h2><h2 id="三代上机文库简介"><a href="#三代上机文库简介" class="headerlink" title="三代上机文库简介"></a>三代上机文库简介</h2><h2 id="了解数据质量矫正的方法"><a href="#了解数据质量矫正的方法" class="headerlink" title="了解数据质量矫正的方法"></a>了解数据质量矫正的方法</h2><h2 id="如何评价数据质量和有效产出比"><a href="#如何评价数据质量和有效产出比" class="headerlink" title="如何评价数据质量和有效产出比"></a>如何评价数据质量和有效产出比</h2>]]></content>
      <categories>
        <category>assemble</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/blog/2022/02/18/20220218-ggplot2/</url>
    <content><![CDATA[<h1 id><a href="#" class="headerlink" title></a></h1><p>reorder降序实现(加**<font color="red">-</font>**号)：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">ggplot(data,aes(x=reorder(v1,v2),y=v2))+genom_bar(stat = <span class="string">&quot;identity&quot;</span>)</span><br><span class="line"></span><br><span class="line">ggplot(data,aes(x=reorder(v1,-v2),y=v2))+genom_bar(stat = <span class="string">&quot;identity&quot;</span>)</span><br></pre></td></tr></table></figure>



]]></content>
  </entry>
  <entry>
    <title>染色质三维结构图谱 Hi-C</title>
    <url>/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/</url>
    <content><![CDATA[<h1 id="Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。"><a href="#Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。" class="headerlink" title="Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。"></a>Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。</h1><span id="more"></span>

<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/0.png" alt="img"></p>
<h1 id="1-C技术"><a href="#1-C技术" class="headerlink" title="1. C技术"></a>1. C技术</h1><h2 id="1-1-3C（一对一）"><a href="#1-1-3C（一对一）" class="headerlink" title="1.1 3C（一对一）"></a>1.1 3C（一对一）</h2><ul>
<li><p>基因组捕获技术（Chromosome conformation capture，3C）是最早研究三维基因组的技术，需要<font color="green">提前知道互作区域</font>，才能<font color="green">量化一对基因组基因座之间的互作</font>。</p>
</li>
<li><p>3C技术2002年Deker提出，目的捕获染色体的interaction，假设染色体中的interaction以蛋白为介导。通过限制酶酶切，补平，连接，打断，PCR后，若染色体A，B两点相互作用，根据这两点特异序列的引物能PCR出产物，验证interaction。每<font color="green">一对位点的验证</font>需要<font color="green">设计一对特异性引物</font>。</p>
</li>
</ul>
<h2 id="1-2-4C（一对多）"><a href="#1-2-4C（一对多）" class="headerlink" title="1.2 4C（一对多）"></a>1.2 4C（一对多）</h2><ul>
<li><p>染色体构象捕获芯片（Chromosome conformation capture-on-chip，4C ），可以捕获<font color="green">一个基因区域</font>和其他区域间的互相作用。该技术不需要知道作用区域的先验知识就可以使用。</p>
</li>
<li><p>3C较麻烦，后设计双酶切位点，然后<font color="green">成环</font>，保证只需要设计一对引物就可以检测一个位点对多个位点的相互作用，4C有circle的意思。</p>
</li>
</ul>
<h2 id="1-3-5C（多对多）"><a href="#1-3-5C（多对多）" class="headerlink" title="1.3 5C（多对多）"></a>1.3 5C（多对多）</h2><p>染色体构象捕获碳拷贝（Chromosome conformation capture carbon copy，5C） ，可以检测<font color="green">某段区域内所有的互作</font>，但是该<font color="red">区域一般&lt;1 Mb</font>。覆盖度问题造成该技术<font color="green">不适用于全基因组测序</font>。</p>
<h2 id="1-4-Hi-C（全部互作）"><a href="#1-4-Hi-C（全部互作）" class="headerlink" title="1.4 Hi-C（全部互作）"></a>1.4 <font color="red">Hi-C（全部互作）</font></h2><ul>
<li><p>高通量基因组捕获技术（High-throughput/resolution chromosome conformation capture），基本解决了上述技术的缺点，可以实现<font color="green">全基因组覆盖</font>检测<font color="green">全部未知互作区域</font>。</p>
</li>
<li><p>Hi-C基本步骤，甲醛交联，限制酶切，末端补平加biotin，平末端连接，超声破碎，biotin富集，建库测序。整个过程没有特异引物存在。</p>
</li>
<li><p>将线性距离远，空间结构近的DNA片段进行交联，并将交联的DNA片段富集，高通量测序，对测序数据分析可以揭示染色质的远程互作，推导出基因组的三维空间结构的可能的记忆之间的调控关系。</p>
</li>
<li><p>\1. 通过Scaffold间的交互频率大小，可以对已组装的基因组序列进行纠错（基因组更准确）。</p>
<p>\2. 基因信息不再仅仅是contig片段，而是被划分至染色体上，成为染色体水平。</p>
<p>\3. 无需辛苦的构建群体，单一一个体就能实现染色体定位。</p>
<p>\4. 相比遗传图谱，标记密度更大，序列定位更完整（能把更多的contig挂至染色体上!信息更全面！）</p>
<p>\5. 染色体重排等结构变异研究可以开展啦~(研究可以更深入！）</p>
<p>\6. QTL、GWAS可以定位区间到某个染色体啦~（追踪变异！）</p>
<p>\7. 该物种的三维基因结构、染色体互作及动态变化可以解析啦~（从基因到表观！全方位解析）</p>
</li>
</ul>
<h2 id="1-5-ChIP-loop-基于免疫沉淀"><a href="#1-5-ChIP-loop-基于免疫沉淀" class="headerlink" title="1.5 ChIP-loop (基于免疫沉淀)"></a>1.5 ChIP-loop (基于免疫沉淀)</h2><p>该技术将 3C 与 ChIP-seq 结合，可以检测<font color="red">目的蛋白质介导</font>的<font color="red">两个目的基因区域互作</font>。</p>
<h2 id="1-6-ChIA-PET-基于免疫沉淀"><a href="#1-6-ChIA-PET-基于免疫沉淀" class="headerlink" title="1.6 ChIA-PET (基于免疫沉淀)"></a>1.6 ChIA-PET (基于免疫沉淀)</h2><p>该技术将 HiC 与 ChIP-seq 结合，可以检测<font color="red">目的蛋白质的所有互相作用</font>。 用特异性抗体富集interaction信息，比如CTCF，pol II抗体，类似步骤建库测序。<font color="red">ChIA-PET数据是Hi-C数据的子集</font>。</p>
<hr>
<table>
<thead>
<tr>
<th></th>
<th>互作</th>
<th>覆盖</th>
<th>作用</th>
<th>研究应用</th>
</tr>
</thead>
<tbody><tr>
<td>3C</td>
<td>单对单</td>
<td>&lt;1Mb</td>
<td>检测已知<font color="red">基因组基因区域之间</font>的互作</td>
<td>确定已知启动子和增强子之间的互作</td>
</tr>
<tr>
<td>4C</td>
<td>一对多</td>
<td>全基因组</td>
<td>确定<font color="red">基因某组区域</font>与<font color="red">其他区域的互作</font></td>
<td>与已知LCR(locus control regions)区互作的全部基因和元件</td>
</tr>
<tr>
<td>5C</td>
<td>多对多</td>
<td>&lt;1Mb</td>
<td>确定<font color="red">染色体特定区域</font>的全部高级结构</td>
<td>确定染色体特定区域的全部高级结构</td>
</tr>
<tr>
<td>Hi-C</td>
<td>全部互作</td>
<td>全基因组</td>
<td>检测<font color="red">全基因组</font>范围的<font color="red">全部高级结构</font></td>
<td>全基因组范围所有染色体互作</td>
</tr>
<tr>
<td>ChIP-loop</td>
<td>一对一</td>
<td>&lt;1Mb</td>
<td>检测目的蛋白介导的<font color="red">两个目的基因区域互作</font></td>
<td></td>
</tr>
<tr>
<td>ChIA-PET</td>
<td>全部互作</td>
<td>全基因组</td>
<td>检测<font color="red">目的蛋白质的所有互作</font></td>
<td>构建已知转录因子介导的染色质互作</td>
</tr>
</tbody></table>
<hr>
<h1 id="2-技术原理"><a href="#2-技术原理" class="headerlink" title="2. 技术原理"></a>2. 技术原理</h1><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/1.png" alt="img"></p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/8.png" alt="img"></p>
<h2 id="2-1-甲醛固定"><a href="#2-1-甲醛固定" class="headerlink" title="2.1 甲醛固定"></a>2.1 甲醛固定</h2><p>先加入甲醛将基因组中参与<font color="red">染色质互作的蛋白质凝固</font>。一般将活体样本在室温用 1-3%的甲醛处理 10-30min，但是此步骤会<font color="green">减少限制内切酶</font>对DNA序列的消化<font color="green">效率</font>，需要严格控制。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/2.png" alt="img"></p>
<h2 id="2-2-酶切序列"><a href="#2-2-酶切序列" class="headerlink" title="2.2 酶切序列"></a>2.2 酶切序列</h2><p>用限制性内切酶切割基因组，打断后的片段大小会影响测序分辨率，一般有两种酶可供选择：6bp 的限制性内切酶，4bp 的限制性内切酶。后者具有更高的分辨率。EcoR1 或 HindIII 用于每4000bp切割一次基因组，在人类基因组中产生约100万个片段。<br><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/3.png" alt="img"></p>
<h2 id="2-3-末端修复"><a href="#2-3-末端修复" class="headerlink" title="2.3 末端修复"></a>2.3 末端修复</h2><p>得到的片段具有平末端或粘性末端，然后将<font color="red">末端补平修复，加入生物素</font>。【生物素pull-down保证只有连接的部分用于分析。读长reads被定位到基因组上，当这一对读长发现在不同片段上的时候，对<font color="red">互作片段进行相应评分</font>。一个包含基因组所有片段的<font color="red">连接频率矩阵被构建</font>。】</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/4.png" alt="img"></p>
<h2 id="2-4-连接及解交联"><a href="#2-4-连接及解交联" class="headerlink" title="2.4 连接及解交联"></a>2.4 连接及解交联</h2><p>使用 <font color="red">T4 DNA连接酶连接互作片段形成环状</font>。将连接DNA片段的<font color="red">蛋白质消化掉</font>，得到交联片段。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/5.png" alt="img"></p>
<h2 id="2-5-序列打断"><a href="#2-5-序列打断" class="headerlink" title="2.5 序列打断"></a>2.5 序列打断</h2><p>使用超声波或其他方式，再次打断片段。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/6.png" alt="img"></p>
<h2 id="2-6-上机测序"><a href="#2-6-上机测序" class="headerlink" title="2.6 上机测序"></a>2.6 上机测序</h2><p>用<font color="red">磁珠将带生物素的捕获</font>，制作文库，上机测序。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/7.png" alt="img"></p>
<h1 id="3-Hi-C应用"><a href="#3-Hi-C应用" class="headerlink" title="3. Hi-C应用"></a>3. Hi-C应用</h1><ul>
<li><font color="red">量化</font>在三维空间中基因组的<font color="red">染色质间交联</font>（cross-linked chromatin ）</li>
<li>解析<font color="red">全基因组互作<strong>模式</strong></font>，如<font color="red">启动子和增强子互作</font></li>
<li>构建<font color="red">三维空间结构<strong>模型</strong></font>，如研究基因组三维结构特征：<strong>compartment，TAD，loop</strong>等</li>
<li>构建<font color="red">全基因组互作<strong>图谱</strong></font></li>
<li><font color="red">辅助提升<strong>基因组组装</strong></font></li>
<li>构建<font color="red">基因组<strong>单体型图谱</strong></font></li>
</ul>
<h1 id="4-分析流程"><a href="#4-分析流程" class="headerlink" title="4. 分析流程"></a>4. 分析流程</h1><h2 id="4-1-基本分析"><a href="#4-1-基本分析" class="headerlink" title="4.1 基本分析"></a>4.1 基本分析</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/9.png" alt="img"></p>
<p>Ferhat Ay et al;2015</p>
<ul>
<li>(a)首先是<font color="green">质控</font>，过滤后高质量的FASTQ数据（PE，150bp），如果比对软件<font color="red">不支持split mapping</font>，一般选用<font color="red">迭代比对</font>，因为连接处由于是基因组外的碱基，可能比对不上。<strong>从序列左端25bp开始比对，如果有唯一比对，则停止，如果多个比对位置，则再继续延伸5bp，直到出现唯一比对</strong>。或选择<strong>支持split mapping的软件进行比对</strong>，可以通过<strong>分段比对处理</strong>。</li>
<li>(b)选择高质量的比对数据</li>
<li>(c)HiC特异的<font color="green">比对标准</font></li>
<li>(d)对Vaild pairs进行<font color="green">矫正</font>。矫正完可以得到<font color="green">互作矩阵</font>。</li>
</ul>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/10.png" alt="img"></p>
<p>Bryan R. Lajoie et al;2014</p>
<h2 id="4-2-Hi-C可视化"><a href="#4-2-Hi-C可视化" class="headerlink" title="4.2 Hi-C可视化"></a>4.2 Hi-C可视化</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/11.png" alt="img"></p>
<h2 id="4-3-序列过滤"><a href="#4-3-序列过滤" class="headerlink" title="4.3 序列过滤"></a>4.3 序列过滤</h2><p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/12.png" alt="img"></p>
<h2 id="4-4-数据矫正"><a href="#4-4-数据矫正" class="headerlink" title="4.4 数据矫正"></a>4.4 数据矫正</h2><p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/13.png" alt="img"></p>
<p>Eitan Yaffe &amp; Amos Tanay；2011</p>
<p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/14.png" alt="img"></p>
<h1 id="5-分析"><a href="#5-分析" class="headerlink" title="5. 分析"></a>5. 分析</h1><h2 id="5-1-cis-trans互作比例"><a href="#5-1-cis-trans互作比例" class="headerlink" title="5.1 cis/trans互作比例"></a>5.1 cis/trans互作比例</h2><p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/15.png" alt="img"></p>
<h2 id="5-2-互作频率与距离有关"><a href="#5-2-互作频率与距离有关" class="headerlink" title="5.2 互作频率与距离有关"></a>5.2 互作频率与距离有关</h2><p>​    <img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/16.png" alt="img"></p>
<h2 id="5-3-compartment分析"><a href="#5-3-compartment分析" class="headerlink" title="5.3 compartment分析"></a>5.3 compartment分析</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/17.png" alt="img"></p>
<h2 id="5-4-TAD分析"><a href="#5-4-TAD分析" class="headerlink" title="5.4 TAD分析"></a>5.4 TAD分析</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/18.png" alt="img"></p>
<p>Hi-C辅助TAD结构研究（<em>Wang et al</em>., Nature Commuications 2018）</p>
<h2 id="5-5-显著互作分析"><a href="#5-5-显著互作分析" class="headerlink" title="5.5 显著互作分析"></a>5.5 显著互作分析</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/19.png" alt="img"></p>
<h1 id="6-应用"><a href="#6-应用" class="headerlink" title="6. 应用"></a>6. 应用</h1><h2 id="6-1-解析全基因组互作模式"><a href="#6-1-解析全基因组互作模式" class="headerlink" title="6.1 解析全基因组互作模式"></a>6.1 解析全基因组互作模式</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/20.png" alt="img"></p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/21.png" alt="img"></p>
<h2 id="6-2-辅助提升基因组组装"><a href="#6-2-辅助提升基因组组装" class="headerlink" title="6.2 辅助提升基因组组装"></a>6.2 辅助提升基因组组装</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/22.png" alt="img"></p>
<ul>
<li><p>Hi-C辅助陆地棉与海岛棉基因组染色体水平组装（<em>Wang et al</em>.,Nature Genetics 2018）</p>
</li>
<li><p>Hi-C无需群体，单一个体就能实现染色体定位。很多物种都无法构建遗传群体，包括大部分高等动物、野生动植物、林木、果树等等。Hi-C是通过染色体上空间距离、线性距离的不同而导致的交互频率的不同来完成染色体的定位，所以不需要构建群体。</p>
</li>
<li><p>标记密度更大，序列定位更完整。相比遗传图谱，染色质之间的交互频率具有更高的标记密度，如此高密度的图谱不仅可以挂载上长的Scaffold，较短的Scaffold也可以被定位，所以通过Hi-C技术，一般可以将90%以上基因组序列定位到染色体。</p>
</li>
<li><p>可以对已组装的基因组进行纠错。通过Scaffold间的交互频率大小，可以对已组装的基因组序列进行纠错。</p>
</li>
</ul>
<h3 id="6-2-1-数据统计和过滤；"><a href="#6-2-1-数据统计和过滤；" class="headerlink" title="6.2.1 数据统计和过滤；"></a>6.2.1 数据统计和过滤；</h3><h3 id="6-2-2-Hi-C文库评估；"><a href="#6-2-2-Hi-C文库评估；" class="headerlink" title="6.2.2 Hi-C文库评估；"></a>6.2.2 Hi-C文库评估；</h3><h3 id="6-2-3Hi-C染色体定位；"><a href="#6-2-3Hi-C染色体定位；" class="headerlink" title="6.2.3Hi-C染色体定位；"></a>6.2.3Hi-C染色体定位；</h3><p>​    ✓ 组装序列染色体群组划分；</p>
<p>   ✓  组装序列各群组内排序；</p>
<p>   ✓  组装序列各群组内定向；</p>
<h3 id="6-2-4-Hi-C定位后统计评估；"><a href="#6-2-4-Hi-C定位后统计评估；" class="headerlink" title="6.2.4 Hi-C定位后统计评估；"></a>6.2.4 Hi-C定位后统计评估；</h3><p>​    ✓  近缘物种参考基因组评估；</p>
<p>​    ✓  遗传标记评估；</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/24.png" alt="img"></p>
<h2 id="6-3-构建基因组单体型图谱"><a href="#6-3-构建基因组单体型图谱" class="headerlink" title="6.3 构建基因组单体型图谱"></a>6.3 构建基因组单体型图谱</h2><p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/23.png" alt="img"></p>
<h1 id="7-文献案例"><a href="#7-文献案例" class="headerlink" title="7. 文献案例"></a>7. 文献案例</h1><h2 id="7-1"><a href="#7-1" class="headerlink" title="7.1"></a>7.1</h2><p><strong>物种：棉花</strong></p>
<p><strong>题目：</strong>Genome sequence of<em>Gossypium herbaceum</em>and genome updates of<em>Gossypium arboreum</em>and<em>Gossypium hirsutum</em>provide insights into cotton A-genome evolution</p>
<p><strong>期刊：</strong>Nature genetics</p>
<p><strong>影响因子：</strong>25.455</p>
<p><strong>研究单位：</strong>武汉大学</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年4月13日，武汉大学朱玉贤院士团队关于草棉、亚洲棉和陆地棉基因组研究成果发表在国际著名期刊Nature genetics。该研究利用了PacBio三代分子测序和北京百迈客生物技术有限公司的Hi-C技术绘制了三个高质量棉花基因图谱，发现了三种棉花中多个染色体易位与倒位事件，解决了围绕A基因组起源的现有争议性概念，确定了与棉花纤维长度这一重要农艺性状相关的丰富的候选基因，并为棉花遗传改良提供了宝贵的基因组资源。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/25.png" alt="草棉与亚洲棉基因组Hi-C热图"></p>
<h2 id="7-2"><a href="#7-2" class="headerlink" title="7.2"></a>7.2</h2><p><strong>物种：珙桐</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/31970919">Genomic analyses of a “living fossil”: The endangered dove-tree</a></p>
<p><strong>期刊：</strong>Molecular Ecology Resources</p>
<p><strong>影响因子：</strong>7.049</p>
<p><strong>研究单位：</strong>四川大学</p>
<p><strong>主要研究内容：</strong>2020年1月四川大学刘建全团队破译了中国特有的濒危物种珙桐（<em>Davidia involucrata</em>）基因组，相关成果发表在著名期刊Molecular Ecology Resources上。四川大学刘建全教授和杨勇志博士为该论文的通讯作者，陈阳和马涛教授为并列一作。该研究利用单分子实时测序SMRT和北京百迈客生物技术有限公司的Hi-C技术组装了一个高质量、染色体体水平的珙桐基因组，研究发现苞片中光合作用相关基因几乎缺失或表达减少，而抗菌、抗冷、抗水等抗逆相关基因在苞片中高度表达，突出了苞片在保护花和吸引授粉者中的重要作用。有效群体大小等研究分析了珙桐的生存机制和濒危原因。在未来气候持续变暖的背景下，研究结果为保护这独特的濒危物种提供了依据。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/26.png" alt="珙桐基因组Hi-C热图"></p>
<h2 id="7-3"><a href="#7-3" class="headerlink" title="7.3"></a>7.3</h2><p><strong>物种：二倍体草莓</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32003918">The high-quality genome of diploid strawberry (Fragaria nilgerrensis) provides new insights into anthocyanin accumulation</a></p>
<p><strong>期刊：</strong>Plant Biotechnology Journal</p>
<p><strong>影响因子：</strong>6.84</p>
<p><strong>研究单位：</strong>沈阳农业大学</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年1月31日沈阳农业大学张志宏研究团队与北京百迈客生物科技有限公司合作，基于单分子实时测序PacBio和染色体构象捕获Hi-C技术，成功构建亚洲东部和东南部地区特有的野生二倍体草莓——黄毛草莓（<em>Fragaria nilgerrensis</em>）高质量基因图谱，相关研究成果发表在知名期刊Plant Biotechnology Journal上。文中通过比较基因组学等系列分析找寻到可能与黄毛草莓特异表型以及环境适应性相关的扩张基因，以及可能与其白色果实相关的变异。该研究为草莓属物种的生物学以及比较基因组学研究提供了宝贵的遗传资源。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/27.png" alt="黄毛草莓基因组Hi-C热图"></p>
<h2 id="7-4"><a href="#7-4" class="headerlink" title="7.4"></a>7.4</h2><p><strong>物种：油桐</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32224189">Tung Tree (Vernicia fordii) Genome Provides A Resource for Understanding Genome Evolution and Improved Oil Production</a></p>
<p><strong>期刊：</strong>Genomics Proteomics &amp; Bioinformatics</p>
<p><strong>影响因子：</strong>6.597</p>
<p><strong>研究单位：</strong>中南林业科技大学</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年4月7日，Genomics Proteomics &amp; Bioinformatics 在线发表了由中南林业科技大学谭晓风团队牵头完成的油桐基因组研究论文。该研究利用Illumina+PacBio组装了1.12Gb油桐基因组，并通过北京百迈客生物技术有限公司的Hi-C技术将95.15%的序列挂载到11条染色体上。基于比较基因组等系列相关研究解析了油桐基因组进化和桐油生物合成的分子机制。该研究为理解基因组演化、以及油脂产量的分子育种与遗传改良都提供了宝贵的遗传资源，为油桐种质资源保护、分子遗传学研究、良种选育及加工利用，奠定了重要的科学基础。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/28.png" alt="油桐基因组circos图"></p>
<h2 id="7-5"><a href="#7-5" class="headerlink" title="7.5"></a>7.5</h2><p><strong>物种：亚麻</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32240956">Genomic Comparison and Population Diversity Analysis Provide Insights into the Domestication and Improvement of Flax</a></p>
<p><strong>期刊：</strong>iScience</p>
<p><strong>影响因子：</strong>——</p>
<p><strong>研究单位：</strong>甘肃省农业科学院</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年4月24日，由甘肃省农科院和北京百迈客等单位合作的亚麻基因组研究成果荣登iScience, 其中张建平研究员，党占海研究员，刘头明研究员，百迈客CEO郑洪坤为本文通讯作者。该研究使用Illumina技术对油用亚麻品种Longya-10、纤维亚麻品种Heiya-14和pale flax分别进行测序与组装，后期利用HiC技术与遗传图谱辅助Longya-10基因组组装，将434 scaffolds组装至染色体水平。通过比较基因组及群体进化等研究探索油用及纤维用亚麻在驯化中受到的选择作用，以及可能在重塑亚麻形态结构中起着至关重要作用的相关基因。该研究揭示了对亚麻驯化和改良有重要影响的基因，这将有助于今后的分子育种。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/29.png" alt="亚麻基因组Hi-C热图"></p>
<h2 id="7-6"><a href="#7-6" class="headerlink" title="7.6"></a>7.6</h2><p><strong>物种：枇杷</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32141509">Chromosome-level genome assembly and annotation of the loquat (Eriobotrya japonica) genome</a></p>
<p><strong>期刊</strong>：Gigascience</p>
<p><strong>影响因子：</strong>4.688</p>
<p><strong>研究单位：</strong>上海市农业科学院</p>
<p><strong>主要研究内容：</strong></p>
<p>2020年2月6日，上海市农业科学院张学英研究员团队于知名期刊Gigascience上首次发表枇杷基因组相关研究论文，该研究中基于北京百迈客生物科技有限公司的Nanopore测序和Hi-C染色体构象捕获技术，构建了高质量的枇杷基因组。文中通过与苹果、水蜜桃、梨、覆盆莓、月季和野草莓的蛋白质序列比较，探索了枇杷的全基因组复制与进化事件，并进行了染色体重排分析。该研究提供了宝贵的染色体水平基因组数据，为研究枇杷性状提供了重要的基因组数据。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/30.png" alt="枇杷基因组circos图"></p>
<h2 id="7-7"><a href="#7-7" class="headerlink" title="7.7"></a>7.7</h2><p><strong>物种：板蓝根（菘蓝）</strong></p>
<p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32025321">A chromosome-scale genome assembly of Isatis indigotica, an important medicinal plant used in traditional Chinese medicine</a></p>
<p><strong>期刊：</strong> Horticulture Research</p>
<p><strong>影响因子：</strong>3.640</p>
<p><strong>研究单位：</strong>四川大学</p>
<p><strong>主要研究内：</strong></p>
<p>2020年2 月1日，四川大学生命科学学院刘建全课题组与华中农业大学作物遗传改良国家重点实验室李再云课题组首次完成了菘蓝（<em>Isatis indigotica</em>，2n=14）染色体级别基因组图谱绘制。该研究利用Pacbio测序(140X)结合北京百迈客生物技术有限公司的Hi-C技术（284X）组装得到294Mb高质量基因组（contigN50=1.2Mb）。基于同源搜索和功能注释，确定了该物种主要化合物（如吲哚类、萜类、黄酮、木脂素等物质）的可能生物合成通路和相关的候选基因。该研究强调了基因组测序在鉴定药用植物代谢产物合成候选基因中的重要性，为今后十字花科植物比较基因组等研究提供了重要遗传信息。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/31.png" alt="菘蓝基因组Hi-C热图"></p>
<h2 id="7-8"><a href="#7-8" class="headerlink" title="7.8"></a>7.8</h2><h6 id="以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究"><a href="#以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究" class="headerlink" title="以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究"></a>以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究</h6><h6 id="RESEQUENCING-OF-243-DIPLOID-COTTON-ACCESSIONS-BASED-ON-AN-UPDATED-A-GENOME-IDENTIFIES-THE-GENETIC-BASIS-OF-KEY-AGRONOMIC-TRAITS"><a href="#RESEQUENCING-OF-243-DIPLOID-COTTON-ACCESSIONS-BASED-ON-AN-UPDATED-A-GENOME-IDENTIFIES-THE-GENETIC-BASIS-OF-KEY-AGRONOMIC-TRAITS" class="headerlink" title="RESEQUENCING OF 243 DIPLOID COTTON ACCESSIONS BASED ON AN UPDATED A GENOME IDENTIFIES THE GENETIC BASIS OF KEY AGRONOMIC TRAITS"></a>RESEQUENCING OF 243 DIPLOID COTTON ACCESSIONS BASED ON AN UPDATED A GENOME IDENTIFIES THE GENETIC BASIS OF KEY AGRONOMIC TRAITS</h6><p>期刊：Nature Genetics</p>
<p>影响因子：27.125</p>
<p>发表单位：中国农业科学院棉花研究所、北京百迈客生物科技有限公司等</p>
<p>发表年份：2018年5月</p>
<p>研究背景：</p>
<p>棉花是研究植物多倍化的有价值的资源。亚洲棉(<em>Gossypium arboreum</em>)和草棉(<em>Gossypium herbaceum</em>)的祖先是现代栽培异源四倍体棉花A亚基因组的供体。 本研究中，利用了三代PacBio和Hi-C技术，重新组装了高质量的亚洲棉基因组，分析了243份二倍体棉花种质的群体结构和基因组分化趋势，同时确定了一些有助于棉花皮棉产量遗传改良的候选基因位点。</p>
<p>研究结果：</p>
<p>1、亚洲棉三代基因组组装：</p>
<p>利用三代测序和Hi-C相结合的方法进行亚洲棉基因组组装。共计获得了142.54 Gb ，组装1.71 Gb亚洲棉基因组，Contig N50=1.1 Mb，最长的Contig为12.37 Mb。利用Hi-C技术将组装的1573 Mb的数据定位到13条染色体上，与已经发表的基因组相比，当Hi-C数据比对到更新的基因组后，对角线外的不一致性明显减少（图1 a-b）</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/33.png" alt="img"></p>
<p>图1 HI-C数据在两版亚洲棉基因组上的比对</p>
<p>2、二倍体棉花群体遗传进化分析：</p>
<p>对230份亚洲棉和13份草棉重测序，进行基因组比对、系统发育树、群体结构分析、PCA、LD和选择性清除分析得出亚洲棉和草棉（A）与雷蒙德氏棉同时进行了分化；亚洲棉起源于中国南部，随后被引入长江和黄河地区，大多数具有驯化相关特性的种质都经历了地理隔离（图2）。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/34.png" alt="img"></p>
<p>图2 二倍体棉群体进化和群体结构分析</p>
<p>3、亚洲棉的全基因组关联分析（GWAS）：</p>
<p>对来自不同环境下的11个重要性状进行全基因组关联分析，鉴定了亚洲棉11个重要农艺性状的98个显著关联位点，GaKASIII的非同义替换（半胱氨酸/精氨酸替换）使得棉籽中的脂肪酸组成（C16:0和C16:1）发生了变化；发现棉花枯萎病抗性与GaGSTF9基因的表达激活相关。选择了亚洲棉种质中的158份有绒毛和57份无绒毛材料进行GWAS关联分析，发现与毛状体和纤维发育有关信息（图3）。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/35.png" alt="img"></p>
<p>图3 二倍体棉群体进化和群体结构分析</p>
<p>研究结论：</p>
<p>利用三代测序+Hi-C技术完成了亚洲棉基因组的重新组装，将基因组组装指标从72 Kb提升到1.1 Mb，为亚洲棉后续的群体遗传学等相关研究奠定了基础；通过群体遗传进化等相关分析，发现亚洲棉和草棉(A型)与雷蒙德氏棉(D型)同时进行了分化，并证明了亚洲棉起源于中国南部，随后被引入长江和黄河地区；整合GWAS与QTL等分析方法，对亚洲棉脂肪酸含量，抗病性及棉绒生长发育相关基因进行定位，并进行相关功能验证，促进了亚洲棉复杂农艺性状的改良。</p>
<h2 id="7-9"><a href="#7-9" class="headerlink" title="7.9"></a>7.9</h2><h6 id="二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良"><a href="#二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良" class="headerlink" title="二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良"></a>二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良</h6><h6 id="COMPARISON-OF-ARACHIS-MONTICOLA-WITH-DIPLOID-AND-CULTIVATED-TETRAPLOID-GENOMES-REVEALS-ASYMMETRIC-SUBGENOME-EVOLUTION-AND-IMPROVEMENT-OF-PEANUT"><a href="#COMPARISON-OF-ARACHIS-MONTICOLA-WITH-DIPLOID-AND-CULTIVATED-TETRAPLOID-GENOMES-REVEALS-ASYMMETRIC-SUBGENOME-EVOLUTION-AND-IMPROVEMENT-OF-PEANUT" class="headerlink" title="COMPARISON OF ARACHIS MONTICOLA WITH DIPLOID AND CULTIVATED TETRAPLOID GENOMES REVEALS ASYMMETRIC SUBGENOME EVOLUTION AND IMPROVEMENT OF PEANUT"></a>COMPARISON OF <em>ARACHIS MONTICOLA</em> WITH DIPLOID AND CULTIVATED TETRAPLOID GENOMES REVEALS ASYMMETRIC SUBGENOME EVOLUTION AND IMPROVEMENT OF PEANUT</h6><p>期刊：Advanced Science</p>
<p>影响因子：15.804</p>
<p>发表单位：河南农业大学、北京百迈客生物科技有限公司等</p>
<p>发表年份：2019年11月</p>
<p>研究背景：</p>
<p>花生作为我国重要的经济作物，是提供重要的蛋白和油料的基础。花生属一共包括30个二倍体品种，1个异源四倍体野生花生(<em>A. monticola</em>)和1个栽培花生(<em>A. hypogaea</em>)。作为栽培花生农艺性状改良的重要野生资源供体，野生四倍体花生一直是国内外学者的研究热点。研究中对花生属唯一的野生异源四倍体花生<em>Arachis monticola</em>基因组进行了研究，同时对17个野生二倍体花生（AA;BB;EE;KK和CC）与30个野生和栽培四倍体花生进行了重测序分析。</p>
<p>研究结果：</p>
<p>1、野生四倍体花生基因组denovo及与栽培四倍体花生的比较分析：</p>
<p>基于 Illumina、PacBio 、Hi-C和光学图谱数据，组装<em>Arachis monticola</em>(2n = 4x = 40)基因组大小为2.62 Gb ，contigs N50=106.66 Kb，scaffolds N50=124.92 Mb；与栽培四倍体花生<em>A. hypogaea</em>基因组结构变异高度保守，且比野生祖先二倍体更加保守；</p>
<p>2、A、B亚基因组的单系起源和多样性：</p>
<p>对17个二倍体野生种（AA、BB、EE、KK和CC）和30个野生和栽培四倍体花生进行了进化树和PCA分析。结果表明，栽培四倍体花生与野生四倍体花生最接近， A和B亚基因组的单系起源（图1）；</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/36.png" alt="img"></p>
<p>3、四倍体花生不对称亚基因组进化及表达差异 <strong>：</strong></p>
<p>栽培花生和野生花生的亚基因组间的同源序列交换率（HSE）分别为2.46%和2.54%。野生花生中A到B的HSE富集的基因为类黄酮生物合成和昼夜节律途径的基因，暗示不对称HSEs在生物学功能中的作用；</p>
<p>4、SV对荚发育和驯化相关基因表达的影响及抗病基因鉴定 <strong>：</strong></p>
<p>对野生四倍体花生和栽培四倍体花生不同发育阶段荚果的SV分析发现SV在荚果发育过程中基因表达的变化上可能起着重要作用；同时在栽培四倍体花生中鉴定到190个SV抗病基因（SV-RGAs），其中32个基因在接种后易感组或抗性组中表现出显著的表达变化（图2）。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/37.png" alt="img"></p>
<p>研究结论：</p>
<p>充分注释了高质量野生四倍体花生基因组，揭示了花生亚基因组单系起源和遗传进化模型，表明了野生和栽培四倍体花生亚基因组发生了不对称进化；此外，野生花生中存在的独特等位基因可以改善栽培花生的抗性和荚果大小等形状，为研究多倍体基因组进化、作物驯化和基因组辅助花生生产改良提供独特的价值。</p>
<hr>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Hi-C/32.png" alt="其他"></p>
<p>北京百迈客自启动Hi-C技术研究以来，自主开发Hi-C排图软件，具有实验+生物信息分析专利双保护，也是中国市场上能独立完成Hi-C实验——数据分析的测序企业之一！并完成上千个物种，近万个文库构建；文库含酶切位点有效数据比例最高达93%以上，针对物种推出定制化内切酶服务；实现多倍体物种的Hi-C辅助基因组组装，<strong>挂载效率最高达100%。</strong></p>
<p>另外为了让更多科研工作者体验Hi-C建库，百迈客在成功构建多种物种Hi-C建库测序的经验上，正式推出了Biomarker Hi-C Library Prep Kit for Illumina。</p>
<p>Biomarker Hi-C Library Prep Kit for Illumina涵盖了Hi-C实验全部环节，包括甲醛交联、Hi-C提取和Hi-C文库构建，适用于细胞系、动物和植物组织样本。1套Hi-C试剂盒包含5个反应，1个反应构建的文库可用于200Gb数据量的测序，试剂盒构建的文库适用于Illumina测序平台。</p>
<hr>
<p>Ref:<a href="https://www.zhihu.com/question/48308074">https://www.zhihu.com/question/48308074</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1625366">https://cloud.tencent.com/developer/article/1625366</a></p>
<p><a href="http://www.biomarker.com.cn/technology-services/hi-c">http://www.biomarker.com.cn/technology-services/hi-c</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/140795830">https://zhuanlan.zhihu.com/p/140795830</a></p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>选择基因</title>
    <url>/blog/2022/02/16/2022-0216-select-gene/</url>
    <content><![CDATA[<h1 id="选择基因-selector-genes-是一类决定体节发育的基因。"><a href="#选择基因-selector-genes-是一类决定体节发育的基因。" class="headerlink" title="选择基因(selector genes)是一类决定体节发育的基因。"></a>选择基因(selector genes)是一类决定体节发育的基因。</h1><span id="more"></span>

<p>有<font color="green">两簇选择基因</font>在控制<font color="green">果蝇外部结构</font>的正确发育途径中起关键作用：<font color="green">双胸复合物(bithorax complex,BX-C)</font>和<font color="green">触角足复合物(antennapedia complex,ANT-C)</font>。BX-C含有三个结构基因，分别是：<font color="green">Ultrabithorax(Ubx)、Abdominal A(abdA)和Abdominal B(abdB)</font>，它们<font color="green">各编码一种具有同源框的转录因子。这三个基因都含有很多内含子</font>，这些内含子对于调节这些基因在不同<a href="https://baike.baidu.com/item/%E5%89%AF%E8%8A%82">副节</a>进行不同的表达具有重要作用。ANT-C<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E7%B0%87">基因簇</a>含有5个基因：<font color="green">labial(lab)、proboscipedia(pb)、Deformed(Dfd)、Sex combs reduced(Scr)和antennapedia(Antp)</font>。这两簇基因都定位于<font color="green">3号染色体</font>。ANT-C簇编码的蛋白质控制<font color="green">0-5副节</font>的发育，BX-C基因簇编码的蛋白质控制<font color="green">5-14</font>副节的发育。</p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>biology</tag>
      </tags>
  </entry>
  <entry>
    <title>染色质三维结构图谱 Micro-C</title>
    <url>/blog/2022/02/16/2022-0216-chromosome-structure-Micro-C/</url>
    <content><![CDATA[<h1 id="Micro-C"><a href="#Micro-C" class="headerlink" title="Micro-C"></a>Micro-C</h1><span id="more"></span>

<h1 id="Micro-C-1"><a href="#Micro-C-1" class="headerlink" title="Micro-C"></a>Micro-C</h1><p>染色质结构与基因表达的调控密切相关（如<font color="green">常染色质/异染色质</font>）。随着近年<font color="green">染色质构象捕捉技术</font>的发展，了解到细胞核内的DNA存在着<font color="green">多重结构调节机制</font>，例如<font color="green">A/B染色质区室（compartment）</font>和<font color="green">拓扑结构域（TAD）</font>。大小分别在<font color="green">百万碱基</font>和<font color="green">十万碱基</font>左右。由于测序深度和技术条件限制，<font color="green">Hi-C很难达到更高分辨率</font>，<strong>限制</strong>了分析关于单个基因，以及启动子（P）、增强子（E）等<font color="green">调控元件之间相互作用</font>。</p>
<p>Molecular Cell杂志发表背靠背文章Resolving the 3D Landscape of Transcription-Linked Mammalian Chromatin Folding和Ultrastructural Details of Mammalian Chromosome Architecture。<font color="green">一种新的染色质构象捕捉技术名为Micro-C</font>。Micro-C达到<strong>单核小体长度（～200bp）</strong>左右的<strong>分辨率</strong>，可以观察到更为精细的染色质结构。</p>
<p>Micro-C和Hi-C在实验步骤上最大的不同，在于Micro-C先对核小体上缠绕的DNA做交联，而后用MNase切断核小体之间的连接DNA。以Tjian和Darzacq实验室的文章为例，他们对38个小鼠干细胞进行Micro-C测序，总共获得约26亿个reads。<strong>相似测序深度</strong>下<strong>20kb精度</strong>的<strong>Micro-C图谱与Hi-C结果相似</strong>，但在<strong>100至20kb的精度之间</strong>，<strong>Micro-C</strong>展示<strong>Hi-C不具备</strong>的<strong>精细</strong>结构，例如很多有关基因启动子和增强子的结构域、条带和点圈。从Hi-C可以得到约6000个DNA环（loop），即高度相互作用的一对区域。而Micro-C可以得到约30000个。</p>
<p>在证实了Micro-C具备可重复性和高精度之后，进一步分析，<font color="green">相比Hi-C，Micro-C独特</font>的主要在于可探查<font color="green">调控元件之间相互作用</font>，如EP，PP等。其中有些相互作用形成了比传统TAD小的结构域。研究者通过隔离分值的分析得到了大约13万个这样的结构域边界。这些<font color="green">边界通常有着活跃转录的基因和动态的核小体结构</font>，而与之前所了解的，<font color="green">以CTCF和Cohesin为标志的TAD边界</font>有很大<font color="green">不同</font>。</p>
<p>利用<strong>回归模型</strong>分析了这些<strong>结构域边界</strong>和<strong>表关遗传特征</strong>的<strong>关联性</strong>。<font color="green">CTCF</font>和<font color="green">Cohesin</font>在<font color="green">决定边界位置</font>最重要，然而决定<font color="green">边界强度</font>却主要是<font color="green">转录活跃的标志物</font>，如<font color="green">H3K4me3修饰和染色质开放度</font>等。进一步发现边界也存在很大差别，将其分为五类：<font color="red">转录相关</font>；<font color="red">干细胞特异性增强子</font>；<font color="red">一般增强子</font>；<font color="red">抑制型</font>；<font color="red">CTCF-Cohesin相关型</font>。各有不同的化学修饰。</p>
<p>选取了一些代表性的区域发现，不仅<strong>启动子、增强子和CTCF之间相互作用</strong>，在<strong>聚梳抑制区</strong>还可以观察到显著的<strong>“巢状”环</strong>。<strong>CTCF相互作用范围较长</strong>，而<strong>Pol II</strong>介导的相互作用则<strong>较短</strong>。基因附近的相互作用越紧密，其转录活性也常常越高。进一步<strong>证明</strong><font color="green">转录对染色质折叠</font>的影响，利用<font color="green">药物抑制转录</font>。对比观察到，<font color="green">TAD等大尺度结构无变化</font>，然而<font color="green">基因附近的相互作用</font>条纹<font color="green">大大减弱</font>，证明了这些条纹团确实是由转录过程导致的。</p>
<p>两篇文章显示了<strong>哺乳动物</strong>的<font color="green">染色质相互作用</font>还有<font color="green">更多的精细结构等待开发</font>。更高精度的数据能帮助人们理解这些<strong>结构的形成和对基因转录的影响</strong>。</p>
<p>原文链接：<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzQyNjY1MQ==&amp;mid=2652482974&amp;idx=3&amp;sn=acc0381ecc6ab6779e335510b87de062&amp;chksm=84e23e2ab395b73">https://mp.weixin.qq.com/s?__biz=MzA3MzQyNjY1MQ==&amp;mid=2652482974&amp;idx=3&amp;sn=acc0381ecc6ab6779e335510b87de062&amp;chksm=84e23e2ab395b73</a></p>
<hr>
<p><font color="green">染色质高级结构</font>由不同层次的结构单元组成。从<font color="green">区块（compartment）</font>，<font color="green">拓扑结构域（TAD）</font>，到单个的<font color="green">环（loop）</font>，这些大小不同的单元各有特征，也对<strong>染色质功能</strong>和<strong>基因表达</strong>起到多种多样的<strong>调控</strong>。CTCF蛋白扮演了重要的角色。</p>
<p><font color="red">CTCF</font>常常位于<strong>TAD和loop的边界</strong>，起到“<font color="red">隔离子</font>”的作用。近年来提出的loop extrusion模型也认为<font color="green">CTCF和cohesin的协调作用是loop形成的普遍机理</font>。虽然有假设，却一直不清楚CTCF<font color="red">如何作用</font>于染色质，并导致复杂结构形成。CTCF蛋白的各个结构域，除了同DNA结合的11-ZF外，其他结构域功能？</p>
<p>2019年9月12日，Molecular Cell杂志发表背靠背文章“Distinct Classes of ChromatinLoops Revealed by Deletion of anRNA-Binding Region in CTCF”和“RNA Interactions Are Essentialfor CTCF-Mediated Genome Organization”<strong>，</strong>共同揭示<font color="green">CTCF与RNA的相互作用</font>对CTCF功能的重要意义。</p>
<p>之前研究发现<font color="green">CTCF常在细胞中成簇聚集</font>。为研究聚集的<font color="green">机理</font>，在细胞中分别加入<font color="green">DNase和RNase</font>。结果吃惊，被认为是DNA结合蛋白的CTCF的聚合对<font color="green">DNase并不敏感</font>，而<font color="green">RNase却显著减少了CTCF的互相结合</font>。 结合之前研究，CTCF上的ZF10和ZF11结构域有一段具有RNA结合功能（<font color="red">RNA-binding region</font>，<strong>RBR</strong>），其中<strong>38个氨基酸</strong>对其结合是必不可少。研究者于是在<font color="red">小鼠干细胞</font>上将这段被称为<font color="red">RBRi的片段替换</font>，发现<font color="green">缺陷型细胞</font>的<strong>CTCF表达水平</strong>虽然<strong>无明显变化</strong>，<strong>生长却慢了2倍</strong>，显示<strong>RBRi</strong>可能具有重要的<strong>生理作用</strong>。RBRi缺陷的CTCF在细胞中和RNA的<font color="green">结合减少但却没有完全消失</font>。研究者接着对<strong>RBRi缺陷和不缺陷的CTCF</strong>分别做了荧光<strong>标记</strong>。结果<strong>野生型CTCF</strong>呈现了明显<strong>更高程度聚团</strong>。不过这些结果并<strong>不排除RBRi间接作用</strong>于其他因子的可能。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Micro-C/1.png" alt="img"></p>
<p>研究者接着分析了**<font color="red">RBRi片段功能和Compartment，TAD，Loop三大结构单元的关系</font><strong>。对</strong>RBRi缺陷<strong>和</strong>野生型<strong>细胞</strong>Micro-C测序<strong>。Micro-C是一种比Hi-C清晰度更高的研究基因组范围染色质相互作用的方法。RBRi的<font color="green">缺陷并不影响compartment形成</font>，但却</strong><font color="red">大范围改变了TAD和loop的结构</font>**。将RBRi<font color="green">替换后</font>，小鼠细胞内<font color="green">TAD的数目和强度都有所减少</font>，其中<font color="green">大部分同TAD边缘CTCF和Cohesin的ChIP-seq信号变化一致</font>。RBRi的替换也使得<font color="green"><strong>Micro-C</strong></font>热图上的<font color="green"><strong>条带（strip）变长</strong></font>，这符合loop extrusion模型的假设。而loop的改变更为有趣–有些loop完全明显削弱（38%～57%），而有些loop却完好无损甚至增强了。研究者于是<font color="green"><strong>将loop分成RBRi依赖和不依赖两类</strong></font>，并发现它们具有不同的转录因子结合特征。他们还据此假设，这两类loop同CTCF有不同的结合方式，因此稳定性也不同。这也许可以解释为什么不是所有的CTCF位点都会形成loop。最后，发现大约500个基因由于RBRi的替换产生了差异表达。</p>
<p><img src="/blog/2022/02/16/2022-0216-chromosome-structure-Micro-C/2.png" alt="img"></p>
<p>Danny Reinberg实验室则将目光集中在<strong>CTCF的ZF1和ZF10结构域</strong>上。他们发现对小鼠细胞的转录抑制在没有降低CTCF表达水平的前提下，减少了CTCF在全基因组范围的结合程度。<font color="red">ZF1或ZF10缺陷的CTCF与RNA的结合能力都大大减少，并且在一定程度导致CTCF结合位点和基因表达改变。而不同的是，ZF1缺陷使得大部分CTCF loop消失，而ZF10缺陷型细胞的loop却仍然保持完好。</font></p>
<p><strong>这两篇背靠背文章共同揭示了CTCF的RNA结合域</strong>（RBR）<strong>在CTCF发挥正常功能中扮演着重要的角色。</strong></p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>CTCF</title>
    <url>/blog/2022/02/15/2022-02-15-CTCF/</url>
    <content><![CDATA[<h1 id="【paper1】CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops"><a href="#【paper1】CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops" class="headerlink" title="【paper1】CTCF: the protein, the binding partners, the binding sites and their chromatin loops"></a>【paper1】CTCF: the protein, the binding partners, the binding sites and their chromatin loops</h1><span id="more"></span>

<p>review: <a href="https://pubmed.ncbi.nlm.nih.gov/23650640/">https://pubmed.ncbi.nlm.nih.gov/23650640/</a></p>
<h1 id="CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops"><a href="#CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops" class="headerlink" title="CTCF: the protein, the binding partners, the binding sites and their chromatin loops"></a>CTCF: the protein, the binding partners, the binding sites and their chromatin loops</h1><p>CTCF:蛋白质，结合伙伴，结合位点和染色质环</p>
<p>CTCF什么都有。转录因子与成千上万个基因组位点结合，有些是组织特异性的，有些是超保守的。它可以作为<strong>转录激活因子</strong>、<strong>抑制子</strong>和<strong>绝缘子</strong>，并可以<strong>暂停转录</strong>。CTCF<strong>结合</strong>在<strong>染色质结构域边界</strong>，<strong>增强子</strong>和<strong>启动子</strong>，以及<strong>基因区</strong>。它可以吸引许多其他转录因子到染色质，包括组织特异性转录激活因子、抑制子、粘连蛋白和RNA聚合酶II，并形成染色质环。因此，CTCF在特定基因组位点的确切功能是不可预测的。它似乎是由相关的转录因子、结合位点相对于基因转录起始位点的位置、以及该位点在染色质环中与其他ctcf位点的结合、与增强子或启动子的结合决定的。该review将讨论CTCF结合事件的全基因组特征，以及这个显著的转录因子的位点特异性功能。</p>
<ol>
<li>introduction</li>
</ol>
<p>CTCF是一种普遍表达的必需蛋白，在许多方面都是一种特殊的转录因子。它最初被描述为转录<strong>抑制</strong>因子，但也被发现作为转录<strong>激活</strong>因子。还具有<strong>绝缘体活性</strong>:当它位于增强子和基因启动子之间时，它阻断它们的通信并阻止转录激活。通过<strong>ChIP-seq</strong>系统研究，在<strong>不同物种的许多组织</strong>中绘制CTCF在基因组尺度的结合事件。结果显示基因组被<strong>无数的CTCF结合位点</strong>所覆盖。与大多数其他转录因子相比，CTCF似乎<strong>更容易</strong>与基因间序列<strong>结合</strong>，通常<strong>距</strong>离转录起始位点(<strong>TSS</strong>)<strong>较远</strong>。CTCF是<strong>最早被证实介导染色质成环</strong>的蛋白之一。进一步观察到，它经常会<strong>结合</strong>到位于细胞核中不同位置的<strong>染色体区域之间的边界</strong>，<strong>结合</strong>具有<strong>不同表观遗传特征</strong>和/或<strong>不同转录活性</strong>的<strong>区域边界</strong>，以及最近确定的<strong>拓扑域之间的边界</strong>，这是空间上确定的<strong>染色体单位</strong>，在其中<strong>序列优先相互作用</strong>。本文讨论CTCF的研究，并评估其在<strong>基因组折叠</strong>和<strong>基因表达</strong>中的功能。</p>
<ol start="2">
<li>CTCF在<strong>Β-globin</strong>和<strong>h19-igf2</strong>位点:一个短暂的历史</li>
</ol>
<p>多功能DNA结合蛋白CTCF的功能最初是在<strong>单个位点</strong>上探索的，特别是在<strong>β-珠蛋白位点</strong>和<strong>印迹H19-Igf2位点</strong>。<strong>chicken β-珠蛋白位点</strong>在其5 ‘侧携带一个DNaseI超敏位点(5 ‘ hs4)，该位点将该位点<strong>与邻近的异染色质分离</strong>，该位点被发现能够<strong>阻断增强子活性</strong>。CTCF随后被证明与5 ‘ hs4的绝缘体活性有关。人和小鼠的β-珠蛋白位点也位于不活跃染色质的大染色体区域内，并类似地被ctcf结合位点包围。这些被怀疑会对进入的异染色质形成屏障，但它们的缺失不会导致β-珠蛋白位点的关闭或失活。<strong>染色体构象捕获(3C)技术</strong>的应用使β-珠蛋白CTCF位点的物理相互作用成为可能。它们形成<strong>大染色质环</strong>，包括β-珠蛋白的主要调节元件，<strong>Locus control region基因位点控制区(LCR)<strong>及其</strong>基因</strong>。这些环是红细胞特异性的，在lcr介导的β-珠蛋白基因高表达之前，在红细胞祖细胞中形成(图1a;)。据推测，CTCF环可以<strong>促进LCR与其靶基因之间的后续空间相互作用</strong>，但这方面的证据仍然缺乏。</p>
<p><img src="/blog/2022/02/15/2022-02-15-CTCF/1.png"></p>
<p>Figure 1. CTCF，染色质环和特定基因位点的转录调控。(a)<strong>位于β-珠蛋白位点的基因</strong>受<strong>基因位点控制区(LCR)*<em><strong>控制。</strong>ctcf结合位点相互作用</em>*，形成</strong>染色质枢纽<strong>，其中包含</strong>LCR和β-珠蛋白基因<strong>。在</strong>红细胞分化<strong>时，</strong>红细胞特异性转录因子和内聚蛋白能够形成一个活跃的染色质枢纽<strong>，其中</strong>LCR与基因接触并增强其表达<strong>。(b) H19和Igf2基因的印迹表达是通过CTCF在印迹控制区(ICR)的甲基化依赖结合介导的。(i)在父系等位基因上，ICR的甲基化</strong>阻止CTCF结合**，并通过远端增强子(E)与Igf2启动子的接触介导Igf2基因的表达。(ii) <strong>CTCF结合在ICR上阻断了Igf2基因和远端增强子之间的通信</strong>，从而导致母源等位基因H19基因的表达。</p>
<p>印迹H19/Igf2位点。该位点包含一个<strong>差异甲基化区域</strong>，称为<strong>印迹控制区(ICR)<strong>，位于H19和Igf2基因之间。ICR决定了H19在</strong>母体等位基因</strong>上<strong>活跃</strong>，而<strong>Igf2</strong>则是从<strong>父系等位基因转录</strong>而来的。当CTCF被发现以<strong>甲基化依赖</strong>的方式与<strong>ICR结合</strong>时，CTCF进入了这个阶段:<strong>CTCF与未甲基化的母源ICR的结合阻</strong>止了H19基因附近的共享增强子<strong>跨越并激活</strong>Igf2。在<strong>父系等位基因CTCF不能发挥其绝缘体活性，因为DNA甲基化阻止了其与ICR的结合</strong>(图1b;)。染色质环再次形成，似乎对ICR的功能很重要。带有增强子和启动子的等位基因特异性染色质环是由母体的、与ctcf结合的ICR形成的，这表明这种接触可能是ctcf介导的绝缘体活性的基础。总的来说，早期关于CTCF在β-珠蛋白和H19-Igf2位点功能的研究表明，该蛋白可以<strong>干扰启动子-增强子通信</strong>。CTCF可以在其结合位点之间形成染色质环，也可能与其他调控序列形成染色质环。</p>
<ol start="3">
<li>CTCF通过基因组与染色质边界、增强子和基因启动子结合</li>
</ol>
<p>通过ChIP对全基因组结合位点的定位发现，CTCF可与数万个基因组位点结合。在不同的细胞类型中，大约<strong>三分之一的位点相对保守</strong>。一项对五种哺乳动物肝脏中CTCF结合谱的物种间比较发现，物种和组织之间大约有5000个超<strong>保守位点</strong>。这些似乎是<strong>高亲和力的结合位点</strong>，提示亲和力的差异可能与的保守强度有关。逆转录因子的激活产生了物种特异性的CTCF结合位点的扩展，这种形式的基因组进化在哺乳动物中仍然高度活跃。基于一致motif评分对CTCF结合位点进行分类得出了类似的结论:<strong>高占用位点似乎在所有细胞类型中都是保守的，而低占用位点则更受组织限制</strong>。</p>
<p>CTCF一致结合序列包含CpG，因此可能受到DNA甲基化的影响。CTCF能够在<strong>体外结合甲基化DNA序列</strong>，但<strong>优先结合未甲基化的序列</strong>，在H19-Igf2位点也可以看到。事实上，DNA甲基化似乎在CTCF的一些组织特异性结合事件中发挥作用。此外，<strong>CTCF</strong>可以通过与两种与DNA甲基化相关的酶:多聚(adp -核糖)聚合酶1 (<strong>PARP1</strong>)和无处不在表达的DNA(胞嘧啶-5)甲基转移酶1 (<strong>DNMT1</strong>)形成<strong>复合物来影响DNA甲基化</strong>。<strong>CTCF激活PARP1, PARP1在DNMT1上添加adp -核糖基团使DNMT1失活，从而维持无甲基CpGs的存在</strong>。</p>
<p><strong>部分CTCF结合位点</strong>在<strong>活性染色质</strong>(<strong>高H2K5Ac</strong>)和<strong>非活性</strong>染色质结构域(<strong>高H3K27me3</strong>)之<strong>间</strong>的过渡<strong>富集</strong>。对于逆转录转座的CTCF结合位点似乎尤其如此。CTCF位点经常位于所谓的<strong>膜相关域</strong>(lad)旁边。lad是与<strong>覆盖核膜内侧的层状蛋白网络相关的染色体区域</strong>;这些染色体区域往往是<strong>转录不活跃</strong>的。它的存在提示<strong>CTCF有助于染色质的三维结构的组织</strong>。在果蝇中，CTCF的抑制导致非活性域内H3K27me3水平的降低，表明CTCF在边界上的结合是<strong>维持抑制</strong>所必需的。CTCF的关联伴随着细胞分化过程中<strong>活性域和非活性域的重置</strong>，进一步表明它的功能是<strong>分离不同的染色质状态</strong>。一些lad在细胞分化过程中也会发生动态变化[35]，但CTCF是否与这些差异lad的边界结合目前尚不清楚。</p>
<p>尽管CTCF结合常出现在TSSs远端，但它确实与<strong>基因密度有很强的相关性</strong>(图2a,b)。事实上，CTCF在转录调控中<strong>直接作用的证据来自于早期对单个基因的研究</strong>。在全基因组范围内，部分CTCF位点与<strong>启动子特异性H3K4me3标记共定位</strong>，另一部分与<strong>增强子标记H3K4me1重合</strong>。启动子上的CTCF结合事件在组织中趋于<strong>保守</strong>，而CTCF与增强子的结合则更受<strong>组织限制</strong>。</p>
<p><img src="/blog/2022/02/15/2022-02-15-CTCF/2.png"></p>
<p>Figure2. CTCF在染色质生物学中的广泛作用。(a) CTCF结合位点的全基因组功能分类，采用Chen et al.[36]。(b) (i) CTCF结合位点位于<strong>分离活性域和非活性域的边界</strong>上。CTCF结合到(ii)<strong>增强子</strong>样序列和(iv)基因<strong>启动子</strong>上可以促进这些序列之间的环环相扣。(iii) CTCF结合在<strong>增强子和基因启动子之间</strong>，可以<strong>阻断</strong>增强子与其目标启动子之间的相互作用。</p>
<ol start="4">
<li>CTCF和内聚蛋白共享DNA结合位点</li>
<li>5.ctcf和其他绑定伙伴</li>
<li>CTCF在单个基因位点的功能</li>
<li>CTCF介导的全基因组染色质环</li>
</ol>
<p>CTCF的基因组结合位点(通过全基因组<strong>ChIP</strong>)与<strong>Hi-C</strong>生成的<strong>genome-wide DNA contact map</strong>的计算交叉表明，CTCF参与染色体之间和基因组内的染色质相互作用。染色质相互作用分析与配对末端标记测序<strong>Chromatin interaction analysis with paired-end tag sequencing (ChIA-PET)</strong> 结合了ChIP和3C方法，用于研究由<strong>感兴趣的蛋白质介导的全基因组DNA相互作用</strong>。当靶向CTCF时，ChIA-PET揭示了蛋白介导的大约<strong>1500个染色体内</strong>和<strong>300个染色体间</strong>的相互作用。随后，根据<strong>组蛋白标记</strong>的分布，对<strong>染色体内环</strong>所包围的<strong>区域(10-200 kb)进行聚类</strong>。这表明CTCF环可以包含从环外非活性染色质分离出来的活性染色质，反之亦然。CTCF还可以同时<strong>捕获染色质环中的增强子和启动子</strong>。在大约<strong>40000个CTCF结合位点</strong>中，只有<strong>一小部分</strong>参与了大约1500个CTCF介导的<strong>环</strong>。这意味着不是所有CTCF介导的相互作用都被识别出来了，或者<strong>大多数CTCF位点没有参与环的形成</strong>。</p>
<p>后者很可能是正确的，因为5C(<strong>chromosome conformation capture carbon copy</strong>染色体构象捕获碳复制)技术表明，在1%的基因组中，大多数CTCF位点不参与染色质环，无论它们是否被内聚蛋白共同占据。<strong>CTCF结合序列常被基因启动子跳过，与增强子或更远的CTCF位点进行接触</strong>。</p>
<p>最近大量的全基因组DNA相互作用数据集有助于<strong>评估CTCF对染色体拓扑的影响</strong>。染色体上靠近<strong>CTCF结合位点的序列</strong>显示在它们的DNA接触中存在偏倚:它们与<strong>CTCF位点同侧</strong>的其他<strong>序列的相互作用</strong>大于与<strong>CTCF位点跨侧</strong>的序列的相互作用(图3a;)。同样的结果也出现在果蝇中另一种不同的绝缘体蛋白上:它与一个位点的结合阻止了侧翼序列在这个位点上相互接触。有趣的是，这可能为绝缘体的功能提供了一种解释:它们可以阻止DNA在绝缘序列上的空间接触。在一个特别详细的全基因组DNA接触研究中，<strong>拓扑域</strong>被定义;它们是<strong>平均大小为1mb的染色体区域</strong>，其中<strong>序列优先相互作用</strong>。在组织之间，甚至在物种之间，拓扑结构域具有很强的<strong>保持性</strong>，这表明这些结构域对<strong>细胞的特异性身份没有贡献</strong>。有趣的是，CTCF结合位点在这些<strong>区域边界周围的20kb窗口中富集</strong>(图3b)，再次强调了其作为<strong>染色质组织者</strong>的作用。其中一项研究表明，边界的破坏会导致拓扑域的混合，并导致相关基因的表达失调[79]。不同于拓扑域本身，域内的接触在分化过程中是变化的。在这里，CTCF似乎发挥了作用，可能适应基因表达的发育变化。</p>
<p><img src="/blog/2022/02/15/2022-02-15-CTCF/3.png"></p>
<p>Fig 3. CTCF通过阻碍DNA在其结合位点上的接触而起到绝缘体的作用。(a) CTCF<strong>阻碍其结合位点在10kb以内的序列跨越</strong>。<strong>线的厚度减小表明交互作用的概率减小</strong>。(b) CTCF结合位点常出现在拓扑域的边界处。(i) ESCs和皮质的Hi-c数据，用小鼠第12号染色体序列之间的颜色编码接触频率。<strong>三角形</strong>显示和突出<strong>拓扑域</strong>，是<strong>染色体序列优先相互作用的区域</strong>。(ii)层关联域(LAD)数据，LAD边界与拓扑域边界重合。(iii) CTCF ChIP-seq profiles，显示在边界的CTCF结合位点簇。请注意，这种CTCF集群在其他地方也存在，特别是在非lad地区。显示区域:chr12: 112.3-119.3 Mb (mm9)。</p>
<ol start="8">
<li>结论</li>
</ol>
<p>尽管CTCF一直是研究的热点，但它仍然是一种<strong>神秘的转录因子</strong>。它与基因组中成千上万个位点结合，与大量其他转录因子相互作用。它常被发现参与染色质<strong>环</strong>，有时有，有时没有<strong>内聚蛋白</strong>的参与。它可以<strong>与其他CTCF结合位点</strong>形<strong>成</strong>染色质<strong>环</strong>，也可以与<strong>增强子</strong>和<strong>启动子</strong>序列形<strong>成</strong>染色质<strong>环</strong>。CTCF不仅与基因内外的序列结合，也与<strong>基因体内</strong>的<strong>序列结合</strong>，在基因体内它似乎能够<strong>暂停滑动聚合酶分子</strong>。最后，CTCF结合位点仍然作为<strong>反转录转座序列</strong>活跃地跳跃，使CTCF结合景观在不同哺乳动物物种之间具有多样性。</p>
<p>可以解释CTCF与染色质关联的许多，<strong>有时是相反的功能</strong>后果的统一主题可能是其<strong>成环能力</strong>。根据环中包含的序列和环外的序列，由CTCF形成的染色质可能会<strong>促进或阻碍增强子和靶基因之间的三维接触</strong>，从而产生不同的转录结果。许多问题仍然存在:为什么一些CTCF位点形成染色质环而另一些则没有?这在多大程度上依赖于相关的蛋白质因子?当蛋白质与染色质结合时，它是如何设法与这么多其他转录因子相互作用的?一种可能是CTCF作为染色质扫描转录因子的路障，当遇到结合蛋白时，这些转录因子以某种方式被困住。ctcf介导的染色体间接触有何相关性?CTCF是否通过阻止3D DNA接触来阻断增强子-启动子通信?或者绝缘是否涉及绝缘体序列与增强剂和启动剂的物理相互作用?这些问题的答案需要能够预测给定的CTCF结合事件是否在功能上不相关，是否会引起转录激活或抑制，是否会干扰转录激活或会产生染色质边界。</p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>【GO】【KEGG】</title>
    <url>/blog/2021/12/20/2021_12_20_GO_KEGG_post/</url>
    <content><![CDATA[<h2 id="Oryza-Sativa-【Gene-ID】【GO】【KEGG】"><a href="#Oryza-Sativa-【Gene-ID】【GO】【KEGG】" class="headerlink" title="Oryza Sativa 【Gene ID】【GO】【KEGG】"></a>Oryza Sativa 【Gene ID】【GO】【KEGG】</h2><span id="more"></span>

<p><strong>GO分析</strong>：基因-&gt;功能类群</p>
<p>**KEGG(Pathway)**：基因-&gt;代谢网络</p>
<p><strong>GO/KEGG选取目标基因</strong></p>
<ul>
<li><p>指标：Enrichment score，p值，FDR</p>
</li>
<li><p>pathway：p和FDR越小越好，问题是有时本就不易富集出，如何取舍</p>
</li>
<li><p>GO：p，FDR，Enrichmentscore（越大越容易受到影响）</p>
</li>
<li><p><font color="green">fold change较大的基因</font>（up，down）</p>
</li>
<li><p>可能有用的蛋白，PPI？</p>
</li>
</ul>
<p>GO: 研究的基因哪些通路？是否变化</p>
<p><strong>KEGG筛选方法：</strong></p>
<ul>
<li>先看KEGG的聚类分析结果（感兴趣研究方向有关的基因是不是有差异）→ GO分为三个分枝，先看BP分枝（感兴趣研究方向有关的基因是不是有差异）→挑选和我们研究比较相关的→后期验证：选FC比较大，验证成功率会高一些</li>
<li>根据Rich factor值、Qvalue值或<font color="green">富集到此通路上的基因个数来衡量KEGG的富集程度</font>，找到富集最显著的通路</li>
<li>找自己感兴趣的：高原反应-&gt;呼吸功能相关通路，免疫系统-&gt;炎症因子、TNF相关通路</li>
<li>从通路中去找到<font color="green">表达倍数显著的基因进行验证</font>，进一步解释相关分子表达机制</li>
</ul>
<p><strong>目标表示</strong></p>
<p>HOTAIR出没于胞核（CC），参与了组蛋白甲基化调控引发癌基因沉默（BP），具体是结合PRC2复合物以及LSD1（MF）</p>
<hr>
<p><strong>转录组数据中筛选关键基因</strong></p>
<p>筛选关键基因的方法有3类：</p>
<p>1.表达量﹢功能富集</p>
<p>2.表达量﹢实验</p>
<p>3.表达量﹢序列</p>
<p>上面的三种方法不难看出，筛选关键基因的<font color="green">核心</font>是<font color="green">表达量</font>，其实转录组的核心就是以表达量为核心展开其他分析的，然后再附加其他一些信息，找出目标基因；最后将分析结果与研究目的巧妙融合，如果再做一些基因功能实验验证（高分必备，可不做），一篇高质量的文章就ok了。</p>
<p><strong>1.表达量﹢功能富集</strong></p>
<p>Zhu T, Wang X, Xu Z, Xu J, Li R, et al. (2020) Screening of key genes responsible for Pennisetum setaceum ‘Rubrum’ leaf color using tranome sequencing. PLOS ONE 15(11): e0242618.</p>
<p>该文研究对象狼尾草观赏草植物，<font color="green">高光</font>环产紫色叶子，<font color="green">低光</font>产浅紫色或绿色叶子。该文鉴定与<font color="green">叶片着色相关的关键基因</font>，并阐明参与狼尾草叶子的颜色变化的分子机制。</p>
<p>差异表达基因分析总共鉴定了19043个DEGs，与T0（未处理阶段的叶子）阶段的表达相比，在T1（遮阴12天后新叶子完全变绿的阶段）阶段上调和下调的基因分别为10761和8642。<font color="green">KEGG富集分析发现，显著富集的通路主要有类黄酮的生物合成，黄酮和黄酮醇的生物合成以及类胡萝卜素的生物合成</font>。<font color="red">基因筛选(显著KEGG内的基因筛选？)</font>发现存在与<strong>叶绿素代谢</strong>有关的31个差异表达基因，其中21个与叶绿素的生物<strong>合成</strong>有关，有10个与叶绿素的<strong>降解</strong>有关，以及3个与叶绿素<strong>降解调控</strong>有关的转录因子，<strong>花青素的合成和积</strong>累有31个关键酶基因，4个可能参与<strong>花色苷代谢调控</strong>的转录因子（图1所示） 。</p>
<p><img src="/blog/2021/12/20/2021_12_20_GO_KEGG_post/selectDEG.png" alt="selectDEG"></p>
<p>快速筛选出感兴趣的基因：基因长度、基因在样品中的表达量、<strong>差异倍数</strong>、<strong>注释信息</strong>等。</p>
<p><font color="green">找显著通路里的基因。做一个信息表。</font></p>
<p><strong>2.表达量﹢实验</strong></p>
<p>Wang A, Chao T, Ji Z, Xuan R, Liu S, Guo M, Wang G, Wang J. 2020. Tranome analysis reveals potential immune function-related regulatory genes/pathways of female Lubo goat submandibular glands at different developmental stages. PeerJ 8:e9947.</p>
<p>课题组前期的基因功能实验或文献查阅来借助别人的已经验证过的基因功能结果，之后再根据表达量筛选关键基因。</p>
<p>转录组研究的目的就是寻找与实验设计相关的关键基因，一般来说研究某生理现象都先要阅读大量文献来判断该实验的可行性。如转录组分析揭示了雌性鲁波<strong>山羊下颌腺</strong>在<strong>不同发育阶段</strong>的潜在<strong>免疫功能相关调节基因</strong>或途径</p>
<p>该文研究的目的是通过<strong>转录组测序</strong>来<strong>定位</strong>差异表达基因（DEG）在<strong>三个不同阶段的表达谱</strong>，预测在<strong>不同发育阶段</strong>的<strong>下颌下腺的免疫功能</strong>。由于<strong>人、小鼠、大鼠、牛</strong>的下颌腺都检测到了<strong>相关抗体</strong>，并且研究发现了下颌腺中的<strong>类红细胞分化因子、内皮素、肝细胞生长因子（HGF）、转移性生长因子（MGF）、转化生长因子-α（TGF-α）和其他因子</strong>。所以在<strong>后续的基因筛选中会重点关注相关因子的表达基因</strong>。</p>
<p>从上面例子中可以发现一个<strong>套路</strong>，先查阅模式生物中该方面的研究结果，然后再结合自己的研究项目筛选出基因，并且<strong>重点关注模式生物中已知的功能基因有没有较大的差异倍数</strong>。</p>
<hr>
<p>ref：</p>
<p><a href="https://zhuanlan.zhihu.com/p/78093534">https://zhuanlan.zhihu.com/p/78093534</a></p>
<p><a href="https://www.sohu.com/a/437865907_278730">https://www.sohu.com/a/437865907_278730</a></p>
<hr>
<h1 id="转录组图形专题之差异基因相关图形"><a href="#转录组图形专题之差异基因相关图形" class="headerlink" title="转录组图形专题之差异基因相关图形"></a>转录组图形专题之差异基因相关图形</h1><p>雷达图、热图、柱状图、韦恩图、火山图</p>
<p><a href="https://www.sohu.com/a/428207189_278730">https://www.sohu.com/a/428207189_278730</a></p>
<h1 id="全套的富集分析相关图形详解"><a href="#全套的富集分析相关图形详解" class="headerlink" title="全套的富集分析相关图形详解"></a>全套的富集分析相关图形详解</h1><p>柱形图，气泡图，圈图，z-score图，网络图</p>
<p><a href="https://www.sohu.com/a/436470973_278730">https://www.sohu.com/a/436470973_278730</a></p>
]]></content>
      <categories>
        <category>GO</category>
        <category>KEGG</category>
      </categories>
      <tags>
        <tag>O_Sativa</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux command awk</title>
    <url>/blog/2021/12/17/2021_12_17_Linux_awk_command/</url>
    <content><![CDATA[<h2 id="Linux-command-【awk】"><a href="#Linux-command-【awk】" class="headerlink" title="Linux command 【awk】"></a>Linux command 【awk】</h2><span id="more"></span>

<h1 id="Linux-awk-命令"><a href="#Linux-awk-命令" class="headerlink" title="Linux awk 命令"></a>Linux awk 命令</h1><p><a href="https://www.runoob.com/linux/linux-command-manual.html"><img src="https://www.runoob.com/images/up.gif" alt="Linux 命令大全"> Linux 命令大全</a></p>
<p>AWK 是一种<font color="green">处理文本文件</font>的语言，是一个强大的文本分析工具。</p>
<p>之所以叫 AWK 是因为其取了三位创始人 Alfred <strong>A</strong>ho，Peter <strong>W</strong>einberger, 和 Brian <strong>K</strong>ernighan 的 Family Name 的首字符。</p>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk [选项参数] <span class="string">&#x27;script&#x27;</span> var=value file(s)</span><br><span class="line">或</span><br><span class="line">awk [选项参数] -f scriptfile var=value file(s)</span><br></pre></td></tr></table></figure>

<p><strong>选项参数说明：</strong></p>
<ul>
<li>-F fs or –field-separator fs<br>指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如<font color="green">-F:</font>。</li>
<li>-v var=value or –asign var=value<br>赋值一个用户定义变量。</li>
<li>-f scripfile or –file scriptfile<br>从脚本文件中读取awk命令。</li>
<li>-W posix<br>打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符<strong>和</strong>=不能代替^和^=；fflush无效?</li>
<li>-W version or –version<br>打印<font color="green">bug报告信息</font>的版本。</li>
</ul>
<hr>
<h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>log.txt文本内容如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">2 this is a <span class="built_in">test</span></span><br><span class="line">3 Are you like awk</span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">10 There are orange,apple,mongo</span></span><br></pre></td></tr></table></figure>

<p>用法一：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;[pattern] action&#125;&#x27;</span> &#123;filenames&#125;   <span class="comment"># 行匹配语句 awk &#x27;&#x27; 只能用单引号</span></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 每行按空格或TAB分割，输出文本中的1、4项</span></span><br><span class="line"> $ awk <span class="string">&#x27;&#123;print $1,$4&#125;&#x27;</span> log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 a</span><br><span class="line"> 3 like</span><br><span class="line"> This<span class="string">&#x27;s</span></span><br><span class="line"><span class="string"> 10 orange,apple,mongo</span></span><br><span class="line"><span class="string"> # 格式化输出</span></span><br><span class="line"><span class="string"> $ awk &#x27;</span>&#123;<span class="built_in">printf</span> <span class="string">&quot;%-8s %-10s\n&quot;</span>,<span class="variable">$1</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string"> ---------------------------------------------</span></span><br><span class="line"><span class="string"> 2        a</span></span><br><span class="line"><span class="string"> 3        like</span></span><br><span class="line"><span class="string"> This&#x27;</span>s</span><br><span class="line"> 10       orange,apple,mongo</span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<p><font color="green">用法二：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk -F  <span class="comment">#-F相当于内置变量FS, 指定分割字符</span></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用&quot;,&quot;分割</span></span><br><span class="line"> $  awk -F, <span class="string">&#x27;&#123;print $1,$2&#125;&#x27;</span>   log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 this is a <span class="built_in">test</span></span><br><span class="line"> 3 Are you like awk</span><br><span class="line"> This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string"> 10 There are orange apple</span></span><br><span class="line"><span class="string"> # 或者使用内建变量</span></span><br><span class="line"><span class="string"> $ awk &#x27;</span>BEGIN&#123;FS=<span class="string">&quot;,&quot;</span>&#125; &#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$2</span>&#125;<span class="string">&#x27;     log.txt</span></span><br><span class="line"><span class="string"> ---------------------------------------------</span></span><br><span class="line"><span class="string"> 2 this is a test</span></span><br><span class="line"><span class="string"> 3 Are you like awk</span></span><br><span class="line"><span class="string"> This&#x27;</span>s a <span class="built_in">test</span></span><br><span class="line"> 10 There are orange apple</span><br><span class="line"> <span class="comment">#! 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割</span></span><br><span class="line"> $ awk -F <span class="string">&#x27;[ ,]&#x27;</span>  <span class="string">&#x27;&#123;print $1,$2,$5&#125;&#x27;</span>   log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 this <span class="built_in">test</span></span><br><span class="line"> 3 Are awk</span><br><span class="line"> This<span class="string">&#x27;s a</span></span><br><span class="line"><span class="string"> 10 There apple</span></span><br></pre></td></tr></table></figure>

<p><font color="green">用法三：</font>-va -vb</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">awk -v  # 设置变量</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -va=1 <span class="string">&#x27;&#123;print $1,$1+a&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">2 3</span><br><span class="line">3 4</span><br><span class="line">This<span class="string">&#x27;s 1</span></span><br><span class="line"><span class="string">10 11</span></span><br><span class="line"><span class="string">$ awk -va=1 -vb=s &#x27;</span>&#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$1</span>+a,<span class="variable">$1b</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">2 3 2s</span></span><br><span class="line"><span class="string">3 4 3s</span></span><br><span class="line"><span class="string">This&#x27;</span>s 1 This<span class="string">&#x27;ss</span></span><br><span class="line"><span class="string">10 11 10s</span></span><br></pre></td></tr></table></figure>

<p>用法四：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk -f &#123;awk脚本&#125; &#123;文件名&#125;</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -f cal.awk log.txt</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><table>
<thead>
<tr>
<th align="left">运算符</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">= += -= *= /= %= ^= **=</td>
<td align="left">赋值</td>
</tr>
<tr>
<td align="left">?:</td>
<td align="left">C条件表达式</td>
</tr>
<tr>
<td align="left">||</td>
<td align="left">逻辑或</td>
</tr>
<tr>
<td align="left">&amp;&amp;</td>
<td align="left">逻辑与</td>
</tr>
<tr>
<td align="left">~ 和 !~</td>
<td align="left">匹配正则表达式和不匹配正则表达式</td>
</tr>
<tr>
<td align="left">&lt; &lt;= &gt; &gt;= != ==</td>
<td align="left">关系运算符</td>
</tr>
<tr>
<td align="left">空格</td>
<td align="left">连接</td>
</tr>
<tr>
<td align="left">+ -</td>
<td align="left">加，减</td>
</tr>
<tr>
<td align="left">* / %</td>
<td align="left">乘，除与求余</td>
</tr>
<tr>
<td align="left">+ - !</td>
<td align="left">一元加，减和逻辑非</td>
</tr>
<tr>
<td align="left">^ ***</td>
<td align="left">求幂</td>
</tr>
<tr>
<td align="left">++ –</td>
<td align="left">增加或减少，作为前缀或后缀</td>
</tr>
<tr>
<td align="left">$</td>
<td align="left">字段引用</td>
</tr>
<tr>
<td align="left">in</td>
<td align="left">数组成员</td>
</tr>
</tbody></table>
<p>过滤第一列大于2的行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1&gt;2&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">3 Are you like awk</span><br><span class="line">This&#x27;s a test</span><br><span class="line">10 There are orange,apple,mongo</span><br></pre></td></tr></table></figure>

<p>过滤第一列等于2的行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1==2 &#123;print $1,$3&#125;&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">2 is</span><br></pre></td></tr></table></figure>

<p><font color="green">过滤第一列大于2并且第二列等于’Are’的行</font></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1&gt;2 &amp;&amp; $2==&quot;Are&quot; &#123;print $1,$2,$3&#125;&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">3 Are you</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="内建变量"><a href="#内建变量" class="headerlink" title="内建变量"></a>内建变量</h2><table>
<thead>
<tr>
<th align="left">变量</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">$n</td>
<td align="left">当前记录的<font color="green">第n个字段</font>，字段间由FS分隔</td>
</tr>
<tr>
<td align="left"><font color="red">$0</font></td>
<td align="left"><font color="green">完整的输入记录</font></td>
</tr>
<tr>
<td align="left">ARGC</td>
<td align="left">命令行参数的数目</td>
</tr>
<tr>
<td align="left">ARGIND</td>
<td align="left">命令行中当前文件的位置(从0开始算)</td>
</tr>
<tr>
<td align="left">ARGV</td>
<td align="left">包含命令行参数的数组</td>
</tr>
<tr>
<td align="left">CONVFMT</td>
<td align="left">数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组</td>
</tr>
<tr>
<td align="left">ERRNO</td>
<td align="left">最后一个系统错误的描述</td>
</tr>
<tr>
<td align="left">FIELDWIDTHS</td>
<td align="left">字段宽度列表(用空格键分隔)</td>
</tr>
<tr>
<td align="left">FILENAME</td>
<td align="left">当前文件名</td>
</tr>
<tr>
<td align="left"><strong>FNR</strong></td>
<td align="left">各文件分别计数的行号</td>
</tr>
<tr>
<td align="left"><strong>FS</strong></td>
<td align="left">字段分隔符(默认是任何空格)</td>
</tr>
<tr>
<td align="left">IGNORECASE</td>
<td align="left">如果为真，则进行忽略大小写的匹配</td>
</tr>
<tr>
<td align="left"><strong>NF</strong></td>
<td align="left">一条记录的字段的数目</td>
</tr>
<tr>
<td align="left"><strong>NR</strong></td>
<td align="left">已经读出的记录数，就是行号，从1开始</td>
</tr>
<tr>
<td align="left">OFMT</td>
<td align="left">数字的输出格式(默认值是%.6g)</td>
</tr>
<tr>
<td align="left"><strong>OFS</strong></td>
<td align="left">输出字段分隔符，默认值与输入字段分隔符一致。</td>
</tr>
<tr>
<td align="left"><strong>ORS</strong></td>
<td align="left">输出记录分隔符(默认值是一个换行符)</td>
</tr>
<tr>
<td align="left">RLENGTH</td>
<td align="left">由match函数所匹配的字符串的长度</td>
</tr>
<tr>
<td align="left">RS</td>
<td align="left">记录分隔符(默认是一个换行符)</td>
</tr>
<tr>
<td align="left">RSTART</td>
<td align="left">由match函数所匹配的字符串的第一个位置</td>
</tr>
<tr>
<td align="left">SUBSEP</td>
<td align="left">数组下标分隔符(默认值是/034)</td>
</tr>
</tbody></table>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#看各变量值</span></span><br><span class="line">$ awk <span class="string">&#x27;BEGIN&#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,&quot;FILENAME&quot;,&quot;ARGC&quot;,&quot;FNR&quot;,&quot;FS&quot;,&quot;NF&quot;,&quot;NR&quot;,&quot;OFS&quot;,&quot;ORS&quot;,&quot;RS&quot;;printf &quot;---------------------------------------------\n&quot;&#125; &#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;&#x27;</span>  log.txt</span><br><span class="line">FILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS</span><br><span class="line">---------------------------------------------</span><br><span class="line">log.txt    2    1         5    1</span><br><span class="line">log.txt    2    2         5    2</span><br><span class="line">log.txt    2    3         3    3</span><br><span class="line">log.txt    2    4         4    4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出顺序号 NR, 匹配文本行号</span></span><br><span class="line">$ awk <span class="string">&#x27;&#123;print NR,FNR,$1,$2,$3&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">1 1 2 this is</span><br><span class="line">2 2 3 Are you</span><br><span class="line">3 3 This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">4 4 10 There are</span></span><br><span class="line"><span class="string"># 指定输出分割符</span></span><br><span class="line"><span class="string">$  awk &#x27;</span>&#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$2</span>,<span class="variable">$5</span>&#125;<span class="string">&#x27; OFS=&quot; $ &quot;  log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">2 $ this $ test</span></span><br><span class="line"><span class="string">3 $ Are $ awk</span></span><br><span class="line"><span class="string">This&#x27;</span>s $ a $</span><br><span class="line">10 $ There $</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="使用正则，字符串匹配"><a href="#使用正则，字符串匹配" class="headerlink" title="使用正则，字符串匹配"></a><font color="green">使用正则，字符串匹配</font></h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出第二列包含 &quot;th&quot;，并打印第二列与第四列</span></span><br><span class="line">$ awk <span class="string">&#x27;$2 ~ /th/ &#123;print $2,$4&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">this a</span><br><span class="line"><span class="comment">#$0是b.txt每一行全部字段，-i &#123;&#125; a.txt 一行一行赋值给 &#123;&#125;</span></span><br><span class="line">cat a.txt | xargs -i awk <span class="string">&#x27;BEGIN&#123;FS=&quot;\t&quot;&#125; $0 ~/&#123;&#125;/ &#123; print &#125;&#x27;</span> b.txt &gt; c.txt</span><br></pre></td></tr></table></figure>

<p><strong>~ 表示模式开始。// 中是模式。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出包含 &quot;re&quot; 的行</span></span><br><span class="line">$ awk <span class="string">&#x27;/re/ &#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">3 Are you like awk</span><br><span class="line">10 There are orange,apple,mongo</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="忽略大小写"><a href="#忽略大小写" class="headerlink" title="忽略大小写"></a>忽略大小写</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk <span class="string">&#x27;BEGIN&#123;IGNORECASE=1&#125; /this/&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">2 this is a <span class="built_in">test</span></span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="模式取反"><a href="#模式取反" class="headerlink" title="模式取反"></a>模式取反</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">this is</span><br><span class="line">Are you</span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">There are</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">$ awk &#x27;</span><span class="variable">$2</span> !~ /th/ &#123;<span class="built_in">print</span> <span class="variable">$2</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">Are like</span></span><br><span class="line"><span class="string">a</span></span><br><span class="line"><span class="string">There orange,apple,mongo</span></span><br><span class="line"><span class="string">$ awk &#x27;</span>!/th/ &#123;<span class="built_in">print</span> <span class="variable">$2</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">Are like</span></span><br><span class="line"><span class="string">a</span></span><br><span class="line"><span class="string">There orange,apple,mongo</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="awk脚本"><a href="#awk脚本" class="headerlink" title="awk脚本"></a>awk脚本</h2><p>关于 awk 脚本，我们需要注意两个关键词 BEGIN 和 END。</p>
<ul>
<li>BEGIN{ 这里面放的是<font color="green">执行前</font>的语句 }</li>
<li>END {这里面放的是处理完<font color="green">所有的行后要执行</font>的语句 }</li>
<li>{这里面放的是处理<font color="green">每一行时</font>要执行的语句}</li>
</ul>
<p>假设有这么一个文件（学生成绩表）：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ cat score.txt</span><br><span class="line">Marry   2143 78 84 77</span><br><span class="line">Jack    2321 66 78 45</span><br><span class="line">Tom     2122 48 77 71</span><br><span class="line">Mike    2537 87 97 95</span><br><span class="line">Bob     2415 40 57 62</span><br></pre></td></tr></table></figure>

<p>我们的 awk 脚本如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ cat cal.awk</span><br><span class="line"><span class="comment">#!/bin/awk -f</span></span><br><span class="line"><span class="comment">#运行前</span></span><br><span class="line">BEGIN &#123;</span><br><span class="line">    math = 0</span><br><span class="line">    english = 0</span><br><span class="line">    computer = 0</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n&quot;</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;---------------------------------------------\n&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#运行中</span></span><br><span class="line">&#123;</span><br><span class="line">    math+=<span class="variable">$3</span></span><br><span class="line">    english+=<span class="variable">$4</span></span><br><span class="line">    computer+=<span class="variable">$5</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;%-6s %-6s %4d %8d %8d %8d\n&quot;</span>, <span class="variable">$1</span>, <span class="variable">$2</span>, <span class="variable">$3</span>,<span class="variable">$4</span>,<span class="variable">$5</span>, <span class="variable">$3</span>+<span class="variable">$4</span>+<span class="variable">$5</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#运行后</span></span><br><span class="line">END &#123;</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;---------------------------------------------\n&quot;</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;  TOTAL:%10d %8d %8d \n&quot;</span>, math, english, computer</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;AVERAGE:%10.2f %8.2f %8.2f\n&quot;</span>, math/NR, english/NR, computer/NR</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们来看一下执行结果：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -f cal.awk score.txt</span><br><span class="line">NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL</span><br><span class="line">---------------------------------------------</span><br><span class="line">Marry  2143     78       84       77      239</span><br><span class="line">Jack   2321     66       78       45      189</span><br><span class="line">Tom    2122     48       77       71      196</span><br><span class="line">Mike   2537     87       97       95      279</span><br><span class="line">Bob    2415     40       57       62      159</span><br><span class="line">---------------------------------------------</span><br><span class="line">  TOTAL:       319      393      350</span><br><span class="line">AVERAGE:     63.80    78.60    70.00</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="另外一些实例"><a href="#另外一些实例" class="headerlink" title="另外一些实例"></a>另外一些实例</h2><p>AWK 的 hello world 程序为：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">BEGIN &#123; <span class="built_in">print</span> <span class="string">&quot;Hello, world!&quot;</span> &#125;</span><br></pre></td></tr></table></figure>

<p>计算文件大小</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ ls -l *.txt | awk <span class="string">&#x27;&#123;sum+=$5&#125; END &#123;print sum&#125;&#x27;</span></span><br><span class="line">--------------------------------------------------</span><br><span class="line">666581</span><br></pre></td></tr></table></figure>

<p>从文件中找出<font color="green">长度大于 80 的行</font>：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;length&gt;80&#x27;</span> log.txt</span><br></pre></td></tr></table></figure>

<p>打印九九乘法表</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">seq 9 | sed <span class="string">&#x27;H;g&#x27;</span> | awk -v RS=<span class="string">&#x27;&#x27;</span> <span class="string">&#x27;&#123;for(i=1;i&lt;=NF;i++)printf(&quot;%dx%d=%d%s&quot;, i, NR, i*NR, i==NR?&quot;\n&quot;:&quot;\t&quot;)&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>更多内容：</p>
<ul>
<li><a href="https://www.runoob.com/w3cnote/awk-work-principle.html">AWK 工作原理</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-arrays.html">AWK 数组</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-if-loop.html">AWK 条件语句与循环</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-user-defined-functions.html">AWK 用户自定义函数</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-built-in-functions.html">AWK 内置函数</a></li>
<li><a href="https://www.runoob.com/w3cnote/8-awesome-awk-built-in-variables.html">8 个有力的 Awk 内建变量</a></li>
<li><a href="http://www.gnu.org/software/gawk/manual/gawk.html">AWK 官方手册</a></li>
</ul>
</blockquote>
<p><strong>awk、sed、grep更适合的方向：</strong></p>
<ul>
<li> grep 更适合单纯的查找或匹配文本</li>
<li> sed 更适合编辑匹配到的文本</li>
<li> awk 更适合格式化文本，对文本进行较复杂格式处理</li>
</ul>
<p>关于awk内建变量个人见解，简单易懂</p>
<p>解释一下变量：</p>
<p>变量：分为内置变量和自定义变量;输入分隔符FS和输出分隔符OFS都属于内置变量。</p>
<p>内置变量就是awk预定义好的、内置在awk内部的变量，而自定义变量就是用户定义的变量。</p>
<ul>
<li> FS(Field Separator)：输入字段分隔符， 默认为空白字符</li>
<li> OFS(Out of Field Separator)：输出字段分隔符， 默认为空白字符</li>
<li> RS(Record Separator)：输入记录分隔符(输入换行符)， 指定输入时的换行符</li>
<li> ORS(Output Record Separate)：输出记录分隔符（输出换行符），输出时用指定符号代替换行符</li>
<li> NF(Number for Field)：当前行的字段的个数(即当前行被分割成了几列)</li>
<li> NR(Number of Record)：行号，当前处理的文本行的行号。</li>
<li> FNR：各文件分别计数的行号</li>
<li> ARGC：命令行参数的个数</li>
<li> ARGV：数组，保存的是命令行所给定的各参数</li>
</ul>
<p><strong>自定义变量的方法</strong></p>
<ul>
<li> 方法一：-v varname=value ，变量名区分字符大小写。</li>
<li> 方法二：在program中直接定义。</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux command xargs</title>
    <url>/blog/2021/12/17/2021_12_17_Linux_xargs_command/</url>
    <content><![CDATA[<h2 id="Linux-command-【xargs】"><a href="#Linux-command-【xargs】" class="headerlink" title="Linux command 【xargs】"></a>Linux command 【xargs】</h2><span id="more"></span>

<h1 id="Linux-xargs-命令"><a href="#Linux-xargs-命令" class="headerlink" title="Linux xargs 命令"></a>Linux xargs 命令</h1><p><a href="https://www.runoob.com/linux/linux-command-manual.html"><img src="/blog/Linux.command/up.gif" alt="Linux 命令大全"> Linux 命令大全</a></p>
<p>xargs（英文全拼： eXtended ARGuments）是给<font color="green">命令传递参数</font>的一个过滤器，也是<font color="green">组合多个命令</font>的一个工具。</p>
<p>xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。</p>
<p>xargs 也可以将单行或多行文本输入转换为其他格式，例如<font color="green">多行变单行，单行变多行</font>。</p>
<p>xargs 默认命令是 echo，这意味着通过<font color="green">管道传递给 xargs 的输入包含换行和空白</font>，通过 xargs 的处理，<font color="green">换行和空白将被空格取代</font>。</p>
<p>xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。</p>
<p>之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令，例如：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /sbin -perm +700 |ls -l       <span class="comment">#这个命令是错误的</span></span><br><span class="line">find /sbin -perm +700 |xargs ls -l   <span class="comment">#这样才是正确的</span></span><br></pre></td></tr></table></figure>

<p>xargs 一般是和管道一起使用。</p>
<p><strong>命令格式：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">somecommand |xargs -item  <span class="built_in">command</span></span><br></pre></td></tr></table></figure>

<p><strong>参数：</strong></p>
<ul>
<li>-a file 从文件中读入作为 stdin</li>
<li>-e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。</li>
<li>-p 当每次执行一个argument的时候询问一次用户。</li>
<li>-n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。</li>
<li>-t 表示先打印命令，然后再执行。</li>
<li><font color="green">-i 或是-I</font>，这得看linux支持了，将xargs的每项名称，一般是<font color="green">一行一行赋值给 {}，可以用 {} 代替</font>。</li>
<li>-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。</li>
<li>-s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。</li>
<li><font color="green">-L num 从标准输入一次读取 num 行送给 command 命令</font>。</li>
<li>-l 同 -L。</li>
<li>-d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。</li>
<li>-x exit的意思，主要是配合-s使用。。</li>
<li>-P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。</li>
</ul>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>xargs 用作替换工具，读取输入数据重新格式化后输出。</p>
<p>定义一个测试文件，内有多行文本数据：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt</span></span><br><span class="line"></span><br><span class="line">a b c d e f g</span><br><span class="line">h i j k l m n</span><br><span class="line">o p q</span><br><span class="line">r s t</span><br><span class="line">u v w x y z</span><br></pre></td></tr></table></figure>

<p><font color="green">多行输入单行输出：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt | xargs</span></span><br><span class="line">a b c d e f g h i j k l m n o p q r s t u v w x y z</span><br></pre></td></tr></table></figure>

<p><font color="green">-n 选项多行输出：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt | xargs -n3</span></span><br><span class="line"></span><br><span class="line">a b c</span><br><span class="line">d e f</span><br><span class="line">g h i</span><br><span class="line">j k l</span><br><span class="line">m n o</span><br><span class="line">p q r</span><br><span class="line">s t u</span><br><span class="line">v w x</span><br><span class="line">y z</span><br></pre></td></tr></table></figure>

<p>-d 选项可以自定义一个定界符：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># echo &quot;nameXnameXnameXname&quot; | xargs -dX</span></span><br><span class="line"></span><br><span class="line">name name name name</span><br></pre></td></tr></table></figure>

<p>结合 -n 选项使用：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># echo &quot;nameXnameXnameXname&quot; | xargs -dX -n2</span></span><br><span class="line"></span><br><span class="line">name name</span><br><span class="line">name name</span><br></pre></td></tr></table></figure>

<p>读取 stdin，将格式化后的参数传递给命令</p>
<p>假设一个命令为 sk.sh 和一个保存参数的文件 arg.txt：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#sk.sh命令内容，打印出所有参数。</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> $*</span><br></pre></td></tr></table></figure>

<p>arg.txt文件内容：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat arg.txt</span></span><br><span class="line"></span><br><span class="line">aaa</span><br><span class="line">bbb</span><br><span class="line">ccc</span><br></pre></td></tr></table></figure>

<p>xargs 的一个选项 -I，使用 -I 指定一个替换字符串 {}，这个字符串在 xargs 扩展时会被替换掉，当 -I 与 xargs 结合使用，每一个参数命令都会被执行一次：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat arg.txt | xargs -I &#123;&#125; ./sk.sh -p &#123;&#125; -l</span></span><br><span class="line"></span><br><span class="line">-p aaa -l</span><br><span class="line">-p bbb -l</span><br><span class="line">-p ccc -l</span><br></pre></td></tr></table></figure>

<p>复制所有图片文件到 /data/images 目录下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ls *.jpg | xargs -n1 -I &#123;&#125; cp &#123;&#125; /data/images</span><br></pre></td></tr></table></figure>

<p>xargs 结合 find 使用</p>
<p>用 rm 删除太多的文件时候，可能得到一个错误信息：**/bin/rm Argument list too long.** 用 xargs 去避免这个问题：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.log&quot;</span> -print0 | xargs -0 rm -f</span><br></pre></td></tr></table></figure>

<p>xargs -0 将 \0 作为定界符。</p>
<p>统计一个源代码目录中所有 php 文件的行数：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.php&quot;</span> -print0 | xargs -0 wc -l</span><br></pre></td></tr></table></figure>

<p>查找所有的 jpg 文件，并且压缩它们：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.jpg&quot;</span> -<span class="built_in">print</span> | xargs tar -czvf images.tar.gz</span><br></pre></td></tr></table></figure>

<p>xargs 其他应用</p>
<p>假如有<font color="green">一个文件包含了很多希望下载的 URL</font>，你能够使用 xargs下载所有链接：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat url-list.txt | xargs wget -c</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Oryza Sativa 【Gene ID】【GO】【KEGG】</title>
    <url>/blog/2021/12/16/2021_12_16_osa_GO_KEGG/</url>
    <content><![CDATA[<h2 id="Oryza-Sativa-【Gene-ID】【GO】【KEGG】"><a href="#Oryza-Sativa-【Gene-ID】【GO】【KEGG】" class="headerlink" title="Oryza Sativa 【Gene ID】【GO】【KEGG】"></a>Oryza Sativa 【Gene ID】【GO】【KEGG】</h2><span id="more"></span>

<h1 id="O-sativa-ID-区分"><a href="#O-sativa-ID-区分" class="headerlink" title="O_sativa ID 区分"></a>O_sativa ID 区分</h1><ul>
<li><p>MSU, <font color="red">RGAP7.0</font>(rice genome annotation project)：<strong>LOC_Os01g01010.1</strong>,  LOC_Osp#g#####，<strong>LOC_Os-Chr-g-number</strong></p>
</li>
<li><p><font color="red">RAP</font>(the rice annotation project), IRGSP-1.0: <strong>Os06t0664200</strong>，<strong>Os-Chr-g-number</strong></p>
</li>
<li><p><font color="red">KEGG支持</font>：osa：RefSeq ID（Gene ID：<strong>4334374</strong>）；dosa：RAP-DB ID（<strong>Os06t0664200-01</strong>）</p>
</li>
<li><p>疑问：RAP-DB ID为什么和IRGSP-1.0 ID多了个-01：RAP-Locus与RAP ID不同</p>
</li>
<li><p>clusterProfiler可能是目前KEGG富集分析最好的软件，因为能<strong>爬取最新的KEGG在线版数据库</strong>，而不是用不再更新的KEGG.db。</p>
</li>
<li><p>对于RGAP水稻的基因编号，如LOC_Os01g01010.1 我们要把它变成<code>Os06t0664200-01</code> RAP-ID的命名方式，符合<code>dosa</code>的要求。</p>
</li>
</ul>
<h2 id="转化id"><a href="#转化id" class="headerlink" title="转化id"></a>转化id</h2><ul>
<li><p>下载一个各个ID对应的文件：<a href="https://shigen.nig.ac.jp/rice/oryzabase/download/riceId%E3%80%82%E5%AF%B9%E4%BA%8ERGAP%E6%B0%B4%E7%A8%BB%E7%9A%84%E5%9F%BA%E5%9B%A0%E7%BC%96%E5%8F%B7%EF%BC%8C%E5%A6%82LOC_Os01g01010.1">https://shigen.nig.ac.jp/rice/oryzabase/download/riceId。对于RGAP水稻的基因编号，如LOC_Os01g01010.1</a> 把它变成<code>Os06t0664200-01</code> RAP-ID的命名方式，符合<code>dosa</code>的要求。</p>
</li>
<li><p>日本晴数据库：<a href="https://shigen.nig.ac.jp/rice/oryzabase">https://shigen.nig.ac.jp/rice/oryzabase</a></p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ grep LOC_Os01g01010.1  rice_id_20140620174522.txt</span><br><span class="line">Os01g0100100    Os01t0100100-01 J075199P03      301700  J075199P03              LOC_Os01g01010.1        AK242339</span><br><span class="line">cat LOC.txt | xargs -i awk <span class="string">&#x27;BEGIN&#123;FS=&quot;\t&quot;&#125;  $0 ~/&#123;&#125;/ &#123; print $2&#125;&#x27;</span> rice_id_20140620174522.txt &gt; RAP_id.txt</span><br></pre></td></tr></table></figure>



<hr>
<h1 id="超几何分布"><a href="#超几何分布" class="headerlink" title="超几何分布"></a>超几何分布</h1><p>它描述了从有限N个物件（其中包含M个指定种类的物件）中抽出n个物件，成功抽出该指定种类的物件的次数（不放回）。称为超几何分布。</p>
<p><a href="https://baike.baidu.com/item/%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83/4782968">https://baike.baidu.com/item/超几何分布/4782968</a></p>
<hr>
<h1 id="GO-enrichment：web"><a href="#GO-enrichment：web" class="headerlink" title="GO enrichment：web"></a>GO enrichment：web</h1><blockquote>
<p>网站：<a href="http://systemsbiology.cau.edu.cn/agriGOv2">http://systemsbiology.cau.edu.cn/agriGOv2</a>  华大</p>
</blockquote>
<h1 id="GO-enrichment：R-clusterProfiler"><a href="#GO-enrichment：R-clusterProfiler" class="headerlink" title="GO enrichment：R clusterProfiler"></a>GO enrichment：R clusterProfiler</h1><p><strong>X</strong> clusterprofiler不能用来做GO的富集分析，因为其20个物种中不包括水稻；</p>
<h2 id="获取Orgdb，"><a href="#获取Orgdb，" class="headerlink" title="获取Orgdb，"></a>获取Orgdb，</h2><p>AnnotationHub在线检索并抓取OrgDb</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; require(AnnotationHub)</span><br><span class="line">&gt; hub &lt;- AnnotationHub()</span><br><span class="line">&gt; query(hub, <span class="string">&quot;oryza sativa&quot;</span>)</span><br><span class="line">title</span><br><span class="line">  AH10561 | hom.Oryza_sativa.inp8.sqlite</span><br><span class="line">  AH55775 | org.Oryza_sativa_Japonica_Group.eg.sqlite</span><br><span class="line">&gt; rice &lt;- hub[[<span class="string">&#x27;AH55775&#x27;</span>]]</span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; <span class="built_in">length</span>(keys(rice))[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#通过检索，org.Oryza_sativa_Japonica_Group.eg.sqlite就是我们所要的OrgDb，可以通过相应的accession number, AH55775 抓取文件，并存入了rice对象中，它包含了32639个基因的注释</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">#这个OrgDb，包含有以下一些注释信息:</span></span><br><span class="line">&gt; columns(rice)</span><br><span class="line"> [<span class="number">1</span>] <span class="string">&quot;ACCNUM&quot;</span>      <span class="string">&quot;ALIAS&quot;</span>       <span class="string">&quot;CHR&quot;</span>         <span class="string">&quot;ENTREZID&quot;</span>    <span class="string">&quot;EVIDENCE&quot;</span></span><br><span class="line"> [<span class="number">6</span>] <span class="string">&quot;EVIDENCEALL&quot;</span> <span class="string">&quot;GENENAME&quot;</span>    <span class="string">&quot;GID&quot;</span>         <span class="string">&quot;GO&quot;</span>          <span class="string">&quot;GOALL&quot;</span></span><br><span class="line">[<span class="number">11</span>] <span class="string">&quot;ONTOLOGY&quot;</span>    <span class="string">&quot;ONTOLOGYALL&quot;</span> <span class="string">&quot;PMID&quot;</span>        <span class="string">&quot;REFSEQ&quot;</span>      <span class="string">&quot;SYMBOL&quot;</span></span><br><span class="line">  [<span class="number">16</span>] <span class="string">&quot;UNIGENE&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##我们可以使用bitr来转换ID，甚至于直接检索GO注释：</span></span><br><span class="line">&gt; require(clusterProfiler)</span><br><span class="line">&gt; bitr(keys(rice)[<span class="number">1</span>], <span class="string">&#x27;ENTREZID&#x27;</span>, <span class="built_in">c</span>(<span class="string">&quot;REFSEQ&quot;</span>, <span class="string">&quot;GO&quot;</span>, <span class="string">&quot;ONTOLOGY&quot;</span>), rice)</span><br><span class="line"><span class="string">&#x27;select()&#x27;</span> returned <span class="number">1</span>:many mapping between keys and columns</span><br><span class="line">  ENTREZID      REFSEQ         GO ONTOLOGY</span><br><span class="line"><span class="number">1</span>  <span class="number">3131385</span> NP_039457.2 GO:<span class="number">0005739</span>       CC</span><br><span class="line"><span class="number">2</span>  <span class="number">3131385</span> NP_039457.2 GO:<span class="number">0005763</span>       CC</span><br><span class="line"><span class="comment">##GO富集分析</span></span><br><span class="line">&gt; sample_genes &lt;- keys(rice)[<span class="number">1</span>:<span class="number">100</span>]</span><br><span class="line">&gt; head(sample_genes)</span><br><span class="line">[<span class="number">1</span>] <span class="string">&quot;3131385&quot;</span> <span class="string">&quot;3131390&quot;</span> <span class="string">&quot;3131391&quot;</span> <span class="string">&quot;3131392&quot;</span> <span class="string">&quot;3131393&quot;</span> <span class="string">&quot;3131394&quot;</span></span><br><span class="line"><span class="comment">##这里只是简单地使用ID列表中前100个ENTREZ基因ID，也可以使用其它的ID，通过借助于bitr进行转换，或者通过给enrichGO指定ID类型(keyType参数）。</span></span><br><span class="line">&gt; 有了OrgDb，使用起来，就跟文档中使用人类基因做为例子一样，用法一致，并且也可以通过clusterProfiler所提供的各种可视化函数对结果进行展示：</span><br><span class="line"></span><br><span class="line">&gt; require(clusterProfiler)</span><br><span class="line">&gt; res = enrichGO(sample_genes, OrgDb=rice, pvalueCutoff=<span class="number">1</span>, qvalueCutoff=<span class="number">1</span>)</span><br><span class="line">&gt; res</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># over-representation test</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#...@organism    Oryza sativa_Japonica_Group</span></span><br><span class="line"><span class="comment">#...@ontology    MF</span></span><br><span class="line"><span class="comment">#...@keytype     ENTREZID</span></span><br><span class="line"><span class="comment">#...@gene        chr [1:100] &quot;3131385&quot; &quot;3131390&quot; &quot;3131391&quot; &quot;3131392&quot; &quot;3131393&quot; &quot;3131394&quot; ...</span></span><br><span class="line"><span class="comment">#...pvalues adjusted by &#x27;BH&#x27; with cutoff &lt;1</span></span><br><span class="line"><span class="comment">#...28 enriched terms found</span></span><br><span class="line"><span class="string">&#x27;data.frame&#x27;</span>:   <span class="number">28</span> obs. of  <span class="number">9</span> variables:</span><br><span class="line"> $ ID         : chr  <span class="string">&quot;GO:0003735&quot;</span> <span class="string">&quot;GO:0005198&quot;</span> <span class="string">&quot;GO:0003723&quot;</span> <span class="string">&quot;GO:0016830&quot;</span> ...</span><br><span class="line"> $ Description: chr  <span class="string">&quot;structural constituent of ribosome&quot;</span> <span class="string">&quot;structural molecule activity&quot;</span> <span class="string">&quot;RNA binding&quot;</span> <span class="string">&quot;carbon-carbon lyase activity&quot;</span> ...</span><br><span class="line"> $ GeneRatio  : chr  <span class="string">&quot;7/12&quot;</span> <span class="string">&quot;7/12&quot;</span> <span class="string">&quot;2/12&quot;</span> <span class="string">&quot;1/12&quot;</span> ...</span><br><span class="line"> $ BgRatio    : chr  <span class="string">&quot;22/478&quot;</span> <span class="string">&quot;22/478&quot;</span> <span class="string">&quot;14/478&quot;</span> <span class="string">&quot;10/478&quot;</span> ...</span><br><span class="line"> $ pvalue     : num  <span class="number">1.08e-07</span> <span class="number">1.08e-07</span> <span class="number">4.45e-02</span> <span class="number">2.26e-01</span> <span class="number">3.24e-01</span> ...</span><br><span class="line"> $ p.adjust   : num  <span class="number">1.52e-06</span> <span class="number">1.52e-06</span> <span class="number">4.15e-01</span> <span class="number">1.00</span> <span class="number">1.00</span> ...</span><br><span class="line"> $ qvalue     : num  <span class="number">1.42e-06</span> <span class="number">1.42e-06</span> <span class="number">3.90e-01</span> <span class="number">9.40e-01</span> <span class="number">9.40e-01</span> ...</span><br><span class="line"> $ geneID     : chr  <span class="string">&quot;3131425/3131435/3131436/3131439/3131441/3131442/3131457&quot;</span> <span class="string">&quot;3131425/3131435/3131436/3131439/3131441/3131442/3131457&quot;</span> <span class="string">&quot;3131425/3131457&quot;</span> <span class="string">&quot;3131463&quot;</span> ...</span><br><span class="line"> $ Count      : int  <span class="number">7</span> <span class="number">7</span> <span class="number">2</span> <span class="number">1</span> <span class="number">3</span> <span class="number">1</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">1</span> ...</span><br></pre></td></tr></table></figure>



<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line">sly &lt;- ah[[<span class="string">&quot;AH61992&quot;</span>]]</span><br><span class="line">sly</span><br><span class="line">saveDb(sly,file=<span class="string">&quot;sly.orgdb&quot;</span>)</span><br><span class="line">laodDb(file=<span class="string">&quot;sly.orgdb&quot;</span>)</span><br></pre></td></tr></table></figure>



<p>plant_GSEA: MSU-&gt;Uniprot</p>
<p>david:Uniprot-&gt;Entrez_id</p>
<hr>
<h1 id="KEGG-enrichment：R-clusterProfiler"><a href="#KEGG-enrichment：R-clusterProfiler" class="headerlink" title="KEGG enrichment：R clusterProfiler"></a>KEGG enrichment：R clusterProfiler</h1><ol>
<li><p>enrichKEGG</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">enrichKEGG(gene, organism = <span class="string">&quot;hsa&quot;</span>, keyType = <span class="string">&quot;kegg&quot;</span>, pvalueCutoff = <span class="number">0.05</span>,</span><br><span class="line">  pAdjustMethod = <span class="string">&quot;BH&quot;</span>, universe, minGSSize = <span class="number">10</span>, maxGSSize = <span class="number">500</span>,</span><br><span class="line">  qvalueCutoff = <span class="number">0.2</span>, use_internal_data = <span class="literal">FALSE</span>)</span><br><span class="line"><span class="comment">#gene： 基因名，要和keyType对应</span></span><br><span class="line"><span class="comment">#organism: 需要参考 http://www.genome.jp/kegg/catalog/org_list.html</span></span><br><span class="line"><span class="comment">#keyType: 基因的命名方式， “kegg”, ‘ncbi-geneid’, ‘ncib-proteinid’ and ‘uniprot’选择其一</span></span><br><span class="line"><span class="comment">#enrichKEGG的一个关键在于理解它是如何获取数据的。在线爬取数据库，相当于在KEGG上手动输入基因名查询。</span></span><br><span class="line"><span class="comment">#所以，把enrichKEGG当做浏览器，试出合适的keytypes。</span></span><br></pre></td></tr></table></figure></li>
<li></li>
</ol>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library(clusterProfiler)</span><br><span class="line"><span class="comment"># 对于GID</span></span><br><span class="line">kk &lt;- enrichkegg(gid_list,organism=<span class="string">&#x27;osa&#x27;</span>,keyType = <span class="string">&#x27;kegg&#x27;</span>,pvalueCutoff=<span class="number">0.05</span>, pAdjustMethod=<span class="string">&#x27;BH&#x27;</span>,qvalueCutoff=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于RAP_ID</span></span><br><span class="line">kk &lt;- enrichkegg(rap_list,organism=<span class="string">&#x27;dosa&#x27;</span>,keyType = <span class="string">&#x27;kegg&#x27;</span>,pvalueCutoff=<span class="number">0.05</span>, pAdjustMethod=<span class="string">&#x27;BH&#x27;</span>,qvalueCutoff=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">write.table(ekk,<span class="string">&quot;kegg.txt&quot;</span>,sep = <span class="string">&quot;\t&quot;</span>,<span class="built_in">quote</span> = <span class="built_in">F</span>,row.names = <span class="built_in">F</span>)</span><br><span class="line">barplot(ekk,showCategory = <span class="number">15</span>,title = <span class="string">&quot;EnrichmentKEGG&quot;</span>)</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>若差异基因集（如500个）本身确实没有生物学功能偏好性，非常有可能无显著富集的kegg通路。</li>
</ol>
<p>修改代码，比如：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">kk.down &lt;- enrichKEGG(gene = gene_down,</span><br><span class="line">                        organism = <span class="string">&#x27;hsa&#x27;</span>, </span><br><span class="line">                        pvalueCutoff = <span class="number">0.9</span>,</span><br><span class="line">                        qvalueCutoff =<span class="number">0.9</span>)</span><br><span class="line"><span class="comment"># 需要自己差异分析筛选得到 gene_down 基因集 ，然后进行超几何分布检验</span></span><br><span class="line"><span class="comment">#再调整阈值</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li><p>或可去MSigDB（Molecular Signatures Database<a href="https://www.gsea-msigdb.org/gsea/msigdb%EF%BC%89%E7%9C%8B%E5%85%B6%E5%AE%83%E5%8A%9F%E8%83%BD%E5%9F%BA%E5%9B%A0%E9%9B%86%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E5%AF%8C%E9%9B%86%EF%BC%8CMSigDB%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B7%B2%E7%9F%A5%E7%9A%84%E5%9F%BA%E5%9B%A0%E9%9B%86%E5%90%88%EF%BC%9A%E5%8C%85%E6%8B%ACH%E5%92%8CC1-C7%E5%85%AB%E4%B8%AA%E7%B3%BB%E5%88%97%EF%BC%88Collection%EF%BC%89%EF%BC%8C%E6%A4%8D%E7%89%A9%E9%80%82%E7%94%A8%EF%BC%9F">https://www.gsea-msigdb.org/gsea/msigdb）看其它功能基因集是否可以富集，MSigDB数据库中定义了已知的基因集合：包括H和C1-C7八个系列（Collection），植物适用？</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/150744437">GSEA分析</a>，不依赖于差异分析本身,植物适用？</p>
</li>
</ol>
<hr>
<h1 id="KEGG数据库不会下载？了解下API！"><a href="#KEGG数据库不会下载？了解下API！" class="headerlink" title="KEGG数据库不会下载？了解下API！"></a>KEGG数据库不会下载？了解下API！</h1><ol>
<li><p>KEGG数据库并不提供免费、批量蛋白序列下载，其官方提供在线分析工具BlastKOALA（<a href="https://link.zhihu.com/?target=https://www.kegg.jp/blastkoala/">https://www.kegg.jp/blastkoala/</a>）等可用于KEGG数据库的注释分析。此外还有其他一些在线分析工具例如很常用的KAAS（<a href="https://link.zhihu.com/?target=https://www.genome.jp/tools/kaas/">https://www.genome.jp/tools/kaas/</a>）等。在线工具内部参数未知。</p>
</li>
<li><p>KEGG API（<a href="https://www.kegg.jp/kegg/rest/keggapi.html%EF%BC%89%E6%98%AF%E5%92%8CKEGG%E5%86%85%E6%A0%B8%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92%E7%9A%84%E7%A8%8B%E5%BA%8F%E7%95%8C%E9%9D%A2%EF%BC%8C%E5%85%81%E8%AE%B8%E7%94%A8%E6%88%B7%E5%9F%BA%E4%BA%8E%E8%AF%A5%E7%95%8C%E9%9D%A2%E6%A3%80%E7%B4%A2KEGG%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C[%E4%B8%8B%E8%BD%BD](https://zhuanlan.zhihu.com/p/76195765)">https://www.kegg.jp/kegg/rest/keggapi.html）是和KEGG内核数据库进行交互的程序界面，允许用户基于该界面检索KEGG数据库，[下载](https://zhuanlan.zhihu.com/p/76195765)</a></p>
<p>(1)<a href="https://mp.weixin.qq.com/s/YlJbkIg9It9On5HWRPPgmQ">https://mp.weixin.qq.com/s/YlJbkIg9It9On5HWRPPgmQ</a></p>
<p>(2)<a href="https://mp.weixin.qq.com/s/F3dRgHBI4a2atvz0O_pukA">https://mp.weixin.qq.com/s/F3dRgHBI4a2atvz0O_pukA</a></p>
<p>(3)<a href="https://mp.weixin.qq.com/s/oDDIlWXsLyTCh18bEEysmQ">https://mp.weixin.qq.com/s/oDDIlWXsLyTCh18bEEysmQ</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>GO</category>
        <category>KEGG</category>
      </categories>
      <tags>
        <tag>O_Sativa</tag>
      </tags>
  </entry>
  <entry>
    <title>KMeans</title>
    <url>/blog/2021/11/15/2021-11-15-kmeans/</url>
    <content><![CDATA[<p>监督学习</p>
<p>无监督学习：数据无标注甚至非结构化。KMeans…</p>
<span id="more"></span>



<h1 id="KMeans"><a href="#KMeans" class="headerlink" title="KMeans"></a>KMeans</h1><h2 id="简介-聚类与KMeans"><a href="#简介-聚类与KMeans" class="headerlink" title="简介-聚类与KMeans"></a>简介-聚类与KMeans</h2><blockquote>
<ul>
<li><strong>聚类（Clustering）</strong>：将数据对象分为多个类或者簇 (Cluster)，使同一簇对象间较高相似度，不同簇对象差别较大。</li>
<li><strong>划分（Partitioning）</strong>：聚类可基于划分，也可基于分层。划分即将对象划分成不同簇，而分层将对象分等级。</li>
<li><strong>排他（Exclusive）</strong>：一个数据对象，只能被划分到一个簇。如果一个数据对象可被划分到多个簇，则称为可重叠（Overlapping）。</li>
<li><strong>距离（Distance）</strong>：基于距离的聚类将距离近的相似对象聚在一起。基于<font color="red">概率分布模型的聚类？</font>在一组对象中，找到符合特定分布模型的对象的集合，不一定是距离最近的或者最相似的，而是能完美的呈现出概率分布模型所描述的模型。</li>
<li>欧氏距离：欧几里得度量二维和三维空间中的欧氏距离就是两点之间的实际距离</li>
</ul>
</blockquote>
<ul>
<li><p>与分类、序列标注不同，聚类事先并不知道任何样本标签，通过数据之间内在关系把样本划分为若干类别，使得同类别样本之间的相似度高，不同类别相似度低（增大类内聚，减少类间距）。</p>
</li>
<li><p>聚类属于非监督学习，K均值聚类最基础常用。基本思想，<font color="green">通过迭代寻找K个簇（Cluster），使聚类结果对应的损失函数最小</font>。终止条件是没有（或最小数目）对象被重新分配给不同的聚类，没有（或最小数目）聚类中心再发生变化，误差平方和局部最小。<font color="red">损失函数定义为各个样本距离所属簇中心点的误差平方和</font>：</p>
</li>
</ul>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/1.png"></p>
<p>xi代表第i个样本，ci是xi所属的簇，uci代表簇对应中心点，M是样本总数。</p>
<ul>
<li><p>？损失函数本质是衡量模型的拟合效果，有求解参数需求的算法，才会有损失函数。Kmeans 不求解什么参数，它的模型本质也没有在拟合数据，而是在对数据进行一 种探索。在决策树中有衡量分类效果的指标准确度<code>accuracy</code>，准确度所对应的损失叫做泛化误差，但不能通过最小化泛化误差来求解某个模型中需要的信息，只是希望模型的效果上表现出来的泛化误差 很小。因此决策树，KNN 等算法，是绝对没有损失函数的。</p>
</li>
<li><table>
<thead>
<tr>
<th>距离度量对比</th>
<th>质心</th>
<th>Inertia</th>
</tr>
</thead>
<tbody><tr>
<td>欧几里得距离</td>
<td>均值</td>
<td>最小化每个样本点到质心的欧式距离之和</td>
</tr>
<tr>
<td>曼哈顿距离</td>
<td>中位数</td>
<td>最小化每个样本点到质心的曼哈顿距离之和</td>
</tr>
<tr>
<td>余弦距离</td>
<td>均值</td>
<td>最小化每个样本点到质心的余弦距离之和</td>
</tr>
</tbody></table>
</li>
<li><p>  上述问题是<font color="green">NP-Hard</font>问题。一般是采用坐标下降（Coordinate Decendet）方法求解。坐标下降法属于非梯度优化方法，每一步迭代中沿着一个坐标轴方向探索，通过循环使用不同的坐标达到求解目标函数的局部最小值。 </p>
</li>
</ul>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/4.png"></p>
<p>如上图，假设两维度x，y：</p>
<ol>
<li>首先选择初始位置(x,y)，假设x未知将y的值代入目标函数中，令目标函数导数0，求得此时最佳x值。</li>
<li>又假设y未知将刚求得x的值代入目标函数，令目标函数导数0，求得此时最佳y。</li>
<li>重复执行第1步第2步，目标函数逐渐接近极小值点，直到达到了极小值点停止。</li>
</ol>
<p>收敛的过程如红色箭头所示。更多维度时，同理，一次只对一个维度最优化。</p>
<p>坐标下降法一般要求目标函数是可微的凸函数(局部最小值即全局最小值?)，此时求得的极小值才能是全局最小值。</p>
<p>使用K-Means前，可先用PCA使各个变量间尽可能独立。否则如两变量间有较强关联性，函数收敛速度会非常慢。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>KMeans的核心目标是将给定的数据集划分成K个簇（K是超参），并给出每个样本数据对应的中心点。具体步骤非常简单，可以分为4步：</p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/2.png"></p>
<p><strong>KMeans最核心的部分就是先固定中心点，调整每个样本所属的类别来减少J；再固定每个样本的类别，调整中心点继续减小J 。两个过程交替循环， J 单调递减直到最（极）小值，中心点和样本划分的类别同时收敛。</strong></p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/3.png"></p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/5.png"></p>
<h1 id="优缺点优化策略"><a href="#优缺点优化策略" class="headerlink" title="优缺点优化策略"></a>优缺点优化策略</h1><p>KMenas优点：</p>
<ul>
<li>高效可伸缩，计算复杂度 为<font color="green">O(NKt)</font>接近于线性（N是数据量，K是聚类总数，t是迭代轮数）。</li>
<li><font color="green">收敛速度快</font>，原理通俗易懂，可解释性强。</li>
</ul>
<p>KMeans明显缺点：</p>
<ul>
<li>受<font color="green">初始值</font>和<font color="green">异常</font>影响，聚类结果可能不是全局最优而是<font color="green">局部最优</font>。</li>
<li><font color="green">K</font>是超参数，按<font color="green">经验选择</font></li>
<li><font color="green">样本点只能划分到单一的类中</font></li>
<li>只能发现球状的簇。</li>
<li>初始值对结果影响较大，可能每次聚类结果都不一样。</li>
</ul>
<p>根据以上特点，我们可以从下面几个角度对算法做调优</p>
<ol>
<li><strong>数据预处理：归一化和异常点过滤</strong></li>
</ol>
<p><strong>KMeans本质是基于欧式距离度量的数据划分方法，均值和方差大的维度将对数据聚类结果产生决定性影响。</strong>聚类前对数据（<strong>具体的说是每一个维度的特征</strong>）做<font color="green">归一化</font>和<font color="green">单位统一</font>至关重要。<font color="green">异常值</font>会对均值计算产生较大影响，导致<strong>中心偏移</strong>，<font color="green">噪声点最好能提前过滤</font>。</p>
<p><strong>2.合理选择K值</strong></p>
<p>K值的选择一般基于实验和多次实验结果。例如采用<strong>手肘法</strong>，尝试不同K值并将对应的损失函数画成折线。手肘法认为图上的<strong>拐点就是K的最佳值</strong>（上图对应K=3）。</p>
<p><strong>Gap Statistic方法</strong>。只需要找到最大的Gap Statistic对应的K(自动)。</p>
<p>沿用第一节中<font color="green">损失函数</font>记为 Dk，当分为K类时，Gap Statistic定义为： Gap(k)=E(logDk)-logDk 。 E(logDk)是logDk的期望，一般由<font color="green">蒙特卡洛模拟</font>产生。在<font color="green">样本所在的区域内按照均匀分布随机地产生和原始样本数一样多的随机样本</font>，对这个<font color="green">随机样本做KMeans</font>，得到一个<font color="green">Dk</font>，<font color="green">重复多次</font>计算出 E(logDk)的近似值。</p>
<p><strong>Gap(K) 的物理含义是<font color="green">随机样本的损失与实际样本的损失之差</font>。Gap越<font color="green">大</font>说明聚类的效果越好</strong>。随着K的变化Gap(K)几乎维持一条直线保持不变。说明这些样本间没有明显的类别关系，<font color="green">数据分布几乎和均匀分布一致</font>，近似随机。此时聚类没有意义。</p>
<p><strong>3.改进初始值的选择</strong></p>
<p>采取随机选择K个中心，<font color="green">可能导致不同中心点距离很近</font>，需<font color="green">更多的迭代次数才能收敛</font>。如在选择初始中心点时<strong>不同的中心尽可能远离</strong>，效果更好。这类算法中，以K-Means++算法最具影响力。</p>
<p><strong>4.采用核函数?</strong></p>
<p>主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的空间进行聚类。非线性映射增加了数据点线性可分的概率（与SVM中使用核函数思想类似）对于非凸的数据分布可以达到更为准确的聚类结果。</p>
<ol start="5">
<li>从EM算法解释KMeans</li>
</ol>
<p>EM（Expectation-Maximum）算法即期望最大化算法，是最常见的隐变量估计方法。EM算法是一种迭代优化策略，每一次迭代都分为两步：期望步（E）、极大步（M）。<strong>EM算法的提出最初是为了解决数据缺失情况下的参数估计问题</strong>，基本思想是首先根据已有的观测数据，通过极大似然估计估计出模型的参数；再根据上一步估计出的参数值估计缺失数据的值；最后根据估计出的缺失数据和原有的观测数据重新对参数值进行估计，反复迭代直到收敛。</p>
<hr>
<p>K均值聚类是使用<a href="https://baike.baidu.com/item/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95/10180861">最大期望算法</a>（Expectation-Maximization algorithm）求解的<a href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/8878468">高斯混合模型</a>（Gaussian Mixture Model, GMM）在<a href="https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/829892">正态分布</a>的协方差为单位矩阵，且隐变量的后验分布为一组<a href="https://baike.baidu.com/item/%E7%8B%84%E6%8B%89%E5%85%8B%CE%B4%E5%87%BD%E6%95%B0/5760582">狄拉克δ函数</a>时所得到的特例?</p>
<p>Python</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeansClusterer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,ndarray,cluster_num</span>):</span></span><br><span class="line">        self.ndarray = ndarray</span><br><span class="line">        self.cluster_num = cluster_num</span><br><span class="line">        self.points=self.__pick_start_point(ndarray,cluster_num)</span><br><span class="line">         </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cluster</span>(<span class="params">self</span>):</span></span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.cluster_num):</span><br><span class="line">            result.append([])</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> self.ndarray:</span><br><span class="line">            distance_min = sys.maxsize</span><br><span class="line">            index=-<span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.points)):                </span><br><span class="line">                distance = self.__distance(item,self.points[i])</span><br><span class="line">                <span class="keyword">if</span> distance &lt; distance_min:</span><br><span class="line">                    distance_min = distance</span><br><span class="line">                    index = i</span><br><span class="line">            result[index] = result[index] + [item.tolist()]</span><br><span class="line">        new_center=[]</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">            new_center.append(self.__center(item).tolist())</span><br><span class="line">        <span class="comment"># 中心点未改变，说明达到稳态，结束递归</span></span><br><span class="line">        <span class="keyword">if</span> (self.points==new_center).<span class="built_in">all</span>():</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">         </span><br><span class="line">        self.points=np.array(new_center)</span><br><span class="line">        <span class="keyword">return</span> self.cluster()</span><br><span class="line">             </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__center</span>(<span class="params">self,<span class="built_in">list</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;计算一组坐标的中心点</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 计算每一列的平均值</span></span><br><span class="line">        <span class="keyword">return</span> np.array(<span class="built_in">list</span>).mean(axis=<span class="number">0</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__distance</span>(<span class="params">self,p1,p2</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;计算两点间距</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        tmp=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(p1)):</span><br><span class="line">            tmp += <span class="built_in">pow</span>(p1[i]-p2[i],<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">pow</span>(tmp,<span class="number">0.5</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__pick_start_point</span>(<span class="params">self,ndarray,cluster_num</span>):</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> cluster_num &lt;<span class="number">0</span> <span class="keyword">or</span> cluster_num &gt; ndarray.shape[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;簇数设置有误&quot;</span>)</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># 随机点的下标</span></span><br><span class="line">        indexes=random.sample(np.arange(<span class="number">0</span>,ndarray.shape[<span class="number">0</span>],step=<span class="number">1</span>).tolist(),cluster_num)</span><br><span class="line">        points=[]</span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexes:</span><br><span class="line">            points.append(ndarray[index].tolist())</span><br><span class="line">        <span class="keyword">return</span> np.array(points)</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="KMeans-and-gaussian-mixture-model"><a href="#KMeans-and-gaussian-mixture-model" class="headerlink" title="KMeans and gaussian mixture model"></a>KMeans and gaussian mixture model</h2><p>数据表示：kmeans单个点对cluster建模（假设各clus数据是圆形或高位球形）。GMM，使用高斯分布表示</p>
<p>数据先验：kmeans，假设各clus先验概率一样，实际clus数据量可能不均匀。clusA10000，B100，新样本不考虑与AB相似度，属于A概率大。GMM对数据先验进行建模。</p>
<p>相似度衡量：Kmeans的欧式距离假设各个维度对相似度衡量作用一样。GMM相似度衡量使用后验概率通过引入协方差矩阵，对各个维度数据的不同重要性建模。</p>
<p>数据分配：kmeans各样本只属于相似度最高clus（hard clusting），GMM使用后验概率对各个clus按比例分配（fuzzy clustering？）。</p>
<hr>
<h2 id="k-means-聚类算法"><a href="#k-means-聚类算法" class="headerlink" title="k-means++聚类算法"></a>k-means++聚类算法</h2><p><code>KMeans</code>算法，<code>KMeans</code>在聚类之前首先需初始化k个簇中心，因此 <code>KMeans</code> 算法对初值敏感，对于不同的初始值，会导致不同聚类结果。若初始化随机，很有可能 k簇中心都在同一个簇，这种情况 <code>KMeans</code> 很大程度上都不会收敛到全局最小。</p>
<p>为优化选择初始质心的方法，2007 年 Arthur,等 三人发表了论文“k-means++: <code>The advantages of careful seeding</code>，<code>sklearn.cluster.KMeans</code> 中默认参数为 <code>init=&#39;k-means++&#39;</code> ，其算法原理为在初始化簇中心时，逐个选取 k个簇中心，且离其他簇中心越远的样本越有可能被选为下个簇中心。</p>
<p>算法步骤：</p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/6.png"></p>
<hr>
<p>ref：</p>
<p><a href="https://zhuanlan.zhihu.com/p/184686598">https://zhuanlan.zhihu.com/p/184686598</a></p>
<p><a href="https://www.cnblogs.com/gaochundong/p/kmeans_clustering.html">https://www.cnblogs.com/gaochundong/p/kmeans_clustering.html</a></p>
<p><a href="https://www.zhihu.com/question/31296149">https://www.zhihu.com/question/31296149</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/342052190#:~:text=KMeans%20">https://zhuanlan.zhihu.com/p/342052190#:~:text=KMeans%20</a></p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-4【Macs2/3 Installation】</title>
    <url>/blog/2021/10/29/ATAC-seq-4-macs3-install/</url>
    <content><![CDATA[<h3 id="Macs2-3-installation-Debug-Record"><a href="#Macs2-3-installation-Debug-Record" class="headerlink" title="Macs2/3 installation Debug Record"></a>Macs2/3 installation Debug Record</h3><span id="more"></span>

<p>macs2 installation record<br>install conda<br>creat work environment<br>install numpy1.17<br>python setup.py install –prefix …./software/MACS</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR1#############################################</span><br><span class="line">#MACS3/fermi-lite/ksw.c:31:26: fatal error: lib/x86/sse2.h: No such file or directory</span><br><span class="line"># #include &quot;lib/x86/sse2.h&quot;                      ^</span><br><span class="line">#compilation terminated.</span><br><span class="line">#error: command &#x27;gcc&#x27; failed with exit status 1</span><br><span class="line">######################################################################################</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/macs3-project/MACS/issues/473">https://github.com/macs3-project/MACS/issues/473</a><br>zip downloaded from github zip is not complete in the deep dir<br>git clone <a href="https://github.com/macs3-project/MACS.git">https://github.com/macs3-project/MACS.git</a> –recursive<br>or download absent files</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR2#############################################</span><br><span class="line">Checking .pth file support in ..../software/MACS2/lib/python3.8/site-packages/</span><br><span class="line">..../.conda/envs/atacseq/bin/python -E -c pass</span><br><span class="line">TEST FAILED: ..../software/MACS2/lib/python3.8/site-packages/ does NOT support .pth files</span><br><span class="line">bad install directory or PYTHONPATH</span><br><span class="line"></span><br><span class="line">You are attempting to install a package to a directory that is not</span><br><span class="line">on PYTHONPATH and which Python does not read &quot;.pth&quot; files from.  The</span><br><span class="line">installation directory you specified (via --install-dir, --prefix, or</span><br><span class="line">the distutils default setting) was:</span><br><span class="line"></span><br><span class="line">    ..../software/MACS2/lib/python3.8/site-packages/</span><br><span class="line"></span><br><span class="line">and your PYTHONPATH environment variable currently contains:</span><br><span class="line"></span><br><span class="line">    &#x27;&#x27;</span><br><span class="line"></span><br><span class="line">Here are some of your options for correcting the problem:</span><br><span class="line"></span><br><span class="line">* You can choose a different installation directory, i.e., one that is</span><br><span class="line">  on PYTHONPATH or supports .pth files</span><br><span class="line"></span><br><span class="line">* You can add the installation directory to the PYTHONPATH environment</span><br><span class="line">  variable.  (It must then also be on PYTHONPATH whenever you run</span><br><span class="line">  Python and want to use the package(s) you are installing.)</span><br><span class="line"></span><br><span class="line">* You can set up the installation directory to support &quot;.pth&quot; files by</span><br><span class="line">  using one of the approaches described here:</span><br><span class="line"></span><br><span class="line">  https://setuptools.readthedocs.io/en/latest/deprecated/easy_install.html#custom-installation-locations</span><br></pre></td></tr></table></figure>

<p>[ok]export PYTHONPATH=${PYTHONPATH}:…./software/MACS2/lib/python3.9/site-packages/</p>
<p>directly set PYTHONPATH=…./software/MACS2/lib/python3.9/site-packages/ in ~/.bashrc was failed.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR3#############################################</span><br><span class="line">error: package directory &#x27;MACS2&#x27; does not exist</span><br><span class="line">#######################################################################################</span><br></pre></td></tr></table></figure>
<p>zip Dir was not complete, tried .tar.gz </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR4#############################################</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;..../software/MACS3/bin/macs3&quot;, line 4, in &lt;module&gt;</span><br><span class="line">    __import__(&#x27;pkg_resources&#x27;).run_script(&#x27;MACS3==3.0.0a6&#x27;, &#x27;macs3&#x27;)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3243, in &lt;module&gt;</span><br><span class="line">    def _initialize_master_working_set():</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3226, in _call_aside</span><br><span class="line">    f(*args, **kwargs)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3255, in _initialize_master_working_set</span><br><span class="line">    working_set = WorkingSet._build_master()</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 568, in _build_master</span><br><span class="line">    ws.require(__requires__)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 886, in require</span><br><span class="line">    needed = self.resolve(parse_requirements(requirements))</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 772, in resolve</span><br><span class="line">    raise DistributionNotFound(req, requirers)</span><br><span class="line">pkg_resources.DistributionNotFound: The &#x27;Cython&gt;=0.29&#x27; distribution was not found and is required by MACS3``</span><br></pre></td></tr></table></figure>

<p><code>conda install Cython=0.29</code></p>
<p><a href="https://pypi.org/project/cykhash/">https://pypi.org/project/cykhash/</a><br><code>pip install cykhash</code><br>Collecting cykhash<br>  Using cached cykhash-1.0.2-cp39-cp39-linux_x86_64.whl<br>Installing collected packages: cykhash<br>Successfully installed cykhash-1.0.2</p>
<p>python setup.py install –prefix …./software/MACS2</p>
<p>success</p>
]]></content>
      <categories>
        <category>Software</category>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-5【PeakCalling-MACS2】</title>
    <url>/blog/2021/10/29/ATAC-seq-5-macs2-info/</url>
    <content><![CDATA[<h2 id="MACS2-detail"><a href="#MACS2-detail" class="headerlink" title="MACS2 detail"></a>MACS2 detail</h2><span id="more"></span>


<h3 id="粗略介绍MACS基本原理。"><a href="#粗略介绍MACS基本原理。" class="headerlink" title="粗略介绍MACS基本原理。"></a>粗略介绍MACS基本原理。</h3><p>TF在基因组上的结合是随机过程，基因组的每个位置都有机会结合某个TF，只是概率不一样，peak出现的位置，是TF结合热点，而peak-calling就为了找这些热点。</p>
<p>如何定义热点？通俗讲，热点是这样一些位置，这些位置多次被测得的read所覆盖（我们测的是一个细胞群体，read出现次数多，说明该位置被TF结合的几率大）。read数达到多少才叫多？就要用到统计检验。假设TF在基因组上的分布没有任何规律，那么测序得到的read在基因组上的分布也必然是随机的，某个碱基上覆盖的read的数目应服从二项分布。和抽小球的过程类似。当n很大，p很小时，二项分布近似用泊松分布替代，在这里：<br><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/1.png"></p>
<p>拉姆达是泊松分布唯一参数，n是测序read总数目，l是单个read长度，s是基因组大小。有了分布，可以算出在某个置信概率（如0.00001）下，随机情况下，某个碱基上可以覆盖的read数目的最小值，当实际观察到的read数目超过这个值（单侧检验）时，认为该碱基是TF的一个结合热点。反过来，针对每一个read数目，我们也可以算出对应的置信概率P。</p>
<p>但这只是简化模型，实际情况复杂好多。由于测序、mapping过程内在<font color="red">偏好性</font>，以及不同染色质间的差异性，相比全基因组，某些碱基可能内在地会被更多的read所覆盖，这种情况得到的很多peak可能都是假的。MACS考虑到这点，<font color="red">当对某个碱基进行假设检验，MACS只考虑该碱基附近染色质区段（如10k），此时上述公式中n表示附近10k区间内的read数目，s被置为10k</font>。当有对照组（Control，相比实验组没有用抗体捕获TF或用了一个通用抗体）存在，利用Control组的数据构建泊松分布，<font color="red">没有Control时，利用实验组，稍大一点的局部区间（比如50k）</font>的数据构建泊松分布。</p>
<p>还有一个问题，read只是跟随着TF一起沉淀下来的DNA fragment的末端，read的位置并不是真实的TF结合位置。所以在peak-calling之前，延伸read是必须的。不同TF大小不一样，对read延伸的长度也理应不同.测得的<font color="red">read最终其实会近似地平均分配到正负链</font>，对于一个TF结合热点，read在附近正负链上会近似地形成<font color="red">“双峰”</font>。MACS会以<font color="red">某个window size扫描基因组，统计每个window里面read的富集程度，然后抽取（比如1000个）合适的（read富集程度适中，过少，无法建立模型，过大，可能反映的只是某种偏好性）window作样本，建立“双峰模型”</font>。最后，两个峰之间的距离就被认为是<font color="red">TF的长度D，每个read将延伸D/2</font>。见下图：</p>
<p><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/2.png"></p>
<p>当有对照组，MACS会进行两次peak calling。第一次以实验组（Treatment）为实验组，对照组为对照组，第二次颠倒，以实验组为对照组，对照组为实验组。之后，MACS对每一个P计算了相应的FDR（False Discovery Rate）值：</p>
<p><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/3.png"></p>
<p>表示第二次peak calling（颠倒的）得到的置信概率小于P的peak的个数。表示第一次peak calling得到的置信概率小于P的peak的个数。FDR综合利用了实验组和对照组的信息，显然，FDR越小越好。</p>
<h3 id="MACS-peak-calling-pipeline："><a href="#MACS-peak-calling-pipeline：" class="headerlink" title="MACS peak-calling pipeline："></a>MACS peak-calling pipeline：</h3><p>在某些情况下，如对组蛋白修饰的ChIP-seq数据peak-calling时，“双峰模型”会建立失败，<font color="red">因为组蛋白修饰往往并不是孤立存在的，可能很长一段染色质区间都被同一个组蛋白修饰占据，组蛋白修饰的peak并不典型。</font>这时，只要多加一个参数：</p>
<p><font color="red">–nomodel –shiftsize=number</font></p>
<p>–nomodel将<font color="red">略过“双峰模型”建立的过程</font>，而<font color="red">–shiftsize将人为指定reads延伸的长度</font>。<font color="red">一个核小体上大概缠绕着147bpDNA</font>，在对组蛋白修饰做peak-calling时可以指定：</p>
<p><font color="red">–nomodel –shiftsize=73</font></p>
<p>CTCF_peaks.bed详细列出了每一个peak的位置信息和可信度（最后一列：)，BED文件格式详见：<a href="http://genome.ucsc.edu/FAQ/FAQformat.html#format1">http://genome.ucsc.edu/FAQ/FAQformat.html#format1</a></p>
<p>其他常用参数：-bw number 建立“双峰模型”过程中window size的一半，默认300bp.<br><font color="red">-p Pvalue</font>设定peak置信概率的临界值（threshold），默认0.00001?(macs2 callpeak -h: pvalue not set, dont use p and q value at the same time)，对于H3k36me3、H3k27me3、H3k9me3等具有“非常规”特征的peak（broad peak）而言，此参数可以稍微设大一点，比如0.001。</p>
<p>-m number1,number2 建立“双峰模型”用到，设定挑选的window上reads的富集程度（<font color="red">fold enrichment</font>，相对全基因组而言），默认10,30。</p>
<p>-slocal=number -llocal=number 共同确定MACS动态计算时所考察的局部区间的长度。默认参数，-slocal=1000 -llocal=10000。除了建立“双峰模型”，在寻找peak过程中，MACS依然会以2倍于-bw的window扫描基因组，对于当前window而言（-slocal,-llocal取默认参数）：</p>
<p>-w/-B 建立wig或BED格式的raw signal（最高精确到每个碱基上reads的覆盖情况）文件，默认每条染色体建一个。</p>
<p>-S 只建立一个raw signal文件。</p>
<p>-space 与-w搭配使用，确定wig文件的分辨率，默认10bp。</p>
<hr>
<p>link：<a href="https://www.plob.org/article/7227.html">https://www.plob.org/article/7227.html</a></p>
]]></content>
      <categories>
        <category>Software</category>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>software</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-3【hbctraining_pipeline】</title>
    <url>/blog/2021/10/26/ATAC-seq-3-hbctraining/</url>
    <content><![CDATA[<h2 id="https-github-com-hbctraining-In-depth-NGS-Data-Analysis-Course-tree-master-sessionV-lessons"><a href="#https-github-com-hbctraining-In-depth-NGS-Data-Analysis-Course-tree-master-sessionV-lessons" class="headerlink" title="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons"></a><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a></h2><span id="more"></span>

<p>算法，参数，输出。</p>
<h2 id="Peak-calling"><a href="#Peak-calling" class="headerlink" title="Peak calling"></a>Peak calling</h2><p><img src="https://img-blog.csdnimg.cn/f2741798d4f04f708412c97b2e6ef045.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>ChIP-seq实验，从比对文件中观察到<code>正/负链</code>上以<code>结合位点为中心</code>的非对称reads<br>密度。<br>For ChIP-seq experiments, what we observe from the alignment files is a strand asymmetry with read densities on the +/- strand, centered around the binding site. <code>The 5’ ends of the selected fragments</code> will form <code>groups</code> on the positive- and negative-strand. The <code>distributions</code> of these groups are then assessed using <code>statistical measures</code> and <code>compared against background</code> (input or mock IP samples) to determine if the site of enrichment is likely to be a real binding site.</p>
<p><img src="https://img-blog.csdnimg.cn/a5f4429afb3348be91f68d90d4011065.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="加粗样式"><br><code>ChIP-seq analysis algorithms</code> are specialized in identifying one of <code>two types of enrichment</code> (or have specific methods for each): <code>broad peaks or broad domains</code> (i.e. <code>histone modifications that cover entire gene bodies</code>) or <code>narrow peaks</code> ( <code>transcription factor binding</code>). <code>Narrow peaks are easier to detect</code> as we are looking for regions that have higher amplitude and are easier to distinguish from the background, compared to broad or dispersed marks. There are also <code>‘mixed’ binding profiles</code> which can be hard for algorithms to discern. An example of this is the binding properties of <code>PolII</code>, which binds at promotor and across the length of the gene resulting in mixed signals (<code>narrow and broad</code>).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">NOTE：ChIP-seq的分析方法可以鉴定两种类型的富集模式：broad domains和narrow peaks。broad domains，如组蛋白修饰在整个基因body区域的分布；narrow peak，如转录因子的结合。narrow peak相对于broad 或者分散的marks更易被检测到。也有一些混合的结合图谱，如PolII包括narrow和broad信号。</span><br></pre></td></tr></table></figure>
<h2 id="MACS2"><a href="#MACS2" class="headerlink" title="MACS2"></a>MACS2</h2><p>MACS2是最常用的call peaks工具。 The MACS algorithm captures the influence of <code>genome complexity</code> to evaluate the significance of enriched ChIP regions。全称<code>Model-based Analysis of ChIP-Seq</code>，最初设计用来<code>鉴定转录因子结合位点</code>（also suited for <code>larger</code> regions），也可用于<code>其他类型</code>的富集方式测序。<br>MACS通过整合<code>序列标签位置信息</code>和<code>方向</code>信息提高<code>结合位点</code>的<code>空间分辨率</code>（ <code>improves</code> the <code>spatial resolution of binding sites</code> through <code>combining the information of both sequencing tag position and orientation</code>）。单独使用或加对照（ <code>increases specificity</code> of the peak calls）。<br><img src="https://img-blog.csdnimg.cn/3929b0f60a01477ea09402760205f200.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_17,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h3 id="1-Remove-redundancy"><a href="#1-Remove-redundancy" class="headerlink" title="1. Remove redundancy"></a>1. Remove redundancy</h3><p><code>Why worry about duplicates?</code> <code>Reads with the same start position</code> are <code>considered duplicates</code>. These duplicates can arise from experimental artifacts, but can also contribute to genuine ChIP-signal. (相同起点的reads被认为是duplicates，可能由于实验误差造成，<code>也可能是ChIP信号</code>)</p>
<ul>
<li><code>坏 duplicates</code>: If initial starting <code>material is low</code> this can lead to <code>overamplification</code> of this material before sequencing. Any <code>biases in PCR</code> will compound this problem and can lead to <code>artificially enriched regions</code>. Also <code>blacklisted (repeat) regions</code> with ultra high signal will also be high in duplicates. <code>Masking these regions</code> prior to analysis can help remove this problem。 实验材料量少，过度扩增，PCR偏差，人为富集区域。<code>blacklist（重复）区域？怎么获得</code>，屏蔽该区域。</li>
<li><code>好 duplicates</code>: You can expect some <code>biological duplicates with ChIP-seq</code> since you are only sequencing a small <code>part of the genome</code>. This number can increase if your depth of coverage is excessive or if your protein only binds to few sites. If there are a good proportion of biological dupicates, <code>removal</code> can lead to an <code>underestimation of the ChIP signal</code>. 有ChIP-seq意义的生物学意义duplicates ，测序基因组小部分。覆盖深度过多，蛋白质与少数位点结合，duplicates会增加。去除此类会导致对ChIP信号的低估。</li>
<li>Consider your <code>enrichment efficiency</code> and <code>sequencing depth</code>. Try to <code>discriminate</code> via genome browser of your non-deduplicated data. Bona fide peaks will have <code>multiple overlapping</code> reads with <code>offsets</code>, while samples with only PCR duplicates will stack up perfectly without offsets. A possible solution to distinguishing biological duplicate from PCR artifact would be to include UMIs into your experimental setup. 考虑<code>富集效率</code>和<code>测序深度</code>。通过<code>基因组浏览器区别</code>。<code>真正的峰</code>会有多个<code>重叠reads和偏移量</code>，<code>PCR重复没有偏移量</code>。如何区分：实验设计考虑<a href="https://www.sohu.com/a/471483238_120055884">UMIs</a>（<code>UMI将被用于合并PCR复制物</code>）。</li>
<li>Retain duplicates for differential binding analysis. 保留duplicates 用于差异结合分析 <code>why</code>？retain和keep区别？</li>
<li>If you are expecting binding in repetitive regions, use paired-end sequencing and keep duplicates. 研究重复区域，使用pariedend测序并<code>保持重复？</code></li>
<li>call peak之前就remove dup<h3 id="2-0-Shift-size-d"><a href="#2-0-Shift-size-d" class="headerlink" title="2.0 Shift size d"></a>2.0 <code>Shift size d</code></h3></li>
<li>真实结合位点周围的tag density应显示<code>双峰富集</code>(<code>成对峰</code>)。MACS利用这种双峰模式 <code>empirically model the shifting size</code>，精确定位结合位点。</li>
<li>为了找到<code>成对峰</code>来<code>构建模型</code>，MACS首先<code>扫描整个数据集</code>，寻找<code>高度显著富集区域</code>。只利用ChIP样本，给定超声大小sonication size(<code>bandwidth</code>)和high-confidence fold-enrichment(<code>mfold</code>)， MACS <code>slides two bandwidth windows</code> across the genome to find <code>regions with tags more than mfold enriched</code> relative to a <code>random tag genome distribution</code>.</li>
<li>MACS<code>随机抽取1000个高质量峰</code>，<code>分离正链和负链标签</code>，aligns them by the midpoint between their centers。The <code>distance between the modes of the two peaks in the alignment is defined as ‘d’</code> and represents the estimated fragment length. MACS shifts all the tags by d/2 toward the 3’ ends to the most likely protein-DNA interaction sites.<br><img src="https://img-blog.csdnimg.cn/eeefe600965542478444f761de31db17.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
</ul>
<h3 id="2-Select-1000-regions-with-a-10-to-30-fold-enrichment-relative-to-the-genome-background"><a href="#2-Select-1000-regions-with-a-10-to-30-fold-enrichment-relative-to-the-genome-background" class="headerlink" title="2. Select 1000 regions with a 10- to 30-fold enrichment relative to the genome background"></a>2. Select 1000 regions with a 10- to 30-fold enrichment relative to the genome background</h3><h3 id="3-Build-model-and-estimate-DNA-fragment-size-d"><a href="#3-Build-model-and-estimate-DNA-fragment-size-d" class="headerlink" title="3. Build model and estimate DNA fragment size d"></a>3. Build model and estimate DNA fragment size d</h3><h3 id="4-Shift-reads-toward-3’end-by-d"><a href="#4-Shift-reads-toward-3’end-by-d" class="headerlink" title="4. Shift reads toward 3’end by d"></a>4. Shift reads toward 3’end by d</h3><h3 id="5-Scale-two-libraries-if-have-control"><a href="#5-Scale-two-libraries-if-have-control" class="headerlink" title="5. Scale two libraries(if have control)"></a>5. Scale two libraries(if have control)</h3><p>For experiments in which <code>sequence depth differs</code> between input and treatment samples, MACS linearly scales the total control tag count to be the same as the total ChIP tag count. The default behaviour is for the <code>larger sample to be scaled down</code>. </p>
<h3 id="6-0-Effective-genome-length"><a href="#6-0-Effective-genome-length" class="headerlink" title="6.0 Effective genome length"></a>6.0 Effective genome length</h3><p>To calculate λBG from tag count, MAC2 requires the <code>effective genome size or the size of the genome that is mappable</code>. Mappability is related to the <code>uniqueness of the k-mers</code> at a particular position the genome. <code>Low-complexity</code> and <code>repetitive regions</code> have <code>low uniqueness</code>, which means <code>low mappability</code>. Therefore we need to provide the effective genome length to correct for the loss of true signals in low-mappable regions. 提供<code>有效基因组长度</code>，以<code>纠正低定位区域真实信号丢失</code>。<br><img src="https://img-blog.csdnimg.cn/5571c4b228cb4706805ba0853c546c3c.png" alt="在这里插入图片描述"><br><code>如何获得？</code>The MACS2 software has some <code>pre-computed values</code> for <code>commonly used</code> organisms (human, mouse, worm and fly，<code>rice？</code>). more accurate values? The <code>deepTools</code> docs has additional pre-computed values for more recent builds but also has some good materials on <code>how to go about computing</code> it.</p>
<h3 id="6-Call-candidate-peaks-relative-to-genome-background"><a href="#6-Call-candidate-peaks-relative-to-genome-background" class="headerlink" title="6. Call candidate peaks relative to genome background"></a>6. Call candidate peaks relative to genome background</h3><p>After MACS <code>shifts every tag by d/2</code>, it then <code>slides across the genome</code> using a window size of <code>2d</code> to <code>find candidate peaks</code>.  The <code>tag distribution</code> along the genome can be modeled by a <code>Poisson distribution</code>.  The Poisson is a one parameter model, where the parameter <code>λ is the expected number of reads in that window</code>.</p>
<h3 id="7-Calculate-dynamic-λ-for-candidate-peaks"><a href="#7-Calculate-dynamic-λ-for-candidate-peaks" class="headerlink" title="7. Calculate dynamic λ for candidate peaks"></a>7. Calculate dynamic λ for candidate peaks</h3><p><img src="https://img-blog.csdnimg.cn/eaac9c4b4c294be3b8b3b3caf7c35a21.png" alt="在这里插入图片描述"><br>泊松分布的参数λ是单位时间(或单位面积)内随机事件的平均发生次数。 泊松分布的期望和方差均为λ.<br>Instead of using a uniform λ estimated from the whole genome, MACS uses a <code>dynamic parameter, λlocal</code>, defined for <code>each candidate peak</code>. The lambda parameter is estimated from the control sample and is deduced by taking the maximum value across <code>various window sizes</code>:</p>
<blockquote>
<p>λlocal = max(λBG, λ1k, λ5k, λ10k).</p>
</blockquote>
<p>In this way lambda <code>captures the influence of local biases</code>, and is robust against occasional low tag counts at small local regions. Possible sources for these biases include local chromatin structure, DNA amplification and sequencing bias, and genome copy number variation. 通过使用动态lambda捕获局部偏差的影响，并且对小局部区域中<code>偶尔出现的low tag counts</code>表现较好。<code>偏差可能来源</code>包括局部染色质结构、DNA扩增和测序偏差以及基因组拷贝数变化。<br><img src="https://img-blog.csdnimg.cn/3c7c645b299e45b2b7975d6327d421bc.png" alt="在这里插入图片描述"><br>A region is considered to have a <code>significant tag enrichment</code> if the <code>p-value &lt; 10e-5</code> (可设置). This is a Poisson distribution p-value based on λ.</p>
<p>Overlapping enriched peaks are merged, and each tag position is <code>extended ‘d’ bases？</code> from its center. The location in the <code>peak with the highest fragment pileup堆积</code>, hereafter referred to as the summit峰顶, is <code>predicted as the precise binding location</code>. The <code>ratio between the ChIP-seq tag count and λlocal？</code> is reported as the fold enrichment.</p>
<h3 id="8-Calculate-P-value-and-filter-candidate-peaks"><a href="#8-Calculate-P-value-and-filter-candidate-peaks" class="headerlink" title="8. Calculate P value and filter candidate peaks"></a>8. Calculate P value and filter candidate peaks</h3><h3 id="9-Calculate-FDR-by-exchanging-treatment-and-control"><a href="#9-Calculate-FDR-by-exchanging-treatment-and-control" class="headerlink" title="9. Calculate FDR by exchanging treatment and control"></a>9. Calculate FDR by exchanging treatment and control</h3><p>Each peak is considered an independent test and thus, when we encounter thousands of significant peaks detected in a sample we have a multiple testing problem. In <code>MACSv1.4</code>, the FDR was determined <code>empirically by exchanging the ChIP and control samples</code>. However, in <code>MACS2</code>, p-values are now corrected for multiple comparison using the <code>Benjamini-Hochberg correction</code>.</p>
<h2 id="MACS2-参数"><a href="#MACS2-参数" class="headerlink" title="MACS2 参数"></a>MACS2 参数</h2><h3 id="1-Input-file-options"><a href="#1-Input-file-options" class="headerlink" title="1. Input file options"></a>1. Input file options</h3><ul>
<li><code>-t</code> : The IP data file (this is the only REQUIRED parameter for MACS) 实验组</li>
<li><code>-c</code> : Control or mock data 对照</li>
<li><code>-f</code> : 输入文件格式，默认值“AUTO” ，bam sam bed</li>
<li><code>-g</code> :  <code>mappable genome size</code> which is defined as the genome size which can be sequenced; some precompiled values provided.</li>
<li>hs: 2.7e9人类基因组有效大小(UCSC human hg18 assembly)<h3 id="2-Output-arguments"><a href="#2-Output-arguments" class="headerlink" title="2. Output arguments"></a>2. Output arguments</h3></li>
<li><code>-outdir</code> : 输出文件夹</li>
<li><code>-n</code> : 文件前缀</li>
<li><code>-B/--bdg</code> : store the fragment pileup, control lambda, -log10pvalue and -log10qvalue scores in bedGraph files 输出bedgraph格式的文件<h3 id="3-Shifting-model-arguments"><a href="#3-Shifting-model-arguments" class="headerlink" title="3. Shifting model arguments"></a>3. Shifting model arguments</h3></li>
<li><code>-s</code> : <code>size of sequencing tags</code>. Default, MACS will use the <code>first 10 sequences</code> from your input treatment file to determine it</li>
<li><code>--bw</code> : The bandwidth which is used to <code>scan the genome</code> ONLY for model building. Can be set to the expected sonication fragment size.</li>
<li><code>--mfold</code> : <code>upper and lower limit</code> for model building</li>
<li><code>--nomodel</code>：<code>和extsize、shift是配套使用</code>，有这个参数才可设置extsize和shift。</li>
<li><code>--extsize</code>：当设置了nomodel时，MACS会用–extsize这个参数从<code>5&#39;-&gt;3&#39;方向扩展reads修复fragments</code>。如转录因子结合范围200bp，设置这个参数是200。</li>
<li><code>--shift</code>：当设置了–nomodel，MACS用这个参数从<code>5&#39; 端移动剪切</code>，然后用–extsize延伸，如果–shift是负值表示从3’端方向移动。建议ChIP-seq数据集这个值保持默认值为0？，对于检测富集剪切位点如DNAseq数据集设置为EXTSIZE的一半。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">想找富集剪切位点，如DNAse-seq，所有5&#x27;端的序列reads应该从两个方向延伸，如果想设置移动的窗口是200bp，参数设置如下：</span><br><span class="line">--nomodel --shift -100 --extsize 200</span><br><span class="line">对nucleosome-seq数据，用核小体大小的一半进行extsize,所以参数设置如下：</span><br><span class="line">--nomodel --shift 37 --extsize 73</span><br></pre></td></tr></table></figure>

<p><code>ATAC-seq</code>关心的是在哪切断，断点才是peak的中心，所以使用shift模型，–shift -75或-100<br>对人细胞系ATAC-seq 数据call peak的参数设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak -t H1hesc.final.bam -n sample --shift -100 --extsize 200 --nomodel -B --SPMR -g hs --outdir Macs2_out 2&gt; sample.macs2.log</span><br></pre></td></tr></table></figure>

<h3 id="4-Peak-calling-arguments"><a href="#4-Peak-calling-arguments" class="headerlink" title="4. Peak calling arguments"></a>4. Peak calling arguments</h3><ul>
<li><code>-q</code> : q-value (minimum FDR) cutoff <code>q value默认值是0.05，与pvalue不能同时使用。</code></li>
<li><code>-p</code> : p-value cutoff (instead of q-value cutoff)</li>
<li><code>--nolambda</code> : do not consider the local bias/lambda at peak candidate regions。不要考虑在峰值候选区域的局部偏差/λ</li>
<li><code>--broad</code> : broad peak calling，narrow peak和broad peak</li>
</ul>
<p> Relaxing the <code>q-value</code> does not behave as expected in this case since it is partially tied to peak widths. Ideally, if you <code>relaxed the thresholds</code>, you would simply get <code>more peaks</code> but with MACS2 relaxing thresholds also results in <code>wider peaks</code>. q值与峰宽有一定的联系。理想情况下，如果放宽阈值，您将简单地获得更多的峰值，但是使用MACS2放松阈值也会导致更宽的峰值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak -t bowtie2/H1hesc_Nanog_Rep1_aln.bam \</span><br><span class="line">	-c bowtie2/H1hesc_Input_Rep1_aln.bam \</span><br><span class="line"> 	-f BAM -g 1.3e+8 \</span><br><span class="line">	-n Nanog-rep1 \</span><br><span class="line">	--outdir macs2 2&gt; macs2/Nanog-rep1-macs2.log</span><br></pre></td></tr></table></figure>


<h2 id="MACS2-Output-files"><a href="#MACS2-Output-files" class="headerlink" title="MACS2 Output files"></a>MACS2 Output files</h2><h3 id="narrowPeak"><a href="#narrowPeak" class="headerlink" title="narrowPeak"></a>narrowPeak</h3><p>A narrowPeak (<code>.narrowPeak</code>) file is used by the ENCODE project to provide <code>called peaks of signal enrichment</code> based on pooled, normalized (interpreted) data. It is a <code>BED 6+4 format</code>, which means the <code>first 6 columns of a standard BED file</code> with <code>4 additional</code> fields:<br><img src="https://img-blog.csdnimg.cn/7bd1ca4fcb3847daacc450a91989b5cd.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h3 id="WIG-format"><a href="#WIG-format" class="headerlink" title="WIG format"></a>WIG format</h3><p>Wiggle format (WIG) allows the <code>display</code> of continuous-valued data in a track format. Wiggle format is <code>line-oriented</code>. It is composed of declaration lines and data lines, and require a separate wiggle track definition line. There are two options for formatting wiggle data: variableStep and fixedStep. These formats were developed to allow the file to be written as compactly as possible.</p>
<h3 id="BedGraph-format"><a href="#BedGraph-format" class="headerlink" title="BedGraph format"></a>BedGraph format</h3><p>The BedGraph format also allows display of continuous-valued data in track format. This display type is useful for probability scores and transcriptome data. This track type is similar to the wiggle (WIG) format, but unlike the wiggle format, data exported in the bedGraph format are preserved in their original state. For the purposes of visualization, these can be interchangeable.</p>
<ul>
<li><p><code>_peaks.narrowPeak</code>: BED6+4 format file which contains the peak locations together with peak summit, pvalue and qvalue。<code>BED6+4格式，可以上传到UCSC浏览。</code></p>
<ul>
<li>1：染色体号</li>
<li>2：peak起始位点</li>
<li>3：结束位点</li>
<li>4：peak name</li>
<li>5：int(-10*log10qvalue)</li>
<li>6 ：正负链</li>
<li>7：fold change</li>
<li>8：-log10pvalue</li>
<li>9：-log10qvalue</li>
<li>10：relative summit position to peak start（？）</li>
</ul>
</li>
<li><p><code>_peaks.xls</code>: a tabular file which contains information about called peaks. Additional information includes pileup and fold enrichment。<code>含peak信息的tab分割的文件，前几行显示callpeak命令</code>。</p>
<ul>
<li>染色体号</li>
<li>peak起始位点</li>
<li>peak结束位点</li>
<li>peak区域长度</li>
<li>peak的峰值位点（summit position）</li>
<li>peak 峰值的高度（pileup height at peak summit, -log10(pvalue) for the peak summit）</li>
<li>peak的富集倍数（相对于random Poisson distribution with local lambda）</li>
<li>XLS里的坐标和bed格式的坐标还不一样，起始坐标需要减1才与narrowPeak的起始坐标一样。</li>
</ul>
</li>
<li><p><code>_summits.bed</code>: peak summits locations for every peak. To find the motifs at the binding sites, this file is recommended。BED格式的文件，包含peak的summits位置，第5列是-log10pvalue。如果想找motif，推荐使用此文件。</p>
</li>
<li><p><code>_model.R</code>: an R script which you can use to produce a PDF image about the model based on your data and cross-correlation plot</p>
</li>
<li><p><code>_control_lambda.bdg</code>: bedGraph format for input sample</p>
</li>
<li><p><code>_treat_pileup.bdg</code>: bedGraph format for treatment sample。bedGraph格式，可以导入UCSC或者转换为bigwig格式。两种bfg文件：treat_pileup, and control_lambda.</p>
</li>
<li><p><code>NAME_peaks.broadPeak</code>： BED6+3格式与narrowPeak类似，只是没有第10列。</p>
</li>
</ul>
<p>R作图the first plot illustrates the distance between the modes from which the shift size was determined？<br><img src="https://img-blog.csdnimg.cn/3d941b11b37c4b7687b11e6766a9daff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_13,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>The second plot is the cross-correlation plot. This is a graphical representation of the Pearson correlation of positive- and negative- strand tag densities, shifting the strands relative to each other by increasing distance？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xls文件</span><br><span class="line">文件包含信息还是比较多的，和narrowPeak唯一不同的是peak的起始位置需要减1才是bed格式的文件，另外还包含fold_enrichment 和narrowPeak的fold change 对应，-log10pvalue,-log10qvalue,peak长度，peak 峰值位置等。</span><br><span class="line">narrowPeak文件</span><br><span class="line">和xls文件信息类似</span><br><span class="line">summits.bed文件</span><br><span class="line">包含峰的位置信息和-log10pvalue</span><br><span class="line">bdg文件</span><br><span class="line">bdg文件适合导入UCSC或IGV进行谱图可视化，或者转换为bigwig格式再进行可视化。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
  <entry>
    <title>单倍型基因组组装算法hifiasm</title>
    <url>/blog/2021/10/20/hifiasm/</url>
    <content><![CDATA[<h2 id="Nat-Methods-等位基因组组装算法hifiasm（20210202）"><a href="#Nat-Methods-等位基因组组装算法hifiasm（20210202）" class="headerlink" title="Nat. Methods|等位基因组组装算法hifiasm（20210202）"></a>Nat. Methods|等位基因组组装算法hifiasm（20210202）</h2><p>paper：    <a href="https://pubmed.ncbi.nlm.nih.gov/33526886/">Haplotype-resolved de novo assembly using phased assembly graphs with hifiasm</a><br>该研究提出一种全新的单倍型基因组组装算法hifiasm，能够有效地对<font color="red">大型复杂基因组生成高质量的单倍型组装结果</font>。</p>
<span id="more"></span>

<h3 id="单倍型组装难点"><a href="#单倍型组装难点" class="headerlink" title="单倍型组装难点"></a>单倍型组装难点</h3><p>单倍型基因组组装是研究基因组结构与变异的最理想方式。由于技术的局限，大多数组装算法倾向于将不同单倍型有损的压缩成一条混合的代表性序列。对于自然界中主流的二倍体和多倍体样本而言，这类方法损失了大量的单倍型信息。这使得长久以来，研究人员难以对高杂合、高重复的基因组进行深入的分析。</p>
<p>为了解决这个难题，一些组装算法首先生成混合的代表性序列，接着从代表性序列中恢复出不同的单倍型信息。但是，由于代表性序列本身已经丢失了大量的信息，这类方法难以获得高质量的单倍型组装结果。</p>
<p>近期的组装算法通过额外的信息，如家系(Trio binning)或者Hi-C等数据，预先全局性的将待组装的测序读段划分到不同单倍型，再进行分别组装，从而试图获得高质量的单倍型组装结果。但是对于低杂合的样本而言，这种方法难以做到完美的预先划分，因此容易产生组装错误。</p>
<h3 id="Hifiasm-算法"><a href="#Hifiasm-算法" class="headerlink" title="Hifiasm 算法"></a>Hifiasm 算法</h3><p>在本研究中，研究人员提出了一种全新的针对PacBio HiFi (High-Fidelity reads) 数据的单倍型组装算法hifiasm。该算法有两项重要创新。</p>
<p>第一，提出了单倍型敏感的组装思路，使得在组装的全过程中能够无损的保留单倍型信息，同时也极大的提升了对基因组高重复和复杂区域的解析能力。</p>
<p>第二，提出了Graph-binning的分型策略，其利用组装图的结构信息对全局分型结果进行校正，从而极大地提高了单倍型组装的质量。Graph-binning不对待组装的测序读段进行预先全局划分，因此能够克服划分错误带来组装问题。</p>
<h3 id="组装结果"><a href="#组装结果" class="headerlink" title="组装结果"></a>组装结果</h3><p>研究人员在不同的数据集上测试了hifiasm算法。对于不同大小，不同杂合度和不同单倍型数量的动物和植物基因组，hifiasm能够产生质量最高的组装结果。尤其值得注意的是，hifiasm仅用三天时间，就完成27Gb超大加州红杉基因组的组装，并且组装结果的连续性7倍于其他算法。</p>
<p>对于人类基因组，hifiasm也能取得最好的效果。相比于现有算法，hifiasm所产生的组装结果连续性最高，同时也正确解析了最多的复杂和高重复区域，如MHC (主要组织相容性复合体)和centromere (着丝端粒)。尤其对于人类二倍体样本HG002和HG00733，hifiasm产生的组装结果的连续性3倍于其他算法，并成功保留了最多的变异信息。</p>
<p><a href="http://www.evolution.ynu.edu.cn/info/1016/1208.htm">http://www.evolution.ynu.edu.cn/info/1016/1208.htm</a></p>
]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>Assemble</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-2【Harvard FAS Informatics】</title>
    <url>/blog/2021/10/14/ATAC-seq-2-harvard/</url>
    <content><![CDATA[<h2 id="ATAC-seq数据质量评估注意"><a href="#ATAC-seq数据质量评估注意" class="headerlink" title="ATAC-seq数据质量评估注意"></a>ATAC-seq数据质量评估注意</h2><span id="more"></span>

<p><code>ENCODE</code>的ATACseq<a href="https://www.encodeproject.org/atac-seq/">数据标准</a>。</p>
<h3 id="Uniform-Processing-Pipeline-Restrictions"><a href="#Uniform-Processing-Pipeline-Restrictions" class="headerlink" title="Uniform Processing Pipeline Restrictions"></a>Uniform Processing Pipeline Restrictions</h3><ul>
<li>The <code>read length</code> prior to any trimming should be a minimum of <code>45 base pairs</code>.</li>
<li>Sequencing may be <code>paired</code>- or <code>single</code>-ended, <code>sequencing type</code> is specified and <code>paired sequences</code> are indicated.</li>
<li>All <code>Illumina platforms</code> are supported for use in the uniform pipeline, though <code>data from different platforms should be processed separately</code>; colorspace (<code>SOLiD</code>) reads are <code>not</code> supported. </li>
<li><code>Barcodes</code>, if present in the fastq, must be <code>indicated</code>.</li>
<li><code>Library insert size</code> range must be <code>indicated</code>. <h3 id="Current-Standards"><a href="#Current-Standards" class="headerlink" title="Current Standards"></a>Current Standards</h3></li>
</ul>
<ol>
<li>必须有两次或更多次<code>生物学重复</code>（稀有样本也必须做两次<code>技术重复</code>）</li>
<li>每次重复要有25million非冗余，非线粒体，能够回帖的fragment（单端25 million reads，<code>双端50 million reads</code>=25 million fragment）</li>
<li>回帖率&gt;95%, &gt;80%可接受。</li>
<li>用<code>IDR(Irreproducible Discovery Rate)</code>计算重复一致性，rescue和self consisty ratios 都&gt;2</li>
<li>用以下指标控制PCR扩增对文库复杂性的影响： <code>Non-Redundant Fraction (NRF)</code> and PCR Bottlenecking Coefficients 1 and 2, or PBC1 and PBC2：NRF&gt;0.9, PBC1&gt;0.9, PBC2&gt;3</li>
<li>peak文件必须满足如下要求：<blockquote>
<p>每个重复peak数&gt;150000，&gt;100000可接受（ENCODE的ATAC-seq的peak file没法用）<br>IDR peak&gt;70000,&gt;50000可接受<br>要存在无核小体区NFR<br>存在单核小体峰，好的ATACseq数据应包含核小体，既能看开放染色质，又能看核小体</p>
</blockquote>
</li>
<li>The fraction of reads in called peak regions(FRip score)&gt;0.3,&gt;0.2 可以接受。对于稀有样本不要求FRiP但TSS富集还是要作为关键的衡量信噪比的指标。</li>
<li>TSS富集分数阈值与参考基因组相关。</li>
</ol>
<h2 id="ATACseq-主干分析流程"><a href="#ATACseq-主干分析流程" class="headerlink" title="ATACseq 主干分析流程"></a>ATACseq 主干分析流程</h2><p>reference：<br><strong>1.文章</strong>：<a href="https://peerj.com/articles/4040/">https://peerj.com/articles/4040/</a><br><strong>2.CHIPseq课程</strong>：<a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a><br><strong>3.Harvard FAS Informatics - ATAC-seq Guidelines</strong>：<a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">https://informatics.fas.harvard.edu/atac-seq-guidelines.html</a></p>
<h2 id="Harvard-FAS-Informatics-ATAC-seq-Guidelines"><a href="#Harvard-FAS-Informatics-ATAC-seq-Guidelines" class="headerlink" title="Harvard FAS Informatics - ATAC-seq Guidelines"></a><a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">Harvard FAS Informatics - ATAC-seq Guidelines</a></h2><h3 id="Experimental-design"><a href="#Experimental-design" class="headerlink" title="Experimental design"></a>Experimental design</h3><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4374986/">Detailed protocol</a></p>
<ul>
<li>Replicates</li>
<li>Controls：一般<code>不设置对照</code>。作用有限，费用。没有转座酶处理的样本测序</li>
<li>PCR amplification：<code>尽可能少</code>地使用<code>PCR循环</code>来扩增样本，减少干扰</li>
<li>Sequencing depth：最佳测序深度取决于<code>参考基因组的大小</code>和<code>预期染色质的开放程度</code>。人类样本的研究推荐每个样本超过5000万个reads。</li>
<li>Sequencing mode：(1) ATACseq推荐使用paired-end。paired-end sequencing, helps to <code>reduce these alignment ambiguities</code>. (2) we are interested in <code>knowing both ends of the DNA fragments generated by the assay</code>, since the ends indicate where the transposase inserted. (3) <strong><code>PCR duplicates are identified more accurately</code></strong>.  PCR duplicates are <code>artifacts of the procedure</code>, and they should be removed as part of the analysis pipeline . <code>Computational programs that remove PCR duplicates typically identify duplicates based on comparing ends of aligned reads</code>. With <strong><code>single-end reads</code></strong>, there is <code>only one position to compare</code>, and so any <code>reads whose 5&#39; ends match are considered duplicates</code>. Thus, <code>many false positives</code> may result, and perfectly <code>good reads are removed</code> from further analysis. <strong><code>Paired-end sequencing</code></strong>, <code>both ends of the original DNA fragments are defined</code>. <code>To be declared a duplicate, both ends of one fragment need to match both ends of another fragment</code>, which is far <code>less likely to occur by chance</code>. Therefore, paired-end sequencing leads to <code>fewer false positives</code>.</li>
<li>Mitochondria: 众所周知ATAC-seq数据通常包含很大比例的<code>来自线粒体DNA的reads</code>（<em>线粒体DNA是裸露的，也可以被Tn5酶识别切割，植物叶绿体</em>）。线粒体基因组中没有ATAC-seq感兴趣的峰，这些reads在计算中被丢弃，浪费测序资源。可在测序前使用洗涤剂<a href="https://www.nature.com/articles/nmeth.4396">去除样本中的线粒体</a>。</li>
</ul>
<h3 id="Quality-control"><a href="#Quality-control" class="headerlink" title="Quality control"></a>Quality control</h3><h4 id="FastQC"><a href="#FastQC" class="headerlink" title="FastQC"></a>FastQC</h4><p>Process a file of <code>20 million reads</code> in about <code>5 minutes</code> with less than <code>250MB memory</code> used. Quality scores, GC levels, PCR duplicates, and adapter content.</p>
<h4 id="Adapter-removal"><a href="#Adapter-removal" class="headerlink" title="Adapter removal"></a>Adapter removal</h4><p>For reads derived from <code>short DNA fragments</code>, the <code>3&#39; ends may contain portions of the Illumina sequencing adapter</code>.  </p>
<h5 id="Cutadapt"><a href="#Cutadapt" class="headerlink" title="Cutadapt"></a><a href="https://cutadapt.readthedocs.io/en/stable/guide.html">Cutadapt</a></h5><h5 id="NGmerge"><a href="#NGmerge" class="headerlink" title="NGmerge"></a><a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2579-2">NGmerge</a></h5><p>Unlike cutadapt, NGmerge <code>does not require</code> that the <code>adapter sequences</code> be provided, <code>nor</code> does it <code>require a parameter for the minimum length of adapter to match</code> (in fact, it <code>does not perform adapter matching</code> at all).For input files of <code>20 million paired reads</code>, NGmerge should run in <code>less than one hour on a single core</code>, with minimal memory usage.<br><img src="https://img-blog.csdnimg.cn/e2669cfa1a184ec2b7026fe528f9c97a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p>
<h5 id="Just-adapter-removal"><a href="#Just-adapter-removal" class="headerlink" title="Just adapter removal"></a>Just adapter removal</h5><p>Other than adapter removal, we <code>do not recommend any trimming of the reads.</code> Such adjustments can complicate later steps, such as the identification of PCR duplicates.</p>
<h3 id="Alignment"><a href="#Alignment" class="headerlink" title="Alignment"></a>Alignment</h3><p>Two of the most popular alignment program are BWA and <code>Bowtie2</code>.</p>
<h4 id="Genome-indexing"><a href="#Genome-indexing" class="headerlink" title="Genome indexing"></a>Genome indexing</h4><p>For many model organisms, the genome and pre-built reference indexes are available from <a href="https://support.illumina.com/sequencing/sequencing_software/igenome.html">iGenomes</a>.<br>Otherwise, Bowtie2 indexes are made from a FASTA genome file using the program <code>bowtie2-build</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2-build  &lt;genome.fa&gt;  &lt;genomeIndexName&gt;</span><br></pre></td></tr></table></figure>
<h4 id="Alignment-1"><a href="#Alignment-1" class="headerlink" title="Alignment"></a>Alignment</h4><p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml">Bowtie2 parameters</a>. Here are a few that <code>may benefit the alignment of an ATAC-seq dataset</code> :</p>
<p><code>-X &lt;int&gt;</code> : Maximum DNA fragment length (<code>default 500bp</code>). If you anticipate that you may have DNA fragments <code>longer than</code> the default value, you should <code>increase</code> this parameter accordingly; otherwise, alignments from such fragments are considered not properly paired (see Fig. 3B below).<br><code>--very-sensitive</code> : Bowtie2 has a number of alignment and effort parameters that interact in complex (and sometimes unexpected) ways. Preset collections of these parameters are provided for convenience; the default is –sensitive, but <code>better alignment results</code> are frequently achieved with –very-sensitive.<br><code>-k &lt;int&gt;</code> : Maximum number of alignments to report per read. By default, Bowtie2 reports at most one alignment per read, and if multiple equivalent alignments exist, it chooses one randomly.<br><code>-p &lt;int&gt;</code> : Number of <code>cores</code> on which to run</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2  --very-sensitive  -k 10  -x &lt;genomeIndexName&gt;  -1 &lt;name&gt;_1.fastq.gz  -2 &lt;name&gt;_2.fastq.gz  \</span><br><span class="line">  |  samtools view  -u  -  \</span><br><span class="line">  |  samtools sort  -n  -o &lt;BAM&gt;  -</span><br></pre></td></tr></table></figure>
<ul>
<li>For input files of <code>20 million</code> paired reads, this command takes around <code>five hours</code> on Cannon(1 core too slow). One could specify eight cores for Bowtie2 with <code>-p 8</code> and adjust the request in the <code>SLURM script</code> to <code>#SBATCH -n 10</code> (that is, <code>eight</code> cores for <code>Bowtie2</code> and <code>one each</code> for <code>SAMtools view</code> and <code>sort</code>). </li>
<li>Bowtie2 also provides (via stderr) a summary of the mapping results, separated according to uniqueness and alignment type.</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/9f961cf3106f4c99b6e85bd1c3f6e373.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"><br> Alignment types for paired-end reads. <strong>A</strong>: Properly paired alignments (“<code>concordant</code>“) have the reads <code>aligned in opposite orientations</code> on the <code>same reference</code> sequence (chromosome). The reads <code>may overlap</code> to some extent (bottom). <strong>B</strong>: A read alignment (for <code>R1</code>) can be <code>unpaired</code> for several reasons: if the read’s mate (<code>R2</code>) is <code>unaligned</code> (<code>upper left</code>), <code>aligns to a different chromosome</code> (<code>upper right</code>), aligns in the <code>incorrect orientation</code> (<code>middle</code> cases), or aligns in the correct orientation but at an <code>invalid distance</code> (<code>bottom</code>). In all cases except the upper left, the R2 read alignment is also unpaired, and the read pair align discordantly (though Bowtie2 also requires uniqueness for such alignments to be counted as discordant).</p>
<p>Generich 版本</p>
<h3 id="Peak-calling"><a href="#Peak-calling" class="headerlink" title="Peak calling"></a>Peak calling</h3><h4 id="推荐新的Generich"><a href="#推荐新的Generich" class="headerlink" title="推荐新的Generich???"></a>推荐新的<a href="https://github.com/jsh58/Genrich"><code>Generich</code></a>???</h4><p>Genrich was designed to be able to <code>run all of the post-alignment steps</code> through <code>peak-calling with one command</code>. It also possesses a few <code>novel features</code>. Consider the following attributes:</p>
<ul>
<li><strong>Removal of mitochondrial reads</strong>. Genrich <code>disregards all alignments to the mitochondrial</code> chromosome with <code>-e chrM</code>.</li>
<li><strong>Removal of PCR duplicates</strong>. Genrich follows a <code>systematic procedure</code> to <code>remove PCR duplicates</code> with <code>-r</code>. Note that this evaluation <code>takes into account multimapping reads</code> (see next), which is <code>not provided by other alignment-based duplicate-removal programs</code>, such as <code>Picard&#39;s MarkDuplicates</code>.</li>
</ul>
<p><strong>Analysis of multimapping reads</strong>. 重复区域多的基因组可能导致非唯一mapping。 Non-uniquely aligned reads can be removed by filtering based on MAPQ scores with <code>samtools</code>, but this effectively renders certain genomic regions inaccessible to the assay. With Genrich, <code>reads with multiple alignments are analyzed</code> by adding a fractional count to each location. Genrich’s <code>statistical model</code> accommodates these values.<br>Along these same lines, Genrich considers the entire reference genome to be part of the assay. If there are chromosomes or genomic regions that should be excluded from analysis, these can be specified by <code>-e or -E</code>, and Genrich will adjust the <code>genome length calculation</code> accordingly. There is no need to <code>guesstimate an &quot;effective&quot; genome size</code> like with MACS2.<br><strong>Analysis of multiple replicates</strong>. When alignment files for multiple replicates are provided to Genrich, it <code>calls peaks for the replicates collectively</code>. <code>No more IDR</code>. Done.<br><strong>Interpretation of alignments suitable for ATAC-seq</strong>. Genrich provides an ATAC-seq analysis mode (-j) in which, rather than inferring the full fragments from the alignments, intervals are interpreted that are centered on transposase cut sites (the ends of each DNA fragment). Only properly paired alignments are analyzed by default, but there is an option to consider unpaired alignments as well (-y) (Fig. 4).</p>
<p><img src="https://img-blog.csdnimg.cn/abb30e7406834c91b7e456ff14e23742.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p>
<ul>
<li>Our previous recommendation was to run <code>MACS2</code> with <code>-f BAMPE</code>, which is similar to the <code>default analysis mode of Genrich</code> (<strong>inferring full fragments, rather than cut site intervals</strong>). Others have attempted to interpret cut site intervals with MACS2 by using the <code>--shif</code>t and <code>--extsize</code> arguments, but these arguments are ignored in <code>BAMPE</code> mode. They do work in the default (<code>BAM</code>) mode, but then, with paired-end reads, <code>most of the alignments are automatically discarded</code> (half of the properly paired alignments and all of the unpaired alignments; secondary alignments are never considered). Is it worse to interpret full fragments that may be less informative biologically, or to disregard more than half of the sequence data? A complicated question. The correct answer is: <strong>use Genrich.</strong><h4 id="Genrich"><a href="#Genrich" class="headerlink" title="Genrich"></a>Genrich</h4></li>
</ul>
<p><strong>most important parameters and options of Genrich for analyzing ATAC-seq：</strong> </p>
<p><code>-j</code> : ATAC-seq mode (<strong>must</strong> be specified)<br><code>-d &lt;int&gt;</code> : Expand cut sites to the given length (default 100bp)<br><code>-y</code> : Analyze <strong>unpaired</strong> alignments<br><code>-r</code> : Remove PCR duplicates<br><code>-e &lt;arg&gt;</code> : Chromosomes (reference sequences) to exclude. Can be a comma-separated list, e.g. <code>-e chrM,chrY</code>.<br><code>-E &lt;file&gt;</code> : Input BED file(s) of genomic regions to exclude, such as ‘N’ homopolymers or high mappability regions<br><code>-q &lt;float&gt;</code> : Maximum q-value (FDR-adjusted p-value) for peak calling (default 0.05). An unadjusted p-value threshold can be used instead with <code>-p &lt;float&gt;</code>.<br><code>-a &lt;float&gt;</code> : Minimum area under the curve (total significance) for a peak (default 20.0). <code>Increasing</code> this value results in <code>fewer</code> but <code>higher confidence</code> peaks.<br><code>-v</code> : Verbose mode</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Genrich  -t &lt;BAM&gt;  -o &lt;OUT&gt;  -j  -y  -r  -e chrM  -v</span><br></pre></td></tr></table></figure>

<ul>
<li>对于重复data,  <code>-t &lt;BAM1&gt;,&lt;BAM2&gt;</code>.</li>
<li>The output file produced by Genrich is in <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format12"><code>ENCODE narrowPeak format</code></a>, listing the genomic coordinates of each peak called and various statistics.</li>
<li>Speed： a single BAM containing <code>146.3 million alignments</code> was analyzed by Genrich in <code>10.5min</code> with <code>17.1GB of memory</code> . In general, input BAM(s) of more alignments take longer to analyze, but the memory usage should not increase greatly. Note that <code>Genrich is not multithreaded</code>, so it runs on a single core only.</li>
<li>Those who wish to explore the results of varying the <code>peak-calling parameters (-q/-p, -a, -l, -g)</code> should consider having Genrich produce a log file when it parses the SAM/BAM files (for example, with <code>-f &lt;LOG&gt;</code> added to the above command). Then, Genrich can call peaks directly from the log file with the <code>-P</code> option（调参数使用此法节省内存和时间）:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Genrich  -P  -f &lt;LOG&gt;  -o &lt;OUT2&gt;  -p 0.01  -a 200  -v</span><br></pre></td></tr></table></figure>

<h3 id="NEXT-Steps"><a href="#NEXT-Steps" class="headerlink" title="NEXT Steps"></a>NEXT Steps</h3><h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>For ATAC-seq in model organisms, the <code>peak file produced by Genrich</code> can be <code>uploaded</code> directly to the <a href="https://genome.ucsc.edu/cgi-bin/hgCustom">UCSC genome browser</a>. Add header.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">track type=narrowPeak</span><br></pre></td></tr></table></figure>
<p>An alternative visualization tool is the <a href="http://software.broadinstitute.org/software/igv/">Integrative Genomics Viewer (IGV)</a>. Peak files can be loaded directly (File → Load from File). <strong>Viewing BAM files with IGV requires that they be sorted by coordinate and indexed</strong> using <a href="http://www.htslib.org/doc/samtools.html">SAMtools</a>. However, the BAMs show the read alignments, <code>not the full fragments generated by the ATAC</code> <code>nor the cut site intervals</code> analyzed by Genrich. To view the intervals, one can use the optional output <code>BED file</code> produced by Genrich with <code>-b</code>.</p>
<h4 id="Comparing-peak-files"><a href="#Comparing-peak-files" class="headerlink" title="Comparing peak files"></a>Comparing peak files</h4><p>Determining genomic regions that are <code>common or different to a set of peak files</code> is best accomplished with <a href="http://bedtools.readthedocs.io/en/latest/index.html">BEDTools</a>, a suite of software tools that enables “genome arithmetic.”<br>For example, <a href="http://bedtools.readthedocs.io/en/latest/content/tools/intersect.html">bedtools intersect</a> determines regions that are <strong><code>common</code></strong> to two peak files. Finding <strong><code>differences</code></strong> between two peak files, such as control vs. experimental groups, is accomplished via <a href="http://bedtools.readthedocs.io/en/latest/content/tools/subtract.html">bedtools subtract</a>.</p>
<h4 id="Annotation"><a href="#Annotation" class="headerlink" title="Annotation"></a>Annotation</h4><p>It is helpful to know <code>what genomic features are near the peaks</code> called by Genrich. One program that is commonly used to annotate peaks is <a href="https://bioconductor.org/packages/release/bioc/html/ChIPseeker.html">ChIPseeker</a>. ChIPseeker was originally designed to be used in the analysis of ChIP-seq, but it works just <code>as well with ATAC-seq.</code><br>ChIPseeker <strong>requires</strong> that the <code>genome of interest be annotated with locations of genes and other features</code>. The <a href="https://bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html">ChIPseeker user guide</a> is extremely helpful in using this R/Bioconductor package.</p>
<h4 id="Motif-finding"><a href="#Motif-finding" class="headerlink" title="Motif finding"></a>Motif finding</h4><p><a href="http://homer.ucsd.edu/homer/introduction/basics.html">HOMER</a> is a suite of software designed for <a href="http://homer.ucsd.edu/homer/ngs/peakMotifs.html">motif discovery</a>. It takes a <code>peak file as input</code> and <code>checks for the enrichment</code> of both <code>known sequence motifs</code> and <code>de novo motifs</code>.</p>
<p>MACS2版本</p>
<h4 id="Alignment（same）"><a href="#Alignment（same）" class="headerlink" title="Alignment（same）"></a>Alignment（same）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2  --very-sensitive  -x &lt;genomeIndexName&gt;  -1 &lt;name&gt;_1.fastq.gz  -2 &lt;name&gt;_2.fastq.gz \</span><br><span class="line"> |  samtools view -u -  \</span><br><span class="line"> |  samtools sort -  &gt;  &lt;BAM&gt;</span><br></pre></td></tr></table></figure>

<h4 id="Alignment-adjustments"><a href="#Alignment-adjustments" class="headerlink" title="Alignment adjustments"></a>Alignment adjustments</h4><h5 id="Mitochondrial-reads"><a href="#Mitochondrial-reads" class="headerlink" title="Mitochondrial reads"></a>Mitochondrial reads</h5><ul>
<li>ATAC-seq datasets usually contain a large percentage of reads that are derived from mitochondrial DNA (<a href="http://seqanswers.com/forums/showthread.php?t=35318">discussion</a>). Using <a href="https://www.nature.com/articles/s41598-017-02547-w">CRISPR to reduce mitochondrial contamination</a>. Or recently <a href="https://www.nature.com/articles/nmeth.4396">Omni-ATAC method</a> uses detergents[洗涤剂] to remove mitochondria and is likely to be more accessible for most researchers ( <a href="https://www.biorxiv.org/content/10.1101/496521v1">bad computational workflow</a>).</li>
<li>Method 1 : <strong>Remove the mitochondrial genome from the reference genome before aligning the reads</strong>. In human/mouse genome builds, the mitochondrial genome is labeled ‘<code>chrM</code>‘. That sequence can be deleted from the reference prior to building the genome indexes. The downside of this approach is that the alignment numbers will look much worse; all of the mitochondrial reads will count as unaligned. [植物？]</li>
<li>Method 2 : <strong>Remove the mitochondrial reads after alignment</strong>. A python script, creatively named removeChrom, is available in the ATAC-seq module to accomplish this. For example, to remove all ‘chrM’ reads from a BAM file, one would run this:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -h  &lt;inBAM&gt;  |  removeChrom - - chrM  |  samtools view -b -  &gt;  &lt;outBAM&gt;</span><br></pre></td></tr></table></figure>
<h5 id="PCR-duplicates"><a href="#PCR-duplicates" class="headerlink" title="PCR duplicates"></a>PCR duplicates</h5><p> Picard’s <a href="http://broadinstitute.github.io/picard/command-line-overview.html#MarkDuplicates">MarkDuplicates</a>. The output file specified by <code>M=</code> lists counts of alignments analyzed and duplicates identified.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -jar $PICARD_TOOLS_HOME/picard.jar MarkDuplicates I=&lt;inBAM&gt; O=&lt;outBAM&gt; M=dups.txt REMOVE_DUPLICATES=true</span><br></pre></td></tr></table></figure>
<h5 id="Non-unique-alignments"><a href="#Non-unique-alignments" class="headerlink" title="Non-unique alignments"></a>Non-unique alignments</h5><p>重复区域多的参考序列可能导致reads多处mapping. 用samtools view的-q <code>去除非唯一比对</code>. For reads with multiple alignments, <code>Bowtie2</code> (or <code>BWA</code>) will <code>report only one alignment</code> (by <code>default</code>) and will assign it a low mapping quality (MAPQ) score, which is defined as -10 * log10Pr{mapping position is wrong}. To eliminate alignments with <code>MAPQ &lt; 10</code> (i.e., where <code>Bowtie2</code> has determined <code>Pr&#123;mapping position is wrong&#125; &gt; 0.1</code>), one would run the following:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -b  -q 10  &lt;inBAM&gt;  &gt;  &lt;outBAM&gt;</span><br></pre></td></tr></table></figure>

<h4 id="Peak-calling-1"><a href="#Peak-calling-1" class="headerlink" title="Peak calling"></a>Peak calling</h4><ul>
<li>Model-based Analysis of ChIP-Seq (<a href="https://github.com/taoliu/MACS">MACS2</a>) is a program for detecting regions of <code>genomic enrichment</code>. Though designed for ChIP-seq, it works just <code>as well on ATAC-seq and other genome-wide enrichment assays that have narrow peaks</code>. The main program in MACS2 is <code>callpeak</code>, and its options are described below. (Note that the latest version of MACS2 on Odyssey (v2.1.2_dev) is different from the updated official MACS2 release (v2.1.2), although the latter does incorporate many of the bug fixes made in the Odyssey <code>version？</code>.)</li>
<li>It is important to remember that the <code>read alignments indicate only a portion of the DNA fragments generated by the ATAC？</code>. Therefore, one must consider how one wants MACS2 to interpret the alignments.<h5 id="Alignments-to-analyze"><a href="#Alignments-to-analyze" class="headerlink" title="Alignments to analyze"></a>Alignments to analyze</h5></li>
<li>alignments分为两类：”<strong>properly paired</strong>“ and “<strong>singletons</strong>“ 。<code>-f</code> 选择其类型。</li>
<li><strong>Analyze only properly paired alignments, but ignore R2 reads and treat R1 reads as singletons</strong>. This is the default option (<code>-f AUTO</code>). MACS2 creates a model of the fragment lengths and extends the 3’ ends of the R1 reads to the calculated average length. An alternative is to skip this model building and instead extend each read to a specified length (e.g., <code>--nomodel --extsize 300</code> for 300bp fragments). The value of the length parameter is usually determined from the average size during library preparation (the default value is 200bp if no value is specified). However, <code>neither of these approaches utilizes the value of paired-end sequencing</code>, which defines both fragment ends.</li>
<li><strong>Analyze only properly paired alignments with <code>-f BAMPE</code></strong>. Here, the fragments are defined by the paired alignments’ ends, and there is <code>no modeling or artificial extension</code>. Singleton alignments are ignored. This is the <code>preferred option</code> for using only properly paired alignments.</li>
<li><strong>Analyze all alignments</strong>. For this approach, a python script, SAMtoBED, is available in the ATAC-seq module. This script converts the read alignments to BED intervals, treating the properly paired alignments as such and extending the singleton alignments as specified. There are <code>four options for the singletons</code>: ignore them, keep them as is, extend them to an arbitrary length (similar to the <code>--extsize</code> option of MACS2), or extend them to the average length calculated from the properly paired alignments. </li>
<li>Here is an example command, using the “extend to average length” option (<code>-x</code>):</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -h  &lt;BAM&gt;  |  SAMtoBED  -i -  -o &lt;BED&gt;  -x  -v</span><br></pre></td></tr></table></figure>
<p>The output from SAMtoBED is a <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format1">BED file</a> that should be analyzed by MACS2 with <code>-f BEDPE</code>.<br>(Note that the BEDTools program <a href="http://bedtools.readthedocs.io/en/latest/content/tools/bamtobed.html">
</a> cannot be used here, since its output is in a nonstandard BED format that MACS2 cannot analyze.)</p>
<ul>
<li>In deciding among these analysis options, it may help to consider the counts produced by Bowtie2, which indicate <code>how many alignments fall into each category</code>. For example, if most of the reads are aligned in proper pairs, it may be sufficient to use <code>option #2</code>. On the other hand, <code>option #3</code> is preferred if a substantial fraction of the reads consists of singletons.<h5 id="Other-arguments"><a href="#Other-arguments" class="headerlink" title="Other arguments"></a>Other arguments</h5></li>
<li>MACS2 is <code>not multithreaded</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak  -t &lt;BED&gt;  -f BEDPE  -n NAME  -g ce  --keep-dup all</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>-n &lt;str&gt;</code>    Name of the sample. The output files  name prefix.<br><code>-g &lt;int&gt;</code>    Effective genome size, the size of the organism’s genome that can be analyzed (not including Ns, repetitive sequences, etc.). This will be less than the actual genome size. Parameters are provided for some model organisms, and the <code>default value is hs</code> (for Homo sapiens), which corresponds to a value of 2.7e9.<br><code>-q &lt;float&gt;</code>    <code>Maximum q-value</code> (FDR-adjusted p-value) for peak calling (default <code>0.05</code>). Reducing this threshold will decrease the number of peaks identified by MACS2 but increase the confidence in the called peaks.<br><code>--keep-dup &lt;arg&gt;</code>    How to handle PCR duplicates (default: –keep-dup 1, i.e. remove all potential duplicates). If PCR duplicates have been removed by another program, such as Picard’s MarkDuplicates, then specify <code>--keep-dup all</code>.<br><code>--max-gap &lt;int&gt;</code>    Maximum gap between significant sites to cluster them together (default 50bp). (v2.1.2_dev only)<br><code>--min-length &lt;int&gt;</code>    Minimum length of a peak (default 100bp). (v2.1.2_dev only)</p>
</blockquote>
<h5 id="Output-files"><a href="#Output-files" class="headerlink" title="Output files"></a>Output files</h5><ul>
<li>NAME_peaks.xls</li>
<li>NAME_peaks.narrowPeak</li>
<li>NAME_summits.bed</li>
<li>The most useful file is <code>NAME_peaks.narrowPeak</code>, a plain-text <code>BED</code> file that lists the <code>genomic coordinates of each peak called</code>, along with various <code>statistics</code> (fold-change, p- and q-values, etc.).</li>
</ul>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-1【Background】</title>
    <url>/blog/2021/10/11/ATAC-seq-1-background/</url>
    <content><![CDATA[<h3 id="ATAC-seq意义"><a href="#ATAC-seq意义" class="headerlink" title="ATAC-seq意义"></a>ATAC-seq意义</h3><span id="more"></span>

<p><img src="https://img-blog.csdnimg.cn/2eb44c70d00b45bab31b0eb915e91cac.png" alt="在这里插入图片描述"></p>
<ul>
<li>为何同样DNA序列的细胞的表型会不同，为何肝细胞是肝细胞，神经细胞是神经细胞？是什么造成了他们生产蛋白不同，决定蛋白生成的RNA不同呢？原因可以用<code>表观遗传</code>来解释。<br><img src="https://img-blog.csdnimg.cn/9bf2e2d5d25a4e2eab27321b99b0b0b8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li>DNA转录成RNA过程复杂，包括：<code>染色质可及性</code>，<code>DNA修饰</code>，<code>组蛋白修饰</code>等等（选择性表达）。</li>
<li><code>染色质可及性即DNA开放区域</code>，尤为重要。<code>核小体</code>由<code>8个组蛋白</code>组成复合物，每个核小体约<code>147bpDNA</code>。转录时DNA将从核小体复合物松开。许多因素，如<code>染色质结构</code>、<code>核小体位置</code>和<code>组蛋白修饰</code>，在染色质的组织和可及性起重要作用。致密核小体结构被破坏后，<code>启动子、增强子、绝缘子、沉默子</code>等<code>顺式调控元件和反式作用因子可以接近</code>的特性，叫<code>染色质的可及性</code>，也叫<code>染色质开放性</code>(chromatin accessibility ），这段区域叫开放染色质（open chromatin） 。</li>
<li>什么是组蛋白修饰<ul>
<li>定义：组蛋白包含5个部分，按分子量大小分别称为<code>H1，H3，H2A，H2B和H4</code>。组蛋白在相关酶作用下发生<code>甲基化，乙酰化，磷酸化，腺苷酸化，泛素化，ADP核糖基化</code>等修饰</li>
<li><code>H3·H4乙酰化</code>形成<code>开放染色质结构</code>，<code>增加基因表达</code></li>
<li>组蛋白<code>甲基化</code>修饰多发生在<code>H3H4</code>，与基因<code>抑制及激活</code>相关，取决于被<code>修饰位置和程度</code></li>
<li>组蛋白<code>磷酸化</code>修饰一般与基因<code>活化</code>有关</li>
<li>组蛋白<code>泛素化</code>则是<code>启动基因表达</code></li>
</ul>
</li>
<li>2013年由斯坦福大学William J. Greenleaf和Howard Y. Chang实验室开发的ATAC-seq（<code>Assay</code> for <code>Transposase</code>-<code>Accessible</code> <code>Chromatin</code> with high throughput sequencing），一种捕获染色质可及性（染色质开放性）的测序方法。</li>
<li>ATAC-seq<code>检测染色质可及性</code>，<code>确定基因表达调控机制</code>。识别<code>启动子区域</code>、<code>潜在的增强子或抑制子</code>。<code>启动子</code>是靠近转录起始点(TSS)的DNA区域。包含<code>转录因子的结合位点</code>，转录因子招募RNA聚合酶。<code>增强子</code>是位于<code>启动子下游或上游1Mb</code>的DNA区域。<code>当转录因子与增强子结合，并与启动子区域接触时，该基因的转录增加</code>。相反<code>抑制子</code>会<code>减少或抑制基因表达</code>。</li>
<li>ATAC-seq的<code>峰</code>往往是<code>启动子</code>，<code>增强子序列</code>以及一些<code>反式调控因子</code>结合位点。</li>
<li>为找到开放染色质区，基因组被<code>TN5转座酶</code>处理。在ATAC-Seq中，<code>修饰后的TN5将与NextEra接头相对应的DNA序列插入到基因组的开放区域</code>，同时，DNA被转座酶活性剪切。</li>
<li>开放染色质的研究方法除了ATAC-seq，还有DNase-Seq，FAIRE-seq，MNase-seq 等。ATAC-Seq<code>所需样本少，建库快，重复性更高</code></li>
<li>技术：制备细胞悬液-&gt;裂解细胞膜，获取细胞核-&gt;采用Tn5进行酶切-&gt;回收DNA片段，PCR扩增建库-&gt;高通量测序-&gt;生信分析</li>
<li><img src="https://img-blog.csdnimg.cn/00f06cb4758b44c7a35b8c5c3ff74eda.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq</code>与<code>Chip-seq</code> call出来的<code>peak</code>代表的<code>意义不同</code>。<code>Chip-seq</code> peak是被<code>目的蛋白结合拉下来的DNA</code>，一般只有<code>一个峰</code>，而<code>ATAC-seq</code>是被<code>Tn5转座酶切开</code>、没有被组蛋白结合、染色质开放的DNA位点，<code>如果是TF结合的区域，一般会有一个山谷般的存在</code>。ChIP-seq和ATAC-seq在TF或者Tn5结合区域<code>都会形成一个双峰的reads结合模式</code>，但<code>判断peak的时会有不同的标准</code>。chip-seq是由于<code>TF一起沉淀下来的DNA fragment一般会大于TF的结合区域</code>，<code>read的位置并不是真实TF结合位置</code>，需要<code>向内shift</code>；而<code>ATAC-seq一般是往两边shift</code>。<br><img src="https://img-blog.csdnimg.cn/e501e5a398b34d0e8fd514fba8333cdb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq</code>与<code>Chip-seq</code>应用上的区别:</li>
<li>ATAC-Seq可<code>检测全基因组DNA结合蛋白</code>，<code>转录结合位点</code> ，一般用于<code>不知道特定的转录因子</code>，用此方法与其他方法结合<code>筛查感兴趣的特定调控因子</code>；</li>
<li>ChIP-Seq是已知转录因子，根据<code>感兴趣的转录因子设计抗体</code>去做ChIP实验<code>富集结合的DNA片段</code>。在测定转录因子的 ChIP-seq 中<code>独有的峰可能是先驱转录因子</code>，其<code>先结合到封闭染色质</code>，然后<code>招募染色质重塑因子或其他转录因子起始转录</code>。这些转录因子 <code>ATAC-seq检测不到</code>。</li>
<li>得到DNA片段后，为测序准备建库，包括<code>用完整的NextEra接头</code>和<code>纯化</code>、<code>PCR扩增</code>等。基于上述原因，<code>ATAC-Seq推荐使用双端配对</code>的方法。</li>
</ul>
<h3 id="ATACseq应用"><a href="#ATACseq应用" class="headerlink" title="ATACseq应用"></a>ATACseq应用</h3><ul>
<li><p>染色质<code>开放性图谱绘制</code>，表观基因组图谱</p>
</li>
<li><p>找<code>调控</code>生物学过程的<code>关键转录因子</code></p>
</li>
<li><p>找<code>哪个转录因子</code>调控了研究的基因</p>
</li>
<li><p>找转录因子调控的<code>靶基因</code></p>
</li>
<li><p>得到<code>不同组织或不同条件下对应可及性区域</code>。</p>
</li>
<li><p>得到核小体位置</p>
</li>
<li><p>生成转录因子结合区域的特征(footprinting)</p>
<h3 id="技术限制"><a href="#技术限制" class="headerlink" title="技术限制"></a>技术限制</h3></li>
<li><p>Tn5通过<code>插入剪断DNA 并将测序接头连接到剪断的两个DNA 片段的末端</code>，因此对于一个DNA 片段而言，其两端的接头连接是随机的，导致<code>同一片段两端的接头有50%的概率是同一接头</code>。而<code>只有连接不同接头的片段才可用于富集扩增及测序</code>，因此<code>一半的片段无法利用</code>； </p>
</li>
<li><p><code>大量剪断的DNA 由于片段过大，无法进行PCR富集</code>; </p>
</li>
<li><p>Tn5 的<code>活性</code>受反应溶液的组成及反应条件<code>影响</code>，仍然需要优化以便提高剪切效果； </p>
</li>
<li><p>ATAC-seq在<code>植物细胞存在以下难点</code>：<code>细胞壁</code>，<code>叶绿体线粒体等细胞器污染</code>，<code>缺少稳定遗传的细胞系</code>; </p>
</li>
</ul>
<h3 id="ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq"><a href="#ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq" class="headerlink" title="ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq"></a>ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq</h3><ul>
<li>整体的分析思路一致，<code>找富集区域</code>，对富集区域进行功能分析。</li>
<li>ChIP-Seq是<code>揭示特定转录因子</code>或<code>蛋白复合物</code>的结合区域，实际是<code>研究DNA和蛋白质的相互作用</code>，利用<code>抗体将蛋白质和DNA一起富集</code>，并对<code>富集的DNA测序</code>。</li>
<li>DNase-Seq、ATAC-Seq、FAIRE-Seq都<code>研究开放染色质区域</code>：</li>
<li>DNase-Seq用<code>DNase I内切酶识别</code>开放染色质区域，</li>
<li>ATAC-seq用<code>Tn5转座酶</code>，随后进行<code>富集扩增</code>；</li>
<li>FAIRE-Seq先超声裂解，后用酚-氯仿富集；</li>
<li>MNase-Seq鉴定核小体区域。 </li>
</ul>
<p>下图是不同测序方法获取的峰形：</p>
<p><img src="https://img-blog.csdnimg.cn/aea5161044eb40e1a1cc4c1a65d63cbb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>检测染色质可及性的方法中，ATAC-seq尤其受欢迎。<br><img src="https://img-blog.csdnimg.cn/96808dfcce9446298f1d0d4cc0db6eee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<ul>
<li>ATAC-seq的优点：<code>Tn5转座酶的高活性</code>使ATAC-seq简单，省时，而且只需500-50,000个细胞。灵敏度特异性与DNase-seq相当，优于FAIRE-seq。</li>
</ul>
<h3 id="整合分析"><a href="#整合分析" class="headerlink" title="整合分析"></a>整合分析</h3><ul>
<li>由于开放染色质是大多数TF结合的先决条件，因此<code>ATAC-seq峰通常与TF ChIP-seq峰重叠，但通常更宽</code>。因此，<code>TF ChIP-seq和ATAC-seq可以在同一实验系统中相互验证</code>彼此的质量和可靠性。 </li>
<li>ATAC-seq与 histone marker ChIP-seq集成，发现与活跃染色质标 H3K4me3，H3K4me1，H3K27ac等正相关，与不活跃的染色质标记 H3K27me3 负相关。 <code>？</code></li>
<li><code>ATAC-seq+RNA-seq</code>： 一般RNA-seq会优先于ATAC-seq先测，但<code>差异基因富集的基因通路只是一种相关性</code>。要分析出其中谁调控目的基因，可通过<code>ATAC-seq做motif分析</code>，<code>寻找潜在的调控因子</code>，然后再后续的<code>实验验证</code>或者<code>chip-seq验证</code>。/ 看ATAC上丰度高的DNA序列区域是否对应转录本表达量增加，找到对应转录本相关基因的上游调控序列，整体分析转录。对基因功能分析，结合实验表型，推测表达调控-表达-功能-表型。<br><img src="https://img-blog.csdnimg.cn/4a3016bfa5c74598a5b7d660fe1cfe84.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq+HiC</code>： 对于一些想了解<code>染色质高级结构对生命行为的作用</code>的时候，通常会需要用到ATAC-seq等技术，因为<code>Hi-C分析</code>得到高级结构compartmentA/B、TADs、Loops等信息，通常只是相关性，但通过ATAC-seq，可以<code>获得promoter、enhancer等信息</code>，更能知道高级结构是如何影响启动子、增强子从而影响基因表达的。<br><img src="https://img-blog.csdnimg.cn/e38ba32597a14ca7a5d4d6b2f36c1b73.png" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq+组蛋白修饰</code>： ATAC-seq预测一个位点的开放程度以及可能有某种转录因子的结合，但<code>不知道</code>该因子是<code>促进</code>基因表达，还是<code>抑制</code>，只通过<code>基因层面鉴定</code>来判断转录因子对基因的促进或者是不够的，它只是一种<code>相关性</code>。而这时候如果能提供像<code>H3K27ac这类激活型组蛋白</code>、<code>H3K27me3这类抑制型组蛋白</code>将能使数据结果可信。国内较早研究iPSCs的学者如裴端卿的工作可以看到，在解析iPSCs重编程中的染色质可及性的时候，不仅用到ATAC-seq来描述细胞的身份转变，还<code>通过H3K27ac指征该区域的激活</code>。其中一篇还通过<code>调控成纤维细胞关键基因启动子区去乙酰化修饰</code>，达到了促进重编程的进程。<br><img src="https://img-blog.csdnimg.cn/abb3dc6c3bb0476985a9f1b2e77c4fcc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>scATAC-seq+scRNA-seq</code>： 更前沿的技术一个细胞里同时进行RNA-seq和ATAC-seq，并且是单细胞水平的检测。SHARE-seq，能够实现在单细胞中同时高质量，高通量的检测基因表达和染色质可及性。该技术可以使用<code>染色质潜力算法</code>（chromatin potential），<code>用ATAC和RNA的差异来预测细胞的变化方向</code>。<code>相对于以往仅依赖于RNA的预测手段，染色质潜力能够大大提前预测的时间</code>。<br><img src="https://img-blog.csdnimg.cn/df76c6e5f3184d58a00a1fa53a398cd5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
</ul>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/27374332/">ATAC-seq与ChIP联合分析</a><br>研究课题为人小细胞肺癌促进癌症扩散转移的背景机制。主要比较原发性和肝转移性的小细胞肺癌细胞之间的差异。利用ATAC-seq，发现NFI家族转录因子富集在具有差异的染色质开放位点中，预示着NFI家族转录因子在调控肿瘤细胞转移中扮演着重要角色。在染色质高开放性位点区域伴随着Nfib拷贝数量增多，且Nfib在侵袭性原发性肿瘤和转移性肿瘤内高表达，Nfib表现出维持染色质及远端调控区域开放和促进神经基因表达的功能，说明了Nfib对促进癌细胞增殖和迁移具有重要的作用。</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/25679813/">motif分析转录因子结合蛋白</a>。对处于发育过程中的黑腹果蝇眼睛及其通过遗传诱导的肿瘤模型，利用ATAC-seq技术分析染色质开放区域已在活体中发现驱动肿瘤发育的转录因子及调控区域。然后对找到的染色质活性开放区域进行转录因子预测分析，发现了两个关键的转录因子，猜测它们可能与染色质图谱的变化有关。通过对候选的一个转录因子进行功能验证和靶标分析，发现其为肿瘤转录组中的一个关键的转录调控因子。</li>
</ul>
<hr>
<ul>
<li><strong>思考</strong>：</li>
<li>ATAC-Seq与ChIP-Seq的异同在哪里？</li>
<li>用和ChIP-Seq一样的参数Call peaks正确吗？</li>
<li>得到peaks后怎么进行质量评估？</li>
<li>样本内的重复怎么处理？</li>
<li>样本间的差异怎么分析？</li>
<li>怎么对peaks进行功能注释分析？</li>
<li>如何找motif?</li>
<li>ATAC-Seq和ChIP-Seq和RNA-Seq的整合分析怎么做？<br><img src="https://img-blog.csdnimg.cn/0920f7a6c41148b2825b189e709a5fbc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="ATAC-seq/CHIP-seq流程"></li>
</ul>
<p>待学习内容：</p>
<ol>
<li><p>ATAC-seq data analysis: from FASTQ to peaks</p>
</li>
<li><p>ATAC-seq Data Standards and Processing Pipeline in ENCODE</p>
</li>
<li><p>ATAC-seq数据分析实战</p>
</li>
<li><p>Harvard FAS Informatics - ATAC-seq Guidelines</p>
</li>
<li><p>Harvard Chan Bioinformatics Core (HBC)深度NGS数据分析课程，第5部分关于ChIP-Seq，整体思路和绝大部分分析方法适合ATAC-seq。</p>
<p>HBC深度NGS数据分析课程：<br><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course</a><br>第五部分ChIP-Seq课程：</p>
<p><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a></p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">参考文献：</span><br><span class="line">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1633159169&amp;ver=3349&amp;signature=*MwqLr1J-qdZoNiKVxF32vEKh5-6TRystOXAJ3UOZ3Pl8XTBIB8Ly95IJM0L2EzGFVWOM-TdKnuhnb0gfMfsUTfahWJ5i3hcM2TcR9UDFSVWuyYw7CONzMjsMaYQG2Ca&amp;new=1</span><br><span class="line">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1633159169&amp;ver=3349&amp;signature=rtYw5NsC62rUZvctQsUg3*w*NFFDdOHgSMu0pcp0HTQdCyqxpgril8yx7GWlJaID*lfd2HRLUWs59zuszSEFeean0jEwdRs4PzYy*T5b7nSpZRWqCs4SHcEQ2jyjDtwQ&amp;new=1</span><br></pre></td></tr></table></figure>

<hr>
<blockquote>
<p>1：ATAC-seq的背景介绍以及与ChIP-Seq的异同<br>2：原始数据的质控、比对和过滤<br>3：用MACS2软件call peaks<br>4：对ATAC-Seq/ChIP-seq的质量评估（一）——phantompeakqualtools<br>5：对ATAC-Seq/ChIP-seq的质量评估（二）——ChIPQC<br>6：重复样本的处理——IDR<br>7：用Y叔的ChIPseeker做功能注释<br>8：用网页版工具进行motif分析<br>9：差异peaks分析——DiffBind<br>10：ATAC-Seq、ChIP-Seq、RNA-Seq整合分析</p>
</blockquote>
<h3 id="简洁版ATACseq分析流程"><a href="#简洁版ATACseq分析流程" class="headerlink" title="简洁版ATACseq分析流程"></a>简洁版ATACseq分析流程</h3><ul>
<li>数据预处理<ul>
<li>（1）比对前质量控制FastQC</li>
<li>（2）原始序列比对 </li>
<li>（3）比对后处理和质量控制：去除重复序列，细胞器序列<ul>
<li>序列比对后，Picard/SAMtools收集unique mapping reads/rate，duplicated rate百分比和片段大小分布</li>
<li>成功的ATACseq实验应生成<code>片段大小分布图</code>（从<code>bam文件</code>得到），具有递减性和周期性的峰，对应于<code>无核小体区域</code>（NFR）（&lt;100bp）和<code>单核双核和三核</code>小体（200，400，600bp）。大多数Linker DNA大小介于10-80bp间，故大多数片段都会是<code>小于100bp</code>。每个Nucleosome的DNA大小为180bp，加上两边插入的冗余，会得到大约<code>200bp</code>长度的mono-nucleosome的DNA。</li>
<li><code>无核小体区域的片段应该在基因的转录起始位点（TSS）周围富集</code>，而<code>核小体结合区域片段TSS处形成低谷</code>，TSS周围<code>侧翼区域稍微富集</code>。<code>ATACseqQC评估</code>。</li>
</ul>
</li>
</ul>
</li>
<li>Peak-calling：从比对得到的bam文件找出reads覆盖区，就是峰出现的位置。</li>
<li>高级分析<ul>
<li>（1）peak 差异分析：寻找不同分组差异peaks</li>
<li>（2）peak注释：峰的注释可将染色质的可及性与基因调控联系。通常峰会被注释到最接近的基因或调控原件。获得最接近的基因列表后，使用GOKEGGReactome等数据库功能富集分析</li>
<li>（3）motif富集分析：得到每个peak region里motif的位置和频率，再和随机背景或其他条件比较，可做motif富集分析</li>
<li>（4）footprint分析 ：ATACseq中footprint指一个TF结合在DNA上，组织Tn5切割，在染色质开放区域留下一个相对缺失的位置。而TF周围的组蛋白因为TF造成空间的推挤反而形成开放度较高区域。</li>
</ul>
</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
</search>
