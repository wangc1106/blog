<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CTCF</title>
    <url>/blog/2022/02/15/2022-02-15-CTCF/</url>
    <content><![CDATA[<h1 id="【paper1】CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops"><a href="#【paper1】CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops" class="headerlink" title="【paper1】CTCF: the protein, the binding partners, the binding sites and their chromatin loops"></a>【paper1】CTCF: the protein, the binding partners, the binding sites and their chromatin loops</h1><span id="more"></span>

<p>review: <a href="https://pubmed.ncbi.nlm.nih.gov/23650640/">https://pubmed.ncbi.nlm.nih.gov/23650640/</a></p>
<h1 id="CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops"><a href="#CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops" class="headerlink" title="CTCF: the protein, the binding partners, the binding sites and their chromatin loops"></a>CTCF: the protein, the binding partners, the binding sites and their chromatin loops</h1><p>CTCF:蛋白质，结合伙伴，结合位点和染色质环</p>
<p>CTCF什么都有。转录因子与成千上万个基因组位点结合，有些是组织特异性的，有些是超保守的。它可以作为<strong>转录激活因子</strong>、<strong>抑制子</strong>和<strong>绝缘子</strong>，并可以<strong>暂停转录</strong>。CTCF<strong>结合</strong>在<strong>染色质结构域边界</strong>，<strong>增强子</strong>和<strong>启动子</strong>，以及<strong>基因区</strong>。它可以吸引许多其他转录因子到染色质，包括组织特异性转录激活因子、抑制子、粘连蛋白和RNA聚合酶II，并形成染色质环。因此，CTCF在特定基因组位点的确切功能是不可预测的。它似乎是由相关的转录因子、结合位点相对于基因转录起始位点的位置、以及该位点在染色质环中与其他ctcf位点的结合、与增强子或启动子的结合决定的。该review将讨论CTCF结合事件的全基因组特征，以及这个显著的转录因子的位点特异性功能。</p>
<ol>
<li>introduction</li>
</ol>
<p>CTCF是一种普遍表达的必需蛋白，在许多方面都是一种特殊的转录因子。它最初被描述为转录<strong>抑制</strong>因子，但也被发现作为转录<strong>激活</strong>因子。还具有<strong>绝缘体活性</strong>:当它位于增强子和基因启动子之间时，它阻断它们的通信并阻止转录激活。通过<strong>ChIP-seq</strong>系统研究，在<strong>不同物种的许多组织</strong>中绘制CTCF在基因组尺度的结合事件。结果显示基因组被<strong>无数的CTCF结合位点</strong>所覆盖。与大多数其他转录因子相比，CTCF似乎<strong>更容易</strong>与基因间序列<strong>结合</strong>，通常<strong>距</strong>离转录起始位点(<strong>TSS</strong>)<strong>较远</strong>。CTCF是<strong>最早被证实介导染色质成环</strong>的蛋白之一。进一步观察到，它经常会<strong>结合</strong>到位于细胞核中不同位置的<strong>染色体区域之间的边界</strong>，<strong>结合</strong>具有<strong>不同表观遗传特征</strong>和/或<strong>不同转录活性</strong>的<strong>区域边界</strong>，以及最近确定的<strong>拓扑域之间的边界</strong>，这是空间上确定的<strong>染色体单位</strong>，在其中<strong>序列优先相互作用</strong>。本文讨论CTCF的研究，并评估其在<strong>基因组折叠</strong>和<strong>基因表达</strong>中的功能。</p>
<ol start="2">
<li>CTCF在<strong>Β-globin</strong>和<strong>h19-igf2</strong>位点:一个短暂的历史</li>
</ol>
<p>多功能DNA结合蛋白CTCF的功能最初是在<strong>单个位点</strong>上探索的，特别是在<strong>β-珠蛋白位点</strong>和<strong>印迹H19-Igf2位点</strong>。<strong>chicken β-珠蛋白位点</strong>在其5 ‘侧携带一个DNaseI超敏位点(5 ‘ hs4)，该位点将该位点<strong>与邻近的异染色质分离</strong>，该位点被发现能够<strong>阻断增强子活性</strong>。CTCF随后被证明与5 ‘ hs4的绝缘体活性有关。人和小鼠的β-珠蛋白位点也位于不活跃染色质的大染色体区域内，并类似地被ctcf结合位点包围。这些被怀疑会对进入的异染色质形成屏障，但它们的缺失不会导致β-珠蛋白位点的关闭或失活。<strong>染色体构象捕获(3C)技术</strong>的应用使β-珠蛋白CTCF位点的物理相互作用成为可能。它们形成<strong>大染色质环</strong>，包括β-珠蛋白的主要调节元件，<strong>Locus control region基因位点控制区(LCR)<strong>及其</strong>基因</strong>。这些环是红细胞特异性的，在lcr介导的β-珠蛋白基因高表达之前，在红细胞祖细胞中形成(图1a;)。据推测，CTCF环可以<strong>促进LCR与其靶基因之间的后续空间相互作用</strong>，但这方面的证据仍然缺乏。</p>
<p><img src="/blog/2022-02-15-CTCF/rstb20120369-g1.jpg" alt="An external file that holds a picture, illustration, etc. Object name is rstb20120369-g1.jpg"></p>
<p>Figure 1. CTCF，染色质环和特定基因位点的转录调控。(a)<strong>位于β-珠蛋白位点的基因</strong>受<strong>基因位点控制区(LCR)*<em><strong>控制。</strong>ctcf结合位点相互作用</em>*，形成</strong>染色质枢纽<strong>，其中包含</strong>LCR和β-珠蛋白基因<strong>。在</strong>红细胞分化<strong>时，</strong>红细胞特异性转录因子和内聚蛋白能够形成一个活跃的染色质枢纽<strong>，其中</strong>LCR与基因接触并增强其表达<strong>。(b) H19和Igf2基因的印迹表达是通过CTCF在印迹控制区(ICR)的甲基化依赖结合介导的。(i)在父系等位基因上，ICR的甲基化</strong>阻止CTCF结合**，并通过远端增强子(E)与Igf2启动子的接触介导Igf2基因的表达。(ii) <strong>CTCF结合在ICR上阻断了Igf2基因和远端增强子之间的通信</strong>，从而导致母源等位基因H19基因的表达。</p>
<p>印迹H19/Igf2位点。该位点包含一个<strong>差异甲基化区域</strong>，称为<strong>印迹控制区(ICR)<strong>，位于H19和Igf2基因之间。ICR决定了H19在</strong>母体等位基因</strong>上<strong>活跃</strong>，而<strong>Igf2</strong>则是从<strong>父系等位基因转录</strong>而来的。当CTCF被发现以<strong>甲基化依赖</strong>的方式与<strong>ICR结合</strong>时，CTCF进入了这个阶段:<strong>CTCF与未甲基化的母源ICR的结合阻</strong>止了H19基因附近的共享增强子<strong>跨越并激活</strong>Igf2。在<strong>父系等位基因CTCF不能发挥其绝缘体活性，因为DNA甲基化阻止了其与ICR的结合</strong>(图1b;)。染色质环再次形成，似乎对ICR的功能很重要。带有增强子和启动子的等位基因特异性染色质环是由母体的、与ctcf结合的ICR形成的，这表明这种接触可能是ctcf介导的绝缘体活性的基础。总的来说，早期关于CTCF在β-珠蛋白和H19-Igf2位点功能的研究表明，该蛋白可以<strong>干扰启动子-增强子通信</strong>。CTCF可以在其结合位点之间形成染色质环，也可能与其他调控序列形成染色质环。</p>
<ol start="3">
<li>CTCF通过基因组与染色质边界、增强子和基因启动子结合</li>
</ol>
<p>通过ChIP对全基因组结合位点的定位发现，CTCF可与数万个基因组位点结合。在不同的细胞类型中，大约<strong>三分之一的位点相对保守</strong>。一项对五种哺乳动物肝脏中CTCF结合谱的物种间比较发现，物种和组织之间大约有5000个超<strong>保守位点</strong>。这些似乎是<strong>高亲和力的结合位点</strong>，提示亲和力的差异可能与的保守强度有关。逆转录因子的激活产生了物种特异性的CTCF结合位点的扩展，这种形式的基因组进化在哺乳动物中仍然高度活跃。基于一致motif评分对CTCF结合位点进行分类得出了类似的结论:<strong>高占用位点似乎在所有细胞类型中都是保守的，而低占用位点则更受组织限制</strong>。</p>
<p>CTCF一致结合序列包含CpG，因此可能受到DNA甲基化的影响。CTCF能够在<strong>体外结合甲基化DNA序列</strong>，但<strong>优先结合未甲基化的序列</strong>，在H19-Igf2位点也可以看到。事实上，DNA甲基化似乎在CTCF的一些组织特异性结合事件中发挥作用。此外，<strong>CTCF</strong>可以通过与两种与DNA甲基化相关的酶:多聚(adp -核糖)聚合酶1 (<strong>PARP1</strong>)和无处不在表达的DNA(胞嘧啶-5)甲基转移酶1 (<strong>DNMT1</strong>)形成<strong>复合物来影响DNA甲基化</strong>。<strong>CTCF激活PARP1, PARP1在DNMT1上添加adp -核糖基团使DNMT1失活，从而维持无甲基CpGs的存在</strong>。</p>
<p><strong>部分CTCF结合位点</strong>在<strong>活性染色质</strong>(<strong>高H2K5Ac</strong>)和<strong>非活性</strong>染色质结构域(<strong>高H3K27me3</strong>)之<strong>间</strong>的过渡<strong>富集</strong>。对于逆转录转座的CTCF结合位点似乎尤其如此。CTCF位点经常位于所谓的<strong>膜相关域</strong>(lad)旁边。lad是与<strong>覆盖核膜内侧的层状蛋白网络相关的染色体区域</strong>;这些染色体区域往往是<strong>转录不活跃</strong>的。它的存在提示<strong>CTCF有助于染色质的三维结构的组织</strong>。在果蝇中，CTCF的抑制导致非活性域内H3K27me3水平的降低，表明CTCF在边界上的结合是<strong>维持抑制</strong>所必需的。CTCF的关联伴随着细胞分化过程中<strong>活性域和非活性域的重置</strong>，进一步表明它的功能是<strong>分离不同的染色质状态</strong>。一些lad在细胞分化过程中也会发生动态变化[35]，但CTCF是否与这些差异lad的边界结合目前尚不清楚。</p>
<p>尽管CTCF结合常出现在TSSs远端，但它确实与<strong>基因密度有很强的相关性</strong>(图2a,b)。事实上，CTCF在转录调控中<strong>直接作用的证据来自于早期对单个基因的研究</strong>。在全基因组范围内，部分CTCF位点与<strong>启动子特异性H3K4me3标记共定位</strong>，另一部分与<strong>增强子标记H3K4me1重合</strong>。启动子上的CTCF结合事件在组织中趋于<strong>保守</strong>，而CTCF与增强子的结合则更受<strong>组织限制</strong>。</p>
<p><img src="/blog/2022-02-15-CTCF/rstb20120369-g2.jpg" alt="An external file that holds a picture, illustration, etc. Object name is rstb20120369-g2.jpg"></p>
<p>Figure2. CTCF在染色质生物学中的广泛作用。(a) CTCF结合位点的全基因组功能分类，采用Chen et al.[36]。(b) (i) CTCF结合位点位于<strong>分离活性域和非活性域的边界</strong>上。CTCF结合到(ii)<strong>增强子</strong>样序列和(iv)基因<strong>启动子</strong>上可以促进这些序列之间的环环相扣。(iii) CTCF结合在<strong>增强子和基因启动子之间</strong>，可以<strong>阻断</strong>增强子与其目标启动子之间的相互作用。</p>
<ol start="4">
<li>CTCF和内聚蛋白共享DNA结合位点</li>
<li>5.ctcf和其他绑定伙伴</li>
<li>CTCF在单个基因位点的功能</li>
<li>CTCF介导的全基因组染色质环</li>
</ol>
<p>CTCF的基因组结合位点(通过全基因组<strong>ChIP</strong>)与<strong>Hi-C</strong>生成的<strong>genome-wide DNA contact map</strong>的计算交叉表明，CTCF参与染色体之间和基因组内的染色质相互作用。染色质相互作用分析与配对末端标记测序<strong>Chromatin interaction analysis with paired-end tag sequencing (ChIA-PET)</strong> 结合了ChIP和3C方法，用于研究由<strong>感兴趣的蛋白质介导的全基因组DNA相互作用</strong>。当靶向CTCF时，ChIA-PET揭示了蛋白介导的大约<strong>1500个染色体内</strong>和<strong>300个染色体间</strong>的相互作用。随后，根据<strong>组蛋白标记</strong>的分布，对<strong>染色体内环</strong>所包围的<strong>区域(10-200 kb)进行聚类</strong>。这表明CTCF环可以包含从环外非活性染色质分离出来的活性染色质，反之亦然。CTCF还可以同时<strong>捕获染色质环中的增强子和启动子</strong>。在大约<strong>40000个CTCF结合位点</strong>中，只有<strong>一小部分</strong>参与了大约1500个CTCF介导的<strong>环</strong>。这意味着不是所有CTCF介导的相互作用都被识别出来了，或者<strong>大多数CTCF位点没有参与环的形成</strong>。</p>
<p>后者很可能是正确的，因为5C(<strong>chromosome conformation capture carbon copy</strong>染色体构象捕获碳复制)技术表明，在1%的基因组中，大多数CTCF位点不参与染色质环，无论它们是否被内聚蛋白共同占据。<strong>CTCF结合序列常被基因启动子跳过，与增强子或更远的CTCF位点进行接触</strong>。</p>
<p>最近大量的全基因组DNA相互作用数据集有助于<strong>评估CTCF对染色体拓扑的影响</strong>。染色体上靠近<strong>CTCF结合位点的序列</strong>显示在它们的DNA接触中存在偏倚:它们与<strong>CTCF位点同侧</strong>的其他<strong>序列的相互作用</strong>大于与<strong>CTCF位点跨侧</strong>的序列的相互作用(图3a;)。同样的结果也出现在果蝇中另一种不同的绝缘体蛋白上:它与一个位点的结合阻止了侧翼序列在这个位点上相互接触。有趣的是，这可能为绝缘体的功能提供了一种解释:它们可以阻止DNA在绝缘序列上的空间接触。在一个特别详细的全基因组DNA接触研究中，<strong>拓扑域</strong>被定义;它们是<strong>平均大小为1mb的染色体区域</strong>，其中<strong>序列优先相互作用</strong>。在组织之间，甚至在物种之间，拓扑结构域具有很强的<strong>保持性</strong>，这表明这些结构域对<strong>细胞的特异性身份没有贡献</strong>。有趣的是，CTCF结合位点在这些<strong>区域边界周围的20kb窗口中富集</strong>(图3b)，再次强调了其作为<strong>染色质组织者</strong>的作用。其中一项研究表明，边界的破坏会导致拓扑域的混合，并导致相关基因的表达失调[79]。不同于拓扑域本身，域内的接触在分化过程中是变化的。在这里，CTCF似乎发挥了作用，可能适应基因表达的发育变化。</p>
<p><img src="/blog/2022-02-15-CTCF/rstb20120369-g3.jpg" alt="An external file that holds a picture, illustration, etc. Object name is rstb20120369-g3.jpg"></p>
<p>Fig 3. CTCF通过阻碍DNA在其结合位点上的接触而起到绝缘体的作用。(a) CTCF<strong>阻碍其结合位点在10kb以内的序列跨越</strong>。<strong>线的厚度减小表明交互作用的概率减小</strong>。(b) CTCF结合位点常出现在拓扑域的边界处。(i) ESCs和皮质的Hi-c数据，用小鼠第12号染色体序列之间的颜色编码接触频率。<strong>三角形</strong>显示和突出<strong>拓扑域</strong>，是<strong>染色体序列优先相互作用的区域</strong>。(ii)层关联域(LAD)数据，LAD边界与拓扑域边界重合。(iii) CTCF ChIP-seq profiles，显示在边界的CTCF结合位点簇。请注意，这种CTCF集群在其他地方也存在，特别是在非lad地区。显示区域:chr12: 112.3-119.3 Mb (mm9)。</p>
<ol start="8">
<li>结论</li>
</ol>
<p>尽管CTCF一直是研究的热点，但它仍然是一种<strong>神秘的转录因子</strong>。它与基因组中成千上万个位点结合，与大量其他转录因子相互作用。它常被发现参与染色质<strong>环</strong>，有时有，有时没有<strong>内聚蛋白</strong>的参与。它可以<strong>与其他CTCF结合位点</strong>形<strong>成</strong>染色质<strong>环</strong>，也可以与<strong>增强子</strong>和<strong>启动子</strong>序列形<strong>成</strong>染色质<strong>环</strong>。CTCF不仅与基因内外的序列结合，也与<strong>基因体内</strong>的<strong>序列结合</strong>，在基因体内它似乎能够<strong>暂停滑动聚合酶分子</strong>。最后，CTCF结合位点仍然作为<strong>反转录转座序列</strong>活跃地跳跃，使CTCF结合景观在不同哺乳动物物种之间具有多样性。</p>
<p>可以解释CTCF与染色质关联的许多，<strong>有时是相反的功能</strong>后果的统一主题可能是其<strong>成环能力</strong>。根据环中包含的序列和环外的序列，由CTCF形成的染色质可能会<strong>促进或阻碍增强子和靶基因之间的三维接触</strong>，从而产生不同的转录结果。许多问题仍然存在:为什么一些CTCF位点形成染色质环而另一些则没有?这在多大程度上依赖于相关的蛋白质因子?当蛋白质与染色质结合时，它是如何设法与这么多其他转录因子相互作用的?一种可能是CTCF作为染色质扫描转录因子的路障，当遇到结合蛋白时，这些转录因子以某种方式被困住。ctcf介导的染色体间接触有何相关性?CTCF是否通过阻止3D DNA接触来阻断增强子-启动子通信?或者绝缘是否涉及绝缘体序列与增强剂和启动剂的物理相互作用?这些问题的答案需要能够预测给定的CTCF结合事件是否在功能上不相关，是否会引起转录激活或抑制，是否会干扰转录激活或会产生染色质边界。</p>
]]></content>
      <categories>
        <category>biology</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>【GO】【KEGG】</title>
    <url>/blog/2021/12/20/2021_12_20_GO_KEGG_post/</url>
    <content><![CDATA[<h2 id="Oryza-Sativa-【Gene-ID】【GO】【KEGG】"><a href="#Oryza-Sativa-【Gene-ID】【GO】【KEGG】" class="headerlink" title="Oryza Sativa 【Gene ID】【GO】【KEGG】"></a>Oryza Sativa 【Gene ID】【GO】【KEGG】</h2><span id="more"></span>

<p><strong>GO分析</strong>：基因-&gt;功能类群</p>
<p>**KEGG(Pathway)**：基因-&gt;代谢网络</p>
<p><strong>GO/KEGG选取目标基因</strong></p>
<ul>
<li><p>指标：Enrichment score，p值，FDR</p>
</li>
<li><p>pathway：p和FDR越小越好，问题是有时本就不易富集出，如何取舍</p>
</li>
<li><p>GO：p，FDR，Enrichmentscore（越大越容易受到影响）</p>
</li>
<li><p><font color="green">fold change较大的基因</font>（up，down）</p>
</li>
<li><p>可能有用的蛋白，PPI？</p>
</li>
</ul>
<p>GO: 研究的基因哪些通路？是否变化</p>
<p><strong>KEGG筛选方法：</strong></p>
<ul>
<li>先看KEGG的聚类分析结果（感兴趣研究方向有关的基因是不是有差异）→ GO分为三个分枝，先看BP分枝（感兴趣研究方向有关的基因是不是有差异）→挑选和我们研究比较相关的→后期验证：选FC比较大，验证成功率会高一些</li>
<li>根据Rich factor值、Qvalue值或<font color="green">富集到此通路上的基因个数来衡量KEGG的富集程度</font>，找到富集最显著的通路</li>
<li>找自己感兴趣的：高原反应-&gt;呼吸功能相关通路，免疫系统-&gt;炎症因子、TNF相关通路</li>
<li>从通路中去找到<font color="green">表达倍数显著的基因进行验证</font>，进一步解释相关分子表达机制</li>
</ul>
<p><strong>目标表示</strong></p>
<p>HOTAIR出没于胞核（CC），参与了组蛋白甲基化调控引发癌基因沉默（BP），具体是结合PRC2复合物以及LSD1（MF）</p>
<hr>
<p><strong>转录组数据中筛选关键基因</strong></p>
<p>筛选关键基因的方法有3类：</p>
<p>1.表达量﹢功能富集</p>
<p>2.表达量﹢实验</p>
<p>3.表达量﹢序列</p>
<p>上面的三种方法不难看出，筛选关键基因的<font color="green">核心</font>是<font color="green">表达量</font>，其实转录组的核心就是以表达量为核心展开其他分析的，然后再附加其他一些信息，找出目标基因；最后将分析结果与研究目的巧妙融合，如果再做一些基因功能实验验证（高分必备，可不做），一篇高质量的文章就ok了。</p>
<p><strong>1.表达量﹢功能富集</strong></p>
<p>Zhu T, Wang X, Xu Z, Xu J, Li R, et al. (2020) Screening of key genes responsible for Pennisetum setaceum ‘Rubrum’ leaf color using tranome sequencing. PLOS ONE 15(11): e0242618.</p>
<p>该文研究对象狼尾草观赏草植物，<font color="green">高光</font>环产紫色叶子，<font color="green">低光</font>产浅紫色或绿色叶子。该文鉴定与<font color="green">叶片着色相关的关键基因</font>，并阐明参与狼尾草叶子的颜色变化的分子机制。</p>
<p>差异表达基因分析总共鉴定了19043个DEGs，与T0（未处理阶段的叶子）阶段的表达相比，在T1（遮阴12天后新叶子完全变绿的阶段）阶段上调和下调的基因分别为10761和8642。<font color="green">KEGG富集分析发现，显著富集的通路主要有类黄酮的生物合成，黄酮和黄酮醇的生物合成以及类胡萝卜素的生物合成</font>。<font color="red">基因筛选(显著KEGG内的基因筛选？)</font>发现存在与<strong>叶绿素代谢</strong>有关的31个差异表达基因，其中21个与叶绿素的生物<strong>合成</strong>有关，有10个与叶绿素的<strong>降解</strong>有关，以及3个与叶绿素<strong>降解调控</strong>有关的转录因子，<strong>花青素的合成和积</strong>累有31个关键酶基因，4个可能参与<strong>花色苷代谢调控</strong>的转录因子（图1所示） 。</p>
<p><img src="/blog/2021/12/20/2021_12_20_GO_KEGG_post/selectDEG.png" alt="selectDEG"></p>
<p>快速筛选出感兴趣的基因：基因长度、基因在样品中的表达量、<strong>差异倍数</strong>、<strong>注释信息</strong>等。</p>
<p><font color="green">找显著通路里的基因。做一个信息表。</font></p>
<p><strong>2.表达量﹢实验</strong></p>
<p>Wang A, Chao T, Ji Z, Xuan R, Liu S, Guo M, Wang G, Wang J. 2020. Tranome analysis reveals potential immune function-related regulatory genes/pathways of female Lubo goat submandibular glands at different developmental stages. PeerJ 8:e9947.</p>
<p>课题组前期的基因功能实验或文献查阅来借助别人的已经验证过的基因功能结果，之后再根据表达量筛选关键基因。</p>
<p>转录组研究的目的就是寻找与实验设计相关的关键基因，一般来说研究某生理现象都先要阅读大量文献来判断该实验的可行性。如转录组分析揭示了雌性鲁波<strong>山羊下颌腺</strong>在<strong>不同发育阶段</strong>的潜在<strong>免疫功能相关调节基因</strong>或途径</p>
<p>该文研究的目的是通过<strong>转录组测序</strong>来<strong>定位</strong>差异表达基因（DEG）在<strong>三个不同阶段的表达谱</strong>，预测在<strong>不同发育阶段</strong>的<strong>下颌下腺的免疫功能</strong>。由于<strong>人、小鼠、大鼠、牛</strong>的下颌腺都检测到了<strong>相关抗体</strong>，并且研究发现了下颌腺中的<strong>类红细胞分化因子、内皮素、肝细胞生长因子（HGF）、转移性生长因子（MGF）、转化生长因子-α（TGF-α）和其他因子</strong>。所以在<strong>后续的基因筛选中会重点关注相关因子的表达基因</strong>。</p>
<p>从上面例子中可以发现一个<strong>套路</strong>，先查阅模式生物中该方面的研究结果，然后再结合自己的研究项目筛选出基因，并且<strong>重点关注模式生物中已知的功能基因有没有较大的差异倍数</strong>。</p>
<hr>
<p>ref：</p>
<p><a href="https://zhuanlan.zhihu.com/p/78093534">https://zhuanlan.zhihu.com/p/78093534</a></p>
<p><a href="https://www.sohu.com/a/437865907_278730">https://www.sohu.com/a/437865907_278730</a></p>
<hr>
<h1 id="转录组图形专题之差异基因相关图形"><a href="#转录组图形专题之差异基因相关图形" class="headerlink" title="转录组图形专题之差异基因相关图形"></a>转录组图形专题之差异基因相关图形</h1><p>雷达图、热图、柱状图、韦恩图、火山图</p>
<p><a href="https://www.sohu.com/a/428207189_278730">https://www.sohu.com/a/428207189_278730</a></p>
<h1 id="全套的富集分析相关图形详解"><a href="#全套的富集分析相关图形详解" class="headerlink" title="全套的富集分析相关图形详解"></a>全套的富集分析相关图形详解</h1><p>柱形图，气泡图，圈图，z-score图，网络图</p>
<p><a href="https://www.sohu.com/a/436470973_278730">https://www.sohu.com/a/436470973_278730</a></p>
]]></content>
      <categories>
        <category>GO</category>
        <category>KEGG</category>
      </categories>
      <tags>
        <tag>O_Sativa</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux command awk</title>
    <url>/blog/2021/12/17/2021_12_17_Linux_awk_command/</url>
    <content><![CDATA[<h2 id="Linux-command-【awk】"><a href="#Linux-command-【awk】" class="headerlink" title="Linux command 【awk】"></a>Linux command 【awk】</h2><span id="more"></span>

<h1 id="Linux-awk-命令"><a href="#Linux-awk-命令" class="headerlink" title="Linux awk 命令"></a>Linux awk 命令</h1><p><a href="https://www.runoob.com/linux/linux-command-manual.html"><img src="https://www.runoob.com/images/up.gif" alt="Linux 命令大全"> Linux 命令大全</a></p>
<p>AWK 是一种<font color="green">处理文本文件</font>的语言，是一个强大的文本分析工具。</p>
<p>之所以叫 AWK 是因为其取了三位创始人 Alfred <strong>A</strong>ho，Peter <strong>W</strong>einberger, 和 Brian <strong>K</strong>ernighan 的 Family Name 的首字符。</p>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk [选项参数] <span class="string">&#x27;script&#x27;</span> var=value file(s)</span><br><span class="line">或</span><br><span class="line">awk [选项参数] -f scriptfile var=value file(s)</span><br></pre></td></tr></table></figure>

<p><strong>选项参数说明：</strong></p>
<ul>
<li>-F fs or –field-separator fs<br>指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如<font color="green">-F:</font>。</li>
<li>-v var=value or –asign var=value<br>赋值一个用户定义变量。</li>
<li>-f scripfile or –file scriptfile<br>从脚本文件中读取awk命令。</li>
<li>-W posix<br>打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符<strong>和</strong>=不能代替^和^=；fflush无效?</li>
<li>-W version or –version<br>打印<font color="green">bug报告信息</font>的版本。</li>
</ul>
<hr>
<h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>log.txt文本内容如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">2 this is a <span class="built_in">test</span></span><br><span class="line">3 Are you like awk</span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">10 There are orange,apple,mongo</span></span><br></pre></td></tr></table></figure>

<p>用法一：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;[pattern] action&#125;&#x27;</span> &#123;filenames&#125;   <span class="comment"># 行匹配语句 awk &#x27;&#x27; 只能用单引号</span></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 每行按空格或TAB分割，输出文本中的1、4项</span></span><br><span class="line"> $ awk <span class="string">&#x27;&#123;print $1,$4&#125;&#x27;</span> log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 a</span><br><span class="line"> 3 like</span><br><span class="line"> This<span class="string">&#x27;s</span></span><br><span class="line"><span class="string"> 10 orange,apple,mongo</span></span><br><span class="line"><span class="string"> # 格式化输出</span></span><br><span class="line"><span class="string"> $ awk &#x27;</span>&#123;<span class="built_in">printf</span> <span class="string">&quot;%-8s %-10s\n&quot;</span>,<span class="variable">$1</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string"> ---------------------------------------------</span></span><br><span class="line"><span class="string"> 2        a</span></span><br><span class="line"><span class="string"> 3        like</span></span><br><span class="line"><span class="string"> This&#x27;</span>s</span><br><span class="line"> 10       orange,apple,mongo</span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<p><font color="green">用法二：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk -F  <span class="comment">#-F相当于内置变量FS, 指定分割字符</span></span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用&quot;,&quot;分割</span></span><br><span class="line"> $  awk -F, <span class="string">&#x27;&#123;print $1,$2&#125;&#x27;</span>   log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 this is a <span class="built_in">test</span></span><br><span class="line"> 3 Are you like awk</span><br><span class="line"> This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string"> 10 There are orange apple</span></span><br><span class="line"><span class="string"> # 或者使用内建变量</span></span><br><span class="line"><span class="string"> $ awk &#x27;</span>BEGIN&#123;FS=<span class="string">&quot;,&quot;</span>&#125; &#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$2</span>&#125;<span class="string">&#x27;     log.txt</span></span><br><span class="line"><span class="string"> ---------------------------------------------</span></span><br><span class="line"><span class="string"> 2 this is a test</span></span><br><span class="line"><span class="string"> 3 Are you like awk</span></span><br><span class="line"><span class="string"> This&#x27;</span>s a <span class="built_in">test</span></span><br><span class="line"> 10 There are orange apple</span><br><span class="line"> <span class="comment">#! 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割</span></span><br><span class="line"> $ awk -F <span class="string">&#x27;[ ,]&#x27;</span>  <span class="string">&#x27;&#123;print $1,$2,$5&#125;&#x27;</span>   log.txt</span><br><span class="line"> ---------------------------------------------</span><br><span class="line"> 2 this <span class="built_in">test</span></span><br><span class="line"> 3 Are awk</span><br><span class="line"> This<span class="string">&#x27;s a</span></span><br><span class="line"><span class="string"> 10 There apple</span></span><br></pre></td></tr></table></figure>

<p><font color="green">用法三：</font>-va -vb</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">awk -v  # 设置变量</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -va=1 <span class="string">&#x27;&#123;print $1,$1+a&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">2 3</span><br><span class="line">3 4</span><br><span class="line">This<span class="string">&#x27;s 1</span></span><br><span class="line"><span class="string">10 11</span></span><br><span class="line"><span class="string">$ awk -va=1 -vb=s &#x27;</span>&#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$1</span>+a,<span class="variable">$1b</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">2 3 2s</span></span><br><span class="line"><span class="string">3 4 3s</span></span><br><span class="line"><span class="string">This&#x27;</span>s 1 This<span class="string">&#x27;ss</span></span><br><span class="line"><span class="string">10 11 10s</span></span><br></pre></td></tr></table></figure>

<p>用法四：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk -f &#123;awk脚本&#125; &#123;文件名&#125;</span><br></pre></td></tr></table></figure>

<p>实例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -f cal.awk log.txt</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><table>
<thead>
<tr>
<th align="left">运算符</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">= += -= *= /= %= ^= **=</td>
<td align="left">赋值</td>
</tr>
<tr>
<td align="left">?:</td>
<td align="left">C条件表达式</td>
</tr>
<tr>
<td align="left">||</td>
<td align="left">逻辑或</td>
</tr>
<tr>
<td align="left">&amp;&amp;</td>
<td align="left">逻辑与</td>
</tr>
<tr>
<td align="left">~ 和 !~</td>
<td align="left">匹配正则表达式和不匹配正则表达式</td>
</tr>
<tr>
<td align="left">&lt; &lt;= &gt; &gt;= != ==</td>
<td align="left">关系运算符</td>
</tr>
<tr>
<td align="left">空格</td>
<td align="left">连接</td>
</tr>
<tr>
<td align="left">+ -</td>
<td align="left">加，减</td>
</tr>
<tr>
<td align="left">* / %</td>
<td align="left">乘，除与求余</td>
</tr>
<tr>
<td align="left">+ - !</td>
<td align="left">一元加，减和逻辑非</td>
</tr>
<tr>
<td align="left">^ ***</td>
<td align="left">求幂</td>
</tr>
<tr>
<td align="left">++ –</td>
<td align="left">增加或减少，作为前缀或后缀</td>
</tr>
<tr>
<td align="left">$</td>
<td align="left">字段引用</td>
</tr>
<tr>
<td align="left">in</td>
<td align="left">数组成员</td>
</tr>
</tbody></table>
<p>过滤第一列大于2的行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1&gt;2&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">3 Are you like awk</span><br><span class="line">This&#x27;s a test</span><br><span class="line">10 There are orange,apple,mongo</span><br></pre></td></tr></table></figure>

<p>过滤第一列等于2的行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1==2 &#123;print $1,$3&#125;&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">2 is</span><br></pre></td></tr></table></figure>

<p><font color="green">过滤第一列大于2并且第二列等于’Are’的行</font></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ awk &#x27;$1&gt;2 &amp;&amp; $2==&quot;Are&quot; &#123;print $1,$2,$3&#125;&#x27; log.txt    #命令</span><br><span class="line">#输出</span><br><span class="line">3 Are you</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="内建变量"><a href="#内建变量" class="headerlink" title="内建变量"></a>内建变量</h2><table>
<thead>
<tr>
<th align="left">变量</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">$n</td>
<td align="left">当前记录的<font color="green">第n个字段</font>，字段间由FS分隔</td>
</tr>
<tr>
<td align="left"><font color="red">$0</font></td>
<td align="left"><font color="green">完整的输入记录</font></td>
</tr>
<tr>
<td align="left">ARGC</td>
<td align="left">命令行参数的数目</td>
</tr>
<tr>
<td align="left">ARGIND</td>
<td align="left">命令行中当前文件的位置(从0开始算)</td>
</tr>
<tr>
<td align="left">ARGV</td>
<td align="left">包含命令行参数的数组</td>
</tr>
<tr>
<td align="left">CONVFMT</td>
<td align="left">数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组</td>
</tr>
<tr>
<td align="left">ERRNO</td>
<td align="left">最后一个系统错误的描述</td>
</tr>
<tr>
<td align="left">FIELDWIDTHS</td>
<td align="left">字段宽度列表(用空格键分隔)</td>
</tr>
<tr>
<td align="left">FILENAME</td>
<td align="left">当前文件名</td>
</tr>
<tr>
<td align="left"><strong>FNR</strong></td>
<td align="left">各文件分别计数的行号</td>
</tr>
<tr>
<td align="left"><strong>FS</strong></td>
<td align="left">字段分隔符(默认是任何空格)</td>
</tr>
<tr>
<td align="left">IGNORECASE</td>
<td align="left">如果为真，则进行忽略大小写的匹配</td>
</tr>
<tr>
<td align="left"><strong>NF</strong></td>
<td align="left">一条记录的字段的数目</td>
</tr>
<tr>
<td align="left"><strong>NR</strong></td>
<td align="left">已经读出的记录数，就是行号，从1开始</td>
</tr>
<tr>
<td align="left">OFMT</td>
<td align="left">数字的输出格式(默认值是%.6g)</td>
</tr>
<tr>
<td align="left"><strong>OFS</strong></td>
<td align="left">输出字段分隔符，默认值与输入字段分隔符一致。</td>
</tr>
<tr>
<td align="left"><strong>ORS</strong></td>
<td align="left">输出记录分隔符(默认值是一个换行符)</td>
</tr>
<tr>
<td align="left">RLENGTH</td>
<td align="left">由match函数所匹配的字符串的长度</td>
</tr>
<tr>
<td align="left">RS</td>
<td align="left">记录分隔符(默认是一个换行符)</td>
</tr>
<tr>
<td align="left">RSTART</td>
<td align="left">由match函数所匹配的字符串的第一个位置</td>
</tr>
<tr>
<td align="left">SUBSEP</td>
<td align="left">数组下标分隔符(默认值是/034)</td>
</tr>
</tbody></table>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#看各变量值</span></span><br><span class="line">$ awk <span class="string">&#x27;BEGIN&#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,&quot;FILENAME&quot;,&quot;ARGC&quot;,&quot;FNR&quot;,&quot;FS&quot;,&quot;NF&quot;,&quot;NR&quot;,&quot;OFS&quot;,&quot;ORS&quot;,&quot;RS&quot;;printf &quot;---------------------------------------------\n&quot;&#125; &#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;&#x27;</span>  log.txt</span><br><span class="line">FILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS</span><br><span class="line">---------------------------------------------</span><br><span class="line">log.txt    2    1         5    1</span><br><span class="line">log.txt    2    2         5    2</span><br><span class="line">log.txt    2    3         3    3</span><br><span class="line">log.txt    2    4         4    4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出顺序号 NR, 匹配文本行号</span></span><br><span class="line">$ awk <span class="string">&#x27;&#123;print NR,FNR,$1,$2,$3&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">1 1 2 this is</span><br><span class="line">2 2 3 Are you</span><br><span class="line">3 3 This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">4 4 10 There are</span></span><br><span class="line"><span class="string"># 指定输出分割符</span></span><br><span class="line"><span class="string">$  awk &#x27;</span>&#123;<span class="built_in">print</span> <span class="variable">$1</span>,<span class="variable">$2</span>,<span class="variable">$5</span>&#125;<span class="string">&#x27; OFS=&quot; $ &quot;  log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">2 $ this $ test</span></span><br><span class="line"><span class="string">3 $ Are $ awk</span></span><br><span class="line"><span class="string">This&#x27;</span>s $ a $</span><br><span class="line">10 $ There $</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="使用正则，字符串匹配"><a href="#使用正则，字符串匹配" class="headerlink" title="使用正则，字符串匹配"></a><font color="green">使用正则，字符串匹配</font></h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出第二列包含 &quot;th&quot;，并打印第二列与第四列</span></span><br><span class="line">$ awk <span class="string">&#x27;$2 ~ /th/ &#123;print $2,$4&#125;&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">this a</span><br><span class="line"><span class="comment">#$0是b.txt每一行全部字段，-i &#123;&#125; a.txt 一行一行赋值给 &#123;&#125;</span></span><br><span class="line">cat a.txt | xargs -i awk <span class="string">&#x27;BEGIN&#123;FS=&quot;\t&quot;&#125; $0 ~/&#123;&#125;/ &#123; print &#125;&#x27;</span> b.txt &gt; c.txt</span><br></pre></td></tr></table></figure>

<p><strong>~ 表示模式开始。// 中是模式。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出包含 &quot;re&quot; 的行</span></span><br><span class="line">$ awk <span class="string">&#x27;/re/ &#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">3 Are you like awk</span><br><span class="line">10 There are orange,apple,mongo</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="忽略大小写"><a href="#忽略大小写" class="headerlink" title="忽略大小写"></a>忽略大小写</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk <span class="string">&#x27;BEGIN&#123;IGNORECASE=1&#125; /this/&#x27;</span> log.txt</span><br><span class="line">---------------------------------------------</span><br><span class="line">2 this is a <span class="built_in">test</span></span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="模式取反"><a href="#模式取反" class="headerlink" title="模式取反"></a>模式取反</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">this is</span><br><span class="line">Are you</span><br><span class="line">This<span class="string">&#x27;s a test</span></span><br><span class="line"><span class="string">There are</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">$ awk &#x27;</span><span class="variable">$2</span> !~ /th/ &#123;<span class="built_in">print</span> <span class="variable">$2</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">Are like</span></span><br><span class="line"><span class="string">a</span></span><br><span class="line"><span class="string">There orange,apple,mongo</span></span><br><span class="line"><span class="string">$ awk &#x27;</span>!/th/ &#123;<span class="built_in">print</span> <span class="variable">$2</span>,<span class="variable">$4</span>&#125;<span class="string">&#x27; log.txt</span></span><br><span class="line"><span class="string">---------------------------------------------</span></span><br><span class="line"><span class="string">Are like</span></span><br><span class="line"><span class="string">a</span></span><br><span class="line"><span class="string">There orange,apple,mongo</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="awk脚本"><a href="#awk脚本" class="headerlink" title="awk脚本"></a>awk脚本</h2><p>关于 awk 脚本，我们需要注意两个关键词 BEGIN 和 END。</p>
<ul>
<li>BEGIN{ 这里面放的是<font color="green">执行前</font>的语句 }</li>
<li>END {这里面放的是处理完<font color="green">所有的行后要执行</font>的语句 }</li>
<li>{这里面放的是处理<font color="green">每一行时</font>要执行的语句}</li>
</ul>
<p>假设有这么一个文件（学生成绩表）：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ cat score.txt</span><br><span class="line">Marry   2143 78 84 77</span><br><span class="line">Jack    2321 66 78 45</span><br><span class="line">Tom     2122 48 77 71</span><br><span class="line">Mike    2537 87 97 95</span><br><span class="line">Bob     2415 40 57 62</span><br></pre></td></tr></table></figure>

<p>我们的 awk 脚本如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ cat cal.awk</span><br><span class="line"><span class="comment">#!/bin/awk -f</span></span><br><span class="line"><span class="comment">#运行前</span></span><br><span class="line">BEGIN &#123;</span><br><span class="line">    math = 0</span><br><span class="line">    english = 0</span><br><span class="line">    computer = 0</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n&quot;</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;---------------------------------------------\n&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#运行中</span></span><br><span class="line">&#123;</span><br><span class="line">    math+=<span class="variable">$3</span></span><br><span class="line">    english+=<span class="variable">$4</span></span><br><span class="line">    computer+=<span class="variable">$5</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;%-6s %-6s %4d %8d %8d %8d\n&quot;</span>, <span class="variable">$1</span>, <span class="variable">$2</span>, <span class="variable">$3</span>,<span class="variable">$4</span>,<span class="variable">$5</span>, <span class="variable">$3</span>+<span class="variable">$4</span>+<span class="variable">$5</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#运行后</span></span><br><span class="line">END &#123;</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;---------------------------------------------\n&quot;</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;  TOTAL:%10d %8d %8d \n&quot;</span>, math, english, computer</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;AVERAGE:%10.2f %8.2f %8.2f\n&quot;</span>, math/NR, english/NR, computer/NR</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们来看一下执行结果：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ awk -f cal.awk score.txt</span><br><span class="line">NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL</span><br><span class="line">---------------------------------------------</span><br><span class="line">Marry  2143     78       84       77      239</span><br><span class="line">Jack   2321     66       78       45      189</span><br><span class="line">Tom    2122     48       77       71      196</span><br><span class="line">Mike   2537     87       97       95      279</span><br><span class="line">Bob    2415     40       57       62      159</span><br><span class="line">---------------------------------------------</span><br><span class="line">  TOTAL:       319      393      350</span><br><span class="line">AVERAGE:     63.80    78.60    70.00</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="另外一些实例"><a href="#另外一些实例" class="headerlink" title="另外一些实例"></a>另外一些实例</h2><p>AWK 的 hello world 程序为：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">BEGIN &#123; <span class="built_in">print</span> <span class="string">&quot;Hello, world!&quot;</span> &#125;</span><br></pre></td></tr></table></figure>

<p>计算文件大小</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ ls -l *.txt | awk <span class="string">&#x27;&#123;sum+=$5&#125; END &#123;print sum&#125;&#x27;</span></span><br><span class="line">--------------------------------------------------</span><br><span class="line">666581</span><br></pre></td></tr></table></figure>

<p>从文件中找出<font color="green">长度大于 80 的行</font>：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;length&gt;80&#x27;</span> log.txt</span><br></pre></td></tr></table></figure>

<p>打印九九乘法表</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">seq 9 | sed <span class="string">&#x27;H;g&#x27;</span> | awk -v RS=<span class="string">&#x27;&#x27;</span> <span class="string">&#x27;&#123;for(i=1;i&lt;=NF;i++)printf(&quot;%dx%d=%d%s&quot;, i, NR, i*NR, i==NR?&quot;\n&quot;:&quot;\t&quot;)&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>更多内容：</p>
<ul>
<li><a href="https://www.runoob.com/w3cnote/awk-work-principle.html">AWK 工作原理</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-arrays.html">AWK 数组</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-if-loop.html">AWK 条件语句与循环</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-user-defined-functions.html">AWK 用户自定义函数</a></li>
<li><a href="https://www.runoob.com/w3cnote/awk-built-in-functions.html">AWK 内置函数</a></li>
<li><a href="https://www.runoob.com/w3cnote/8-awesome-awk-built-in-variables.html">8 个有力的 Awk 内建变量</a></li>
<li><a href="http://www.gnu.org/software/gawk/manual/gawk.html">AWK 官方手册</a></li>
</ul>
</blockquote>
<p><strong>awk、sed、grep更适合的方向：</strong></p>
<ul>
<li> grep 更适合单纯的查找或匹配文本</li>
<li> sed 更适合编辑匹配到的文本</li>
<li> awk 更适合格式化文本，对文本进行较复杂格式处理</li>
</ul>
<p>关于awk内建变量个人见解，简单易懂</p>
<p>解释一下变量：</p>
<p>变量：分为内置变量和自定义变量;输入分隔符FS和输出分隔符OFS都属于内置变量。</p>
<p>内置变量就是awk预定义好的、内置在awk内部的变量，而自定义变量就是用户定义的变量。</p>
<ul>
<li> FS(Field Separator)：输入字段分隔符， 默认为空白字符</li>
<li> OFS(Out of Field Separator)：输出字段分隔符， 默认为空白字符</li>
<li> RS(Record Separator)：输入记录分隔符(输入换行符)， 指定输入时的换行符</li>
<li> ORS(Output Record Separate)：输出记录分隔符（输出换行符），输出时用指定符号代替换行符</li>
<li> NF(Number for Field)：当前行的字段的个数(即当前行被分割成了几列)</li>
<li> NR(Number of Record)：行号，当前处理的文本行的行号。</li>
<li> FNR：各文件分别计数的行号</li>
<li> ARGC：命令行参数的个数</li>
<li> ARGV：数组，保存的是命令行所给定的各参数</li>
</ul>
<p><strong>自定义变量的方法</strong></p>
<ul>
<li> 方法一：-v varname=value ，变量名区分字符大小写。</li>
<li> 方法二：在program中直接定义。</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux command xargs</title>
    <url>/blog/2021/12/17/2021_12_17_Linux_xargs_command/</url>
    <content><![CDATA[<h2 id="Linux-command-【xargs】"><a href="#Linux-command-【xargs】" class="headerlink" title="Linux command 【xargs】"></a>Linux command 【xargs】</h2><span id="more"></span>

<h1 id="Linux-xargs-命令"><a href="#Linux-xargs-命令" class="headerlink" title="Linux xargs 命令"></a>Linux xargs 命令</h1><p><a href="https://www.runoob.com/linux/linux-command-manual.html"><img src="/blog/Linux.command/up.gif" alt="Linux 命令大全"> Linux 命令大全</a></p>
<p>xargs（英文全拼： eXtended ARGuments）是给<font color="green">命令传递参数</font>的一个过滤器，也是<font color="green">组合多个命令</font>的一个工具。</p>
<p>xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。</p>
<p>xargs 也可以将单行或多行文本输入转换为其他格式，例如<font color="green">多行变单行，单行变多行</font>。</p>
<p>xargs 默认命令是 echo，这意味着通过<font color="green">管道传递给 xargs 的输入包含换行和空白</font>，通过 xargs 的处理，<font color="green">换行和空白将被空格取代</font>。</p>
<p>xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。</p>
<p>之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令，例如：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /sbin -perm +700 |ls -l       <span class="comment">#这个命令是错误的</span></span><br><span class="line">find /sbin -perm +700 |xargs ls -l   <span class="comment">#这样才是正确的</span></span><br></pre></td></tr></table></figure>

<p>xargs 一般是和管道一起使用。</p>
<p><strong>命令格式：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">somecommand |xargs -item  <span class="built_in">command</span></span><br></pre></td></tr></table></figure>

<p><strong>参数：</strong></p>
<ul>
<li>-a file 从文件中读入作为 stdin</li>
<li>-e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。</li>
<li>-p 当每次执行一个argument的时候询问一次用户。</li>
<li>-n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。</li>
<li>-t 表示先打印命令，然后再执行。</li>
<li><font color="green">-i 或是-I</font>，这得看linux支持了，将xargs的每项名称，一般是<font color="green">一行一行赋值给 {}，可以用 {} 代替</font>。</li>
<li>-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。</li>
<li>-s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。</li>
<li><font color="green">-L num 从标准输入一次读取 num 行送给 command 命令</font>。</li>
<li>-l 同 -L。</li>
<li>-d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。</li>
<li>-x exit的意思，主要是配合-s使用。。</li>
<li>-P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。</li>
</ul>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>xargs 用作替换工具，读取输入数据重新格式化后输出。</p>
<p>定义一个测试文件，内有多行文本数据：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt</span></span><br><span class="line"></span><br><span class="line">a b c d e f g</span><br><span class="line">h i j k l m n</span><br><span class="line">o p q</span><br><span class="line">r s t</span><br><span class="line">u v w x y z</span><br></pre></td></tr></table></figure>

<p><font color="green">多行输入单行输出：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt | xargs</span></span><br><span class="line">a b c d e f g h i j k l m n o p q r s t u v w x y z</span><br></pre></td></tr></table></figure>

<p><font color="green">-n 选项多行输出：</font></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat test.txt | xargs -n3</span></span><br><span class="line"></span><br><span class="line">a b c</span><br><span class="line">d e f</span><br><span class="line">g h i</span><br><span class="line">j k l</span><br><span class="line">m n o</span><br><span class="line">p q r</span><br><span class="line">s t u</span><br><span class="line">v w x</span><br><span class="line">y z</span><br></pre></td></tr></table></figure>

<p>-d 选项可以自定义一个定界符：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># echo &quot;nameXnameXnameXname&quot; | xargs -dX</span></span><br><span class="line"></span><br><span class="line">name name name name</span><br></pre></td></tr></table></figure>

<p>结合 -n 选项使用：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># echo &quot;nameXnameXnameXname&quot; | xargs -dX -n2</span></span><br><span class="line"></span><br><span class="line">name name</span><br><span class="line">name name</span><br></pre></td></tr></table></figure>

<p>读取 stdin，将格式化后的参数传递给命令</p>
<p>假设一个命令为 sk.sh 和一个保存参数的文件 arg.txt：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#sk.sh命令内容，打印出所有参数。</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> $*</span><br></pre></td></tr></table></figure>

<p>arg.txt文件内容：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat arg.txt</span></span><br><span class="line"></span><br><span class="line">aaa</span><br><span class="line">bbb</span><br><span class="line">ccc</span><br></pre></td></tr></table></figure>

<p>xargs 的一个选项 -I，使用 -I 指定一个替换字符串 {}，这个字符串在 xargs 扩展时会被替换掉，当 -I 与 xargs 结合使用，每一个参数命令都会被执行一次：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat arg.txt | xargs -I &#123;&#125; ./sk.sh -p &#123;&#125; -l</span></span><br><span class="line"></span><br><span class="line">-p aaa -l</span><br><span class="line">-p bbb -l</span><br><span class="line">-p ccc -l</span><br></pre></td></tr></table></figure>

<p>复制所有图片文件到 /data/images 目录下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ls *.jpg | xargs -n1 -I &#123;&#125; cp &#123;&#125; /data/images</span><br></pre></td></tr></table></figure>

<p>xargs 结合 find 使用</p>
<p>用 rm 删除太多的文件时候，可能得到一个错误信息：**/bin/rm Argument list too long.** 用 xargs 去避免这个问题：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.log&quot;</span> -print0 | xargs -0 rm -f</span><br></pre></td></tr></table></figure>

<p>xargs -0 将 \0 作为定界符。</p>
<p>统计一个源代码目录中所有 php 文件的行数：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.php&quot;</span> -print0 | xargs -0 wc -l</span><br></pre></td></tr></table></figure>

<p>查找所有的 jpg 文件，并且压缩它们：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find . -<span class="built_in">type</span> f -name <span class="string">&quot;*.jpg&quot;</span> -<span class="built_in">print</span> | xargs tar -czvf images.tar.gz</span><br></pre></td></tr></table></figure>

<p>xargs 其他应用</p>
<p>假如有<font color="green">一个文件包含了很多希望下载的 URL</font>，你能够使用 xargs下载所有链接：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat url-list.txt | xargs wget -c</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Oryza Sativa 【Gene ID】【GO】【KEGG】</title>
    <url>/blog/2021/12/16/2021_12_16_osa_GO_KEGG/</url>
    <content><![CDATA[<h2 id="Oryza-Sativa-【Gene-ID】【GO】【KEGG】"><a href="#Oryza-Sativa-【Gene-ID】【GO】【KEGG】" class="headerlink" title="Oryza Sativa 【Gene ID】【GO】【KEGG】"></a>Oryza Sativa 【Gene ID】【GO】【KEGG】</h2><span id="more"></span>

<h1 id="O-sativa-ID-区分"><a href="#O-sativa-ID-区分" class="headerlink" title="O_sativa ID 区分"></a>O_sativa ID 区分</h1><ul>
<li><p>MSU, <font color="red">RGAP7.0</font>(rice genome annotation project)：<strong>LOC_Os01g01010.1</strong>,  LOC_Osp#g#####，<strong>LOC_Os-Chr-g-number</strong></p>
</li>
<li><p><font color="red">RAP</font>(the rice annotation project), IRGSP-1.0: <strong>Os06t0664200</strong>，<strong>Os-Chr-g-number</strong></p>
</li>
<li><p><font color="red">KEGG支持</font>：osa：RefSeq ID（Gene ID：<strong>4334374</strong>）；dosa：RAP-DB ID（<strong>Os06t0664200-01</strong>）</p>
</li>
<li><p>疑问：RAP-DB ID为什么和IRGSP-1.0 ID多了个-01：RAP-Locus与RAP ID不同</p>
</li>
<li><p>clusterProfiler可能是目前KEGG富集分析最好的软件，因为能<strong>爬取最新的KEGG在线版数据库</strong>，而不是用不再更新的KEGG.db。</p>
</li>
<li><p>对于RGAP水稻的基因编号，如LOC_Os01g01010.1 我们要把它变成<code>Os06t0664200-01</code> RAP-ID的命名方式，符合<code>dosa</code>的要求。</p>
</li>
</ul>
<h2 id="转化id"><a href="#转化id" class="headerlink" title="转化id"></a>转化id</h2><ul>
<li><p>下载一个各个ID对应的文件：<a href="https://shigen.nig.ac.jp/rice/oryzabase/download/riceId%E3%80%82%E5%AF%B9%E4%BA%8ERGAP%E6%B0%B4%E7%A8%BB%E7%9A%84%E5%9F%BA%E5%9B%A0%E7%BC%96%E5%8F%B7%EF%BC%8C%E5%A6%82LOC_Os01g01010.1">https://shigen.nig.ac.jp/rice/oryzabase/download/riceId。对于RGAP水稻的基因编号，如LOC_Os01g01010.1</a> 把它变成<code>Os06t0664200-01</code> RAP-ID的命名方式，符合<code>dosa</code>的要求。</p>
</li>
<li><p>日本晴数据库：<a href="https://shigen.nig.ac.jp/rice/oryzabase">https://shigen.nig.ac.jp/rice/oryzabase</a></p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ grep LOC_Os01g01010.1  rice_id_20140620174522.txt</span><br><span class="line">Os01g0100100    Os01t0100100-01 J075199P03      301700  J075199P03              LOC_Os01g01010.1        AK242339</span><br><span class="line">cat LOC.txt | xargs -i awk <span class="string">&#x27;BEGIN&#123;FS=&quot;\t&quot;&#125;  $0 ~/&#123;&#125;/ &#123; print $2&#125;&#x27;</span> rice_id_20140620174522.txt &gt; RAP_id.txt</span><br></pre></td></tr></table></figure>



<hr>
<h1 id="超几何分布"><a href="#超几何分布" class="headerlink" title="超几何分布"></a>超几何分布</h1><p>它描述了从有限N个物件（其中包含M个指定种类的物件）中抽出n个物件，成功抽出该指定种类的物件的次数（不放回）。称为超几何分布。</p>
<p><a href="https://baike.baidu.com/item/%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83/4782968">https://baike.baidu.com/item/超几何分布/4782968</a></p>
<hr>
<h1 id="GO-enrichment：web"><a href="#GO-enrichment：web" class="headerlink" title="GO enrichment：web"></a>GO enrichment：web</h1><blockquote>
<p>网站：<a href="http://systemsbiology.cau.edu.cn/agriGOv2">http://systemsbiology.cau.edu.cn/agriGOv2</a>  华大</p>
</blockquote>
<h1 id="GO-enrichment：R-clusterProfiler"><a href="#GO-enrichment：R-clusterProfiler" class="headerlink" title="GO enrichment：R clusterProfiler"></a>GO enrichment：R clusterProfiler</h1><p><strong>X</strong> clusterprofiler不能用来做GO的富集分析，因为其20个物种中不包括水稻；</p>
<h2 id="获取Orgdb，"><a href="#获取Orgdb，" class="headerlink" title="获取Orgdb，"></a>获取Orgdb，</h2><p>AnnotationHub在线检索并抓取OrgDb</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; require(AnnotationHub)</span><br><span class="line">&gt; hub &lt;- AnnotationHub()</span><br><span class="line">&gt; query(hub, <span class="string">&quot;oryza sativa&quot;</span>)</span><br><span class="line">title</span><br><span class="line">  AH10561 | hom.Oryza_sativa.inp8.sqlite</span><br><span class="line">  AH55775 | org.Oryza_sativa_Japonica_Group.eg.sqlite</span><br><span class="line">&gt; rice &lt;- hub[[<span class="string">&#x27;AH55775&#x27;</span>]]</span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">&gt; <span class="built_in">length</span>(keys(rice))[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#通过检索，org.Oryza_sativa_Japonica_Group.eg.sqlite就是我们所要的OrgDb，可以通过相应的accession number, AH55775 抓取文件，并存入了rice对象中，它包含了32639个基因的注释</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">#这个OrgDb，包含有以下一些注释信息:</span></span><br><span class="line">&gt; columns(rice)</span><br><span class="line"> [<span class="number">1</span>] <span class="string">&quot;ACCNUM&quot;</span>      <span class="string">&quot;ALIAS&quot;</span>       <span class="string">&quot;CHR&quot;</span>         <span class="string">&quot;ENTREZID&quot;</span>    <span class="string">&quot;EVIDENCE&quot;</span></span><br><span class="line"> [<span class="number">6</span>] <span class="string">&quot;EVIDENCEALL&quot;</span> <span class="string">&quot;GENENAME&quot;</span>    <span class="string">&quot;GID&quot;</span>         <span class="string">&quot;GO&quot;</span>          <span class="string">&quot;GOALL&quot;</span></span><br><span class="line">[<span class="number">11</span>] <span class="string">&quot;ONTOLOGY&quot;</span>    <span class="string">&quot;ONTOLOGYALL&quot;</span> <span class="string">&quot;PMID&quot;</span>        <span class="string">&quot;REFSEQ&quot;</span>      <span class="string">&quot;SYMBOL&quot;</span></span><br><span class="line">  [<span class="number">16</span>] <span class="string">&quot;UNIGENE&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment">##我们可以使用bitr来转换ID，甚至于直接检索GO注释：</span></span><br><span class="line">&gt; require(clusterProfiler)</span><br><span class="line">&gt; bitr(keys(rice)[<span class="number">1</span>], <span class="string">&#x27;ENTREZID&#x27;</span>, <span class="built_in">c</span>(<span class="string">&quot;REFSEQ&quot;</span>, <span class="string">&quot;GO&quot;</span>, <span class="string">&quot;ONTOLOGY&quot;</span>), rice)</span><br><span class="line"><span class="string">&#x27;select()&#x27;</span> returned <span class="number">1</span>:many mapping between keys and columns</span><br><span class="line">  ENTREZID      REFSEQ         GO ONTOLOGY</span><br><span class="line"><span class="number">1</span>  <span class="number">3131385</span> NP_039457.2 GO:<span class="number">0005739</span>       CC</span><br><span class="line"><span class="number">2</span>  <span class="number">3131385</span> NP_039457.2 GO:<span class="number">0005763</span>       CC</span><br><span class="line"><span class="comment">##GO富集分析</span></span><br><span class="line">&gt; sample_genes &lt;- keys(rice)[<span class="number">1</span>:<span class="number">100</span>]</span><br><span class="line">&gt; head(sample_genes)</span><br><span class="line">[<span class="number">1</span>] <span class="string">&quot;3131385&quot;</span> <span class="string">&quot;3131390&quot;</span> <span class="string">&quot;3131391&quot;</span> <span class="string">&quot;3131392&quot;</span> <span class="string">&quot;3131393&quot;</span> <span class="string">&quot;3131394&quot;</span></span><br><span class="line"><span class="comment">##这里只是简单地使用ID列表中前100个ENTREZ基因ID，也可以使用其它的ID，通过借助于bitr进行转换，或者通过给enrichGO指定ID类型(keyType参数）。</span></span><br><span class="line">&gt; 有了OrgDb，使用起来，就跟文档中使用人类基因做为例子一样，用法一致，并且也可以通过clusterProfiler所提供的各种可视化函数对结果进行展示：</span><br><span class="line"></span><br><span class="line">&gt; require(clusterProfiler)</span><br><span class="line">&gt; res = enrichGO(sample_genes, OrgDb=rice, pvalueCutoff=<span class="number">1</span>, qvalueCutoff=<span class="number">1</span>)</span><br><span class="line">&gt; res</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># over-representation test</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#...@organism    Oryza sativa_Japonica_Group</span></span><br><span class="line"><span class="comment">#...@ontology    MF</span></span><br><span class="line"><span class="comment">#...@keytype     ENTREZID</span></span><br><span class="line"><span class="comment">#...@gene        chr [1:100] &quot;3131385&quot; &quot;3131390&quot; &quot;3131391&quot; &quot;3131392&quot; &quot;3131393&quot; &quot;3131394&quot; ...</span></span><br><span class="line"><span class="comment">#...pvalues adjusted by &#x27;BH&#x27; with cutoff &lt;1</span></span><br><span class="line"><span class="comment">#...28 enriched terms found</span></span><br><span class="line"><span class="string">&#x27;data.frame&#x27;</span>:   <span class="number">28</span> obs. of  <span class="number">9</span> variables:</span><br><span class="line"> $ ID         : chr  <span class="string">&quot;GO:0003735&quot;</span> <span class="string">&quot;GO:0005198&quot;</span> <span class="string">&quot;GO:0003723&quot;</span> <span class="string">&quot;GO:0016830&quot;</span> ...</span><br><span class="line"> $ Description: chr  <span class="string">&quot;structural constituent of ribosome&quot;</span> <span class="string">&quot;structural molecule activity&quot;</span> <span class="string">&quot;RNA binding&quot;</span> <span class="string">&quot;carbon-carbon lyase activity&quot;</span> ...</span><br><span class="line"> $ GeneRatio  : chr  <span class="string">&quot;7/12&quot;</span> <span class="string">&quot;7/12&quot;</span> <span class="string">&quot;2/12&quot;</span> <span class="string">&quot;1/12&quot;</span> ...</span><br><span class="line"> $ BgRatio    : chr  <span class="string">&quot;22/478&quot;</span> <span class="string">&quot;22/478&quot;</span> <span class="string">&quot;14/478&quot;</span> <span class="string">&quot;10/478&quot;</span> ...</span><br><span class="line"> $ pvalue     : num  <span class="number">1.08e-07</span> <span class="number">1.08e-07</span> <span class="number">4.45e-02</span> <span class="number">2.26e-01</span> <span class="number">3.24e-01</span> ...</span><br><span class="line"> $ p.adjust   : num  <span class="number">1.52e-06</span> <span class="number">1.52e-06</span> <span class="number">4.15e-01</span> <span class="number">1.00</span> <span class="number">1.00</span> ...</span><br><span class="line"> $ qvalue     : num  <span class="number">1.42e-06</span> <span class="number">1.42e-06</span> <span class="number">3.90e-01</span> <span class="number">9.40e-01</span> <span class="number">9.40e-01</span> ...</span><br><span class="line"> $ geneID     : chr  <span class="string">&quot;3131425/3131435/3131436/3131439/3131441/3131442/3131457&quot;</span> <span class="string">&quot;3131425/3131435/3131436/3131439/3131441/3131442/3131457&quot;</span> <span class="string">&quot;3131425/3131457&quot;</span> <span class="string">&quot;3131463&quot;</span> ...</span><br><span class="line"> $ Count      : int  <span class="number">7</span> <span class="number">7</span> <span class="number">2</span> <span class="number">1</span> <span class="number">3</span> <span class="number">1</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">1</span> ...</span><br></pre></td></tr></table></figure>



<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line">sly &lt;- ah[[<span class="string">&quot;AH61992&quot;</span>]]</span><br><span class="line">sly</span><br><span class="line">saveDb(sly,file=<span class="string">&quot;sly.orgdb&quot;</span>)</span><br><span class="line">laodDb(file=<span class="string">&quot;sly.orgdb&quot;</span>)</span><br></pre></td></tr></table></figure>



<p>plant_GSEA: MSU-&gt;Uniprot</p>
<p>david:Uniprot-&gt;Entrez_id</p>
<hr>
<h1 id="KEGG-enrichment：R-clusterProfiler"><a href="#KEGG-enrichment：R-clusterProfiler" class="headerlink" title="KEGG enrichment：R clusterProfiler"></a>KEGG enrichment：R clusterProfiler</h1><ol>
<li><p>enrichKEGG</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">enrichKEGG(gene, organism = <span class="string">&quot;hsa&quot;</span>, keyType = <span class="string">&quot;kegg&quot;</span>, pvalueCutoff = <span class="number">0.05</span>,</span><br><span class="line">  pAdjustMethod = <span class="string">&quot;BH&quot;</span>, universe, minGSSize = <span class="number">10</span>, maxGSSize = <span class="number">500</span>,</span><br><span class="line">  qvalueCutoff = <span class="number">0.2</span>, use_internal_data = <span class="literal">FALSE</span>)</span><br><span class="line"><span class="comment">#gene： 基因名，要和keyType对应</span></span><br><span class="line"><span class="comment">#organism: 需要参考 http://www.genome.jp/kegg/catalog/org_list.html</span></span><br><span class="line"><span class="comment">#keyType: 基因的命名方式， “kegg”, ‘ncbi-geneid’, ‘ncib-proteinid’ and ‘uniprot’选择其一</span></span><br><span class="line"><span class="comment">#enrichKEGG的一个关键在于理解它是如何获取数据的。在线爬取数据库，相当于在KEGG上手动输入基因名查询。</span></span><br><span class="line"><span class="comment">#所以，把enrichKEGG当做浏览器，试出合适的keytypes。</span></span><br></pre></td></tr></table></figure></li>
<li></li>
</ol>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">library(clusterProfiler)</span><br><span class="line"><span class="comment"># 对于GID</span></span><br><span class="line">kk &lt;- enrichkegg(gid_list,organism=<span class="string">&#x27;osa&#x27;</span>,keyType = <span class="string">&#x27;kegg&#x27;</span>,pvalueCutoff=<span class="number">0.05</span>, pAdjustMethod=<span class="string">&#x27;BH&#x27;</span>,qvalueCutoff=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于RAP_ID</span></span><br><span class="line">kk &lt;- enrichkegg(rap_list,organism=<span class="string">&#x27;dosa&#x27;</span>,keyType = <span class="string">&#x27;kegg&#x27;</span>,pvalueCutoff=<span class="number">0.05</span>, pAdjustMethod=<span class="string">&#x27;BH&#x27;</span>,qvalueCutoff=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">write.table(ekk,<span class="string">&quot;kegg.txt&quot;</span>,sep = <span class="string">&quot;\t&quot;</span>,<span class="built_in">quote</span> = <span class="built_in">F</span>,row.names = <span class="built_in">F</span>)</span><br><span class="line">barplot(ekk,showCategory = <span class="number">15</span>,title = <span class="string">&quot;EnrichmentKEGG&quot;</span>)</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>若差异基因集（如500个）本身确实没有生物学功能偏好性，非常有可能无显著富集的kegg通路。</li>
</ol>
<p>修改代码，比如：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">kk.down &lt;- enrichKEGG(gene = gene_down,</span><br><span class="line">                        organism = <span class="string">&#x27;hsa&#x27;</span>, </span><br><span class="line">                        pvalueCutoff = <span class="number">0.9</span>,</span><br><span class="line">                        qvalueCutoff =<span class="number">0.9</span>)</span><br><span class="line"><span class="comment"># 需要自己差异分析筛选得到 gene_down 基因集 ，然后进行超几何分布检验</span></span><br><span class="line"><span class="comment">#再调整阈值</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li><p>或可去MSigDB（Molecular Signatures Database<a href="https://www.gsea-msigdb.org/gsea/msigdb%EF%BC%89%E7%9C%8B%E5%85%B6%E5%AE%83%E5%8A%9F%E8%83%BD%E5%9F%BA%E5%9B%A0%E9%9B%86%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E5%AF%8C%E9%9B%86%EF%BC%8CMSigDB%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B7%B2%E7%9F%A5%E7%9A%84%E5%9F%BA%E5%9B%A0%E9%9B%86%E5%90%88%EF%BC%9A%E5%8C%85%E6%8B%ACH%E5%92%8CC1-C7%E5%85%AB%E4%B8%AA%E7%B3%BB%E5%88%97%EF%BC%88Collection%EF%BC%89%EF%BC%8C%E6%A4%8D%E7%89%A9%E9%80%82%E7%94%A8%EF%BC%9F">https://www.gsea-msigdb.org/gsea/msigdb）看其它功能基因集是否可以富集，MSigDB数据库中定义了已知的基因集合：包括H和C1-C7八个系列（Collection），植物适用？</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/150744437">GSEA分析</a>，不依赖于差异分析本身,植物适用？</p>
</li>
</ol>
<hr>
<h1 id="KEGG数据库不会下载？了解下API！"><a href="#KEGG数据库不会下载？了解下API！" class="headerlink" title="KEGG数据库不会下载？了解下API！"></a>KEGG数据库不会下载？了解下API！</h1><ol>
<li><p>KEGG数据库并不提供免费、批量蛋白序列下载，其官方提供在线分析工具BlastKOALA（<a href="https://link.zhihu.com/?target=https://www.kegg.jp/blastkoala/">https://www.kegg.jp/blastkoala/</a>）等可用于KEGG数据库的注释分析。此外还有其他一些在线分析工具例如很常用的KAAS（<a href="https://link.zhihu.com/?target=https://www.genome.jp/tools/kaas/">https://www.genome.jp/tools/kaas/</a>）等。在线工具内部参数未知。</p>
</li>
<li><p>KEGG API（<a href="https://www.kegg.jp/kegg/rest/keggapi.html%EF%BC%89%E6%98%AF%E5%92%8CKEGG%E5%86%85%E6%A0%B8%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92%E7%9A%84%E7%A8%8B%E5%BA%8F%E7%95%8C%E9%9D%A2%EF%BC%8C%E5%85%81%E8%AE%B8%E7%94%A8%E6%88%B7%E5%9F%BA%E4%BA%8E%E8%AF%A5%E7%95%8C%E9%9D%A2%E6%A3%80%E7%B4%A2KEGG%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C[%E4%B8%8B%E8%BD%BD](https://zhuanlan.zhihu.com/p/76195765)">https://www.kegg.jp/kegg/rest/keggapi.html）是和KEGG内核数据库进行交互的程序界面，允许用户基于该界面检索KEGG数据库，[下载](https://zhuanlan.zhihu.com/p/76195765)</a></p>
<p>(1)<a href="https://mp.weixin.qq.com/s/YlJbkIg9It9On5HWRPPgmQ">https://mp.weixin.qq.com/s/YlJbkIg9It9On5HWRPPgmQ</a></p>
<p>(2)<a href="https://mp.weixin.qq.com/s/F3dRgHBI4a2atvz0O_pukA">https://mp.weixin.qq.com/s/F3dRgHBI4a2atvz0O_pukA</a></p>
<p>(3)<a href="https://mp.weixin.qq.com/s/oDDIlWXsLyTCh18bEEysmQ">https://mp.weixin.qq.com/s/oDDIlWXsLyTCh18bEEysmQ</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>GO</category>
        <category>KEGG</category>
      </categories>
      <tags>
        <tag>O_Sativa</tag>
      </tags>
  </entry>
  <entry>
    <title>KMeans</title>
    <url>/blog/2021/11/15/2021-11-15-kmeans/</url>
    <content><![CDATA[<p>监督学习</p>
<p>无监督学习：数据无标注甚至非结构化。KMeans…</p>
<span id="more"></span>



<h1 id="KMeans"><a href="#KMeans" class="headerlink" title="KMeans"></a>KMeans</h1><h2 id="简介-聚类与KMeans"><a href="#简介-聚类与KMeans" class="headerlink" title="简介-聚类与KMeans"></a>简介-聚类与KMeans</h2><blockquote>
<ul>
<li><strong>聚类（Clustering）</strong>：将数据对象分为多个类或者簇 (Cluster)，使同一簇对象间较高相似度，不同簇对象差别较大。</li>
<li><strong>划分（Partitioning）</strong>：聚类可基于划分，也可基于分层。划分即将对象划分成不同簇，而分层将对象分等级。</li>
<li><strong>排他（Exclusive）</strong>：一个数据对象，只能被划分到一个簇。如果一个数据对象可被划分到多个簇，则称为可重叠（Overlapping）。</li>
<li><strong>距离（Distance）</strong>：基于距离的聚类将距离近的相似对象聚在一起。基于<font color="red">概率分布模型的聚类？</font>在一组对象中，找到符合特定分布模型的对象的集合，不一定是距离最近的或者最相似的，而是能完美的呈现出概率分布模型所描述的模型。</li>
<li>欧氏距离：欧几里得度量二维和三维空间中的欧氏距离就是两点之间的实际距离</li>
</ul>
</blockquote>
<ul>
<li><p>与分类、序列标注不同，聚类事先并不知道任何样本标签，通过数据之间内在关系把样本划分为若干类别，使得同类别样本之间的相似度高，不同类别相似度低（增大类内聚，减少类间距）。</p>
</li>
<li><p>聚类属于非监督学习，K均值聚类最基础常用。基本思想，<font color="green">通过迭代寻找K个簇（Cluster），使聚类结果对应的损失函数最小</font>。终止条件是没有（或最小数目）对象被重新分配给不同的聚类，没有（或最小数目）聚类中心再发生变化，误差平方和局部最小。<font color="red">损失函数定义为各个样本距离所属簇中心点的误差平方和</font>：</p>
</li>
</ul>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/1.png"></p>
<p>xi代表第i个样本，ci是xi所属的簇，uci代表簇对应中心点，M是样本总数。</p>
<ul>
<li><p>？损失函数本质是衡量模型的拟合效果，有求解参数需求的算法，才会有损失函数。Kmeans 不求解什么参数，它的模型本质也没有在拟合数据，而是在对数据进行一 种探索。在决策树中有衡量分类效果的指标准确度<code>accuracy</code>，准确度所对应的损失叫做泛化误差，但不能通过最小化泛化误差来求解某个模型中需要的信息，只是希望模型的效果上表现出来的泛化误差 很小。因此决策树，KNN 等算法，是绝对没有损失函数的。</p>
</li>
<li><table>
<thead>
<tr>
<th>距离度量对比</th>
<th>质心</th>
<th>Inertia</th>
</tr>
</thead>
<tbody><tr>
<td>欧几里得距离</td>
<td>均值</td>
<td>最小化每个样本点到质心的欧式距离之和</td>
</tr>
<tr>
<td>曼哈顿距离</td>
<td>中位数</td>
<td>最小化每个样本点到质心的曼哈顿距离之和</td>
</tr>
<tr>
<td>余弦距离</td>
<td>均值</td>
<td>最小化每个样本点到质心的余弦距离之和</td>
</tr>
</tbody></table>
</li>
<li><p>  上述问题是<font color="green">NP-Hard</font>问题。一般是采用坐标下降（Coordinate Decendet）方法求解。坐标下降法属于非梯度优化方法，每一步迭代中沿着一个坐标轴方向探索，通过循环使用不同的坐标达到求解目标函数的局部最小值。 </p>
</li>
</ul>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/4.png"></p>
<p>如上图，假设两维度x，y：</p>
<ol>
<li>首先选择初始位置(x,y)，假设x未知将y的值代入目标函数中，令目标函数导数0，求得此时最佳x值。</li>
<li>又假设y未知将刚求得x的值代入目标函数，令目标函数导数0，求得此时最佳y。</li>
<li>重复执行第1步第2步，目标函数逐渐接近极小值点，直到达到了极小值点停止。</li>
</ol>
<p>收敛的过程如红色箭头所示。更多维度时，同理，一次只对一个维度最优化。</p>
<p>坐标下降法一般要求目标函数是可微的凸函数(局部最小值即全局最小值?)，此时求得的极小值才能是全局最小值。</p>
<p>使用K-Means前，可先用PCA使各个变量间尽可能独立。否则如两变量间有较强关联性，函数收敛速度会非常慢。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>KMeans的核心目标是将给定的数据集划分成K个簇（K是超参），并给出每个样本数据对应的中心点。具体步骤非常简单，可以分为4步：</p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/2.png"></p>
<p><strong>KMeans最核心的部分就是先固定中心点，调整每个样本所属的类别来减少J；再固定每个样本的类别，调整中心点继续减小J 。两个过程交替循环， J 单调递减直到最（极）小值，中心点和样本划分的类别同时收敛。</strong></p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/3.png"></p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/5.png"></p>
<h1 id="优缺点优化策略"><a href="#优缺点优化策略" class="headerlink" title="优缺点优化策略"></a>优缺点优化策略</h1><p>KMenas优点：</p>
<ul>
<li>高效可伸缩，计算复杂度 为<font color="green">O(NKt)</font>接近于线性（N是数据量，K是聚类总数，t是迭代轮数）。</li>
<li><font color="green">收敛速度快</font>，原理通俗易懂，可解释性强。</li>
</ul>
<p>KMeans明显缺点：</p>
<ul>
<li>受<font color="green">初始值</font>和<font color="green">异常</font>影响，聚类结果可能不是全局最优而是<font color="green">局部最优</font>。</li>
<li><font color="green">K</font>是超参数，按<font color="green">经验选择</font></li>
<li><font color="green">样本点只能划分到单一的类中</font></li>
<li>只能发现球状的簇。</li>
<li>初始值对结果影响较大，可能每次聚类结果都不一样。</li>
</ul>
<p>根据以上特点，我们可以从下面几个角度对算法做调优</p>
<ol>
<li><strong>数据预处理：归一化和异常点过滤</strong></li>
</ol>
<p><strong>KMeans本质是基于欧式距离度量的数据划分方法，均值和方差大的维度将对数据聚类结果产生决定性影响。</strong>聚类前对数据（<strong>具体的说是每一个维度的特征</strong>）做<font color="green">归一化</font>和<font color="green">单位统一</font>至关重要。<font color="green">异常值</font>会对均值计算产生较大影响，导致<strong>中心偏移</strong>，<font color="green">噪声点最好能提前过滤</font>。</p>
<p><strong>2.合理选择K值</strong></p>
<p>K值的选择一般基于实验和多次实验结果。例如采用<strong>手肘法</strong>，尝试不同K值并将对应的损失函数画成折线。手肘法认为图上的<strong>拐点就是K的最佳值</strong>（上图对应K=3）。</p>
<p><strong>Gap Statistic方法</strong>。只需要找到最大的Gap Statistic对应的K(自动)。</p>
<p>沿用第一节中<font color="green">损失函数</font>记为 Dk，当分为K类时，Gap Statistic定义为： Gap(k)=E(logDk)-logDk 。 E(logDk)是logDk的期望，一般由<font color="green">蒙特卡洛模拟</font>产生。在<font color="green">样本所在的区域内按照均匀分布随机地产生和原始样本数一样多的随机样本</font>，对这个<font color="green">随机样本做KMeans</font>，得到一个<font color="green">Dk</font>，<font color="green">重复多次</font>计算出 E(logDk)的近似值。</p>
<p><strong>Gap(K) 的物理含义是<font color="green">随机样本的损失与实际样本的损失之差</font>。Gap越<font color="green">大</font>说明聚类的效果越好</strong>。随着K的变化Gap(K)几乎维持一条直线保持不变。说明这些样本间没有明显的类别关系，<font color="green">数据分布几乎和均匀分布一致</font>，近似随机。此时聚类没有意义。</p>
<p><strong>3.改进初始值的选择</strong></p>
<p>采取随机选择K个中心，<font color="green">可能导致不同中心点距离很近</font>，需<font color="green">更多的迭代次数才能收敛</font>。如在选择初始中心点时<strong>不同的中心尽可能远离</strong>，效果更好。这类算法中，以K-Means++算法最具影响力。</p>
<p><strong>4.采用核函数?</strong></p>
<p>主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的空间进行聚类。非线性映射增加了数据点线性可分的概率（与SVM中使用核函数思想类似）对于非凸的数据分布可以达到更为准确的聚类结果。</p>
<ol start="5">
<li>从EM算法解释KMeans</li>
</ol>
<p>EM（Expectation-Maximum）算法即期望最大化算法，是最常见的隐变量估计方法。EM算法是一种迭代优化策略，每一次迭代都分为两步：期望步（E）、极大步（M）。<strong>EM算法的提出最初是为了解决数据缺失情况下的参数估计问题</strong>，基本思想是首先根据已有的观测数据，通过极大似然估计估计出模型的参数；再根据上一步估计出的参数值估计缺失数据的值；最后根据估计出的缺失数据和原有的观测数据重新对参数值进行估计，反复迭代直到收敛。</p>
<hr>
<p>K均值聚类是使用<a href="https://baike.baidu.com/item/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95/10180861">最大期望算法</a>（Expectation-Maximization algorithm）求解的<a href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/8878468">高斯混合模型</a>（Gaussian Mixture Model, GMM）在<a href="https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/829892">正态分布</a>的协方差为单位矩阵，且隐变量的后验分布为一组<a href="https://baike.baidu.com/item/%E7%8B%84%E6%8B%89%E5%85%8B%CE%B4%E5%87%BD%E6%95%B0/5760582">狄拉克δ函数</a>时所得到的特例?</p>
<p>Python</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeansClusterer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,ndarray,cluster_num</span>):</span></span><br><span class="line">        self.ndarray = ndarray</span><br><span class="line">        self.cluster_num = cluster_num</span><br><span class="line">        self.points=self.__pick_start_point(ndarray,cluster_num)</span><br><span class="line">         </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cluster</span>(<span class="params">self</span>):</span></span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.cluster_num):</span><br><span class="line">            result.append([])</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> self.ndarray:</span><br><span class="line">            distance_min = sys.maxsize</span><br><span class="line">            index=-<span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.points)):                </span><br><span class="line">                distance = self.__distance(item,self.points[i])</span><br><span class="line">                <span class="keyword">if</span> distance &lt; distance_min:</span><br><span class="line">                    distance_min = distance</span><br><span class="line">                    index = i</span><br><span class="line">            result[index] = result[index] + [item.tolist()]</span><br><span class="line">        new_center=[]</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">            new_center.append(self.__center(item).tolist())</span><br><span class="line">        <span class="comment"># 中心点未改变，说明达到稳态，结束递归</span></span><br><span class="line">        <span class="keyword">if</span> (self.points==new_center).<span class="built_in">all</span>():</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">         </span><br><span class="line">        self.points=np.array(new_center)</span><br><span class="line">        <span class="keyword">return</span> self.cluster()</span><br><span class="line">             </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__center</span>(<span class="params">self,<span class="built_in">list</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;计算一组坐标的中心点</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 计算每一列的平均值</span></span><br><span class="line">        <span class="keyword">return</span> np.array(<span class="built_in">list</span>).mean(axis=<span class="number">0</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__distance</span>(<span class="params">self,p1,p2</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;计算两点间距</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        tmp=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(p1)):</span><br><span class="line">            tmp += <span class="built_in">pow</span>(p1[i]-p2[i],<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">pow</span>(tmp,<span class="number">0.5</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__pick_start_point</span>(<span class="params">self,ndarray,cluster_num</span>):</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> cluster_num &lt;<span class="number">0</span> <span class="keyword">or</span> cluster_num &gt; ndarray.shape[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;簇数设置有误&quot;</span>)</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># 随机点的下标</span></span><br><span class="line">        indexes=random.sample(np.arange(<span class="number">0</span>,ndarray.shape[<span class="number">0</span>],step=<span class="number">1</span>).tolist(),cluster_num)</span><br><span class="line">        points=[]</span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexes:</span><br><span class="line">            points.append(ndarray[index].tolist())</span><br><span class="line">        <span class="keyword">return</span> np.array(points)</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="KMeans-and-gaussian-mixture-model"><a href="#KMeans-and-gaussian-mixture-model" class="headerlink" title="KMeans and gaussian mixture model"></a>KMeans and gaussian mixture model</h2><p>数据表示：kmeans单个点对cluster建模（假设各clus数据是圆形或高位球形）。GMM，使用高斯分布表示</p>
<p>数据先验：kmeans，假设各clus先验概率一样，实际clus数据量可能不均匀。clusA10000，B100，新样本不考虑与AB相似度，属于A概率大。GMM对数据先验进行建模。</p>
<p>相似度衡量：Kmeans的欧式距离假设各个维度对相似度衡量作用一样。GMM相似度衡量使用后验概率通过引入协方差矩阵，对各个维度数据的不同重要性建模。</p>
<p>数据分配：kmeans各样本只属于相似度最高clus（hard clusting），GMM使用后验概率对各个clus按比例分配（fuzzy clustering？）。</p>
<hr>
<h2 id="k-means-聚类算法"><a href="#k-means-聚类算法" class="headerlink" title="k-means++聚类算法"></a>k-means++聚类算法</h2><p><code>KMeans</code>算法，<code>KMeans</code>在聚类之前首先需初始化k个簇中心，因此 <code>KMeans</code> 算法对初值敏感，对于不同的初始值，会导致不同聚类结果。若初始化随机，很有可能 k簇中心都在同一个簇，这种情况 <code>KMeans</code> 很大程度上都不会收敛到全局最小。</p>
<p>为优化选择初始质心的方法，2007 年 Arthur,等 三人发表了论文“k-means++: <code>The advantages of careful seeding</code>，<code>sklearn.cluster.KMeans</code> 中默认参数为 <code>init=&#39;k-means++&#39;</code> ，其算法原理为在初始化簇中心时，逐个选取 k个簇中心，且离其他簇中心越远的样本越有可能被选为下个簇中心。</p>
<p>算法步骤：</p>
<p><img src="/blog/2021/11/15/2021-11-15-kmeans/6.png"></p>
<hr>
<p>ref：</p>
<p><a href="https://zhuanlan.zhihu.com/p/184686598">https://zhuanlan.zhihu.com/p/184686598</a></p>
<p><a href="https://www.cnblogs.com/gaochundong/p/kmeans_clustering.html">https://www.cnblogs.com/gaochundong/p/kmeans_clustering.html</a></p>
<p><a href="https://www.zhihu.com/question/31296149">https://www.zhihu.com/question/31296149</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/342052190#:~:text=KMeans%20">https://zhuanlan.zhihu.com/p/342052190#:~:text=KMeans%20</a></p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-4【Macs2/3 Installation】</title>
    <url>/blog/2021/10/29/ATAC-seq-4-macs3-install/</url>
    <content><![CDATA[<h3 id="Macs2-3-installation-Debug-Record"><a href="#Macs2-3-installation-Debug-Record" class="headerlink" title="Macs2/3 installation Debug Record"></a>Macs2/3 installation Debug Record</h3><span id="more"></span>

<p>macs2 installation record<br>install conda<br>creat work environment<br>install numpy1.17<br>python setup.py install –prefix …./software/MACS</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR1#############################################</span><br><span class="line">#MACS3/fermi-lite/ksw.c:31:26: fatal error: lib/x86/sse2.h: No such file or directory</span><br><span class="line"># #include &quot;lib/x86/sse2.h&quot;                      ^</span><br><span class="line">#compilation terminated.</span><br><span class="line">#error: command &#x27;gcc&#x27; failed with exit status 1</span><br><span class="line">######################################################################################</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/macs3-project/MACS/issues/473">https://github.com/macs3-project/MACS/issues/473</a><br>zip downloaded from github zip is not complete in the deep dir<br>git clone <a href="https://github.com/macs3-project/MACS.git">https://github.com/macs3-project/MACS.git</a> –recursive<br>or download absent files</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR2#############################################</span><br><span class="line">Checking .pth file support in ..../software/MACS2/lib/python3.8/site-packages/</span><br><span class="line">..../.conda/envs/atacseq/bin/python -E -c pass</span><br><span class="line">TEST FAILED: ..../software/MACS2/lib/python3.8/site-packages/ does NOT support .pth files</span><br><span class="line">bad install directory or PYTHONPATH</span><br><span class="line"></span><br><span class="line">You are attempting to install a package to a directory that is not</span><br><span class="line">on PYTHONPATH and which Python does not read &quot;.pth&quot; files from.  The</span><br><span class="line">installation directory you specified (via --install-dir, --prefix, or</span><br><span class="line">the distutils default setting) was:</span><br><span class="line"></span><br><span class="line">    ..../software/MACS2/lib/python3.8/site-packages/</span><br><span class="line"></span><br><span class="line">and your PYTHONPATH environment variable currently contains:</span><br><span class="line"></span><br><span class="line">    &#x27;&#x27;</span><br><span class="line"></span><br><span class="line">Here are some of your options for correcting the problem:</span><br><span class="line"></span><br><span class="line">* You can choose a different installation directory, i.e., one that is</span><br><span class="line">  on PYTHONPATH or supports .pth files</span><br><span class="line"></span><br><span class="line">* You can add the installation directory to the PYTHONPATH environment</span><br><span class="line">  variable.  (It must then also be on PYTHONPATH whenever you run</span><br><span class="line">  Python and want to use the package(s) you are installing.)</span><br><span class="line"></span><br><span class="line">* You can set up the installation directory to support &quot;.pth&quot; files by</span><br><span class="line">  using one of the approaches described here:</span><br><span class="line"></span><br><span class="line">  https://setuptools.readthedocs.io/en/latest/deprecated/easy_install.html#custom-installation-locations</span><br></pre></td></tr></table></figure>

<p>[ok]export PYTHONPATH=${PYTHONPATH}:…./software/MACS2/lib/python3.9/site-packages/</p>
<p>directly set PYTHONPATH=…./software/MACS2/lib/python3.9/site-packages/ in ~/.bashrc was failed.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR3#############################################</span><br><span class="line">error: package directory &#x27;MACS2&#x27; does not exist</span><br><span class="line">#######################################################################################</span><br></pre></td></tr></table></figure>
<p>zip Dir was not complete, tried .tar.gz </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">####################################ERROR4#############################################</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;..../software/MACS3/bin/macs3&quot;, line 4, in &lt;module&gt;</span><br><span class="line">    __import__(&#x27;pkg_resources&#x27;).run_script(&#x27;MACS3==3.0.0a6&#x27;, &#x27;macs3&#x27;)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3243, in &lt;module&gt;</span><br><span class="line">    def _initialize_master_working_set():</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3226, in _call_aside</span><br><span class="line">    f(*args, **kwargs)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 3255, in _initialize_master_working_set</span><br><span class="line">    working_set = WorkingSet._build_master()</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 568, in _build_master</span><br><span class="line">    ws.require(__requires__)</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 886, in require</span><br><span class="line">    needed = self.resolve(parse_requirements(requirements))</span><br><span class="line">  File &quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;, line 772, in resolve</span><br><span class="line">    raise DistributionNotFound(req, requirers)</span><br><span class="line">pkg_resources.DistributionNotFound: The &#x27;Cython&gt;=0.29&#x27; distribution was not found and is required by MACS3``</span><br></pre></td></tr></table></figure>

<p><code>conda install Cython=0.29</code></p>
<p><a href="https://pypi.org/project/cykhash/">https://pypi.org/project/cykhash/</a><br><code>pip install cykhash</code><br>Collecting cykhash<br>  Using cached cykhash-1.0.2-cp39-cp39-linux_x86_64.whl<br>Installing collected packages: cykhash<br>Successfully installed cykhash-1.0.2</p>
<p>python setup.py install –prefix …./software/MACS2</p>
<p>success</p>
]]></content>
      <categories>
        <category>ATAC-seq</category>
        <category>Software</category>
      </categories>
      <tags>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-5【PeakCalling-MACS2】</title>
    <url>/blog/2021/10/29/ATAC-seq-5-macs2-info/</url>
    <content><![CDATA[<h2 id="MACS2-detail"><a href="#MACS2-detail" class="headerlink" title="MACS2 detail"></a>MACS2 detail</h2><span id="more"></span>


<h3 id="粗略介绍MACS基本原理。"><a href="#粗略介绍MACS基本原理。" class="headerlink" title="粗略介绍MACS基本原理。"></a>粗略介绍MACS基本原理。</h3><p>TF在基因组上的结合是随机过程，基因组的每个位置都有机会结合某个TF，只是概率不一样，peak出现的位置，是TF结合热点，而peak-calling就为了找这些热点。</p>
<p>如何定义热点？通俗讲，热点是这样一些位置，这些位置多次被测得的read所覆盖（我们测的是一个细胞群体，read出现次数多，说明该位置被TF结合的几率大）。read数达到多少才叫多？就要用到统计检验。假设TF在基因组上的分布没有任何规律，那么测序得到的read在基因组上的分布也必然是随机的，某个碱基上覆盖的read的数目应服从二项分布。和抽小球的过程类似。当n很大，p很小时，二项分布近似用泊松分布替代，在这里：<br><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/1.png"></p>
<p>拉姆达是泊松分布唯一参数，n是测序read总数目，l是单个read长度，s是基因组大小。有了分布，可以算出在某个置信概率（如0.00001）下，随机情况下，某个碱基上可以覆盖的read数目的最小值，当实际观察到的read数目超过这个值（单侧检验）时，认为该碱基是TF的一个结合热点。反过来，针对每一个read数目，我们也可以算出对应的置信概率P。</p>
<p>但这只是简化模型，实际情况复杂好多。由于测序、mapping过程内在<font color="red">偏好性</font>，以及不同染色质间的差异性，相比全基因组，某些碱基可能内在地会被更多的read所覆盖，这种情况得到的很多peak可能都是假的。MACS考虑到这点，<font color="red">当对某个碱基进行假设检验，MACS只考虑该碱基附近染色质区段（如10k），此时上述公式中n表示附近10k区间内的read数目，s被置为10k</font>。当有对照组（Control，相比实验组没有用抗体捕获TF或用了一个通用抗体）存在，利用Control组的数据构建泊松分布，<font color="red">没有Control时，利用实验组，稍大一点的局部区间（比如50k）</font>的数据构建泊松分布。</p>
<p>还有一个问题，read只是跟随着TF一起沉淀下来的DNA fragment的末端，read的位置并不是真实的TF结合位置。所以在peak-calling之前，延伸read是必须的。不同TF大小不一样，对read延伸的长度也理应不同.测得的<font color="red">read最终其实会近似地平均分配到正负链</font>，对于一个TF结合热点，read在附近正负链上会近似地形成<font color="red">“双峰”</font>。MACS会以<font color="red">某个window size扫描基因组，统计每个window里面read的富集程度，然后抽取（比如1000个）合适的（read富集程度适中，过少，无法建立模型，过大，可能反映的只是某种偏好性）window作样本，建立“双峰模型”</font>。最后，两个峰之间的距离就被认为是<font color="red">TF的长度D，每个read将延伸D/2</font>。见下图：</p>
<p><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/2.png"></p>
<p>当有对照组，MACS会进行两次peak calling。第一次以实验组（Treatment）为实验组，对照组为对照组，第二次颠倒，以实验组为对照组，对照组为实验组。之后，MACS对每一个P计算了相应的FDR（False Discovery Rate）值：</p>
<p><img src="/blog/2021/10/29/ATAC-seq-5-macs2-info/3.png"></p>
<p>表示第二次peak calling（颠倒的）得到的置信概率小于P的peak的个数。表示第一次peak calling得到的置信概率小于P的peak的个数。FDR综合利用了实验组和对照组的信息，显然，FDR越小越好。</p>
<h3 id="MACS-peak-calling-pipeline："><a href="#MACS-peak-calling-pipeline：" class="headerlink" title="MACS peak-calling pipeline："></a>MACS peak-calling pipeline：</h3><p>在某些情况下，如对组蛋白修饰的ChIP-seq数据peak-calling时，“双峰模型”会建立失败，<font color="red">因为组蛋白修饰往往并不是孤立存在的，可能很长一段染色质区间都被同一个组蛋白修饰占据，组蛋白修饰的peak并不典型。</font>这时，只要多加一个参数：</p>
<p><font color="red">–nomodel –shiftsize=number</font></p>
<p>–nomodel将<font color="red">略过“双峰模型”建立的过程</font>，而<font color="red">–shiftsize将人为指定reads延伸的长度</font>。<font color="red">一个核小体上大概缠绕着147bpDNA</font>，在对组蛋白修饰做peak-calling时可以指定：</p>
<p><font color="red">–nomodel –shiftsize=73</font></p>
<p>CTCF_peaks.bed详细列出了每一个peak的位置信息和可信度（最后一列：)，BED文件格式详见：<a href="http://genome.ucsc.edu/FAQ/FAQformat.html#format1">http://genome.ucsc.edu/FAQ/FAQformat.html#format1</a></p>
<p>其他常用参数：-bw number 建立“双峰模型”过程中window size的一半，默认300bp.<br><font color="red">-p Pvalue</font>设定peak置信概率的临界值（threshold），默认0.00001?(macs2 callpeak -h: pvalue not set, dont use p and q value at the same time)，对于H3k36me3、H3k27me3、H3k9me3等具有“非常规”特征的peak（broad peak）而言，此参数可以稍微设大一点，比如0.001。</p>
<p>-m number1,number2 建立“双峰模型”用到，设定挑选的window上reads的富集程度（<font color="red">fold enrichment</font>，相对全基因组而言），默认10,30。</p>
<p>-slocal=number -llocal=number 共同确定MACS动态计算时所考察的局部区间的长度。默认参数，-slocal=1000 -llocal=10000。除了建立“双峰模型”，在寻找peak过程中，MACS依然会以2倍于-bw的window扫描基因组，对于当前window而言（-slocal,-llocal取默认参数）：</p>
<p>-w/-B 建立wig或BED格式的raw signal（最高精确到每个碱基上reads的覆盖情况）文件，默认每条染色体建一个。</p>
<p>-S 只建立一个raw signal文件。</p>
<p>-space 与-w搭配使用，确定wig文件的分辨率，默认10bp。</p>
<hr>
<p>link：<a href="https://www.plob.org/article/7227.html">https://www.plob.org/article/7227.html</a></p>
]]></content>
      <categories>
        <category>ATAC-seq</category>
        <category>Software</category>
      </categories>
      <tags>
        <tag>software</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-3【hbctraining_pipeline】</title>
    <url>/blog/2021/10/26/ATAC-seq-3-hbctraining/</url>
    <content><![CDATA[<h2 id="https-github-com-hbctraining-In-depth-NGS-Data-Analysis-Course-tree-master-sessionV-lessons"><a href="#https-github-com-hbctraining-In-depth-NGS-Data-Analysis-Course-tree-master-sessionV-lessons" class="headerlink" title="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons"></a><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a></h2><span id="more"></span>

<p>算法，参数，输出。</p>
<h2 id="Peak-calling"><a href="#Peak-calling" class="headerlink" title="Peak calling"></a>Peak calling</h2><p><img src="https://img-blog.csdnimg.cn/f2741798d4f04f708412c97b2e6ef045.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>ChIP-seq实验，从比对文件中观察到<code>正/负链</code>上以<code>结合位点为中心</code>的非对称reads<br>密度。<br>For ChIP-seq experiments, what we observe from the alignment files is a strand asymmetry with read densities on the +/- strand, centered around the binding site. <code>The 5’ ends of the selected fragments</code> will form <code>groups</code> on the positive- and negative-strand. The <code>distributions</code> of these groups are then assessed using <code>statistical measures</code> and <code>compared against background</code> (input or mock IP samples) to determine if the site of enrichment is likely to be a real binding site.</p>
<p><img src="https://img-blog.csdnimg.cn/a5f4429afb3348be91f68d90d4011065.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="加粗样式"><br><code>ChIP-seq analysis algorithms</code> are specialized in identifying one of <code>two types of enrichment</code> (or have specific methods for each): <code>broad peaks or broad domains</code> (i.e. <code>histone modifications that cover entire gene bodies</code>) or <code>narrow peaks</code> ( <code>transcription factor binding</code>). <code>Narrow peaks are easier to detect</code> as we are looking for regions that have higher amplitude and are easier to distinguish from the background, compared to broad or dispersed marks. There are also <code>‘mixed’ binding profiles</code> which can be hard for algorithms to discern. An example of this is the binding properties of <code>PolII</code>, which binds at promotor and across the length of the gene resulting in mixed signals (<code>narrow and broad</code>).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">NOTE：ChIP-seq的分析方法可以鉴定两种类型的富集模式：broad domains和narrow peaks。broad domains，如组蛋白修饰在整个基因body区域的分布；narrow peak，如转录因子的结合。narrow peak相对于broad 或者分散的marks更易被检测到。也有一些混合的结合图谱，如PolII包括narrow和broad信号。</span><br></pre></td></tr></table></figure>
<h2 id="MACS2"><a href="#MACS2" class="headerlink" title="MACS2"></a>MACS2</h2><p>MACS2是最常用的call peaks工具。 The MACS algorithm captures the influence of <code>genome complexity</code> to evaluate the significance of enriched ChIP regions。全称<code>Model-based Analysis of ChIP-Seq</code>，最初设计用来<code>鉴定转录因子结合位点</code>（also suited for <code>larger</code> regions），也可用于<code>其他类型</code>的富集方式测序。<br>MACS通过整合<code>序列标签位置信息</code>和<code>方向</code>信息提高<code>结合位点</code>的<code>空间分辨率</code>（ <code>improves</code> the <code>spatial resolution of binding sites</code> through <code>combining the information of both sequencing tag position and orientation</code>）。单独使用或加对照（ <code>increases specificity</code> of the peak calls）。<br><img src="https://img-blog.csdnimg.cn/3929b0f60a01477ea09402760205f200.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_17,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h3 id="1-Remove-redundancy"><a href="#1-Remove-redundancy" class="headerlink" title="1. Remove redundancy"></a>1. Remove redundancy</h3><p><code>Why worry about duplicates?</code> <code>Reads with the same start position</code> are <code>considered duplicates</code>. These duplicates can arise from experimental artifacts, but can also contribute to genuine ChIP-signal. (相同起点的reads被认为是duplicates，可能由于实验误差造成，<code>也可能是ChIP信号</code>)</p>
<ul>
<li><code>坏 duplicates</code>: If initial starting <code>material is low</code> this can lead to <code>overamplification</code> of this material before sequencing. Any <code>biases in PCR</code> will compound this problem and can lead to <code>artificially enriched regions</code>. Also <code>blacklisted (repeat) regions</code> with ultra high signal will also be high in duplicates. <code>Masking these regions</code> prior to analysis can help remove this problem。 实验材料量少，过度扩增，PCR偏差，人为富集区域。<code>blacklist（重复）区域？怎么获得</code>，屏蔽该区域。</li>
<li><code>好 duplicates</code>: You can expect some <code>biological duplicates with ChIP-seq</code> since you are only sequencing a small <code>part of the genome</code>. This number can increase if your depth of coverage is excessive or if your protein only binds to few sites. If there are a good proportion of biological dupicates, <code>removal</code> can lead to an <code>underestimation of the ChIP signal</code>. 有ChIP-seq意义的生物学意义duplicates ，测序基因组小部分。覆盖深度过多，蛋白质与少数位点结合，duplicates会增加。去除此类会导致对ChIP信号的低估。</li>
<li>Consider your <code>enrichment efficiency</code> and <code>sequencing depth</code>. Try to <code>discriminate</code> via genome browser of your non-deduplicated data. Bona fide peaks will have <code>multiple overlapping</code> reads with <code>offsets</code>, while samples with only PCR duplicates will stack up perfectly without offsets. A possible solution to distinguishing biological duplicate from PCR artifact would be to include UMIs into your experimental setup. 考虑<code>富集效率</code>和<code>测序深度</code>。通过<code>基因组浏览器区别</code>。<code>真正的峰</code>会有多个<code>重叠reads和偏移量</code>，<code>PCR重复没有偏移量</code>。如何区分：实验设计考虑<a href="https://www.sohu.com/a/471483238_120055884">UMIs</a>（<code>UMI将被用于合并PCR复制物</code>）。</li>
<li>Retain duplicates for differential binding analysis. 保留duplicates 用于差异结合分析 <code>why</code>？retain和keep区别？</li>
<li>If you are expecting binding in repetitive regions, use paired-end sequencing and keep duplicates. 研究重复区域，使用pariedend测序并<code>保持重复？</code></li>
<li>call peak之前就remove dup<h3 id="2-0-Shift-size-d"><a href="#2-0-Shift-size-d" class="headerlink" title="2.0 Shift size d"></a>2.0 <code>Shift size d</code></h3></li>
<li>真实结合位点周围的tag density应显示<code>双峰富集</code>(<code>成对峰</code>)。MACS利用这种双峰模式 <code>empirically model the shifting size</code>，精确定位结合位点。</li>
<li>为了找到<code>成对峰</code>来<code>构建模型</code>，MACS首先<code>扫描整个数据集</code>，寻找<code>高度显著富集区域</code>。只利用ChIP样本，给定超声大小sonication size(<code>bandwidth</code>)和high-confidence fold-enrichment(<code>mfold</code>)， MACS <code>slides two bandwidth windows</code> across the genome to find <code>regions with tags more than mfold enriched</code> relative to a <code>random tag genome distribution</code>.</li>
<li>MACS<code>随机抽取1000个高质量峰</code>，<code>分离正链和负链标签</code>，aligns them by the midpoint between their centers。The <code>distance between the modes of the two peaks in the alignment is defined as ‘d’</code> and represents the estimated fragment length. MACS shifts all the tags by d/2 toward the 3’ ends to the most likely protein-DNA interaction sites.<br><img src="https://img-blog.csdnimg.cn/eeefe600965542478444f761de31db17.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
</ul>
<h3 id="2-Select-1000-regions-with-a-10-to-30-fold-enrichment-relative-to-the-genome-background"><a href="#2-Select-1000-regions-with-a-10-to-30-fold-enrichment-relative-to-the-genome-background" class="headerlink" title="2. Select 1000 regions with a 10- to 30-fold enrichment relative to the genome background"></a>2. Select 1000 regions with a 10- to 30-fold enrichment relative to the genome background</h3><h3 id="3-Build-model-and-estimate-DNA-fragment-size-d"><a href="#3-Build-model-and-estimate-DNA-fragment-size-d" class="headerlink" title="3. Build model and estimate DNA fragment size d"></a>3. Build model and estimate DNA fragment size d</h3><h3 id="4-Shift-reads-toward-3’end-by-d"><a href="#4-Shift-reads-toward-3’end-by-d" class="headerlink" title="4. Shift reads toward 3’end by d"></a>4. Shift reads toward 3’end by d</h3><h3 id="5-Scale-two-libraries-if-have-control"><a href="#5-Scale-two-libraries-if-have-control" class="headerlink" title="5. Scale two libraries(if have control)"></a>5. Scale two libraries(if have control)</h3><p>For experiments in which <code>sequence depth differs</code> between input and treatment samples, MACS linearly scales the total control tag count to be the same as the total ChIP tag count. The default behaviour is for the <code>larger sample to be scaled down</code>. </p>
<h3 id="6-0-Effective-genome-length"><a href="#6-0-Effective-genome-length" class="headerlink" title="6.0 Effective genome length"></a>6.0 Effective genome length</h3><p>To calculate λBG from tag count, MAC2 requires the <code>effective genome size or the size of the genome that is mappable</code>. Mappability is related to the <code>uniqueness of the k-mers</code> at a particular position the genome. <code>Low-complexity</code> and <code>repetitive regions</code> have <code>low uniqueness</code>, which means <code>low mappability</code>. Therefore we need to provide the effective genome length to correct for the loss of true signals in low-mappable regions. 提供<code>有效基因组长度</code>，以<code>纠正低定位区域真实信号丢失</code>。<br><img src="https://img-blog.csdnimg.cn/5571c4b228cb4706805ba0853c546c3c.png" alt="在这里插入图片描述"><br><code>如何获得？</code>The MACS2 software has some <code>pre-computed values</code> for <code>commonly used</code> organisms (human, mouse, worm and fly，<code>rice？</code>). more accurate values? The <code>deepTools</code> docs has additional pre-computed values for more recent builds but also has some good materials on <code>how to go about computing</code> it.</p>
<h3 id="6-Call-candidate-peaks-relative-to-genome-background"><a href="#6-Call-candidate-peaks-relative-to-genome-background" class="headerlink" title="6. Call candidate peaks relative to genome background"></a>6. Call candidate peaks relative to genome background</h3><p>After MACS <code>shifts every tag by d/2</code>, it then <code>slides across the genome</code> using a window size of <code>2d</code> to <code>find candidate peaks</code>.  The <code>tag distribution</code> along the genome can be modeled by a <code>Poisson distribution</code>.  The Poisson is a one parameter model, where the parameter <code>λ is the expected number of reads in that window</code>.</p>
<h3 id="7-Calculate-dynamic-λ-for-candidate-peaks"><a href="#7-Calculate-dynamic-λ-for-candidate-peaks" class="headerlink" title="7. Calculate dynamic λ for candidate peaks"></a>7. Calculate dynamic λ for candidate peaks</h3><p><img src="https://img-blog.csdnimg.cn/eaac9c4b4c294be3b8b3b3caf7c35a21.png" alt="在这里插入图片描述"><br>泊松分布的参数λ是单位时间(或单位面积)内随机事件的平均发生次数。 泊松分布的期望和方差均为λ.<br>Instead of using a uniform λ estimated from the whole genome, MACS uses a <code>dynamic parameter, λlocal</code>, defined for <code>each candidate peak</code>. The lambda parameter is estimated from the control sample and is deduced by taking the maximum value across <code>various window sizes</code>:</p>
<blockquote>
<p>λlocal = max(λBG, λ1k, λ5k, λ10k).</p>
</blockquote>
<p>In this way lambda <code>captures the influence of local biases</code>, and is robust against occasional low tag counts at small local regions. Possible sources for these biases include local chromatin structure, DNA amplification and sequencing bias, and genome copy number variation. 通过使用动态lambda捕获局部偏差的影响，并且对小局部区域中<code>偶尔出现的low tag counts</code>表现较好。<code>偏差可能来源</code>包括局部染色质结构、DNA扩增和测序偏差以及基因组拷贝数变化。<br><img src="https://img-blog.csdnimg.cn/3c7c645b299e45b2b7975d6327d421bc.png" alt="在这里插入图片描述"><br>A region is considered to have a <code>significant tag enrichment</code> if the <code>p-value &lt; 10e-5</code> (可设置). This is a Poisson distribution p-value based on λ.</p>
<p>Overlapping enriched peaks are merged, and each tag position is <code>extended ‘d’ bases？</code> from its center. The location in the <code>peak with the highest fragment pileup堆积</code>, hereafter referred to as the summit峰顶, is <code>predicted as the precise binding location</code>. The <code>ratio between the ChIP-seq tag count and λlocal？</code> is reported as the fold enrichment.</p>
<h3 id="8-Calculate-P-value-and-filter-candidate-peaks"><a href="#8-Calculate-P-value-and-filter-candidate-peaks" class="headerlink" title="8. Calculate P value and filter candidate peaks"></a>8. Calculate P value and filter candidate peaks</h3><h3 id="9-Calculate-FDR-by-exchanging-treatment-and-control"><a href="#9-Calculate-FDR-by-exchanging-treatment-and-control" class="headerlink" title="9. Calculate FDR by exchanging treatment and control"></a>9. Calculate FDR by exchanging treatment and control</h3><p>Each peak is considered an independent test and thus, when we encounter thousands of significant peaks detected in a sample we have a multiple testing problem. In <code>MACSv1.4</code>, the FDR was determined <code>empirically by exchanging the ChIP and control samples</code>. However, in <code>MACS2</code>, p-values are now corrected for multiple comparison using the <code>Benjamini-Hochberg correction</code>.</p>
<h2 id="MACS2-参数"><a href="#MACS2-参数" class="headerlink" title="MACS2 参数"></a>MACS2 参数</h2><h3 id="1-Input-file-options"><a href="#1-Input-file-options" class="headerlink" title="1. Input file options"></a>1. Input file options</h3><ul>
<li><code>-t</code> : The IP data file (this is the only REQUIRED parameter for MACS) 实验组</li>
<li><code>-c</code> : Control or mock data 对照</li>
<li><code>-f</code> : 输入文件格式，默认值“AUTO” ，bam sam bed</li>
<li><code>-g</code> :  <code>mappable genome size</code> which is defined as the genome size which can be sequenced; some precompiled values provided.</li>
<li>hs: 2.7e9人类基因组有效大小(UCSC human hg18 assembly)<h3 id="2-Output-arguments"><a href="#2-Output-arguments" class="headerlink" title="2. Output arguments"></a>2. Output arguments</h3></li>
<li><code>-outdir</code> : 输出文件夹</li>
<li><code>-n</code> : 文件前缀</li>
<li><code>-B/--bdg</code> : store the fragment pileup, control lambda, -log10pvalue and -log10qvalue scores in bedGraph files 输出bedgraph格式的文件<h3 id="3-Shifting-model-arguments"><a href="#3-Shifting-model-arguments" class="headerlink" title="3. Shifting model arguments"></a>3. Shifting model arguments</h3></li>
<li><code>-s</code> : <code>size of sequencing tags</code>. Default, MACS will use the <code>first 10 sequences</code> from your input treatment file to determine it</li>
<li><code>--bw</code> : The bandwidth which is used to <code>scan the genome</code> ONLY for model building. Can be set to the expected sonication fragment size.</li>
<li><code>--mfold</code> : <code>upper and lower limit</code> for model building</li>
<li><code>--nomodel</code>：<code>和extsize、shift是配套使用</code>，有这个参数才可设置extsize和shift。</li>
<li><code>--extsize</code>：当设置了nomodel时，MACS会用–extsize这个参数从<code>5&#39;-&gt;3&#39;方向扩展reads修复fragments</code>。如转录因子结合范围200bp，设置这个参数是200。</li>
<li><code>--shift</code>：当设置了–nomodel，MACS用这个参数从<code>5&#39; 端移动剪切</code>，然后用–extsize延伸，如果–shift是负值表示从3’端方向移动。建议ChIP-seq数据集这个值保持默认值为0？，对于检测富集剪切位点如DNAseq数据集设置为EXTSIZE的一半。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">想找富集剪切位点，如DNAse-seq，所有5&#x27;端的序列reads应该从两个方向延伸，如果想设置移动的窗口是200bp，参数设置如下：</span><br><span class="line">--nomodel --shift -100 --extsize 200</span><br><span class="line">对nucleosome-seq数据，用核小体大小的一半进行extsize,所以参数设置如下：</span><br><span class="line">--nomodel --shift 37 --extsize 73</span><br></pre></td></tr></table></figure>

<p><code>ATAC-seq</code>关心的是在哪切断，断点才是peak的中心，所以使用shift模型，–shift -75或-100<br>对人细胞系ATAC-seq 数据call peak的参数设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak -t H1hesc.final.bam -n sample --shift -100 --extsize 200 --nomodel -B --SPMR -g hs --outdir Macs2_out 2&gt; sample.macs2.log</span><br></pre></td></tr></table></figure>

<h3 id="4-Peak-calling-arguments"><a href="#4-Peak-calling-arguments" class="headerlink" title="4. Peak calling arguments"></a>4. Peak calling arguments</h3><ul>
<li><code>-q</code> : q-value (minimum FDR) cutoff <code>q value默认值是0.05，与pvalue不能同时使用。</code></li>
<li><code>-p</code> : p-value cutoff (instead of q-value cutoff)</li>
<li><code>--nolambda</code> : do not consider the local bias/lambda at peak candidate regions。不要考虑在峰值候选区域的局部偏差/λ</li>
<li><code>--broad</code> : broad peak calling，narrow peak和broad peak</li>
</ul>
<p> Relaxing the <code>q-value</code> does not behave as expected in this case since it is partially tied to peak widths. Ideally, if you <code>relaxed the thresholds</code>, you would simply get <code>more peaks</code> but with MACS2 relaxing thresholds also results in <code>wider peaks</code>. q值与峰宽有一定的联系。理想情况下，如果放宽阈值，您将简单地获得更多的峰值，但是使用MACS2放松阈值也会导致更宽的峰值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak -t bowtie2/H1hesc_Nanog_Rep1_aln.bam \</span><br><span class="line">	-c bowtie2/H1hesc_Input_Rep1_aln.bam \</span><br><span class="line"> 	-f BAM -g 1.3e+8 \</span><br><span class="line">	-n Nanog-rep1 \</span><br><span class="line">	--outdir macs2 2&gt; macs2/Nanog-rep1-macs2.log</span><br></pre></td></tr></table></figure>


<h2 id="MACS2-Output-files"><a href="#MACS2-Output-files" class="headerlink" title="MACS2 Output files"></a>MACS2 Output files</h2><h3 id="narrowPeak"><a href="#narrowPeak" class="headerlink" title="narrowPeak"></a>narrowPeak</h3><p>A narrowPeak (<code>.narrowPeak</code>) file is used by the ENCODE project to provide <code>called peaks of signal enrichment</code> based on pooled, normalized (interpreted) data. It is a <code>BED 6+4 format</code>, which means the <code>first 6 columns of a standard BED file</code> with <code>4 additional</code> fields:<br><img src="https://img-blog.csdnimg.cn/7bd1ca4fcb3847daacc450a91989b5cd.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h3 id="WIG-format"><a href="#WIG-format" class="headerlink" title="WIG format"></a>WIG format</h3><p>Wiggle format (WIG) allows the <code>display</code> of continuous-valued data in a track format. Wiggle format is <code>line-oriented</code>. It is composed of declaration lines and data lines, and require a separate wiggle track definition line. There are two options for formatting wiggle data: variableStep and fixedStep. These formats were developed to allow the file to be written as compactly as possible.</p>
<h3 id="BedGraph-format"><a href="#BedGraph-format" class="headerlink" title="BedGraph format"></a>BedGraph format</h3><p>The BedGraph format also allows display of continuous-valued data in track format. This display type is useful for probability scores and transcriptome data. This track type is similar to the wiggle (WIG) format, but unlike the wiggle format, data exported in the bedGraph format are preserved in their original state. For the purposes of visualization, these can be interchangeable.</p>
<ul>
<li><p><code>_peaks.narrowPeak</code>: BED6+4 format file which contains the peak locations together with peak summit, pvalue and qvalue。<code>BED6+4格式，可以上传到UCSC浏览。</code></p>
<ul>
<li>1：染色体号</li>
<li>2：peak起始位点</li>
<li>3：结束位点</li>
<li>4：peak name</li>
<li>5：int(-10*log10qvalue)</li>
<li>6 ：正负链</li>
<li>7：fold change</li>
<li>8：-log10pvalue</li>
<li>9：-log10qvalue</li>
<li>10：relative summit position to peak start（？）</li>
</ul>
</li>
<li><p><code>_peaks.xls</code>: a tabular file which contains information about called peaks. Additional information includes pileup and fold enrichment。<code>含peak信息的tab分割的文件，前几行显示callpeak命令</code>。</p>
<ul>
<li>染色体号</li>
<li>peak起始位点</li>
<li>peak结束位点</li>
<li>peak区域长度</li>
<li>peak的峰值位点（summit position）</li>
<li>peak 峰值的高度（pileup height at peak summit, -log10(pvalue) for the peak summit）</li>
<li>peak的富集倍数（相对于random Poisson distribution with local lambda）</li>
<li>XLS里的坐标和bed格式的坐标还不一样，起始坐标需要减1才与narrowPeak的起始坐标一样。</li>
</ul>
</li>
<li><p><code>_summits.bed</code>: peak summits locations for every peak. To find the motifs at the binding sites, this file is recommended。BED格式的文件，包含peak的summits位置，第5列是-log10pvalue。如果想找motif，推荐使用此文件。</p>
</li>
<li><p><code>_model.R</code>: an R script which you can use to produce a PDF image about the model based on your data and cross-correlation plot</p>
</li>
<li><p><code>_control_lambda.bdg</code>: bedGraph format for input sample</p>
</li>
<li><p><code>_treat_pileup.bdg</code>: bedGraph format for treatment sample。bedGraph格式，可以导入UCSC或者转换为bigwig格式。两种bfg文件：treat_pileup, and control_lambda.</p>
</li>
<li><p><code>NAME_peaks.broadPeak</code>： BED6+3格式与narrowPeak类似，只是没有第10列。</p>
</li>
</ul>
<p>R作图the first plot illustrates the distance between the modes from which the shift size was determined？<br><img src="https://img-blog.csdnimg.cn/3d941b11b37c4b7687b11e6766a9daff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_13,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>The second plot is the cross-correlation plot. This is a graphical representation of the Pearson correlation of positive- and negative- strand tag densities, shifting the strands relative to each other by increasing distance？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xls文件</span><br><span class="line">文件包含信息还是比较多的，和narrowPeak唯一不同的是peak的起始位置需要减1才是bed格式的文件，另外还包含fold_enrichment 和narrowPeak的fold change 对应，-log10pvalue,-log10qvalue,peak长度，peak 峰值位置等。</span><br><span class="line">narrowPeak文件</span><br><span class="line">和xls文件信息类似</span><br><span class="line">summits.bed文件</span><br><span class="line">包含峰的位置信息和-log10pvalue</span><br><span class="line">bdg文件</span><br><span class="line">bdg文件适合导入UCSC或IGV进行谱图可视化，或者转换为bigwig格式再进行可视化。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
  <entry>
    <title>单倍型基因组组装算法hifiasm</title>
    <url>/blog/2021/10/20/hifiasm/</url>
    <content><![CDATA[<h2 id="Nat-Methods-等位基因组组装算法hifiasm（20210202）"><a href="#Nat-Methods-等位基因组组装算法hifiasm（20210202）" class="headerlink" title="Nat. Methods|等位基因组组装算法hifiasm（20210202）"></a>Nat. Methods|等位基因组组装算法hifiasm（20210202）</h2><p>paper：    <a href="https://pubmed.ncbi.nlm.nih.gov/33526886/">Haplotype-resolved de novo assembly using phased assembly graphs with hifiasm</a><br>该研究提出一种全新的单倍型基因组组装算法hifiasm，能够有效地对<font color="red">大型复杂基因组生成高质量的单倍型组装结果</font>。</p>
<span id="more"></span>

<h3 id="单倍型组装难点"><a href="#单倍型组装难点" class="headerlink" title="单倍型组装难点"></a>单倍型组装难点</h3><p>单倍型基因组组装是研究基因组结构与变异的最理想方式。由于技术的局限，大多数组装算法倾向于将不同单倍型有损的压缩成一条混合的代表性序列。对于自然界中主流的二倍体和多倍体样本而言，这类方法损失了大量的单倍型信息。这使得长久以来，研究人员难以对高杂合、高重复的基因组进行深入的分析。</p>
<p>为了解决这个难题，一些组装算法首先生成混合的代表性序列，接着从代表性序列中恢复出不同的单倍型信息。但是，由于代表性序列本身已经丢失了大量的信息，这类方法难以获得高质量的单倍型组装结果。</p>
<p>近期的组装算法通过额外的信息，如家系(Trio binning)或者Hi-C等数据，预先全局性的将待组装的测序读段划分到不同单倍型，再进行分别组装，从而试图获得高质量的单倍型组装结果。但是对于低杂合的样本而言，这种方法难以做到完美的预先划分，因此容易产生组装错误。</p>
<h3 id="Hifiasm-算法"><a href="#Hifiasm-算法" class="headerlink" title="Hifiasm 算法"></a>Hifiasm 算法</h3><p>在本研究中，研究人员提出了一种全新的针对PacBio HiFi (High-Fidelity reads) 数据的单倍型组装算法hifiasm。该算法有两项重要创新。</p>
<p>第一，提出了单倍型敏感的组装思路，使得在组装的全过程中能够无损的保留单倍型信息，同时也极大的提升了对基因组高重复和复杂区域的解析能力。</p>
<p>第二，提出了Graph-binning的分型策略，其利用组装图的结构信息对全局分型结果进行校正，从而极大地提高了单倍型组装的质量。Graph-binning不对待组装的测序读段进行预先全局划分，因此能够克服划分错误带来组装问题。</p>
<h3 id="组装结果"><a href="#组装结果" class="headerlink" title="组装结果"></a>组装结果</h3><p>研究人员在不同的数据集上测试了hifiasm算法。对于不同大小，不同杂合度和不同单倍型数量的动物和植物基因组，hifiasm能够产生质量最高的组装结果。尤其值得注意的是，hifiasm仅用三天时间，就完成27Gb超大加州红杉基因组的组装，并且组装结果的连续性7倍于其他算法。</p>
<p>对于人类基因组，hifiasm也能取得最好的效果。相比于现有算法，hifiasm所产生的组装结果连续性最高，同时也正确解析了最多的复杂和高重复区域，如MHC (主要组织相容性复合体)和centromere (着丝端粒)。尤其对于人类二倍体样本HG002和HG00733，hifiasm产生的组装结果的连续性3倍于其他算法，并成功保留了最多的变异信息。</p>
<p><a href="http://www.evolution.ynu.edu.cn/info/1016/1208.htm">http://www.evolution.ynu.edu.cn/info/1016/1208.htm</a></p>
]]></content>
      <categories>
        <category>Papers</category>
      </categories>
      <tags>
        <tag>Assemble</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-2【Harvard FAS Informatics】</title>
    <url>/blog/2021/10/14/ATAC-seq-2-harvard/</url>
    <content><![CDATA[<h2 id="ATAC-seq数据质量评估注意"><a href="#ATAC-seq数据质量评估注意" class="headerlink" title="ATAC-seq数据质量评估注意"></a>ATAC-seq数据质量评估注意</h2><span id="more"></span>

<p><code>ENCODE</code>的ATACseq<a href="https://www.encodeproject.org/atac-seq/">数据标准</a>。</p>
<h3 id="Uniform-Processing-Pipeline-Restrictions"><a href="#Uniform-Processing-Pipeline-Restrictions" class="headerlink" title="Uniform Processing Pipeline Restrictions"></a>Uniform Processing Pipeline Restrictions</h3><ul>
<li>The <code>read length</code> prior to any trimming should be a minimum of <code>45 base pairs</code>.</li>
<li>Sequencing may be <code>paired</code>- or <code>single</code>-ended, <code>sequencing type</code> is specified and <code>paired sequences</code> are indicated.</li>
<li>All <code>Illumina platforms</code> are supported for use in the uniform pipeline, though <code>data from different platforms should be processed separately</code>; colorspace (<code>SOLiD</code>) reads are <code>not</code> supported. </li>
<li><code>Barcodes</code>, if present in the fastq, must be <code>indicated</code>.</li>
<li><code>Library insert size</code> range must be <code>indicated</code>. <h3 id="Current-Standards"><a href="#Current-Standards" class="headerlink" title="Current Standards"></a>Current Standards</h3></li>
</ul>
<ol>
<li>必须有两次或更多次<code>生物学重复</code>（稀有样本也必须做两次<code>技术重复</code>）</li>
<li>每次重复要有25million非冗余，非线粒体，能够回帖的fragment（单端25 million reads，<code>双端50 million reads</code>=25 million fragment）</li>
<li>回帖率&gt;95%, &gt;80%可接受。</li>
<li>用<code>IDR(Irreproducible Discovery Rate)</code>计算重复一致性，rescue和self consisty ratios 都&gt;2</li>
<li>用以下指标控制PCR扩增对文库复杂性的影响： <code>Non-Redundant Fraction (NRF)</code> and PCR Bottlenecking Coefficients 1 and 2, or PBC1 and PBC2：NRF&gt;0.9, PBC1&gt;0.9, PBC2&gt;3</li>
<li>peak文件必须满足如下要求：<blockquote>
<p>每个重复peak数&gt;150000，&gt;100000可接受（ENCODE的ATAC-seq的peak file没法用）<br>IDR peak&gt;70000,&gt;50000可接受<br>要存在无核小体区NFR<br>存在单核小体峰，好的ATACseq数据应包含核小体，既能看开放染色质，又能看核小体</p>
</blockquote>
</li>
<li>The fraction of reads in called peak regions(FRip score)&gt;0.3,&gt;0.2 可以接受。对于稀有样本不要求FRiP但TSS富集还是要作为关键的衡量信噪比的指标。</li>
<li>TSS富集分数阈值与参考基因组相关。</li>
</ol>
<h2 id="ATACseq-主干分析流程"><a href="#ATACseq-主干分析流程" class="headerlink" title="ATACseq 主干分析流程"></a>ATACseq 主干分析流程</h2><p>reference：<br><strong>1.文章</strong>：<a href="https://peerj.com/articles/4040/">https://peerj.com/articles/4040/</a><br><strong>2.CHIPseq课程</strong>：<a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a><br><strong>3.Harvard FAS Informatics - ATAC-seq Guidelines</strong>：<a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">https://informatics.fas.harvard.edu/atac-seq-guidelines.html</a></p>
<h2 id="Harvard-FAS-Informatics-ATAC-seq-Guidelines"><a href="#Harvard-FAS-Informatics-ATAC-seq-Guidelines" class="headerlink" title="Harvard FAS Informatics - ATAC-seq Guidelines"></a><a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">Harvard FAS Informatics - ATAC-seq Guidelines</a></h2><h3 id="Experimental-design"><a href="#Experimental-design" class="headerlink" title="Experimental design"></a>Experimental design</h3><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4374986/">Detailed protocol</a></p>
<ul>
<li>Replicates</li>
<li>Controls：一般<code>不设置对照</code>。作用有限，费用。没有转座酶处理的样本测序</li>
<li>PCR amplification：<code>尽可能少</code>地使用<code>PCR循环</code>来扩增样本，减少干扰</li>
<li>Sequencing depth：最佳测序深度取决于<code>参考基因组的大小</code>和<code>预期染色质的开放程度</code>。人类样本的研究推荐每个样本超过5000万个reads。</li>
<li>Sequencing mode：(1) ATACseq推荐使用paired-end。paired-end sequencing, helps to <code>reduce these alignment ambiguities</code>. (2) we are interested in <code>knowing both ends of the DNA fragments generated by the assay</code>, since the ends indicate where the transposase inserted. (3) <strong><code>PCR duplicates are identified more accurately</code></strong>.  PCR duplicates are <code>artifacts of the procedure</code>, and they should be removed as part of the analysis pipeline . <code>Computational programs that remove PCR duplicates typically identify duplicates based on comparing ends of aligned reads</code>. With <strong><code>single-end reads</code></strong>, there is <code>only one position to compare</code>, and so any <code>reads whose 5&#39; ends match are considered duplicates</code>. Thus, <code>many false positives</code> may result, and perfectly <code>good reads are removed</code> from further analysis. <strong><code>Paired-end sequencing</code></strong>, <code>both ends of the original DNA fragments are defined</code>. <code>To be declared a duplicate, both ends of one fragment need to match both ends of another fragment</code>, which is far <code>less likely to occur by chance</code>. Therefore, paired-end sequencing leads to <code>fewer false positives</code>.</li>
<li>Mitochondria: 众所周知ATAC-seq数据通常包含很大比例的<code>来自线粒体DNA的reads</code>（<em>线粒体DNA是裸露的，也可以被Tn5酶识别切割，植物叶绿体</em>）。线粒体基因组中没有ATAC-seq感兴趣的峰，这些reads在计算中被丢弃，浪费测序资源。可在测序前使用洗涤剂<a href="https://www.nature.com/articles/nmeth.4396">去除样本中的线粒体</a>。</li>
</ul>
<h3 id="Quality-control"><a href="#Quality-control" class="headerlink" title="Quality control"></a>Quality control</h3><h4 id="FastQC"><a href="#FastQC" class="headerlink" title="FastQC"></a>FastQC</h4><p>Process a file of <code>20 million reads</code> in about <code>5 minutes</code> with less than <code>250MB memory</code> used. Quality scores, GC levels, PCR duplicates, and adapter content.</p>
<h4 id="Adapter-removal"><a href="#Adapter-removal" class="headerlink" title="Adapter removal"></a>Adapter removal</h4><p>For reads derived from <code>short DNA fragments</code>, the <code>3&#39; ends may contain portions of the Illumina sequencing adapter</code>.  </p>
<h5 id="Cutadapt"><a href="#Cutadapt" class="headerlink" title="Cutadapt"></a><a href="https://cutadapt.readthedocs.io/en/stable/guide.html">Cutadapt</a></h5><h5 id="NGmerge"><a href="#NGmerge" class="headerlink" title="NGmerge"></a><a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2579-2">NGmerge</a></h5><p>Unlike cutadapt, NGmerge <code>does not require</code> that the <code>adapter sequences</code> be provided, <code>nor</code> does it <code>require a parameter for the minimum length of adapter to match</code> (in fact, it <code>does not perform adapter matching</code> at all).For input files of <code>20 million paired reads</code>, NGmerge should run in <code>less than one hour on a single core</code>, with minimal memory usage.<br><img src="https://img-blog.csdnimg.cn/e2669cfa1a184ec2b7026fe528f9c97a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p>
<h5 id="Just-adapter-removal"><a href="#Just-adapter-removal" class="headerlink" title="Just adapter removal"></a>Just adapter removal</h5><p>Other than adapter removal, we <code>do not recommend any trimming of the reads.</code> Such adjustments can complicate later steps, such as the identification of PCR duplicates.</p>
<h3 id="Alignment"><a href="#Alignment" class="headerlink" title="Alignment"></a>Alignment</h3><p>Two of the most popular alignment program are BWA and <code>Bowtie2</code>.</p>
<h4 id="Genome-indexing"><a href="#Genome-indexing" class="headerlink" title="Genome indexing"></a>Genome indexing</h4><p>For many model organisms, the genome and pre-built reference indexes are available from <a href="https://support.illumina.com/sequencing/sequencing_software/igenome.html">iGenomes</a>.<br>Otherwise, Bowtie2 indexes are made from a FASTA genome file using the program <code>bowtie2-build</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2-build  &lt;genome.fa&gt;  &lt;genomeIndexName&gt;</span><br></pre></td></tr></table></figure>
<h4 id="Alignment-1"><a href="#Alignment-1" class="headerlink" title="Alignment"></a>Alignment</h4><p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml">Bowtie2 parameters</a>. Here are a few that <code>may benefit the alignment of an ATAC-seq dataset</code> :</p>
<p><code>-X &lt;int&gt;</code> : Maximum DNA fragment length (<code>default 500bp</code>). If you anticipate that you may have DNA fragments <code>longer than</code> the default value, you should <code>increase</code> this parameter accordingly; otherwise, alignments from such fragments are considered not properly paired (see Fig. 3B below).<br><code>--very-sensitive</code> : Bowtie2 has a number of alignment and effort parameters that interact in complex (and sometimes unexpected) ways. Preset collections of these parameters are provided for convenience; the default is –sensitive, but <code>better alignment results</code> are frequently achieved with –very-sensitive.<br><code>-k &lt;int&gt;</code> : Maximum number of alignments to report per read. By default, Bowtie2 reports at most one alignment per read, and if multiple equivalent alignments exist, it chooses one randomly.<br><code>-p &lt;int&gt;</code> : Number of <code>cores</code> on which to run</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2  --very-sensitive  -k 10  -x &lt;genomeIndexName&gt;  -1 &lt;name&gt;_1.fastq.gz  -2 &lt;name&gt;_2.fastq.gz  \</span><br><span class="line">  |  samtools view  -u  -  \</span><br><span class="line">  |  samtools sort  -n  -o &lt;BAM&gt;  -</span><br></pre></td></tr></table></figure>
<ul>
<li>For input files of <code>20 million</code> paired reads, this command takes around <code>five hours</code> on Cannon(1 core too slow). One could specify eight cores for Bowtie2 with <code>-p 8</code> and adjust the request in the <code>SLURM script</code> to <code>#SBATCH -n 10</code> (that is, <code>eight</code> cores for <code>Bowtie2</code> and <code>one each</code> for <code>SAMtools view</code> and <code>sort</code>). </li>
<li>Bowtie2 also provides (via stderr) a summary of the mapping results, separated according to uniqueness and alignment type.</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/9f961cf3106f4c99b6e85bd1c3f6e373.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"><br> Alignment types for paired-end reads. <strong>A</strong>: Properly paired alignments (“<code>concordant</code>“) have the reads <code>aligned in opposite orientations</code> on the <code>same reference</code> sequence (chromosome). The reads <code>may overlap</code> to some extent (bottom). <strong>B</strong>: A read alignment (for <code>R1</code>) can be <code>unpaired</code> for several reasons: if the read’s mate (<code>R2</code>) is <code>unaligned</code> (<code>upper left</code>), <code>aligns to a different chromosome</code> (<code>upper right</code>), aligns in the <code>incorrect orientation</code> (<code>middle</code> cases), or aligns in the correct orientation but at an <code>invalid distance</code> (<code>bottom</code>). In all cases except the upper left, the R2 read alignment is also unpaired, and the read pair align discordantly (though Bowtie2 also requires uniqueness for such alignments to be counted as discordant).</p>
<p>Generich 版本</p>
<h3 id="Peak-calling"><a href="#Peak-calling" class="headerlink" title="Peak calling"></a>Peak calling</h3><h4 id="推荐新的Generich"><a href="#推荐新的Generich" class="headerlink" title="推荐新的Generich???"></a>推荐新的<a href="https://github.com/jsh58/Genrich"><code>Generich</code></a>???</h4><p>Genrich was designed to be able to <code>run all of the post-alignment steps</code> through <code>peak-calling with one command</code>. It also possesses a few <code>novel features</code>. Consider the following attributes:</p>
<ul>
<li><strong>Removal of mitochondrial reads</strong>. Genrich <code>disregards all alignments to the mitochondrial</code> chromosome with <code>-e chrM</code>.</li>
<li><strong>Removal of PCR duplicates</strong>. Genrich follows a <code>systematic procedure</code> to <code>remove PCR duplicates</code> with <code>-r</code>. Note that this evaluation <code>takes into account multimapping reads</code> (see next), which is <code>not provided by other alignment-based duplicate-removal programs</code>, such as <code>Picard&#39;s MarkDuplicates</code>.</li>
</ul>
<p><strong>Analysis of multimapping reads</strong>. 重复区域多的基因组可能导致非唯一mapping。 Non-uniquely aligned reads can be removed by filtering based on MAPQ scores with <code>samtools</code>, but this effectively renders certain genomic regions inaccessible to the assay. With Genrich, <code>reads with multiple alignments are analyzed</code> by adding a fractional count to each location. Genrich’s <code>statistical model</code> accommodates these values.<br>Along these same lines, Genrich considers the entire reference genome to be part of the assay. If there are chromosomes or genomic regions that should be excluded from analysis, these can be specified by <code>-e or -E</code>, and Genrich will adjust the <code>genome length calculation</code> accordingly. There is no need to <code>guesstimate an &quot;effective&quot; genome size</code> like with MACS2.<br><strong>Analysis of multiple replicates</strong>. When alignment files for multiple replicates are provided to Genrich, it <code>calls peaks for the replicates collectively</code>. <code>No more IDR</code>. Done.<br><strong>Interpretation of alignments suitable for ATAC-seq</strong>. Genrich provides an ATAC-seq analysis mode (-j) in which, rather than inferring the full fragments from the alignments, intervals are interpreted that are centered on transposase cut sites (the ends of each DNA fragment). Only properly paired alignments are analyzed by default, but there is an option to consider unpaired alignments as well (-y) (Fig. 4).</p>
<p><img src="https://img-blog.csdnimg.cn/abb30e7406834c91b7e456ff14e23742.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p>
<ul>
<li>Our previous recommendation was to run <code>MACS2</code> with <code>-f BAMPE</code>, which is similar to the <code>default analysis mode of Genrich</code> (<strong>inferring full fragments, rather than cut site intervals</strong>). Others have attempted to interpret cut site intervals with MACS2 by using the <code>--shif</code>t and <code>--extsize</code> arguments, but these arguments are ignored in <code>BAMPE</code> mode. They do work in the default (<code>BAM</code>) mode, but then, with paired-end reads, <code>most of the alignments are automatically discarded</code> (half of the properly paired alignments and all of the unpaired alignments; secondary alignments are never considered). Is it worse to interpret full fragments that may be less informative biologically, or to disregard more than half of the sequence data? A complicated question. The correct answer is: <strong>use Genrich.</strong><h4 id="Genrich"><a href="#Genrich" class="headerlink" title="Genrich"></a>Genrich</h4></li>
</ul>
<p><strong>most important parameters and options of Genrich for analyzing ATAC-seq：</strong> </p>
<p><code>-j</code> : ATAC-seq mode (<strong>must</strong> be specified)<br><code>-d &lt;int&gt;</code> : Expand cut sites to the given length (default 100bp)<br><code>-y</code> : Analyze <strong>unpaired</strong> alignments<br><code>-r</code> : Remove PCR duplicates<br><code>-e &lt;arg&gt;</code> : Chromosomes (reference sequences) to exclude. Can be a comma-separated list, e.g. <code>-e chrM,chrY</code>.<br><code>-E &lt;file&gt;</code> : Input BED file(s) of genomic regions to exclude, such as ‘N’ homopolymers or high mappability regions<br><code>-q &lt;float&gt;</code> : Maximum q-value (FDR-adjusted p-value) for peak calling (default 0.05). An unadjusted p-value threshold can be used instead with <code>-p &lt;float&gt;</code>.<br><code>-a &lt;float&gt;</code> : Minimum area under the curve (total significance) for a peak (default 20.0). <code>Increasing</code> this value results in <code>fewer</code> but <code>higher confidence</code> peaks.<br><code>-v</code> : Verbose mode</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Genrich  -t &lt;BAM&gt;  -o &lt;OUT&gt;  -j  -y  -r  -e chrM  -v</span><br></pre></td></tr></table></figure>

<ul>
<li>对于重复data,  <code>-t &lt;BAM1&gt;,&lt;BAM2&gt;</code>.</li>
<li>The output file produced by Genrich is in <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format12"><code>ENCODE narrowPeak format</code></a>, listing the genomic coordinates of each peak called and various statistics.</li>
<li>Speed： a single BAM containing <code>146.3 million alignments</code> was analyzed by Genrich in <code>10.5min</code> with <code>17.1GB of memory</code> . In general, input BAM(s) of more alignments take longer to analyze, but the memory usage should not increase greatly. Note that <code>Genrich is not multithreaded</code>, so it runs on a single core only.</li>
<li>Those who wish to explore the results of varying the <code>peak-calling parameters (-q/-p, -a, -l, -g)</code> should consider having Genrich produce a log file when it parses the SAM/BAM files (for example, with <code>-f &lt;LOG&gt;</code> added to the above command). Then, Genrich can call peaks directly from the log file with the <code>-P</code> option（调参数使用此法节省内存和时间）:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Genrich  -P  -f &lt;LOG&gt;  -o &lt;OUT2&gt;  -p 0.01  -a 200  -v</span><br></pre></td></tr></table></figure>

<h3 id="NEXT-Steps"><a href="#NEXT-Steps" class="headerlink" title="NEXT Steps"></a>NEXT Steps</h3><h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>For ATAC-seq in model organisms, the <code>peak file produced by Genrich</code> can be <code>uploaded</code> directly to the <a href="https://genome.ucsc.edu/cgi-bin/hgCustom">UCSC genome browser</a>. Add header.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">track type=narrowPeak</span><br></pre></td></tr></table></figure>
<p>An alternative visualization tool is the <a href="http://software.broadinstitute.org/software/igv/">Integrative Genomics Viewer (IGV)</a>. Peak files can be loaded directly (File → Load from File). <strong>Viewing BAM files with IGV requires that they be sorted by coordinate and indexed</strong> using <a href="http://www.htslib.org/doc/samtools.html">SAMtools</a>. However, the BAMs show the read alignments, <code>not the full fragments generated by the ATAC</code> <code>nor the cut site intervals</code> analyzed by Genrich. To view the intervals, one can use the optional output <code>BED file</code> produced by Genrich with <code>-b</code>.</p>
<h4 id="Comparing-peak-files"><a href="#Comparing-peak-files" class="headerlink" title="Comparing peak files"></a>Comparing peak files</h4><p>Determining genomic regions that are <code>common or different to a set of peak files</code> is best accomplished with <a href="http://bedtools.readthedocs.io/en/latest/index.html">BEDTools</a>, a suite of software tools that enables “genome arithmetic.”<br>For example, <a href="http://bedtools.readthedocs.io/en/latest/content/tools/intersect.html">bedtools intersect</a> determines regions that are <strong><code>common</code></strong> to two peak files. Finding <strong><code>differences</code></strong> between two peak files, such as control vs. experimental groups, is accomplished via <a href="http://bedtools.readthedocs.io/en/latest/content/tools/subtract.html">bedtools subtract</a>.</p>
<h4 id="Annotation"><a href="#Annotation" class="headerlink" title="Annotation"></a>Annotation</h4><p>It is helpful to know <code>what genomic features are near the peaks</code> called by Genrich. One program that is commonly used to annotate peaks is <a href="https://bioconductor.org/packages/release/bioc/html/ChIPseeker.html">ChIPseeker</a>. ChIPseeker was originally designed to be used in the analysis of ChIP-seq, but it works just <code>as well with ATAC-seq.</code><br>ChIPseeker <strong>requires</strong> that the <code>genome of interest be annotated with locations of genes and other features</code>. The <a href="https://bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html">ChIPseeker user guide</a> is extremely helpful in using this R/Bioconductor package.</p>
<h4 id="Motif-finding"><a href="#Motif-finding" class="headerlink" title="Motif finding"></a>Motif finding</h4><p><a href="http://homer.ucsd.edu/homer/introduction/basics.html">HOMER</a> is a suite of software designed for <a href="http://homer.ucsd.edu/homer/ngs/peakMotifs.html">motif discovery</a>. It takes a <code>peak file as input</code> and <code>checks for the enrichment</code> of both <code>known sequence motifs</code> and <code>de novo motifs</code>.</p>
<p>MACS2版本</p>
<h4 id="Alignment（same）"><a href="#Alignment（same）" class="headerlink" title="Alignment（same）"></a>Alignment（same）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2  --very-sensitive  -x &lt;genomeIndexName&gt;  -1 &lt;name&gt;_1.fastq.gz  -2 &lt;name&gt;_2.fastq.gz \</span><br><span class="line"> |  samtools view -u -  \</span><br><span class="line"> |  samtools sort -  &gt;  &lt;BAM&gt;</span><br></pre></td></tr></table></figure>

<h4 id="Alignment-adjustments"><a href="#Alignment-adjustments" class="headerlink" title="Alignment adjustments"></a>Alignment adjustments</h4><h5 id="Mitochondrial-reads"><a href="#Mitochondrial-reads" class="headerlink" title="Mitochondrial reads"></a>Mitochondrial reads</h5><ul>
<li>ATAC-seq datasets usually contain a large percentage of reads that are derived from mitochondrial DNA (<a href="http://seqanswers.com/forums/showthread.php?t=35318">discussion</a>). Using <a href="https://www.nature.com/articles/s41598-017-02547-w">CRISPR to reduce mitochondrial contamination</a>. Or recently <a href="https://www.nature.com/articles/nmeth.4396">Omni-ATAC method</a> uses detergents[洗涤剂] to remove mitochondria and is likely to be more accessible for most researchers ( <a href="https://www.biorxiv.org/content/10.1101/496521v1">bad computational workflow</a>).</li>
<li>Method 1 : <strong>Remove the mitochondrial genome from the reference genome before aligning the reads</strong>. In human/mouse genome builds, the mitochondrial genome is labeled ‘<code>chrM</code>‘. That sequence can be deleted from the reference prior to building the genome indexes. The downside of this approach is that the alignment numbers will look much worse; all of the mitochondrial reads will count as unaligned. [植物？]</li>
<li>Method 2 : <strong>Remove the mitochondrial reads after alignment</strong>. A python script, creatively named removeChrom, is available in the ATAC-seq module to accomplish this. For example, to remove all ‘chrM’ reads from a BAM file, one would run this:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -h  &lt;inBAM&gt;  |  removeChrom - - chrM  |  samtools view -b -  &gt;  &lt;outBAM&gt;</span><br></pre></td></tr></table></figure>
<h5 id="PCR-duplicates"><a href="#PCR-duplicates" class="headerlink" title="PCR duplicates"></a>PCR duplicates</h5><p> Picard’s <a href="http://broadinstitute.github.io/picard/command-line-overview.html#MarkDuplicates">MarkDuplicates</a>. The output file specified by <code>M=</code> lists counts of alignments analyzed and duplicates identified.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -jar $PICARD_TOOLS_HOME/picard.jar MarkDuplicates I=&lt;inBAM&gt; O=&lt;outBAM&gt; M=dups.txt REMOVE_DUPLICATES=true</span><br></pre></td></tr></table></figure>
<h5 id="Non-unique-alignments"><a href="#Non-unique-alignments" class="headerlink" title="Non-unique alignments"></a>Non-unique alignments</h5><p>重复区域多的参考序列可能导致reads多处mapping. 用samtools view的-q <code>去除非唯一比对</code>. For reads with multiple alignments, <code>Bowtie2</code> (or <code>BWA</code>) will <code>report only one alignment</code> (by <code>default</code>) and will assign it a low mapping quality (MAPQ) score, which is defined as -10 * log10Pr{mapping position is wrong}. To eliminate alignments with <code>MAPQ &lt; 10</code> (i.e., where <code>Bowtie2</code> has determined <code>Pr&#123;mapping position is wrong&#125; &gt; 0.1</code>), one would run the following:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -b  -q 10  &lt;inBAM&gt;  &gt;  &lt;outBAM&gt;</span><br></pre></td></tr></table></figure>

<h4 id="Peak-calling-1"><a href="#Peak-calling-1" class="headerlink" title="Peak calling"></a>Peak calling</h4><ul>
<li>Model-based Analysis of ChIP-Seq (<a href="https://github.com/taoliu/MACS">MACS2</a>) is a program for detecting regions of <code>genomic enrichment</code>. Though designed for ChIP-seq, it works just <code>as well on ATAC-seq and other genome-wide enrichment assays that have narrow peaks</code>. The main program in MACS2 is <code>callpeak</code>, and its options are described below. (Note that the latest version of MACS2 on Odyssey (v2.1.2_dev) is different from the updated official MACS2 release (v2.1.2), although the latter does incorporate many of the bug fixes made in the Odyssey <code>version？</code>.)</li>
<li>It is important to remember that the <code>read alignments indicate only a portion of the DNA fragments generated by the ATAC？</code>. Therefore, one must consider how one wants MACS2 to interpret the alignments.<h5 id="Alignments-to-analyze"><a href="#Alignments-to-analyze" class="headerlink" title="Alignments to analyze"></a>Alignments to analyze</h5></li>
<li>alignments分为两类：”<strong>properly paired</strong>“ and “<strong>singletons</strong>“ 。<code>-f</code> 选择其类型。</li>
<li><strong>Analyze only properly paired alignments, but ignore R2 reads and treat R1 reads as singletons</strong>. This is the default option (<code>-f AUTO</code>). MACS2 creates a model of the fragment lengths and extends the 3’ ends of the R1 reads to the calculated average length. An alternative is to skip this model building and instead extend each read to a specified length (e.g., <code>--nomodel --extsize 300</code> for 300bp fragments). The value of the length parameter is usually determined from the average size during library preparation (the default value is 200bp if no value is specified). However, <code>neither of these approaches utilizes the value of paired-end sequencing</code>, which defines both fragment ends.</li>
<li><strong>Analyze only properly paired alignments with <code>-f BAMPE</code></strong>. Here, the fragments are defined by the paired alignments’ ends, and there is <code>no modeling or artificial extension</code>. Singleton alignments are ignored. This is the <code>preferred option</code> for using only properly paired alignments.</li>
<li><strong>Analyze all alignments</strong>. For this approach, a python script, SAMtoBED, is available in the ATAC-seq module. This script converts the read alignments to BED intervals, treating the properly paired alignments as such and extending the singleton alignments as specified. There are <code>four options for the singletons</code>: ignore them, keep them as is, extend them to an arbitrary length (similar to the <code>--extsize</code> option of MACS2), or extend them to the average length calculated from the properly paired alignments. </li>
<li>Here is an example command, using the “extend to average length” option (<code>-x</code>):</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view -h  &lt;BAM&gt;  |  SAMtoBED  -i -  -o &lt;BED&gt;  -x  -v</span><br></pre></td></tr></table></figure>
<p>The output from SAMtoBED is a <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format1">BED file</a> that should be analyzed by MACS2 with <code>-f BEDPE</code>.<br>(Note that the BEDTools program <a href="http://bedtools.readthedocs.io/en/latest/content/tools/bamtobed.html">
</a> cannot be used here, since its output is in a nonstandard BED format that MACS2 cannot analyze.)</p>
<ul>
<li>In deciding among these analysis options, it may help to consider the counts produced by Bowtie2, which indicate <code>how many alignments fall into each category</code>. For example, if most of the reads are aligned in proper pairs, it may be sufficient to use <code>option #2</code>. On the other hand, <code>option #3</code> is preferred if a substantial fraction of the reads consists of singletons.<h5 id="Other-arguments"><a href="#Other-arguments" class="headerlink" title="Other arguments"></a>Other arguments</h5></li>
<li>MACS2 is <code>not multithreaded</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">macs2 callpeak  -t &lt;BED&gt;  -f BEDPE  -n NAME  -g ce  --keep-dup all</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>-n &lt;str&gt;</code>    Name of the sample. The output files  name prefix.<br><code>-g &lt;int&gt;</code>    Effective genome size, the size of the organism’s genome that can be analyzed (not including Ns, repetitive sequences, etc.). This will be less than the actual genome size. Parameters are provided for some model organisms, and the <code>default value is hs</code> (for Homo sapiens), which corresponds to a value of 2.7e9.<br><code>-q &lt;float&gt;</code>    <code>Maximum q-value</code> (FDR-adjusted p-value) for peak calling (default <code>0.05</code>). Reducing this threshold will decrease the number of peaks identified by MACS2 but increase the confidence in the called peaks.<br><code>--keep-dup &lt;arg&gt;</code>    How to handle PCR duplicates (default: –keep-dup 1, i.e. remove all potential duplicates). If PCR duplicates have been removed by another program, such as Picard’s MarkDuplicates, then specify <code>--keep-dup all</code>.<br><code>--max-gap &lt;int&gt;</code>    Maximum gap between significant sites to cluster them together (default 50bp). (v2.1.2_dev only)<br><code>--min-length &lt;int&gt;</code>    Minimum length of a peak (default 100bp). (v2.1.2_dev only)</p>
</blockquote>
<h5 id="Output-files"><a href="#Output-files" class="headerlink" title="Output files"></a>Output files</h5><ul>
<li>NAME_peaks.xls</li>
<li>NAME_peaks.narrowPeak</li>
<li>NAME_summits.bed</li>
<li>The most useful file is <code>NAME_peaks.narrowPeak</code>, a plain-text <code>BED</code> file that lists the <code>genomic coordinates of each peak called</code>, along with various <code>statistics</code> (fold-change, p- and q-values, etc.).</li>
</ul>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
  <entry>
    <title>ATAC-seq-1【Background】</title>
    <url>/blog/2021/10/11/ATAC-seq-1-background/</url>
    <content><![CDATA[<h3 id="ATAC-seq意义"><a href="#ATAC-seq意义" class="headerlink" title="ATAC-seq意义"></a>ATAC-seq意义</h3><span id="more"></span>

<p><img src="https://img-blog.csdnimg.cn/2eb44c70d00b45bab31b0eb915e91cac.png" alt="在这里插入图片描述"></p>
<ul>
<li>为何同样DNA序列的细胞的表型会不同，为何肝细胞是肝细胞，神经细胞是神经细胞？是什么造成了他们生产蛋白不同，决定蛋白生成的RNA不同呢？原因可以用<code>表观遗传</code>来解释。<br><img src="https://img-blog.csdnimg.cn/9bf2e2d5d25a4e2eab27321b99b0b0b8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li>DNA转录成RNA过程复杂，包括：<code>染色质可及性</code>，<code>DNA修饰</code>，<code>组蛋白修饰</code>等等（选择性表达）。</li>
<li><code>染色质可及性即DNA开放区域</code>，尤为重要。<code>核小体</code>由<code>8个组蛋白</code>组成复合物，每个核小体约<code>147bpDNA</code>。转录时DNA将从核小体复合物松开。许多因素，如<code>染色质结构</code>、<code>核小体位置</code>和<code>组蛋白修饰</code>，在染色质的组织和可及性起重要作用。致密核小体结构被破坏后，<code>启动子、增强子、绝缘子、沉默子</code>等<code>顺式调控元件和反式作用因子可以接近</code>的特性，叫<code>染色质的可及性</code>，也叫<code>染色质开放性</code>(chromatin accessibility ），这段区域叫开放染色质（open chromatin） 。</li>
<li>什么是组蛋白修饰<ul>
<li>定义：组蛋白包含5个部分，按分子量大小分别称为<code>H1，H3，H2A，H2B和H4</code>。组蛋白在相关酶作用下发生<code>甲基化，乙酰化，磷酸化，腺苷酸化，泛素化，ADP核糖基化</code>等修饰</li>
<li><code>H3·H4乙酰化</code>形成<code>开放染色质结构</code>，<code>增加基因表达</code></li>
<li>组蛋白<code>甲基化</code>修饰多发生在<code>H3H4</code>，与基因<code>抑制及激活</code>相关，取决于被<code>修饰位置和程度</code></li>
<li>组蛋白<code>磷酸化</code>修饰一般与基因<code>活化</code>有关</li>
<li>组蛋白<code>泛素化</code>则是<code>启动基因表达</code></li>
</ul>
</li>
<li>2013年由斯坦福大学William J. Greenleaf和Howard Y. Chang实验室开发的ATAC-seq（<code>Assay</code> for <code>Transposase</code>-<code>Accessible</code> <code>Chromatin</code> with high throughput sequencing），一种捕获染色质可及性（染色质开放性）的测序方法。</li>
<li>ATAC-seq<code>检测染色质可及性</code>，<code>确定基因表达调控机制</code>。识别<code>启动子区域</code>、<code>潜在的增强子或抑制子</code>。<code>启动子</code>是靠近转录起始点(TSS)的DNA区域。包含<code>转录因子的结合位点</code>，转录因子招募RNA聚合酶。<code>增强子</code>是位于<code>启动子下游或上游1Mb</code>的DNA区域。<code>当转录因子与增强子结合，并与启动子区域接触时，该基因的转录增加</code>。相反<code>抑制子</code>会<code>减少或抑制基因表达</code>。</li>
<li>ATAC-seq的<code>峰</code>往往是<code>启动子</code>，<code>增强子序列</code>以及一些<code>反式调控因子</code>结合位点。</li>
<li>为找到开放染色质区，基因组被<code>TN5转座酶</code>处理。在ATAC-Seq中，<code>修饰后的TN5将与NextEra接头相对应的DNA序列插入到基因组的开放区域</code>，同时，DNA被转座酶活性剪切。</li>
<li>开放染色质的研究方法除了ATAC-seq，还有DNase-Seq，FAIRE-seq，MNase-seq 等。ATAC-Seq<code>所需样本少，建库快，重复性更高</code></li>
<li>技术：制备细胞悬液-&gt;裂解细胞膜，获取细胞核-&gt;采用Tn5进行酶切-&gt;回收DNA片段，PCR扩增建库-&gt;高通量测序-&gt;生信分析</li>
<li><img src="https://img-blog.csdnimg.cn/00f06cb4758b44c7a35b8c5c3ff74eda.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq</code>与<code>Chip-seq</code> call出来的<code>peak</code>代表的<code>意义不同</code>。<code>Chip-seq</code> peak是被<code>目的蛋白结合拉下来的DNA</code>，一般只有<code>一个峰</code>，而<code>ATAC-seq</code>是被<code>Tn5转座酶切开</code>、没有被组蛋白结合、染色质开放的DNA位点，<code>如果是TF结合的区域，一般会有一个山谷般的存在</code>。ChIP-seq和ATAC-seq在TF或者Tn5结合区域<code>都会形成一个双峰的reads结合模式</code>，但<code>判断peak的时会有不同的标准</code>。chip-seq是由于<code>TF一起沉淀下来的DNA fragment一般会大于TF的结合区域</code>，<code>read的位置并不是真实TF结合位置</code>，需要<code>向内shift</code>；而<code>ATAC-seq一般是往两边shift</code>。<br><img src="https://img-blog.csdnimg.cn/e501e5a398b34d0e8fd514fba8333cdb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq</code>与<code>Chip-seq</code>应用上的区别:</li>
<li>ATAC-Seq可<code>检测全基因组DNA结合蛋白</code>，<code>转录结合位点</code> ，一般用于<code>不知道特定的转录因子</code>，用此方法与其他方法结合<code>筛查感兴趣的特定调控因子</code>；</li>
<li>ChIP-Seq是已知转录因子，根据<code>感兴趣的转录因子设计抗体</code>去做ChIP实验<code>富集结合的DNA片段</code>。在测定转录因子的 ChIP-seq 中<code>独有的峰可能是先驱转录因子</code>，其<code>先结合到封闭染色质</code>，然后<code>招募染色质重塑因子或其他转录因子起始转录</code>。这些转录因子 <code>ATAC-seq检测不到</code>。</li>
<li>得到DNA片段后，为测序准备建库，包括<code>用完整的NextEra接头</code>和<code>纯化</code>、<code>PCR扩增</code>等。基于上述原因，<code>ATAC-Seq推荐使用双端配对</code>的方法。</li>
</ul>
<h3 id="ATACseq应用"><a href="#ATACseq应用" class="headerlink" title="ATACseq应用"></a>ATACseq应用</h3><ul>
<li><p>染色质<code>开放性图谱绘制</code>，表观基因组图谱</p>
</li>
<li><p>找<code>调控</code>生物学过程的<code>关键转录因子</code></p>
</li>
<li><p>找<code>哪个转录因子</code>调控了研究的基因</p>
</li>
<li><p>找转录因子调控的<code>靶基因</code></p>
</li>
<li><p>得到<code>不同组织或不同条件下对应可及性区域</code>。</p>
</li>
<li><p>得到核小体位置</p>
</li>
<li><p>生成转录因子结合区域的特征(footprinting)</p>
<h3 id="技术限制"><a href="#技术限制" class="headerlink" title="技术限制"></a>技术限制</h3></li>
<li><p>Tn5通过<code>插入剪断DNA 并将测序接头连接到剪断的两个DNA 片段的末端</code>，因此对于一个DNA 片段而言，其两端的接头连接是随机的，导致<code>同一片段两端的接头有50%的概率是同一接头</code>。而<code>只有连接不同接头的片段才可用于富集扩增及测序</code>，因此<code>一半的片段无法利用</code>； </p>
</li>
<li><p><code>大量剪断的DNA 由于片段过大，无法进行PCR富集</code>; </p>
</li>
<li><p>Tn5 的<code>活性</code>受反应溶液的组成及反应条件<code>影响</code>，仍然需要优化以便提高剪切效果； </p>
</li>
<li><p>ATAC-seq在<code>植物细胞存在以下难点</code>：<code>细胞壁</code>，<code>叶绿体线粒体等细胞器污染</code>，<code>缺少稳定遗传的细胞系</code>; </p>
</li>
</ul>
<h3 id="ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq"><a href="#ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq" class="headerlink" title="ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq"></a>ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq</h3><ul>
<li>整体的分析思路一致，<code>找富集区域</code>，对富集区域进行功能分析。</li>
<li>ChIP-Seq是<code>揭示特定转录因子</code>或<code>蛋白复合物</code>的结合区域，实际是<code>研究DNA和蛋白质的相互作用</code>，利用<code>抗体将蛋白质和DNA一起富集</code>，并对<code>富集的DNA测序</code>。</li>
<li>DNase-Seq、ATAC-Seq、FAIRE-Seq都<code>研究开放染色质区域</code>：</li>
<li>DNase-Seq用<code>DNase I内切酶识别</code>开放染色质区域，</li>
<li>ATAC-seq用<code>Tn5转座酶</code>，随后进行<code>富集扩增</code>；</li>
<li>FAIRE-Seq先超声裂解，后用酚-氯仿富集；</li>
<li>MNase-Seq鉴定核小体区域。 </li>
</ul>
<p>下图是不同测序方法获取的峰形：</p>
<p><img src="https://img-blog.csdnimg.cn/aea5161044eb40e1a1cc4c1a65d63cbb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>检测染色质可及性的方法中，ATAC-seq尤其受欢迎。<br><img src="https://img-blog.csdnimg.cn/96808dfcce9446298f1d0d4cc0db6eee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<ul>
<li>ATAC-seq的优点：<code>Tn5转座酶的高活性</code>使ATAC-seq简单，省时，而且只需500-50,000个细胞。灵敏度特异性与DNase-seq相当，优于FAIRE-seq。</li>
</ul>
<h3 id="整合分析"><a href="#整合分析" class="headerlink" title="整合分析"></a>整合分析</h3><ul>
<li>由于开放染色质是大多数TF结合的先决条件，因此<code>ATAC-seq峰通常与TF ChIP-seq峰重叠，但通常更宽</code>。因此，<code>TF ChIP-seq和ATAC-seq可以在同一实验系统中相互验证</code>彼此的质量和可靠性。 </li>
<li>ATAC-seq与 histone marker ChIP-seq集成，发现与活跃染色质标 H3K4me3，H3K4me1，H3K27ac等正相关，与不活跃的染色质标记 H3K27me3 负相关。 <code>？</code></li>
<li><code>ATAC-seq+RNA-seq</code>： 一般RNA-seq会优先于ATAC-seq先测，但<code>差异基因富集的基因通路只是一种相关性</code>。要分析出其中谁调控目的基因，可通过<code>ATAC-seq做motif分析</code>，<code>寻找潜在的调控因子</code>，然后再后续的<code>实验验证</code>或者<code>chip-seq验证</code>。/ 看ATAC上丰度高的DNA序列区域是否对应转录本表达量增加，找到对应转录本相关基因的上游调控序列，整体分析转录。对基因功能分析，结合实验表型，推测表达调控-表达-功能-表型。<br><img src="https://img-blog.csdnimg.cn/4a3016bfa5c74598a5b7d660fe1cfe84.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq+HiC</code>： 对于一些想了解<code>染色质高级结构对生命行为的作用</code>的时候，通常会需要用到ATAC-seq等技术，因为<code>Hi-C分析</code>得到高级结构compartmentA/B、TADs、Loops等信息，通常只是相关性，但通过ATAC-seq，可以<code>获得promoter、enhancer等信息</code>，更能知道高级结构是如何影响启动子、增强子从而影响基因表达的。<br><img src="https://img-blog.csdnimg.cn/e38ba32597a14ca7a5d4d6b2f36c1b73.png" alt="在这里插入图片描述"></li>
<li><code>ATAC-seq+组蛋白修饰</code>： ATAC-seq预测一个位点的开放程度以及可能有某种转录因子的结合，但<code>不知道</code>该因子是<code>促进</code>基因表达，还是<code>抑制</code>，只通过<code>基因层面鉴定</code>来判断转录因子对基因的促进或者是不够的，它只是一种<code>相关性</code>。而这时候如果能提供像<code>H3K27ac这类激活型组蛋白</code>、<code>H3K27me3这类抑制型组蛋白</code>将能使数据结果可信。国内较早研究iPSCs的学者如裴端卿的工作可以看到，在解析iPSCs重编程中的染色质可及性的时候，不仅用到ATAC-seq来描述细胞的身份转变，还<code>通过H3K27ac指征该区域的激活</code>。其中一篇还通过<code>调控成纤维细胞关键基因启动子区去乙酰化修饰</code>，达到了促进重编程的进程。<br><img src="https://img-blog.csdnimg.cn/abb3dc6c3bb0476985a9f1b2e77c4fcc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
<li><code>scATAC-seq+scRNA-seq</code>： 更前沿的技术一个细胞里同时进行RNA-seq和ATAC-seq，并且是单细胞水平的检测。SHARE-seq，能够实现在单细胞中同时高质量，高通量的检测基因表达和染色质可及性。该技术可以使用<code>染色质潜力算法</code>（chromatin potential），<code>用ATAC和RNA的差异来预测细胞的变化方向</code>。<code>相对于以往仅依赖于RNA的预测手段，染色质潜力能够大大提前预测的时间</code>。<br><img src="https://img-blog.csdnimg.cn/df76c6e5f3184d58a00a1fa53a398cd5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
</ul>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/27374332/">ATAC-seq与ChIP联合分析</a><br>研究课题为人小细胞肺癌促进癌症扩散转移的背景机制。主要比较原发性和肝转移性的小细胞肺癌细胞之间的差异。利用ATAC-seq，发现NFI家族转录因子富集在具有差异的染色质开放位点中，预示着NFI家族转录因子在调控肿瘤细胞转移中扮演着重要角色。在染色质高开放性位点区域伴随着Nfib拷贝数量增多，且Nfib在侵袭性原发性肿瘤和转移性肿瘤内高表达，Nfib表现出维持染色质及远端调控区域开放和促进神经基因表达的功能，说明了Nfib对促进癌细胞增殖和迁移具有重要的作用。</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/25679813/">motif分析转录因子结合蛋白</a>。对处于发育过程中的黑腹果蝇眼睛及其通过遗传诱导的肿瘤模型，利用ATAC-seq技术分析染色质开放区域已在活体中发现驱动肿瘤发育的转录因子及调控区域。然后对找到的染色质活性开放区域进行转录因子预测分析，发现了两个关键的转录因子，猜测它们可能与染色质图谱的变化有关。通过对候选的一个转录因子进行功能验证和靶标分析，发现其为肿瘤转录组中的一个关键的转录调控因子。</li>
</ul>
<hr>
<ul>
<li><strong>思考</strong>：</li>
<li>ATAC-Seq与ChIP-Seq的异同在哪里？</li>
<li>用和ChIP-Seq一样的参数Call peaks正确吗？</li>
<li>得到peaks后怎么进行质量评估？</li>
<li>样本内的重复怎么处理？</li>
<li>样本间的差异怎么分析？</li>
<li>怎么对peaks进行功能注释分析？</li>
<li>如何找motif?</li>
<li>ATAC-Seq和ChIP-Seq和RNA-Seq的整合分析怎么做？<br><img src="https://img-blog.csdnimg.cn/0920f7a6c41148b2825b189e709a5fbc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="ATAC-seq/CHIP-seq流程"></li>
</ul>
<p>待学习内容：</p>
<ol>
<li><p>ATAC-seq data analysis: from FASTQ to peaks</p>
</li>
<li><p>ATAC-seq Data Standards and Processing Pipeline in ENCODE</p>
</li>
<li><p>ATAC-seq数据分析实战</p>
</li>
<li><p>Harvard FAS Informatics - ATAC-seq Guidelines</p>
</li>
<li><p>Harvard Chan Bioinformatics Core (HBC)深度NGS数据分析课程，第5部分关于ChIP-Seq，整体思路和绝大部分分析方法适合ATAC-seq。</p>
<p>HBC深度NGS数据分析课程：<br><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course</a><br>第五部分ChIP-Seq课程：</p>
<p><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a></p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">参考文献：</span><br><span class="line">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1633159169&amp;ver=3349&amp;signature=*MwqLr1J-qdZoNiKVxF32vEKh5-6TRystOXAJ3UOZ3Pl8XTBIB8Ly95IJM0L2EzGFVWOM-TdKnuhnb0gfMfsUTfahWJ5i3hcM2TcR9UDFSVWuyYw7CONzMjsMaYQG2Ca&amp;new=1</span><br><span class="line">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1633159169&amp;ver=3349&amp;signature=rtYw5NsC62rUZvctQsUg3*w*NFFDdOHgSMu0pcp0HTQdCyqxpgril8yx7GWlJaID*lfd2HRLUWs59zuszSEFeean0jEwdRs4PzYy*T5b7nSpZRWqCs4SHcEQ2jyjDtwQ&amp;new=1</span><br></pre></td></tr></table></figure>

<hr>
<blockquote>
<p>1：ATAC-seq的背景介绍以及与ChIP-Seq的异同<br>2：原始数据的质控、比对和过滤<br>3：用MACS2软件call peaks<br>4：对ATAC-Seq/ChIP-seq的质量评估（一）——phantompeakqualtools<br>5：对ATAC-Seq/ChIP-seq的质量评估（二）——ChIPQC<br>6：重复样本的处理——IDR<br>7：用Y叔的ChIPseeker做功能注释<br>8：用网页版工具进行motif分析<br>9：差异peaks分析——DiffBind<br>10：ATAC-Seq、ChIP-Seq、RNA-Seq整合分析</p>
</blockquote>
<h3 id="简洁版ATACseq分析流程"><a href="#简洁版ATACseq分析流程" class="headerlink" title="简洁版ATACseq分析流程"></a>简洁版ATACseq分析流程</h3><ul>
<li>数据预处理<ul>
<li>（1）比对前质量控制FastQC</li>
<li>（2）原始序列比对 </li>
<li>（3）比对后处理和质量控制：去除重复序列，细胞器序列<ul>
<li>序列比对后，Picard/SAMtools收集unique mapping reads/rate，duplicated rate百分比和片段大小分布</li>
<li>成功的ATACseq实验应生成<code>片段大小分布图</code>（从<code>bam文件</code>得到），具有递减性和周期性的峰，对应于<code>无核小体区域</code>（NFR）（&lt;100bp）和<code>单核双核和三核</code>小体（200，400，600bp）。大多数Linker DNA大小介于10-80bp间，故大多数片段都会是<code>小于100bp</code>。每个Nucleosome的DNA大小为180bp，加上两边插入的冗余，会得到大约<code>200bp</code>长度的mono-nucleosome的DNA。</li>
<li><code>无核小体区域的片段应该在基因的转录起始位点（TSS）周围富集</code>，而<code>核小体结合区域片段TSS处形成低谷</code>，TSS周围<code>侧翼区域稍微富集</code>。<code>ATACseqQC评估</code>。</li>
</ul>
</li>
</ul>
</li>
<li>Peak-calling：从比对得到的bam文件找出reads覆盖区，就是峰出现的位置。</li>
<li>高级分析<ul>
<li>（1）peak 差异分析：寻找不同分组差异peaks</li>
<li>（2）peak注释：峰的注释可将染色质的可及性与基因调控联系。通常峰会被注释到最接近的基因或调控原件。获得最接近的基因列表后，使用GOKEGGReactome等数据库功能富集分析</li>
<li>（3）motif富集分析：得到每个peak region里motif的位置和频率，再和随机背景或其他条件比较，可做motif富集分析</li>
<li>（4）footprint分析 ：ATACseq中footprint指一个TF结合在DNA上，组织Tn5切割，在染色质开放区域留下一个相对缺失的位置。而TF周围的组蛋白因为TF造成空间的推挤反而形成开放度较高区域。</li>
</ul>
</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>ATAC-seq</category>
      </categories>
      <tags>
        <tag>ATAC-seq</tag>
      </tags>
  </entry>
</search>
